[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Blog documenting the tinkerings and helpful tips I have accumulated in the area of data science and machine learning, with some flavor of chemical science sprinkled sporadically.\nThe posts are meant to be a reference for my future self or whoever wishes to start in the data science and ML space."
  },
  {
    "objectID": "posts/2021-04-08-matplotlib-equal-aspect.html",
    "href": "posts/2021-04-08-matplotlib-equal-aspect.html",
    "title": "Making equal spaces parity plots using Matplotlib",
    "section": "",
    "text": "import os\nimport matplotlib.pyplot as plt\nimport numpy as np \n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 22,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)\n\n\n# Make dataset\nX = np.linspace(0,5,200)\nY = 1.3*X + np.random.normal(0.01, size=X.shape)\n\nQuick plotting\n\nfig, ax = plt.subplots(1,1, figsize=(8,8))\nax.scatter(X, Y)\nax.set_xlabel('X')\nax.set_ylabel('Y')\n\nText(0, 0.5, 'Y')\n\n\n\n\n\n\n\n\n\nMake plots with equal aspect ratio and axes\n\nfig, ax = plt.subplots(1,1, figsize=(8,8))\nax.scatter(X, Y, label='data')\n\n# Find limits for each axes \nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n       ]\n\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='parity')\nax.set_aspect('equal')\n\nax.set_xlim(lims)\nax.set_ylim(lims)\n\nax.set_xlabel('X')\nax.set_ylabel('Y')\n\nhandles, labels = ax.get_legend_handles_labels()\nprint(labels)\nax.legend(handles=handles, labels=labels, title=\"Legend\")\n\n['parity', 'data']\n\n\n\n\n\n\n\n\n\nSlightly fancier output with parity and linear fit plots\n\nfig, ax = plt.subplots(1,1, figsize=(8,8))\nax.scatter(X, Y, alpha=0.6, label='data')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n\n# Linear fit line \nreg = np.polyfit(X, Y, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='linear fit')\n\n# Parity plot \nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='parity')\n#ax.set_aspect('equal')\n        \nax.set_xlabel('X')\nax.set_ylabel('Y')\n\nhandles, labels = ax.get_legend_handles_labels()\nprint(labels)\n\n# Put a legend to the right of the current axis\nax.legend(handles=handles, labels=labels, title=\"Legend\", loc='center left', bbox_to_anchor=(1, 0.5))\n\n['linear fit', 'parity', 'data']"
  },
  {
    "objectID": "posts/2024-05-1-Language_Models.html",
    "href": "posts/2024-05-1-Language_Models.html",
    "title": "Large Language Models",
    "section": "",
    "text": "How LLMs benefit modeling processes: 1. Low data modeling 2. Fewer (one model) to predict multiple end points across different modalities (sentiment, regression, classification, text completion) 3. Rich embeddings generated for unstructured data sets - useful for recommenders | similarity search 4. Quick prototyping - LLMs based workflow can increase the pace at which we code, search, train models\nGeneral areas:\n1) Predictive modeling 2) Automation and novel human-machine interaction 3) Knowledge extraction and translation 4) Education (lowering entry barrier) ## Applications ### Chemistry - [[Autonomous chemical research with large language models]] - Chemcrow - [Is GPT-3 all you need?](https://chemrxiv.org/engage/chemrxiv/article-details/63eb5a669da0bc6b33e97a35](https://chemrxiv.org/engage/chemrxiv/article-details/63eb5a669da0bc6b33e97a35)Nature Paper - Catalyst Property Prediction with CatBERTa: Unveiling Feature Exploration Strategies through Large Language Models * Chemistry reaction entity extraction * [[Multi-modal molecule structure–text model for text-based retrieval and editing]] * Are large language models superhuman chemists?"
  },
  {
    "objectID": "posts/2024-05-1-Language_Models.html#prompt-engineering",
    "href": "posts/2024-05-1-Language_Models.html#prompt-engineering",
    "title": "Large Language Models",
    "section": "Prompt engineering",
    "text": "Prompt engineering\nPrompt blog: https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#external-apis\nPrompts are tiny programs Inspiration &gt; Prompt engineering is a subset of software engineering\nPromptBase : https://github.com/microsoft/promptbase &gt;&gt; Medicine related prompts\nOpenAI Prompt Engineering : https://platform.openai.com/docs/guides/prompt-engineering/prompt-engineering"
  },
  {
    "objectID": "posts/2024-05-1-Language_Models.html#chains",
    "href": "posts/2024-05-1-Language_Models.html#chains",
    "title": "Large Language Models",
    "section": "Chains",
    "text": "Chains\nPre-determined set of steps to undertake a task This is first step in creating a platform\n\nRAGs\nRAG for LLMs - A Survey : https://arxiv.org/abs/2312.10997\nDeconstructing RAG https://twitter.com/RLanceMartin/status/1727019896394207624\nIt can be hard to follow all of the RAG strategies that have come out over the past months.\nI created a few guides to organize them into major themes and show how to build multi-modal / semi-structured RAG on complex docs (w/ images, tables).\nHere’s a few of the major themes:\n\nQuery Transformations - User questions may not be well-posed / -worded for retrieval. There’s a host of methods that re-write and / or expand (fan-out into multiple sub-questions) questions that maximize the chance of retrieving relevant documents. See blog: https://blog.langchain.dev/query-transformations/\nRouting - Queries may need to be routed to different data sources depending on what is being asked. Recent blog reviewing OpenAI’s RAG strategies provides some guidance on question routing: https://blog.langchain.dev/applying-openai-rag/\nQuery Construction - To access structured data, natural language needs to be converted into specific a query syntax. Various approaches can access data in SQL, SQL w/ semantic columns (pgvector), graph DBs, vectorDB w/ metadata filters, etc. See blog: https://blog.langchain.dev/query-construction/\nIndex Building - One of the most useful tricks I’ve been using is multi-representation indexing: decouple what you index for retrieval (e.g., table or image summary) from what you pass to the llm for answer synthesis (e.g., the raw image, a table). See blog:\n\nhttps://blog.langchain.dev/semi-structured-multi-modal-rag/\n4a. Multi-Modal -\nThis cookbook show how I used this approach for RAG on a substack (\n@jaminball\n’s Clouded Judgement) that has many images of densely packed tables, graphs:\nhttps://github.com/langchain-ai/langchain/blob/master/cookbook/Multi_modal_RAG.ipynb\n4b. Semi-Structured -\nThis cookbook show how I used this for RAG on a docs (papers) with tables, which can be split using naive RAG text-splitting (that does not explicitly preserve them):\nhttps://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb\n\nPost-processing - Given retrieved documents, there are various way to rank / filter them. Recent blog reviewing OpenAI’s RAG strategies provides a few ideas on applying post-processing: https://blog.langchain.dev/applying-openai-rag/\n\nSelf-querying to work with meta data in the document chunks :https://python.langchain.com/docs/modules/data_connection/retrievers/self_query\nKnowledge graph data : https://www.youtube.com/watch?v=nPG_jKrSpi0&t=11s\nOpenAI recipe for graphDB implementation : https://github.com/openai/openai-cookbook/blob/main/examples/RAG_with_graph_db.ipynb"
  },
  {
    "objectID": "posts/2024-05-1-Language_Models.html#agents",
    "href": "posts/2024-05-1-Language_Models.html#agents",
    "title": "Large Language Models",
    "section": "[[Agents]]",
    "text": "[[Agents]]\nHitchhiker’s Guide from Chain-of-Thought reasoning to Language Agents: https://arxiv.org/pdf/2311.11797.pdf\nNon-structured ways to do task by giving central model access to tools - Different orchestration platforms : 1) https://github.com/guidance-ai/guidance 2) Semantic kernel 3) Langchain 4) Autogen\nMedium open solution from. companies : crew.ai\nAgent on MineCraft : Voyager / MineDojo\nAgents with API : Gorilla\nAutoGen with Semantic Kernel : https://github.com/microsoft/semantic-kernel/blob/sk-autogen/python/notebooks/12-sk-autogen-agents.ipynb\n\nAutoGen vs Semantic Kernel :\nAutogen is a framework for letting multiple agents collaborate with each other to complete a request. Semantic Kernel, on the other hand, is an SDK that helps you give a single agent a set of tools (via plugins). Because of this, we believe both projects complement each other. To make a team of agents in Autogen productive, you’ll ultimately want to give them plugins so they can complete real work. This is when you’d want to use the two projects together.\nPut more simply…\n– Need agents to collaborate with each other? Use agents.\n– Need agents to do work with tools (i.e., plugins)? Use Semantic Kernel.\n– Need agents to collaborate with each other with tools? Use both!\nHow does LLM use the function/tool ?\nWe pass the parameters in term of json or protobuf with function name, description, params\nThe LLM doesnt call the function for us - it JUST tells us with the known information what would be the function we NEED to call Not every time we would get a json output so we need safeguards for it.\nfunctions and function_calls are accounted in the tokens\nGorilla : https://gorilla.cs.berkeley.edu/\nSolutions from external companies : https://www.lindy.ai/ crew.ai\nLLM powered autonomous agents :\nhttps://lilianweng.github.io/posts/2023-06-23-agent/?utm_source=pocket_saves\nhttps://peterroelants.github.io/posts/react-repl-agent/\nPython REPL agent:https://python.langchain.com/docs/integrations/toolkits/python\nRobust MRKL:\nhttps://github.com/whitead/robust-mrkl/tree/main\nMicrosoft Autogen : https://github.com/microsoft/semantic-kernel/blob/sk-autogen/python/notebooks/12-sk-autogen-agents.ipynb https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat/#diverse-applications-implemented-with-autogen\nOpenAI’s Assistant API vs Langchain Agent : https://blog.langchain.dev/openais-bet-on-a-cognitive-architecture/"
  },
  {
    "objectID": "posts/2024-05-1-Language_Models.html#evaluations",
    "href": "posts/2024-05-1-Language_Models.html#evaluations",
    "title": "Large Language Models",
    "section": "Evaluations",
    "text": "Evaluations\n\nRegas\nPromptFlow\nStaRK from James Zou lab: https://arxiv.org/abs/2404.13207\n\nAndrej Karpathy : https://nicholas.carlini.com/writing/2024/my-benchmark-for-large-language-models.html"
  },
  {
    "objectID": "posts/2024-05-1-Language_Models.html#training",
    "href": "posts/2024-05-1-Language_Models.html#training",
    "title": "Large Language Models",
    "section": "Training",
    "text": "Training\n\nRLHF\n[[DPO]]"
  },
  {
    "objectID": "posts/data/fingerprints.html",
    "href": "posts/data/fingerprints.html",
    "title": "Fingerprints",
    "section": "",
    "text": "import os \nimport pandas as pd\nimport numpy as np \nimport tqdm.notebook as tqdm\n# RDkit imports\nimport rdkit\nfrom rdkit import Chem\nfrom rdkit.Chem import Draw\nfrom rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\n\nprint(rdkit.__version__)\n\nChem.WrapLogs()\nlg = rdkit.RDLogger.logger() \nlg.setLevel(rdkit.RDLogger.CRITICAL)\n\n2021.09.2\nqm9_data_csv = pd.read_csv(os.path.join('small_molecule_data/qm9.csv'))\nqm9_data_csv.head(3)\n\n\n\n\n\n\n\n\nsmiles\nmu\nalpha\nhomo\nlumo\ngap\nr2\nzpve\ncv\nu0\nu298\nh298\ng298\n\n\n\n\n0\nC\n0.0000\n13.21\n-0.3877\n0.1171\n0.5048\n35.3641\n0.044749\n6.469\n-40.478930\n-40.476062\n-40.475117\n-40.498597\n\n\n1\nN\n1.6256\n9.46\n-0.2570\n0.0829\n0.3399\n26.1563\n0.034358\n6.316\n-56.525887\n-56.523026\n-56.522082\n-56.544961\n\n\n2\nO\n1.8511\n6.31\n-0.2928\n0.0687\n0.3615\n19.0002\n0.021375\n6.002\n-76.404702\n-76.401867\n-76.400922\n-76.422349\nqm9_data_csv.shape\n\n(133885, 13)\nThe QM9 dataset from the MoleculeNet: A Benchmark for Molecular Machine Learning paper, consisting of about 130,000 molecules with multiple regression targets.\nEach molecule includes complete spatial information for the single low energy conformation of the atoms in the molecule.\nMore information on each descriptor here\nmol_temp = qm9_data_csv.iloc[125559]\nmol_temp\n\nsmiles    Cc1nnc2n1cc[nH]2\nmu                  5.8215\nalpha                72.81\nhomo               -0.2062\nlumo                0.0085\ngap                 0.2147\nr2                995.2925\nzpve              0.115329\ncv                  27.504\nu0             -413.018354\nu298           -413.011142\nh298           -413.010198\ng298           -413.049831\nName: 125559, dtype: object\nmol_obj = Chem.MolFromSmiles(mol_temp['smiles'])\nmol_obj\n# To output x y z of the molecule \nprint(Chem.MolToMolBlock(mol_obj))\n\n\n     RDKit          2D\n\n  9 10  0  0  0  0  0  0  0  0999 V2000\n    1.6078    3.5952    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n    0.3943    2.7135    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n   -1.0323    3.1771    0.0000 N   0  0  0  0  0  0  0  0  0  0  0  0\n   -1.9140    1.9635    0.0000 N   0  0  0  0  0  0  0  0  0  0  0  0\n   -1.0323    0.7500    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n    0.3943    1.2135    0.0000 N   0  0  0  0  0  0  0  0  0  0  0  0\n    1.2760    0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n    0.3943   -1.2135    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n   -1.0323   -0.7500    0.0000 N   0  0  0  0  0  0  0  0  0  0  0  0\n  1  2  1  0\n  2  3  2  0\n  3  4  1  0\n  4  5  2  0\n  5  6  1  0\n  6  7  1  0\n  7  8  2  0\n  8  9  1  0\n  6  2  1  0\n  9  5  1  0\nM  END\nTake a small sample from QM9 dataset\nQM9_df_smol = qm9_data_csv.sample(10).reset_index(drop=True)\nQM9_df_smol.head(2)\n\n\n\n\n\n\n\n\nsmiles\nmu\nalpha\nhomo\nlumo\ngap\nr2\nzpve\ncv\nu0\nu298\nh298\ng298\n\n\n\n\n0\nCC(C#C)C1CNC1=O\n3.8673\n78.47\n-0.2445\n0.0327\n0.2772\n1256.9197\n0.145972\n34.328\n-401.936628\n-401.927155\n-401.926211\n-401.971364\n\n\n1\nNC1=NC2CC2O1\n1.5272\n54.01\n-0.2181\n0.0534\n0.2715\n615.3852\n0.104048\n22.139\n-340.637231\n-340.631628\n-340.630684\n-340.666236\nQM9_df_smol.shape\n\n(10, 13)\nPandasTools module helps add mol molecule objects from RDKit as per the SMILES in the dataframe\nfrom rdkit.Chem import PandasTools\nPandasTools.AddMoleculeColumnToFrame(QM9_df_smol, smilesCol='smiles')\nCheck the new ROMol columns being appended in the dataframe\nQM9_df_smol.columns\n\nIndex(['smiles', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve', 'cv',\n       'u0', 'u298', 'h298', 'g298', 'ROMol'],\n      dtype='object')\nQM9_df_smol['ROMol'][0]\nVisualize the dataframe, add properties of interest at the bottom, you can add index too if need\nPandasTools.FrameToGridImage(QM9_df_smol, legendsCol='gap', molsPerRow=3, subImgSize=(200,200))"
  },
  {
    "objectID": "posts/data/fingerprints.html#fingerprints",
    "href": "posts/data/fingerprints.html#fingerprints",
    "title": "Fingerprints",
    "section": "Fingerprints",
    "text": "Fingerprints\nCompress molecules into vectors for mathetical operations and comparisons. First we will look at MorganFingerprint method. For this method we have to define the radius and the size of the vector being used. More information on Morgan Fingerprints can be read at this blogpost\n\nNice Review on this matter from Peter Willet\nPresentation by Gregory Landrum (creator of RDkit) on Fingerprints\nOfficial Documentation on Fingerprints in RDkit\n\n\n# Fingerprints\nfrom rdkit.Chem import AllChem\n\n\n_radius = 2\n_nBits = 2 ** 10\nECFP6 = [AllChem.GetMorganFingerprint(m, radius) for m in QM9_df_smol['ROMol']]\n\n\nlen(ECFP6)\n\n\nTypes of fingerprints to consider:\n\nDescriptor based fingerprints - more information here\nCount or binary-based fingerprints\n2.1. Circular Fingerprints (Morgan) - Extended Connectivity (ECFP)\n2.2. Atom pair\n2.3. Torsion\n2.4. MACCS Keys\n2.5. RDkit\nData-driven fingerprints\n\nfps1 = [Chem.RDKFingerprint(x, fpSize=1024, minPath=1, maxPath=4) for x in suppl]\nfps2 = [Chem.GetHashedMorganFingerprint(x, radius=2, nBits=1024) for x in suppl]\nfps3 = [Chem.GetMorganFingerprint(x, radius=2, useCounts= True) for x in suppl]\nfps4 = [Pairs.GetAtomPairFingerprintAsIntVect(x) for x in suppl]\narr = np.zeros((4,1024), dtype = np.int8)\nfor i in range(0,len(suppl)):\nDataStructs.ConvertToNumpyArray(fps2[i], arr[i])\nprint(arr)"
  },
  {
    "objectID": "posts/data/fingerprints.html#count-or-binary-fingerprint",
    "href": "posts/data/fingerprints.html#count-or-binary-fingerprint",
    "title": "Fingerprints",
    "section": "2. Count or binary fingerprint",
    "text": "2. Count or binary fingerprint\n\nfrom rdkit.Chem import AllChem\n\n\nfp = AllChem.GetMorganFingerprintAsBitVect(mol_obj, _radius, nBits= _nBits)\nfp_array = [int(x) for x in fp.ToBitString()]\n\nPairs.GetHashedAtomPairFingerprint GetMorganFingerprintAsBitVect GetHashedMorganFingerprint\n\nfrom rdkit.Chem.AtomPairs import Pairs, Torsions\nfpvect1 = Pairs.GetHashedAtomPairFingerprint(mol_obj)\nfpvect2 = Pairs.GetAtomPairFingerprint(mol_obj)\nfp1 = np.zeros((1,))\nfp2 = np.zeros((1,))\n#DataStructs.ConvertToNumpyArray(fp_vect, fp) \n#print(type(fp))\n\n\nDataStructs.ConvertToNumpyArray(fpvect1, fp1) \n\n\nDataStructs.ConvertToNumpyArray(fpvect2, fp2) \n\n\nfp1.shape\n\n\nfp2.shape\n\n\nfrom rdkit.Chem.AtomPairs import Pairs, Torsions\nfrom rdkit import Chem, DataStructs\nfpvect1 = AllChem.GetHashedMorganFingerprint(mol_obj, 2, nBits= 1024)\nfpvect2 = AllChem.GetMorganFingerprint(mol_obj, 2)\nfp1 = np.zeros((1,))\nfp2 = np.zeros((1,))\nDataStructs.ConvertToNumpyArray(fpvect1, fp1) \nDataStructs.ConvertToNumpyArray(fpvect2, fp2) \n\n\nfrom rdkit import Chem, DataStructs\nfrom rdkit.Chem import MACCSkeys\nfrom rdkit.Chem.AtomPairs import Pairs, Torsions\n\ndef get_fingerprint(smiles: str, radius: int = 2, num_bits: int = 2048, use_counts: bool = False, type_fp: str = 'Morgan') -&gt; np.ndarray:\n    \"\"\"\n    Generates a morgan fingerprint for a smiles string.\n\n    :param smiles: A smiles string for a molecule.\n    :param radius: The radius of the fingerprint.\n    :param num_bits: The number of bits to use in the fingerprint.\n    :param use_counts: Whether to use counts or just a bit vector for the fingerprint\n    :return: A 1-D numpy array containing the morgan fingerprint.\n    \"\"\"\n    if type(smiles) == str:\n        mol = Chem.MolFromSmiles(smiles)\n    else:\n        mol = smiles\n    \n    if type_fp == 'Morgan': \n        if use_counts:\n            fp_vect = AllChem.GetHashedMorganFingerprint(mol, radius, nBits=num_bits)\n        else:\n            fp_vect = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n    \n    if type_fp == 'MACCS': \n        fp_vect = MACCSkeys.GenMACCSKeys(mol)\n        \n    if type_fp == 'RDkit':\n        Chem.RDKFingerprint(x)\n        \n    fp = np.zeros((1,))\n    DataStructs.ConvertToNumpyArray(fp_vect, fp)\n\n    return fp"
  },
  {
    "objectID": "posts/data/fingerprints.html#similarity",
    "href": "posts/data/fingerprints.html#similarity",
    "title": "Fingerprints",
    "section": "Similarity",
    "text": "Similarity\nRDKit provides tools for different kinds of similarity search, including Tanimoto, Dice, Cosine, Sokal, Russel… and more. Tanimoto is a very widely use similarity search metric because it incorporates substructure matching. Here is an example\n\nref_mol = QM9_df_smol.iloc[3]['ROMol']\n\n\nref_mol\n\n\n# Generate finger print based representation for that molecule \nref_ECFP4_fps = AllChem.GetMorganFingerprintAsBitVect(ref_mol, radius= _radius, nBits=_nBits)\n\n\nQM9_smol_ECFP4_fps = [AllChem.GetMorganFingerprintAsBitVect(x, _radius, _nBits) for x in QM9_df_smol['ROMol']]\n\n\nfrom rdkit import DataStructs\nsimilarity_efcp4 = [DataStructs.FingerprintSimilarity(ref_ECFP4_fps, x) for x in QM9_smol_ECFP4_fps]\n\n\nQM9_df_smol = QM9_df_smol.sort_values(['Tanimoto_Similarity (ECFP4)'], ascending=False)\nPandasTools.FrameToGridImage(QM9_df_smol, legendsCol=\"Tanimoto_Similarity (ECFP4)\", molsPerRow=4)"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html",
    "href": "posts/2020-01-14-test-markdown-post.html",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "Jekyll requires blog post files to be named according to the following format:\nYEAR-MONTH-DAY-filename.md\nWhere YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files.\nThe first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above.\n\n\n\nYou can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule:\n\n\n\n\nHere’s a list:\n\nitem 1\nitem 2\n\nAnd a numbered list:\n\nitem 1\nitem 2\n\n\n\n\n\nThis is a quotation\n\n{% include alert.html text=“You can include alert boxes” %}\n…and…\n{% include info.html text=“You can include info boxes” %}\n\n\n\n\n\n\n\nYou can format text and code per usual\nGeneral preformatted text:\n# Do a thing\ndo_thing()\nPython code and output:\n# Prints '2'\nprint(1+1)\n2\nFormatting text as shell commands:\necho \"hello world\"\n./some_script.sh --option \"value\"\nwget https://example.com/cat_photo1.png\nFormatting text as YAML:\nkey: value\n- another_key: \"another value\"\n\n\n\n\n\n\nColumn 1\nColumn 2\n\n\n\n\nA thing\nAnother thing\n\n\n\n\n\n\n{% twitter https://twitter.com/jakevdp/status/1204765621767901185?s=20 %}"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#basic-setup",
    "href": "posts/2020-01-14-test-markdown-post.html#basic-setup",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "Jekyll requires blog post files to be named according to the following format:\nYEAR-MONTH-DAY-filename.md\nWhere YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files.\nThe first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above."
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#basic-formatting",
    "href": "posts/2020-01-14-test-markdown-post.html#basic-formatting",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule:"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#lists",
    "href": "posts/2020-01-14-test-markdown-post.html#lists",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "Here’s a list:\n\nitem 1\nitem 2\n\nAnd a numbered list:\n\nitem 1\nitem 2"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#boxes-and-stuff",
    "href": "posts/2020-01-14-test-markdown-post.html#boxes-and-stuff",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "This is a quotation\n\n{% include alert.html text=“You can include alert boxes” %}\n…and…\n{% include info.html text=“You can include info boxes” %}"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#code",
    "href": "posts/2020-01-14-test-markdown-post.html#code",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "You can format text and code per usual\nGeneral preformatted text:\n# Do a thing\ndo_thing()\nPython code and output:\n# Prints '2'\nprint(1+1)\n2\nFormatting text as shell commands:\necho \"hello world\"\n./some_script.sh --option \"value\"\nwget https://example.com/cat_photo1.png\nFormatting text as YAML:\nkey: value\n- another_key: \"another value\""
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#tables",
    "href": "posts/2020-01-14-test-markdown-post.html#tables",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "Column 1\nColumn 2\n\n\n\n\nA thing\nAnother thing"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#tweetcards",
    "href": "posts/2020-01-14-test-markdown-post.html#tweetcards",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "{% twitter https://twitter.com/jakevdp/status/1204765621767901185?s=20 %}"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html#footnotes",
    "href": "posts/2020-01-14-test-markdown-post.html#footnotes",
    "title": "An Example Markdown Post",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is the footnote.↩︎"
  },
  {
    "objectID": "posts/2020-04-22-activation_functions.html",
    "href": "posts/2020-04-22-activation_functions.html",
    "title": "Activation functions",
    "section": "",
    "text": "Function that activates the particular neuron or node if the value across a particular threshold. These functions add the necessary non-linearity in the ANNs. Each perceptron is, in reality (and traditionally), a logistic regression unit. When N units are stacked on top of each other we get a basic single layer perceptron which serves as the basis of Artificial neural network.\nClick here for Google’s ML glossary definition\nThere are different types of activation function and each has its benefits and faults. One of the consideration is the ease in evaluation of the gradient. It should be easy but also help in the final learning process by translating the necessary abstraction and non-linearity across the network. Some of the activation functions are primarily used to model the output of the ANN. Traditionally for a classification task, we would use a sigmoid activation function for a binary classification to predict a binary output (yes/no). In the case of multi-class classification that activation is replaced by softmax activation to estimate the ‘probability’ across different classes.\nimport numpy as np\nimport matplotlib.pyplot as plt\n%config InlineBackend.figure_format = 'retina'\nimport seaborn as sns\nsns.set_palette(\"deep\")"
  },
  {
    "objectID": "posts/2020-04-22-activation_functions.html#baseline-reference",
    "href": "posts/2020-04-22-activation_functions.html#baseline-reference",
    "title": "Activation functions",
    "section": "## Baseline reference",
    "text": "## Baseline reference\n\nz = np.linspace(-10,10,100)\n\n\nSigmoid activation function\n\ndef sigmoid(z):\n    return 1/(1+np.exp(-z))\n# derivative of Sigmoid Function\ndef dsigmoid(a):\n    return a*(1-a) # returns a derivative od sigmoid function if a=sigmoid then a'=a(1-a)\n\n\nplt.plot(z, sigmoid(z), label = r'$sigmoid$')\nplt.plot(z, dsigmoid(sigmoid(z)), label = r'$ \\frac{\\partial (sigmoid)}{\\partial z}$')\nplt.legend(fontsize = 12)\nplt.xlabel('z')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Pytorch autograd example\nimport torch\nx = torch.tensor(z, requires_grad=True)\nprint(x.requires_grad)\nb = torch.sigmoid(x)\n\nTrue\n\n\n\nx\n\ntensor([-10.0000,  -9.7980,  -9.5960,  -9.3939,  -9.1919,  -8.9899,  -8.7879,\n         -8.5859,  -8.3838,  -8.1818,  -7.9798,  -7.7778,  -7.5758,  -7.3737,\n         -7.1717,  -6.9697,  -6.7677,  -6.5657,  -6.3636,  -6.1616,  -5.9596,\n         -5.7576,  -5.5556,  -5.3535,  -5.1515,  -4.9495,  -4.7475,  -4.5455,\n         -4.3434,  -4.1414,  -3.9394,  -3.7374,  -3.5354,  -3.3333,  -3.1313,\n         -2.9293,  -2.7273,  -2.5253,  -2.3232,  -2.1212,  -1.9192,  -1.7172,\n         -1.5152,  -1.3131,  -1.1111,  -0.9091,  -0.7071,  -0.5051,  -0.3030,\n         -0.1010,   0.1010,   0.3030,   0.5051,   0.7071,   0.9091,   1.1111,\n          1.3131,   1.5152,   1.7172,   1.9192,   2.1212,   2.3232,   2.5253,\n          2.7273,   2.9293,   3.1313,   3.3333,   3.5354,   3.7374,   3.9394,\n          4.1414,   4.3434,   4.5455,   4.7475,   4.9495,   5.1515,   5.3535,\n          5.5556,   5.7576,   5.9596,   6.1616,   6.3636,   6.5657,   6.7677,\n          6.9697,   7.1717,   7.3737,   7.5758,   7.7778,   7.9798,   8.1818,\n          8.3838,   8.5859,   8.7879,   8.9899,   9.1919,   9.3939,   9.5960,\n          9.7980,  10.0000], dtype=torch.float64, requires_grad=True)\n\n\n\nb.backward(torch.ones(x.shape))\n\n\nx.grad\n\ntensor([4.5396e-05, 5.5558e-05, 6.7994e-05, 8.3213e-05, 1.0184e-04, 1.2463e-04,\n        1.5252e-04, 1.8666e-04, 2.2843e-04, 2.7954e-04, 3.4207e-04, 4.1859e-04,\n        5.1221e-04, 6.2673e-04, 7.6682e-04, 9.3817e-04, 1.1477e-03, 1.4039e-03,\n        1.7172e-03, 2.1000e-03, 2.5677e-03, 3.1389e-03, 3.8362e-03, 4.6869e-03,\n        5.7241e-03, 6.9876e-03, 8.5250e-03, 1.0394e-02, 1.2661e-02, 1.5407e-02,\n        1.8724e-02, 2.2721e-02, 2.7521e-02, 3.3259e-02, 4.0084e-02, 4.8151e-02,\n        5.7615e-02, 6.8615e-02, 8.1257e-02, 9.5592e-02, 1.1158e-01, 1.2906e-01,\n        1.4771e-01, 1.6703e-01, 1.8633e-01, 2.0471e-01, 2.2118e-01, 2.3471e-01,\n        2.4435e-01, 2.4936e-01, 2.4936e-01, 2.4435e-01, 2.3471e-01, 2.2118e-01,\n        2.0471e-01, 1.8633e-01, 1.6703e-01, 1.4771e-01, 1.2906e-01, 1.1158e-01,\n        9.5592e-02, 8.1257e-02, 6.8615e-02, 5.7615e-02, 4.8151e-02, 4.0084e-02,\n        3.3259e-02, 2.7521e-02, 2.2721e-02, 1.8724e-02, 1.5407e-02, 1.2661e-02,\n        1.0394e-02, 8.5250e-03, 6.9876e-03, 5.7241e-03, 4.6869e-03, 3.8362e-03,\n        3.1389e-03, 2.5677e-03, 2.1000e-03, 1.7172e-03, 1.4039e-03, 1.1477e-03,\n        9.3817e-04, 7.6682e-04, 6.2673e-04, 5.1221e-04, 4.1859e-04, 3.4207e-04,\n        2.7954e-04, 2.2843e-04, 1.8666e-04, 1.5252e-04, 1.2463e-04, 1.0184e-04,\n        8.3213e-05, 6.7994e-05, 5.5558e-05, 4.5396e-05], dtype=torch.float64)\n\n\n\nplt.plot(x.data.numpy(), b.data.numpy(), label = r'$sigmoid$')\nplt.plot(x.data.numpy(), x.grad.data.numpy(), label = r'$ \\frac{\\partial (sigmoid)}{\\partial z}$')\nplt.legend(fontsize = 12)\n\n\n\n\n\n\n\n\n\nnp.unique(np.round((x.grad.data.numpy() - dsigmoid(sigmoid(z))),4))\n\narray([0.])\n\n\n\n\nHyperbolic tangent activation function\n\ndef tanh(z):\n    return np.tanh(z)\n\n# derivative of tanh\ndef dtanh(a):\n    return 1-np.power(a,2)\n\n\nplt.plot(z, tanh(z),'b', label = 'tanh')\nplt.plot(z, dtanh(tanh(z)),'r', label=r'$ \\frac{dtanh}{dz}$')\nplt.legend(fontsize = 12)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nReLU (Rectified Linear Unit) Activation function\n\ndef ReLU(z):\n    return np.maximum(0,z)\n\n# derivative of ReLu\ndef dReLU(a):\n    return 1*(a&gt;0)\n\n\nplt.plot(z, ReLU(z),'b', label ='ReLU')\nplt.plot(z, dReLU(ReLU(z)),'r', label=r'$ \\frac{dReLU}{dz}$')\nplt.legend(fontsize = 12)\nplt.xlabel('z')\nplt.ylim(0,4)\nplt.xlim(-4,4)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nLeaky ReLU Activation function\n\ndef LeakyReLU(z):\n    return np.maximum(0.01*z,z)\n\n# derivative of ReLu\ndef dLeakyReLU(a):\n    return 0.01*(a&gt;0)\n\n\nplt.plot(z, LeakyReLU(z),'b', label = 'LeakyReLU')\nplt.plot(z, dLeakyReLU(LeakyReLU(z)),'r', label=r'$ \\frac{dLeakyReLU}{dz}$')\nplt.legend(fontsize = 12)\nplt.xlabel('z')\nplt.ylim(0,4)\nplt.xlim(-4,4)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nComparison of derivative for activation functions\n\nplt.plot(z, dsigmoid(sigmoid(z)),label = r'$ \\frac{dsigmoid}{dz}$' )\nplt.plot(z, dtanh(tanh(z)), label = r'$ \\frac{dtanh}{dz}$')\nplt.plot(z, dReLU(ReLU(z)), label=r'$ \\frac{dReLU}{dz}$')\nplt.plot(z, dLeakyReLU(LeakyReLU(z)), label=r'$ \\frac{dLeakyReLU}{dz}$')\nplt.legend(fontsize = 12)\nplt.xlabel('z')\nplt.title('Derivatives of activation functions')\nplt.show()"
  },
  {
    "objectID": "posts/2025-08-08-Resources_revisit.html",
    "href": "posts/2025-08-08-Resources_revisit.html",
    "title": "Resources I Keep Coming Back To",
    "section": "",
    "text": "Last update: August 2025"
  },
  {
    "objectID": "posts/2025-08-08-Resources_revisit.html#core-reading-viewing",
    "href": "posts/2025-08-08-Resources_revisit.html#core-reading-viewing",
    "title": "Resources I Keep Coming Back To",
    "section": "Core Reading & Viewing",
    "text": "Core Reading & Viewing\n\nNobel Lectures\n\nFrances Arnold – 2018 Chemistry Nobel — How evolution can be engineered.\nJennifer Doudna – 2020 Chemistry Nobel — The CRISPR story and why it matters.\n\n\n\nTalks\n\nAndrew Ng – How AI Could Empower Any Business — AI as systematic application, not magic.\n\n\n\nBooks\n\nThree Hour Chef — A manual for learning anything fast, disguised as a cookbook\nThinking, Fast and Slow\nStumbling on to Happiness\nLoonshots\nDemon Haunted World\n\nFooled by Randomness\nA Random Walk Down Wall Street\nThe Way to Love\nHouston, We Have a Narrative - Great book on how to improve scientific communication\n\nSapiens\n\n\n\nFavorite Blogs\n\nVenture Capital for Life Scientists\n\nStudying the Studies — Nice overview for understanding statistical studies and how they are reported in peer-reviews, complement this by How to Lie with Statistics\n\nThe AI Revolution – Wait But Why\n\nBiotech Platforms and Taste — Why “taste” matters in science."
  },
  {
    "objectID": "posts/2025-08-08-Resources_revisit.html#machine-learning-data-science-essentials",
    "href": "posts/2025-08-08-Resources_revisit.html#machine-learning-data-science-essentials",
    "title": "Resources I Keep Coming Back To",
    "section": "Machine Learning & Data Science Essentials",
    "text": "Machine Learning & Data Science Essentials\n80/20 rule: get the core idea, apply it, then fill gaps as you hit them.\n\nData science & ML\n\nData Science from Scratch\nIntroduction to Statistical Learning\nThe 100 Page ML Book — Key ML concepts boiled to the essentials.\n\n\n\nAI / ML\n\nHands-On Machine Learning with Scikit-Learn & TensorFlow (GitHub) — Still the best structured ML intro.\nPractical Deep Learning for Coders – fast.ai\n\n\n\nLLMs\n\nHands-on LLMs - Actionable lessons with practical math and algorithm background\n\n\n\nSeminal Papers\n\nWord2Vec — Words as vectors, meaning as geometry.\n\nAttention Is All You Need — The Transformer blueprint.\n\nBERT — Pretraining changes everything.\n\nReACT — LLMs that think and act."
  },
  {
    "objectID": "posts/2025-08-08-Resources_revisit.html#perspectives-reviews-commentaries",
    "href": "posts/2025-08-08-Resources_revisit.html#perspectives-reviews-commentaries",
    "title": "Resources I Keep Coming Back To",
    "section": "Perspectives, Reviews & Commentaries",
    "text": "Perspectives, Reviews & Commentaries\n\nArea Reviews\n\nA Survey of Deep Learning for Scientific Discovery — How deep learning is reshaping science.\n\nThe Discipline of Machine Learning — ML’s core principles from one of its founders.\n\n\n\nBest Practices & Pitfalls\n\nHow to Avoid Machine Learning Pitfalls — The mistakes researchers keep making.\n\nScikit-learn – Common Pitfalls — Debugging bad ML habits.\n\nThree Pitfalls to Avoid in Machine Learning — Shortlist of costly errors.\n\nA Few Useful Things to Know About Machine Learning — Timeless, hard-earned lessons.\n\n\n\nCommentaries\n\nStatistical Modeling: The Two Cultures — Why stats and ML often talk past each other.\n\nThe Hardware Lottery — How progress gets stuck on the wrong tools.\n\nWhy Is AI Harder Than We Think? — The gap between perception and reality.\n\n\n\nIn Chemical Sciences\n\nMachine Learning for Materials Scientists – Best Practices — What works (and what doesn’t) in materials ML.\n\nMachine Learning in Synthetic Chemistry — Principles and promising directions.\n\n\n\nGraph Networks\n\nGraph Networks: Relational Inductive Biases — The foundations of graph ML.\n\nHow to Get Started with Graph Machine Learning — Beginner’s map to the field.\n\nDemystifying Graph Deep Learning — Making graphs intuitive."
  },
  {
    "objectID": "posts/2025-08-08-Resources_revisit.html#courses-worth-finishing",
    "href": "posts/2025-08-08-Resources_revisit.html#courses-worth-finishing",
    "title": "Resources I Keep Coming Back To",
    "section": "Courses Worth Finishing",
    "text": "Courses Worth Finishing\n\nMachine Learning\n\nMIT Intro to Deep Learning\n\nGoogle ML Crash Course — Quick, pragmatic entry point\nStanford CS231n — Computer vision’s modern foundation.\n\nNYU PyTorch Deep Learning — Great for PyTorch fluency\n\n\n\nData Science & Computation\n\nMIT Computational Thinking\n\nHarvard CS109 Data Science"
  },
  {
    "objectID": "posts/2025-08-08-Resources_revisit.html#python-code-resources",
    "href": "posts/2025-08-08-Resources_revisit.html#python-code-resources",
    "title": "Resources I Keep Coming Back To",
    "section": "Python code resources",
    "text": "Python code resources\n\nLearning\n\nAutomate the Boring Stuff — Coding utility from day one.\n\nPython Data Science Handbook — Essential Pandas, NumPy, Matplotlib.\n\nVisual Guide to NumPy — Arrays explained visually.\n\n\n\nProjects & Practice\n\nProject Euler — Math puzzles that teach coding fluency.\n\nCalmcode — Bite-sized Python tips.\n\n\n\nWriting Better Code\n\nCorey Schafer – Tips — Pragmatic code hygiene."
  },
  {
    "objectID": "posts/2025-08-08-Resources_revisit.html#data-viz-stats",
    "href": "posts/2025-08-08-Resources_revisit.html#data-viz-stats",
    "title": "Resources I Keep Coming Back To",
    "section": "Data, Viz & Stats",
    "text": "Data, Viz & Stats\n\nStats\n\nThink Stats — Stats for hackers.\n\nTelling Stories with Data — Numbers need a plot.\n\n\n\nVisualization\n\nFundamentals of Data Visualization — Clear thinking via clear charts.\n\nPython Graph Gallery — Examples by type."
  },
  {
    "objectID": "posts/2025-08-08-Resources_revisit.html#videos-lecture-series",
    "href": "posts/2025-08-08-Resources_revisit.html#videos-lecture-series",
    "title": "Resources I Keep Coming Back To",
    "section": "Videos & Lecture Series",
    "text": "Videos & Lecture Series\n\nScience & AI\n\nMedicinal Chemistry Lecture Series\nMIT Deep Learning Series\nAndrej Karpathy’s Lectures — Deep learning taught by a leading industry expert\n3Blue1Brown — Beautiful videos on foundational ML/DS concepts\n\n\n\nConcept Explainers\n\nStatQuest — Stats explained like you’re five."
  },
  {
    "objectID": "posts/2025-08-08-Resources_revisit.html#blogs-writing",
    "href": "posts/2025-08-08-Resources_revisit.html#blogs-writing",
    "title": "Resources I Keep Coming Back To",
    "section": "Blogs & Writing",
    "text": "Blogs & Writing\n\nPaul Graham Essays — Thinking about thinking.\n\nFarnam Street — Tools for better decisions.\n\nWait But Why — Long-form deep dives."
  },
  {
    "objectID": "posts/2025-08-08-Resources_revisit.html#good-articles-that-focus-on-better-writing",
    "href": "posts/2025-08-08-Resources_revisit.html#good-articles-that-focus-on-better-writing",
    "title": "Resources I Keep Coming Back To",
    "section": "Good articles that focus on better writing",
    "text": "Good articles that focus on better writing\n\nPaul Graham – Writing Usefully\n\nDraft No. 4 — John McPhee on the architecture of writing\nThis Is Your Mind on Plants — Michael Pollan very nicely written account of plants effect on altered states and culture\nSmart Words – Linking Words"
  },
  {
    "objectID": "posts/2020-03-17-cnn_pytorch_tutorial.html",
    "href": "posts/2020-03-17-cnn_pytorch_tutorial.html",
    "title": "Convolutional neural network example",
    "section": "",
    "text": "This tutorial is adopted from Python-Engineer’s Pytorch Tutorial | Video\nGood reading links: - CMU’s CS231 Course\nConvolutional neural network is used to train CIFAR-10 dataset. It is implemented in PyTorch"
  },
  {
    "objectID": "posts/2020-03-17-cnn_pytorch_tutorial.html#loading-the-data",
    "href": "posts/2020-03-17-cnn_pytorch_tutorial.html#loading-the-data",
    "title": "Convolutional neural network example",
    "section": "Loading the data",
    "text": "Loading the data\nDataset has PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1]\n\n# dataset has PILImage images of range [0, 1]. \n# We transform them to Tensors of normalized range [-1, 1]\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n#Importing the training set for the CIFAR10 dataset\ntrain_dataset = torchvision.datasets.CIFAR10(root=dataset_dir, train=True,\n                                        download=True, transform=transform)\n\n#Importing the testing set for the CIFAR10 dataset\ntest_dataset = torchvision.datasets.CIFAR10(root=dataset_dir, train=False,\n                                       download=True, transform=transform)\n\nDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n\n\n\n\n\nExtracting data/cifar-10-python.tar.gz to data/\nFiles already downloaded and verified\n\n\n\ndef imshow(img):\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n#Define data-loader classs and labels for the images in the dataset\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n                                          shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n                                         shuffle=False)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n\n# get some random training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\nprint('Images of: {}'.format([classes[i] for i in labels]))\nprint('Size of the image array for a given batch: {}'.format(images.shape))\n\n\n\n\n\n\n\n\nImages of: ['truck', 'horse', 'deer', 'ship']\nSize of the image array for a given batch: torch.Size([4, 3, 32, 32])"
  },
  {
    "objectID": "posts/2020-03-17-cnn_pytorch_tutorial.html#testing-the-convolutions",
    "href": "posts/2020-03-17-cnn_pytorch_tutorial.html#testing-the-convolutions",
    "title": "Convolutional neural network example",
    "section": "Testing the convolutions",
    "text": "Testing the convolutions\nBefore implementing the CNN for the image recognition let’s see what the convolutions and the pooling layers do the images\nConvolution is the first layer to extract features from an input image. It preserves the relationship between pixels by learning images features using small squares of input data. It’s a matrix operation that takes two inputs – image matrix and a filter/kernel\nTwo main hyper-parameters for the pooling layers: 1. Stride – controls how filters ‘slides’ on the input volume. Stride is normally set in a way so that the output volume is an integer and not a fraction. Increase the stride if you want receptive fields to overlap less and want smaller spatial dimensions\n\nPadding –  Image matrix multiplies kernel or filter matrix\n\n 3 x 3 Output matrix\n\nCalculating the output size of the image after convolutions:\nTo calculate the output size of the image after convolution layer:\n\\[O = \\frac{W - F + 2P}{S} + 1\\]\nwhere O is the output height/length, W is the input height/length, F is the filter size, P is the padding, and S is the stride."
  },
  {
    "objectID": "posts/2020-03-17-cnn_pytorch_tutorial.html#pooling-layers",
    "href": "posts/2020-03-17-cnn_pytorch_tutorial.html#pooling-layers",
    "title": "Convolutional neural network example",
    "section": "Pooling layers",
    "text": "Pooling layers\nPooling layers section would reduce the number of parameters when the images are too large. Spatial pooling also called subsampling or downsampling which reduces the dimensionality of each map but retains important information. Spatial pooling can be of different types: 1. Max Pooling 2. Average Pooling 3. Sum Pooling\nMax pooling takes the largest element from the rectified feature map. Taking the largest element could also take the average pooling. Sum of all elements in the feature map call as sum pooling.\n Max pooling scheme\n\nconv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0)\npool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #Take max of the 2x2 array and shift by 2 \nconv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n\n\nprint(images.shape)\nx = conv1(images)\nprint(x.shape)\n\ntorch.Size([4, 3, 32, 32])\ntorch.Size([4, 6, 28, 28])\n\n\n\nx = pool(x)\nprint(x.shape)\n\ntorch.Size([4, 6, 14, 14])\n\n\n\nx = conv2(x)\nprint(x.shape)\n\ntorch.Size([4, 16, 10, 10])\n\n\n\nx = pool(x)\nprint(x.shape)\n\ntorch.Size([4, 16, 5, 5])\n\n\n\nBuilding the CNN class\n\nclass ConvNet(nn.Module):\n    '''\n    Inherit from the nn.Module all the necessary routines \n    \n    super() is in the business of delegating method calls \n    to some class in the instance’s ancestor tree.\n    \n    Conv1 = First convolution 3 color channels (RGB) to 6 output, \n    filter size=5\n    \n    pool = Max pool layer of 2x2 and stride of 2 ie. we shift 2 \n    pixel to the right after each pooling operations \n    \n    Conv2 = Second convolution layer with 6 input channel and \n    16 output channel, filter size of 5 \n    \n    Full connected layer \n    \n    FC1 = Flatten output of the final convolution + pooling (16 * 5 * 5)\n    to 120 dim array \n    \n    FC2 = 120 to 84 \n    FC3 = 84 to no of hidden equal to that of class labels \n    \n    Forward operation \n    -----------------------\n    images --&gt; conv --&gt; relu --&gt; pool --&gt; conv2 --&gt; relu --&gt; pool\n    Flatten pooled output --&gt; FC (w/ relu) --&gt; FC (relu) --&gt; FC --&gt; output\n    '''\n    def __init__(self):\n        super(ConvNet, self).__init__()\n        #Here we built the architecture for the CNN\n        #First conv1 function instantiation\n        self.conv1 = nn.Conv2d(3,6,5) \n        #General purpose pooling \n        self.pool = nn.MaxPool2d(2,2) \n        #Second conv2 function instantiation\n        self.conv2 = nn.Conv2d(6,16,5)\n        #1st NN layer\n        self.fc1 = nn.Linear(16*5*5,120)\n        #2nd NN layer \n        self.fc2 = nn.Linear(120,84)\n        #Final output layer \n        self.fc3 = nn.Linear(84,10) \n    \n    def forward(self, x):\n        #Two pooling operations\n        x = self.pool(F.relu(self.conv1(x)))  # -&gt; n, 6, 14, 14\n        x = self.pool(F.relu(self.conv2(x)))  # -&gt; n, 16, 5, 5\n        #Flatten the output from pooling/convoltions\n        x = x.view(-1, 16 * 5 * 5)            # -&gt; n, 400\n        x = F.relu(self.fc1(x))               # -&gt; n, 120\n        x = F.relu(self.fc2(x))               # -&gt; n, 84\n        x = self.fc3(x)                       # -&gt; n, 10\n        return x\n\n\n\nDefining the training criterion and optmizer\n\n#Define model, criterion, optimizer for the GD \nmodel = ConvNet().to(device)\n#For multiclass classification -- crossentropy loss \ncriterion = nn.CrossEntropyLoss() \noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n\n\nTrain the CNN on the test dataset\n\nn_total_steps = len(train_loader)\nfor epoch in range(num_epochs):\n    for i, (images,labels) in enumerate(train_loader):\n        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        #Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        #Backward prop and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 2000 == 0: \n            print (f'Epoch [{epoch+1}/{num_epochs}],\\\n                   Step [{i+1}/{n_total_steps}],\\\n                   Loss: {loss.item():.4f}')\nprint('Finished Training')\nPATH = './cnn.pth'\ntorch.save(model.state_dict(), PATH)\n\n\nwith torch.no_grad(): #We dont need backward propogation here\n    n_correct = 0\n    n_samples = 0\n    n_class_correct = [0 for i in range(10)]\n    n_class_samples = [0 for i in range(10)]\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        # max returns (value ,index)\n        _, predicted = torch.max(outputs, 1)\n        n_samples += labels.size(0)\n        n_correct += (predicted == labels).sum().item()\n        \n        for i in range(batch_size):\n            label = labels[i]\n            pred = predicted[i]\n            if (label == pred):\n                n_class_correct[label] += 1\n            n_class_samples[label] += 1\n\n    acc = 100.0 * n_correct / n_samples\n    print(f'Accuracy of the network: {acc} %')\n\n    for i in range(10):\n        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n        print(f'Accuracy of {classes[i]}: {acc} %')\n\nAccuracy of the network: 48.28 %\nAccuracy of plane: 55.7 %\nAccuracy of car: 62.1 %\nAccuracy of bird: 26.1 %\nAccuracy of cat: 34.2 %\nAccuracy of deer: 31.0 %\nAccuracy of dog: 33.3 %\nAccuracy of frog: 75.1 %\nAccuracy of horse: 50.0 %\nAccuracy of ship: 58.7 %\nAccuracy of truck: 56.6 %"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html",
    "href": "posts/2021-04-28-material_prop_walkthrough.html",
    "title": "Mateiral informatics sample project",
    "section": "",
    "text": "A random forest regression model is built to predict the heat capacity (\\(C_p\\)) of solid inorganic materials at different temperatures. The dataset is collected from the NIST JANAF Thermochemical Table\nThis project is adapted from recent publication looking at best practices for setting up mateial informatics task. * A. Y. T. Wang et al., “Machine Learning for Materials Scientists: An Introductory Guide toward Best Practices,” Chem. Mater., vol. 32, no. 12, pp. 4954–4965, 2020.\nimport os \nimport pandas as pd \nimport numpy as np \n\nnp.random.seed(42)\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 15,\n'axes.titlesize' : 15,\n'axes.labelsize' : 15,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 12,\n'ytick.labelsize' : 12,\n}\n \nplt.rcParams.update(plot_params)"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#featurization",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#featurization",
    "title": "Mateiral informatics sample project",
    "section": "Featurization",
    "text": "Featurization\nComposition-based feature vector (CBFV) is used to describe each mateiral entry (eg: Cr2O3) with set of elemental and composition based numbers.\n\n# Import the package and the generate_features function\nfrom cbfv.composition import generate_features\n\n\nrename_columns = {'Cp':'target'}\ntrain_points['Type'] = 'Train'\nval_points['Type'] = 'Val'\ntest_points['Type'] = 'Test'\ntotal_data = pd.concat([train_points, val_points, test_points], ignore_index=True);\n\ntotal_data = total_data.rename(columns=rename_columns)\n\n/Users/pghaneka/miniconda3/envs/torch_38/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/Users/pghaneka/miniconda3/envs/torch_38/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n/Users/pghaneka/miniconda3/envs/torch_38/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  after removing the cwd from sys.path.\n\n\n\ntotal_data.sample(5)\n\n\n\n\n\n\n\n\nformula\nT\ntarget\nType\n\n\n\n\n3833\nI1K1\n1400.0\n74.601\nVal\n\n\n4215\nCr2O3\n298.0\n120.366\nTest\n\n\n1290\nI2Mo1\n1000.0\n91.458\nTrain\n\n\n1578\nI2Zr1\n700.0\n97.445\nTrain\n\n\n2379\nNa2O5Si2\n1700.0\n292.880\nTrain\n\n\n\n\n\n\n\n\ntrain_df = total_data.loc[ total_data['Type'] == 'Train' ].drop(columns=['Type']).reset_index(drop=True)\nval_df = total_data.loc[ total_data['Type'] == 'Val' ].drop(columns=['Type']).reset_index(drop=True)\ntest_df = total_data.loc[ total_data['Type'] == 'Test' ].drop(columns=['Type']).reset_index(drop=True)\n\n\nSub-sampling\nOnly some points from the original training data train_df are used to ensure the analysis is tractable\n\ntrain_df.shape\n\n(3131, 3)\n\n\n\ntrain_df = train_df.sample(n=1000, random_state=42)\ntrain_df.shape\n\n(1000, 3)\n\n\n\n# Generate features \nX_unscaled_train, y_train, formulae_entry_train, skipped_entry = generate_features(train_df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\nX_unscaled_val, y_val, formulae_entry_val, skipped_entry = generate_features(val_df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\nX_unscaled_test, y_test, formulae_entry_test, skipped_entry = generate_features(test_df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n\nProcessing Input Data: 100%|██████████| 1000/1000 [00:00&lt;00:00, 26074.09it/s]\nAssigning Features...:   0%|          | 0/1000 [00:00&lt;?, ?it/s]\n\n\n    Featurizing Compositions...\n\n\nAssigning Features...: 100%|██████████| 1000/1000 [00:00&lt;00:00, 13526.13it/s]\n\n\n    Creating Pandas Objects...\n\n\n\nProcessing Input Data: 100%|██████████| 944/944 [00:00&lt;00:00, 28169.72it/s]\nAssigning Features...:   0%|          | 0/944 [00:00&lt;?, ?it/s]\n\n\n    Featurizing Compositions...\n\n\nAssigning Features...: 100%|██████████| 944/944 [00:00&lt;00:00, 14855.23it/s]\n\n\n    Creating Pandas Objects...\n\n\nProcessing Input Data: 100%|██████████| 489/489 [00:00&lt;00:00, 25491.43it/s]\nAssigning Features...: 100%|██████████| 489/489 [00:00&lt;00:00, 12626.83it/s]\n\n\n    Featurizing Compositions...\n    Creating Pandas Objects...\n\n\n\nX_unscaled_train.head(5)\n\n\n\n\n\n\n\n\nsum_Atomic_Number\nsum_Atomic_Weight\nsum_Period\nsum_group\nsum_families\nsum_Metal\nsum_Nonmetal\nsum_Metalliod\nsum_Mendeleev_Number\nsum_l_quantum_number\n...\nrange_Melting_point_(K)\nrange_Boiling_Point_(K)\nrange_Density_(g/mL)\nrange_specific_heat_(J/g_K)_\nrange_heat_of_fusion_(kJ/mol)_\nrange_heat_of_vaporization_(kJ/mol)_\nrange_thermal_conductivity_(W/(m_K))_\nrange_heat_atomization(kJ/mol)\nrange_Cohesive_energy\nT\n\n\n\n\n0\n64.0\n139.938350\n10.5\n50.0\n23.25\n1.0\n2.75\n0.0\n289.25\n4.75\n...\n2009873.29\n5.748006e+06\n26.002708\n0.112225\n252.450947\n88384.346755\n4759.155119\n41820.25\n4.410000\n1100.0\n\n\n1\n58.0\n119.979000\n10.0\n40.0\n18.00\n1.0\n2.00\n0.0\n231.00\n4.00\n...\n505663.21\n1.328602e+06\n8.381025\n0.018225\n36.496702\n28866.010000\n1597.241190\n4830.25\n0.511225\n1100.0\n\n\n2\n27.0\n58.691000\n6.0\n17.0\n10.00\n1.0\n0.00\n1.0\n115.00\n3.00\n...\n43890.25\n1.277526e+05\n1.210000\n0.062500\n301.890625\n1179.922500\n6.502500\n2652.25\n0.230400\n3400.0\n\n\n3\n36.0\n72.144000\n7.0\n18.0\n9.00\n1.0\n1.00\n0.0\n95.00\n1.00\n...\n131841.61\n2.700361e+05\n0.067600\n0.001600\n11.636627\n5148.062500\n9973.118090\n2550.25\n0.255025\n2900.0\n\n\n4\n80.0\n162.954986\n19.0\n120.0\n56.00\n0.0\n8.00\n0.0\n659.00\n8.00\n...\n16129.00\n5.659641e+04\n0.826963\n0.018225\n0.021993\n21.791158\n0.010922\n6241.00\n0.555025\n1300.0\n\n\n\n\n5 rows × 177 columns\n\n\n\n\nformulae_entry_train.head(5)\n\n0    Mo1O2.750\n1        Fe1S2\n2        B1Ti1\n3        Ca1S1\n4         N5P3\nName: formula, dtype: object\n\n\n\nX_unscaled_train.shape\n\n(1000, 177)"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#feature-scaling",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#feature-scaling",
    "title": "Mateiral informatics sample project",
    "section": "Feature scaling",
    "text": "Feature scaling\n\nX_unscaled_train.columns\n\nIndex(['sum_Atomic_Number', 'sum_Atomic_Weight', 'sum_Period', 'sum_group',\n       'sum_families', 'sum_Metal', 'sum_Nonmetal', 'sum_Metalliod',\n       'sum_Mendeleev_Number', 'sum_l_quantum_number',\n       ...\n       'range_Melting_point_(K)', 'range_Boiling_Point_(K)',\n       'range_Density_(g/mL)', 'range_specific_heat_(J/g_K)_',\n       'range_heat_of_fusion_(kJ/mol)_',\n       'range_heat_of_vaporization_(kJ/mol)_',\n       'range_thermal_conductivity_(W/(m_K))_',\n       'range_heat_atomization(kJ/mol)', 'range_Cohesive_energy', 'T'],\n      dtype='object', length=177)\n\n\n\nX_unscaled_train.describe().round(2)\n\n\n\n\n\n\n\n\nsum_Atomic_Number\nsum_Atomic_Weight\nsum_Period\nsum_group\nsum_families\nsum_Metal\nsum_Nonmetal\nsum_Metalliod\nsum_Mendeleev_Number\nsum_l_quantum_number\n...\nrange_Melting_point_(K)\nrange_Boiling_Point_(K)\nrange_Density_(g/mL)\nrange_specific_heat_(J/g_K)_\nrange_heat_of_fusion_(kJ/mol)_\nrange_heat_of_vaporization_(kJ/mol)_\nrange_thermal_conductivity_(W/(m_K))_\nrange_heat_atomization(kJ/mol)\nrange_Cohesive_energy\nT\n\n\n\n\ncount\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n...\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n\n\nmean\n66.57\n147.21\n11.28\n46.27\n23.19\n1.28\n2.64\n0.08\n292.01\n3.73\n...\n579042.62\n1803422.99\n8.45\n3.34\n181.31\n28201.58\n3305.55\n14959.38\n1.70\n1195.38\n\n\nstd\n48.94\n116.53\n6.33\n36.29\n16.68\n0.76\n2.32\n0.31\n210.15\n2.59\n...\n750702.41\n2017584.79\n17.52\n10.61\n413.13\n36421.94\n4474.33\n22191.74\n2.45\n760.90\n\n\nmin\n4.00\n7.95\n2.00\n1.00\n1.00\n0.00\n0.00\n0.00\n3.00\n0.00\n...\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n25%\n31.00\n65.12\n6.00\n18.00\n10.00\n1.00\n1.00\n0.00\n126.00\n2.00\n...\n20619.03\n199191.78\n0.23\n0.01\n1.88\n1451.91\n119.61\n729.00\n0.09\n600.00\n\n\n50%\n55.00\n118.00\n10.00\n36.00\n20.00\n1.00\n2.00\n0.00\n247.00\n3.00\n...\n222030.88\n1169819.78\n1.25\n0.05\n20.92\n18260.29\n1607.65\n5312.67\n0.63\n1054.00\n\n\n75%\n86.00\n182.15\n15.00\n72.00\n36.00\n2.00\n4.00\n0.00\n442.00\n5.00\n...\n882096.64\n3010225.00\n9.33\n0.12\n171.31\n40317.25\n4968.28\n18080.67\n2.08\n1600.00\n\n\nmax\n278.00\n685.60\n41.00\n256.00\n113.00\n4.00\n15.00\n2.00\n1418.00\n19.00\n...\n3291321.64\n8535162.25\n93.11\n44.12\n2391.45\n168342.03\n40198.47\n95733.56\n10.59\n4600.00\n\n\n\n\n8 rows × 177 columns\n\n\n\n\nX_unscaled_train['range_heat_of_vaporization_(kJ/mol)_'].hist();\n\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler, normalize\n\n\nstdscaler = StandardScaler()\nX_train = stdscaler.fit_transform(X_unscaled_train)\nX_val = stdscaler.transform(X_unscaled_val)\nX_test = stdscaler.transform(X_unscaled_test)\n\n\npd.DataFrame(X_train, columns=X_unscaled_train.columns).describe().round(2)\n\n\n\n\n\n\n\n\nsum_Atomic_Number\nsum_Atomic_Weight\nsum_Period\nsum_group\nsum_families\nsum_Metal\nsum_Nonmetal\nsum_Metalliod\nsum_Mendeleev_Number\nsum_l_quantum_number\n...\nrange_Melting_point_(K)\nrange_Boiling_Point_(K)\nrange_Density_(g/mL)\nrange_specific_heat_(J/g_K)_\nrange_heat_of_fusion_(kJ/mol)_\nrange_heat_of_vaporization_(kJ/mol)_\nrange_thermal_conductivity_(W/(m_K))_\nrange_heat_atomization(kJ/mol)\nrange_Cohesive_energy\nT\n\n\n\n\ncount\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n...\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n\n\nmean\n-0.00\n-0.00\n-0.00\n0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n-0.00\n...\n0.00\n0.00\n-0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n-0.00\n\n\nstd\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n...\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n\n\nmin\n-1.28\n-1.20\n-1.47\n-1.25\n-1.33\n-1.68\n-1.14\n-0.27\n-1.38\n-1.44\n...\n-0.77\n-0.89\n-0.48\n-0.31\n-0.44\n-0.77\n-0.74\n-0.67\n-0.69\n-1.57\n\n\n25%\n-0.73\n-0.70\n-0.83\n-0.78\n-0.79\n-0.36\n-0.71\n-0.27\n-0.79\n-0.67\n...\n-0.74\n-0.80\n-0.47\n-0.31\n-0.43\n-0.73\n-0.71\n-0.64\n-0.66\n-0.78\n\n\n50%\n-0.24\n-0.25\n-0.20\n-0.28\n-0.19\n-0.36\n-0.27\n-0.27\n-0.21\n-0.28\n...\n-0.48\n-0.31\n-0.41\n-0.31\n-0.39\n-0.27\n-0.38\n-0.43\n-0.43\n-0.19\n\n\n75%\n0.40\n0.30\n0.59\n0.71\n0.77\n0.96\n0.59\n-0.27\n0.71\n0.49\n...\n0.40\n0.60\n0.05\n-0.30\n-0.02\n0.33\n0.37\n0.14\n0.15\n0.53\n\n\nmax\n4.32\n4.62\n4.69\n5.78\n5.39\n3.59\n5.34\n6.18\n5.36\n5.89\n...\n3.61\n3.34\n4.83\n3.84\n5.35\n3.85\n8.25\n3.64\n3.62\n4.48\n\n\n\n\n8 rows × 177 columns\n\n\n\n\npd.DataFrame(X_train, columns=X_unscaled_train.columns)['range_heat_of_vaporization_(kJ/mol)_'].hist()\n\n\n\n\n\n\n\n\n\nX_train = normalize(X_train)\nX_val = normalize(X_val)\nX_test = normalize(X_test)\n\n\npd.DataFrame(X_train, columns=X_unscaled_train.columns).describe().round(2)\n\n\n\n\n\n\n\n\nsum_Atomic_Number\nsum_Atomic_Weight\nsum_Period\nsum_group\nsum_families\nsum_Metal\nsum_Nonmetal\nsum_Metalliod\nsum_Mendeleev_Number\nsum_l_quantum_number\n...\nrange_Melting_point_(K)\nrange_Boiling_Point_(K)\nrange_Density_(g/mL)\nrange_specific_heat_(J/g_K)_\nrange_heat_of_fusion_(kJ/mol)_\nrange_heat_of_vaporization_(kJ/mol)_\nrange_thermal_conductivity_(W/(m_K))_\nrange_heat_atomization(kJ/mol)\nrange_Cohesive_energy\nT\n\n\n\n\ncount\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n...\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n1000.00\n\n\nmean\n-0.01\n-0.01\n-0.00\n-0.00\n-0.00\n0.00\n-0.00\n-0.01\n-0.00\n0.00\n...\n0.00\n0.01\n-0.00\n-0.01\n-0.00\n0.01\n0.00\n-0.00\n-0.00\n0.00\n\n\nstd\n0.07\n0.07\n0.07\n0.07\n0.07\n0.08\n0.07\n0.07\n0.07\n0.08\n...\n0.08\n0.08\n0.07\n0.07\n0.07\n0.08\n0.09\n0.08\n0.08\n0.09\n\n\nmin\n-0.12\n-0.11\n-0.13\n-0.11\n-0.11\n-0.12\n-0.11\n-0.04\n-0.12\n-0.13\n...\n-0.08\n-0.10\n-0.06\n-0.05\n-0.05\n-0.08\n-0.12\n-0.09\n-0.09\n-0.19\n\n\n25%\n-0.06\n-0.06\n-0.06\n-0.06\n-0.06\n-0.04\n-0.06\n-0.03\n-0.06\n-0.05\n...\n-0.05\n-0.05\n-0.03\n-0.03\n-0.04\n-0.05\n-0.05\n-0.05\n-0.05\n-0.06\n\n\n50%\n-0.02\n-0.03\n-0.02\n-0.02\n-0.02\n-0.03\n-0.02\n-0.02\n-0.02\n-0.02\n...\n-0.03\n-0.03\n-0.03\n-0.02\n-0.03\n-0.02\n-0.03\n-0.04\n-0.04\n-0.02\n\n\n75%\n0.03\n0.02\n0.06\n0.06\n0.06\n0.06\n0.05\n-0.02\n0.07\n0.05\n...\n0.04\n0.04\n0.01\n-0.02\n-0.00\n0.02\n0.03\n0.02\n0.01\n0.05\n\n\nmax\n0.25\n0.26\n0.19\n0.20\n0.19\n0.25\n0.20\n0.40\n0.19\n0.24\n...\n0.22\n0.23\n0.29\n0.32\n0.43\n0.26\n0.58\n0.26\n0.24\n0.38\n\n\n\n\n8 rows × 177 columns\n\n\n\n\npd.DataFrame(X_train, columns=X_unscaled_train.columns)['range_heat_of_vaporization_(kJ/mol)_'].hist()"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#model-fitting-1",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#model-fitting-1",
    "title": "Mateiral informatics sample project",
    "section": "Model fitting",
    "text": "Model fitting\n\nfrom time import time \n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n\n\nmodel = RandomForestRegressor(random_state=42)\n\n\n%%time\nmodel.fit(X_train, y_train)\n\nCPU times: user 5.51 s, sys: 31.7 ms, total: 5.54 s\nWall time: 5.57 s\n\n\nRandomForestRegressor(random_state=42)\n\n\n\ndef display_performance(y_true, y_pred):\n    r2 = r2_score(y_true, y_pred)\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    \n    print('R2: {0:0.2f}\\n'\n          'MAE: {1:0.2f}\\n'\n          'RMSE: {2:0.2f}'.format(r2, mae, rmse))\n    return(r2, mae, rmse)\n\n\ny_pred = model.predict(X_val)\ndisplay_performance(y_val,y_pred);\n\nR2: 0.81\nMAE: 14.03\nRMSE: 20.48\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(y_val, y_pred, alpha=0.6, label='Random Forest')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n# Linear fit\nreg = np.polyfit(y_val, y_pred, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='Linear Fit')\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='Parity Line')\nax.set_aspect('equal')\n        \nax.set_xlabel('True value')\nax.set_ylabel('Model predicted')\nax.legend(loc='best')"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#feature-importance",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#feature-importance",
    "title": "Mateiral informatics sample project",
    "section": "Feature Importance",
    "text": "Feature Importance\n\nfeature_name = [i for i in X_unscaled_train.columns]\n\n\nlen(feature_name)\n\n177\n\n\n\nX_train.shape\n\n(1000, 177)\n\n\n\nlen(model.estimators_)\n\n100\n\n\n\nmean_feature_importance = model.feature_importances_\nstd_feature_importance = np.std([ tree.feature_importances_ for tree in model.estimators_ ], axis=0)\n\n\nfeat_imp_df = pd.DataFrame({'name':feature_name, 'mean_imp':mean_feature_importance, 'std_dev':std_feature_importance})\n\n\nfeat_imp_df_top = feat_imp_df.sort_values('mean_imp', ascending=False)[:20]\n\n\nfeat_imp_df_top[:5]\n\n\n\n\n\n\n\n\nname\nmean_imp\nstd_dev\n\n\n\n\n24\nsum_valence_s\n0.383415\n0.273328\n\n\n12\nsum_Covalent_Radius\n0.205463\n0.220244\n\n\n17\nsum_MB_electonegativity\n0.098704\n0.212963\n\n\n31\nsum_Number_of_unfilled_f_valence_electrons\n0.076559\n0.028590\n\n\n176\nT\n0.049666\n0.008509\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(30,3))\nax.bar(feat_imp_df_top['name'], feat_imp_df_top['mean_imp'], yerr=feat_imp_df_top['std_dev'])\nax.tick_params(axis='x', rotation=90)\nax.set_title('Feature Importance');\n\n\n\n\n\n\n\n\n\ntop_feature_list = feat_imp_df.loc[ feat_imp_df['mean_imp'] &gt; 0.001 ]['name']\n\n\nlen(top_feature_list)\n\n40\n\n\n\nX_train_df = pd.DataFrame(X_train, columns=feature_name)\nX_val_df = pd.DataFrame(X_val, columns=feature_name)\n\nX_train_short = X_train_df[list(top_feature_list)]\nX_val_short = X_val_df[list(top_feature_list)]\n\n\nprint(X_train_short.shape, X_train.shape)\n\n(1000, 40) (1000, 177)\n\n\n\nRefit a new model on small feature set\n\nmodel_small = RandomForestRegressor(random_state=42)\n\n\n%%time\nmodel_small.fit(X_train_short, y_train)\n\nCPU times: user 1.41 s, sys: 13.9 ms, total: 1.43 s\nWall time: 1.44 s\n\n\nRandomForestRegressor(random_state=42)\n\n\n\ny_pred = model_small.predict(X_val_short)\ndisplay_performance(y_val, y_pred);\n\nR2: 0.81\nMAE: 13.87\nRMSE: 20.40\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(y_val, y_pred, alpha=0.6, label='Random Forest')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n# Linear fit\nreg = np.polyfit(y_val, y_pred, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='Linear Fit')\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='Parity Line')\nax.set_aspect('equal')\n        \nax.set_xlabel('True value')\nax.set_ylabel('Model predicted')\nax.legend(loc='best')"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#cross-validation",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#cross-validation",
    "title": "Mateiral informatics sample project",
    "section": "Cross-validation",
    "text": "Cross-validation\nCombine train and validation set to generate one train - test set for cross-validation\n\n# Train stack \nX_y_train = np.c_[X_train_short, y_train]\nX_y_train.shape\n\n(1000, 41)\n\n\n\nnp.unique(X_y_train[:,-1] - y_train)\n\narray([0.])\n\n\n\n# Validation stack\nX_y_val = np.c_[X_val_short, y_val]\n\n\nX_Y_TRAIN = np.vstack((X_y_train, X_y_val))\n\n\nX_TRAIN = X_Y_TRAIN[:,0:-1].copy()\nY_TRAIN = X_Y_TRAIN[:,-1].copy()\n\nprint(X_TRAIN.shape, Y_TRAIN.shape)\n\n(1944, 40) (1944,)\n\n\n\nfrom sklearn.model_selection import cross_validate\n\ndef display_score(scores, metric):\n    score_key = 'test_{}'.format(metric)\n    print(metric)\n    print('Mean: {}'.format(scores[score_key].mean()))\n    print('Std dev: {}'.format(scores[score_key].std()))\n\n\n%%time\n_scoring = ['neg_root_mean_squared_error', 'neg_mean_absolute_error']\nforest_scores = cross_validate(model, X_TRAIN, Y_TRAIN, \n                              scoring = _scoring, cv=5)\n\nCPU times: user 11.1 s, sys: 66 ms, total: 11.1 s\nWall time: 11.2 s\n\n\n\ndisplay_score(forest_scores, _scoring[0])\n\nneg_root_mean_squared_error\nMean: -15.22268277329878\nStd dev: 3.677396464443359\n\n\n\ndisplay_score(forest_scores, _scoring[1])\n\nneg_mean_absolute_error\nMean: -9.559763633911203\nStd dev: 2.786793874037375"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#hyperparameter-optimization",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#hyperparameter-optimization",
    "title": "Mateiral informatics sample project",
    "section": "Hyperparameter Optimization",
    "text": "Hyperparameter Optimization\n\nimport joblib\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\nrandom_forest_base_model = RandomForestRegressor(random_state=42)\n\nparam_grid = {\n    'bootstrap':[True],\n    'min_samples_leaf':[5,10,100,200,500],\n    'min_samples_split':[5,10,100,200,500],\n    'n_estimators':[100,200,400,500],\n    'max_features':['auto','sqrt','log2'],\n    'max_depth':[5,10,15,20]\n}\n\n\nCV_rf = RandomizedSearchCV(estimator=random_forest_base_model, \n                           n_iter=50, \n                           param_distributions=param_grid, \n                           scoring='neg_root_mean_squared_error',\n                           cv = 5, verbose = 1, n_jobs=-1, refit=True)\n\n\n%%time\nwith joblib.parallel_backend('multiprocessing'):\n    CV_rf.fit(X_TRAIN, Y_TRAIN)\n\nFitting 5 folds for each of 50 candidates, totalling 250 fits\nCPU times: user 646 ms, sys: 183 ms, total: 829 ms\nWall time: 1min 5s\n\n\n\nprint(CV_rf.best_params_, CV_rf.best_score_)\n\n{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'auto', 'max_depth': 20, 'bootstrap': True} -19.161578679126375\n\n\n\npd.DataFrame(CV_rf.cv_results_).sort_values('rank_test_score')[:5]\n\n\n\n\n\n\n\n\nmean_fit_time\nstd_fit_time\nmean_score_time\nstd_score_time\nparam_n_estimators\nparam_min_samples_split\nparam_min_samples_leaf\nparam_max_features\nparam_max_depth\nparam_bootstrap\nparams\nsplit0_test_score\nsplit1_test_score\nsplit2_test_score\nsplit3_test_score\nsplit4_test_score\nmean_test_score\nstd_test_score\nrank_test_score\n\n\n\n\n4\n2.390702\n0.061919\n0.014793\n0.000683\n100\n10\n10\nauto\n20\nTrue\n{'n_estimators': 100, 'min_samples_split': 10,...\n-19.636059\n-20.949326\n-16.321387\n-18.878979\n-20.022143\n-19.161579\n1.568968\n1\n\n\n20\n1.299131\n0.010285\n0.033008\n0.003166\n200\n10\n10\nsqrt\n10\nTrue\n{'n_estimators': 200, 'min_samples_split': 10,...\n-21.980440\n-23.012936\n-18.847124\n-19.781677\n-17.760789\n-20.276593\n1.949783\n2\n\n\n22\n10.616245\n0.066480\n0.084979\n0.025942\n500\n5\n10\nauto\n5\nTrue\n{'n_estimators': 500, 'min_samples_split': 5, ...\n-21.048335\n-23.039862\n-18.059296\n-18.935399\n-20.566808\n-20.329940\n1.733000\n3\n\n\n40\n3.364752\n0.126191\n0.089052\n0.004354\n500\n10\n10\nsqrt\n15\nTrue\n{'n_estimators': 500, 'min_samples_split': 10,...\n-22.245647\n-23.261791\n-18.796893\n-20.179776\n-17.747398\n-20.446301\n2.061082\n4\n\n\n2\n0.448634\n0.006245\n0.015180\n0.001035\n100\n5\n10\nlog2\n20\nTrue\n{'n_estimators': 100, 'min_samples_split': 5, ...\n-22.658766\n-23.491199\n-19.473837\n-20.457559\n-17.931118\n-20.802496\n2.039804\n5\n\n\n\n\n\n\n\n\nbest_model = CV_rf.best_estimator_\n\n\nbest_model\n\nRandomForestRegressor(max_depth=20, min_samples_leaf=10, min_samples_split=10,\n                      random_state=42)"
  },
  {
    "objectID": "posts/2022-08-31-cheminfo_smirks.html",
    "href": "posts/2022-08-31-cheminfo_smirks.html",
    "title": "Cheminformatics basics - Why the SMIRKS?",
    "section": "",
    "text": "The code and discussion in this notebook is inspired and borrowed from: * Efficient Bits\nThe Reaction SMARTS or SMIRKS way to query chemical reactions\nSMIRKS as per the Daylight definition are used to describe a transform (or reaction) to modify molecules. They are rules to make new molecules but also be used a ‘Reaction SMARTS’ to search for reactions smiles which match that transformation.\nRDKit treats these slightly differently - it has Reaction SMARTS which are used for substructure matching alone.\n# collapse_output\n# Install requirements for the tutorial\n!pip install pandas rdkit-pypi mols2grid matplotlib scikit-learn ipywidgets\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pandas in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (1.1.5)\nRequirement already satisfied: rdkit-pypi in /home/l017301/.local/lib/python3.8/site-packages (2021.9.4)\nRequirement already satisfied: mols2grid in /home/l017301/.local/lib/python3.8/site-packages (0.2.1)\nRequirement already satisfied: matplotlib in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (3.3.0)\nRequirement already satisfied: scikit-learn in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (0.23.2)\nRequirement already satisfied: ipywidgets in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (7.5.1)\nRequirement already satisfied: numpy&gt;=1.15.4 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pandas) (1.18.5)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: pytz&gt;=2017.2 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pandas) (2020.1)\nRequirement already satisfied: Pillow in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from rdkit-pypi) (7.2.0)\nRequirement already satisfied: jinja2&gt;=2.11.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from mols2grid) (2.11.2)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.3 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from matplotlib) (2.4.7)\nRequirement already satisfied: cycler&gt;=0.10 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from matplotlib) (0.10.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: joblib&gt;=0.11 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from scikit-learn) (0.16.0)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\nRequirement already satisfied: scipy&gt;=0.19.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from scikit-learn) (1.4.1)\nRequirement already satisfied: traitlets&gt;=4.3.1 in /home/l017301/.local/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\nRequirement already satisfied: nbformat&gt;=4.2.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (5.0.7)\nRequirement already satisfied: widgetsnbextension~=3.5.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (3.5.1)\nRequirement already satisfied: ipykernel&gt;=4.5.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (5.3.4)\nRequirement already satisfied: ipython&gt;=4.0.0; python_version &gt;= \"3.3\" in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (7.17.0)\nRequirement already satisfied: six&gt;=1.5 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas) (1.15.0)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jinja2&gt;=2.11.0-&gt;mols2grid) (1.1.1)\nRequirement already satisfied: ipython-genutils in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets) (0.2.0)\nRequirement already satisfied: jsonschema!=2.5.0,&gt;=2.4 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets) (3.2.0)\nRequirement already satisfied: jupyter-core in /home/l017301/.local/lib/python3.8/site-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets) (4.9.1)\nRequirement already satisfied: notebook&gt;=4.4.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0-&gt;ipywidgets) (6.1.1)\nRequirement already satisfied: tornado&gt;=4.2 in /home/l017301/.local/lib/python3.8/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets) (6.1)\nRequirement already satisfied: jupyter-client in /home/l017301/.local/lib/python3.8/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets) (7.1.2)\nRequirement already satisfied: backcall in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.2.0)\nRequirement already satisfied: jedi&gt;=0.10 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.17.1)\nRequirement already satisfied: pygments in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (2.6.1)\nRequirement already satisfied: pexpect; sys_platform != \"win32\" in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (4.8.0)\nRequirement already satisfied: pickleshare in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.7.5)\nRequirement already satisfied: decorator in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (4.4.2)\nRequirement already satisfied: setuptools&gt;=18.5 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (47.1.0)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /home/l017301/.local/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (3.0.24)\nRequirement already satisfied: pyrsistent&gt;=0.14.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.2.0-&gt;ipywidgets) (0.16.0)\nRequirement already satisfied: attrs&gt;=17.4.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.2.0-&gt;ipywidgets) (19.3.0)\nRequirement already satisfied: argon2-cffi in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (20.1.0)\nRequirement already satisfied: nbconvert in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (5.6.1)\nRequirement already satisfied: Send2Trash in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (1.5.0)\nRequirement already satisfied: terminado&gt;=0.8.3 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.8.3)\nRequirement already satisfied: prometheus-client in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.8.0)\nRequirement already satisfied: pyzmq&gt;=17 in /home/l017301/.local/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (22.3.0)\nRequirement already satisfied: nest-asyncio&gt;=1.5 in /home/l017301/.local/lib/python3.8/site-packages (from jupyter-client-&gt;ipykernel&gt;=4.5.1-&gt;ipywidgets) (1.5.4)\nRequirement already satisfied: entrypoints in /home/l017301/.local/lib/python3.8/site-packages (from jupyter-client-&gt;ipykernel&gt;=4.5.1-&gt;ipywidgets) (0.3)\nRequirement already satisfied: parso&lt;0.8.0,&gt;=0.7.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jedi&gt;=0.10-&gt;ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.7.0)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pexpect; sys_platform != \"win32\"-&gt;ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.6.0)\nRequirement already satisfied: wcwidth in /home/l017301/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.2.5)\nRequirement already satisfied: cffi&gt;=1.0.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from argon2-cffi-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (1.14.1)\nRequirement already satisfied: bleach in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (3.1.5)\nRequirement already satisfied: defusedxml in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.6.0)\nRequirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.8.4)\nRequirement already satisfied: testpath in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.4.4)\nRequirement already satisfied: pandocfilters&gt;=1.4.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (1.4.2)\nRequirement already satisfied: pycparser in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from cffi&gt;=1.0.0-&gt;argon2-cffi-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (2.20)\nRequirement already satisfied: webencodings in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from bleach-&gt;nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.5.1)\nRequirement already satisfied: packaging in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from bleach-&gt;nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (20.4)\nWARNING: You are using pip version 20.2.2; however, version 22.2.2 is available.\nYou should consider upgrading via the '/lrlhps/apps/python/python-3.8.5/bin/python -m pip install --upgrade pip' command.\nimport os \nimport pandas as pd\nimport numpy as np \n\n# RDkit imports\nimport rdkit\nfrom rdkit import Chem #This gives us most of RDkits's functionality\nfrom rdkit.Chem import AllChem\nfrom rdkit.Chem import Draw\nfrom rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\nIPythonConsole.ipython_useSVG=True  #SVG's tend to look nicer than the png counterparts\nprint(rdkit.__version__)\n\n## Enumerator \nfrom rdkit.Chem.Draw import rdDepictor\nfrom rdkit.Chem import rdMolEnumerator\n\n# Mute all errors except critical\nChem.WrapLogs()\nlg = rdkit.RDLogger.logger() \nlg.setLevel(rdkit.RDLogger.CRITICAL)\n\nfrom collections import defaultdict\nfrom rdkit.Chem.Draw import rdMolDraw2D\nfrom IPython.display import SVG\n\n2021.09.3\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 15,\n'axes.titlesize' : 15,\n'axes.labelsize' : 15,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 12,\n'ytick.labelsize' : 12,\n}\n \nplt.rcParams.update(plot_params)\nrxn = AllChem.ReactionFromSmarts('[C:1]=[O,N:2]&gt;&gt;[C:1][*:2]')\nrxn\n[Chem.MolToSmiles(x,1) for x in rxn.RunReactants((Chem.MolFromSmiles('CC=O'),))[0]]\n\n['CCO']\nrxn = AllChem.ReactionFromSmarts('[C:1]~[O,N:2]&gt;&gt;*[C:1]~[*:2]')\nrxn\n[Chem.MolToSmiles(x,1) for x in rxn.RunReactants((Chem.MolFromSmiles('C#N'),))[0]]\n\n['*C#N']\nrxn = AllChem.ReactionFromSmarts(\"([C:1]=[C;H2].[C:2]=[C;H2])&gt;&gt;[*:1]=[*:2]\")\nrxn\nm1 = Chem.MolFromSmiles('C=CCOCC=C')\nm1\nps = rxn.RunReactants((m1,))\nps[0][0]"
  },
  {
    "objectID": "posts/2022-08-31-cheminfo_smirks.html#set-up-the-reactants-and-reaction-definitions",
    "href": "posts/2022-08-31-cheminfo_smirks.html#set-up-the-reactants-and-reaction-definitions",
    "title": "Cheminformatics basics - Why the SMIRKS?",
    "section": "Set up the reactants and reaction definitions",
    "text": "Set up the reactants and reaction definitions\n\nfrom rdkit.Chem import rdmolfiles as rdfiles\n\nlib_alcohols = rdfiles.SmilesMolSupplier('./molecule_enumerations/alcohol.smi') #Read input file with all reactants\nlib_alkynes = rdfiles.SmilesMolSupplier('./molecule_enumerations/alkynes.smi')\nreaction_library = pd.read_csv('./molecule_enumerations/rxn_definitions.txt', sep='\\t', index_col = 'ReactionName')\nreaction_library\n\n\n\n\n\n\n\n\nReactionSMARTS\n\n\nReactionName\n\n\n\n\n\nPrimary alc ox\n[CH2:1][OD1] &gt;&gt; [C:1]=[OD1]\n\n\nAmide coupling\n[C:1](=[O:2])O.[N:3] &gt;&gt; [C:1](=[O:2])[N:3]\n\n\nDiels-Alder\n'[C:1]=[C:2]-[C:3]=[C:4].[C:5]=[C:6] &gt;&gt; [C:5]-...\n\n\n4-Click\n[N:1]=[N+1:2]=[N-1:3].[CH:4]#[C:5]&gt;&gt;[N:1]-1-[C..."
  },
  {
    "objectID": "posts/2022-08-31-cheminfo_smirks.html#single-molecule-reaction",
    "href": "posts/2022-08-31-cheminfo_smirks.html#single-molecule-reaction",
    "title": "Cheminformatics basics - Why the SMIRKS?",
    "section": "Single molecule reaction",
    "text": "Single molecule reaction\n\ndef unimolecular(molecule, reaction_smirk):\n  rxn = AllChem.ReactionFromSmarts(reaction_smirk)\n  product = rxn.RunReactants([molecule,])\n  \n  final_smiles_list = []\n  try: \n    for i in range(len(product)):\n      final_smiles = Chem.MolToSmiles(product[i][0])\n      final_smiles_list.append(final_smiles)\n  except:\n    pass\n  return final_smiles_list\n\n\nDraw.MolsToGridImage(lib_alcohols)\n\n\n\n\n\n\n\n\n\nreaction_library.ReactionSMARTS['Primary alc ox']\n\n'[CH2:1][OD1] &gt;&gt; [C:1]=[OD1]'\n\n\n\nunimolecular(lib_alcohols[0], reaction_library.ReactionSMARTS['Primary alc ox'])\n\n['CC=O']\n\n\n\nproducts = []\nfor alcohol_mol in lib_alcohols:\n  prod = unimolecular(alcohol_mol, reaction_library.ReactionSMARTS['Primary alc ox'])\n  for mol in prod:\n    product = Chem.MolFromSmiles(mol)\n    products.append(product)\nalign_bundle_coords(products)\nDraw.MolsToGridImage(products)"
  },
  {
    "objectID": "posts/2022-08-31-cheminfo_smirks.html#reacting-two-compounds",
    "href": "posts/2022-08-31-cheminfo_smirks.html#reacting-two-compounds",
    "title": "Cheminformatics basics - Why the SMIRKS?",
    "section": "Reacting two compounds",
    "text": "Reacting two compounds\n\ndef bimolecular_rxn(mol1, mol2, reaction_smirk):\n  rxn = AllChem.ReactionFromSmarts(reaction_smirk)\n  product = rxn.RunReactants([mol1, mol2])\n  \n  final_smiles_list = []\n  try: \n    for i in range(len(product)):\n      final_smiles = Chem.MolToSmiles(product[i][0])\n      final_smiles_list.append(final_smiles)\n  except:\n    pass\n  return final_smiles_list\n\n\nreaction_smirks = reaction_library.ReactionSMARTS[\"4-Click\"] #Define the reaction type from the reaction library\nreaction_smirks\n\n'[N:1]=[N+1:2]=[N-1:3].[CH:4]#[C:5]&gt;&gt;[N:1]-1-[CH:4]=[C:5]-[N-0:3]=[N+0:2]-1'\n\n\n\nproduct_bimolecular = [] #List of enumerated molecules\nCore = Chem.MolFromSmiles('O[C@@H]1[C@@H](O)[C@H](OCC2=CC=CC=C2)[C@H](C[C@H]1N=[N+]=[N-])C([O-])=O') #Define the molecular core\nCore\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfor i in lib_alkynes: #Read the .smi-file of reagents to be used for enumeration\n    resulting_smiles = bimolecular_rxn(Core, i, reaction_smirks)\n    \n    for i in resulting_smiles:\n        prod1 = Chem.MolFromSmiles(i)\n        product_bimolecular.append(prod1)\nalign_bundle_coords(product_bimolecular)\nDraw.MolsToGridImage(product_bimolecular)"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html",
    "href": "posts/2021-06-13-pandas_resources.html",
    "title": "Pandas cookbook",
    "section": "",
    "text": "Selected Pandas code snippets and recipes that I revisit now and again. The snippets are adopted from different python scripts written over time, ignore the variable names.\nThis post was inspired by the wonderful work of Chris Albon and his snippets of code blocks."
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#reading-and-writing",
    "href": "posts/2021-06-13-pandas_resources.html#reading-and-writing",
    "title": "Pandas cookbook",
    "section": "Reading and Writing",
    "text": "Reading and Writing\nBasic reading a blank csv file\n# If you have no column names but know the number of columns\npd.read_csv(file_name, header=None, names=['col1','col2'])\nSaving a file to not have ‘Unamed’ column\ndf1.to_csv(os.path.join(output_dir, 'file_name_to_save_as.csv'), sep=',',columns=df1.columns, index=False, header=False) # header = None for no column names\nQuickly generate pandas dataframe from n lists\nsmiles = [\"C\", \"CCC\"]\nlabels = [1.5, 2.3]\ndf = pd.DataFrame( list( zip(smiles, labels) ), columns=[\"smiles\", \"task\"] )\nInformation about the dataframe\npandas_dataframe.info()\nSummary statistics (mean, quartile ranges)\npandas_dataframe.describe().round(2)\nReplace\ndf = df.replace( [list_of_value_to_replace], value_to_replace_with)\n# Eg: df.replace( [98-99], np.nan)\nReplace characters in the columns\n# List of characters to remove\nchars_to_remove = ['+','$',',']\n\n# List of column names to clean\ncols_to_clean = ['Installs','Price']\n\n# Loop for each column in cols_to_clean\nfor col in cols_to_clean:\n    # Loop for each char in chars_to_remove\n    for char in chars_to_remove:\n        # Replace the character with an empty string\n        apps[col] = apps[col].apply(lambda x: x.replace(char, ''))\n    # Convert col to float data type\n    apps[col] = apps[col].astype(float)\nConvert spaces titles in the row to one word separated by ‘-’\nreduced_df['product_title'] = reduced_df['product_title'].apply( lambda x: x.lower().replace(' ', '-') )\nDefine a new column with temp entries\npandas_dataframe['columns_name'] = 42 \nCreate columns in a loop\npandas_dataframe.columns = ['feature_' + str(i) for i in range(n_columns)]\nDropping miscellaneous columns and NaN entries\ncolumns_to_drop = ['CookTimeInMins', 'Servings', 'Course', 'Diet', 'Instructions', 'TranslatedInstructions', 'URL']\nfood_df = food_df.drop(columns = columns_to_drop).dropna()"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#post-process",
    "href": "posts/2021-06-13-pandas_resources.html#post-process",
    "title": "Pandas cookbook",
    "section": "Post process",
    "text": "Post process\nHighlight cells based on a condition\ndf = pd.DataFrame({\n    \"col1\":[-5,-2,1,4],\n    \"col2\":[2,3,-1,4]\n})\n\ndef highlight_number(row):\n    return[\n    \"background-color: red; color:white\"\n    if cell &lt;= 0\n    else \"background-color: green; color:white\"\n    for cell in row\n    ]\n\ndf.style.apply(highlight_number)"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#quick-plotting",
    "href": "posts/2021-06-13-pandas_resources.html#quick-plotting",
    "title": "Pandas cookbook",
    "section": "Quick plotting",
    "text": "Quick plotting\nSimple pearson correlation plot\n# Generate Pearson Correlation Matrix for HOUSING \ncorr_matrix=housing.corr()\n\n# Edit the visuals and precision \ncorr_matrix.style.background_gradient(cmap='coolwarm').set_precision(2)\n\n# Look at Pearson values for one attribute \ncorr_matrix['median_house_value'].sort_values(ascending=True)\nPlot multiple scatter plots\nfrom pandas.plotting import scatter_matrix\nattributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n              \"housing_median_age\"]\nscatter_axes = scatter_matrix(housing[attributes], figsize=(12, 8));"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#handling-missing-values",
    "href": "posts/2021-06-13-pandas_resources.html#handling-missing-values",
    "title": "Pandas cookbook",
    "section": "Handling missing values",
    "text": "Handling missing values\nOption A: Dropping values in the columns with NaN\nhousing.dropna(subset=[\"total_bedrooms\"])\nOption B: Drop that column entirely\nhousing.drop(\"total_bedrooms\", axis=1)\nOption C: Fill missing value with some central tendency\nattribute_median = housing[\"total_bedrooms\"].median()\nhousing[\"total_bedrooms\"].fillna( attribute_median, inplace=True ) \nChecking the NULL enties in the dataset\nsample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\nGet number of NULL entries in the dataframe columns\nnull_columns=food_df.columns[food_df.isnull().any()]\nfood_df[null_columns].isnull().sum()\nPrint full rows having NULL entries in the df\nis_NaN = food_df.isnull()\nrow_has_NaN = is_NaN.any(axis=1)\nrows_with_NaN = food_df[row_has_NaN]\nDropping NULL only from a particular column\ndf_income_drop_na = df.dropna(subset=['INCOME2'])"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#join-two-datasets",
    "href": "posts/2021-06-13-pandas_resources.html#join-two-datasets",
    "title": "Pandas cookbook",
    "section": "Join two datasets",
    "text": "Join two datasets\n1. Inner join\nOnly returns rows with matching values in both df.\nA_B = A.merge(B, on = &lt;common column name&gt;, suffixes = tuples to append the name of columns with similar names) \nRemember that .merge() only returns rows where the values match in both tables.\n2. Merging more than one table\ndf1.merge(df2, on='col_A') \\\n    .merge(df3, on='col_B') \\\n    .merge(df4, on='col_C')\n3. Merge across multiple columns tags\ndf1.merge( df2, on = ['col_A', 'col_B'])"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#searching",
    "href": "posts/2021-06-13-pandas_resources.html#searching",
    "title": "Pandas cookbook",
    "section": "Searching",
    "text": "Searching\nFind columns names based on a string\ndf_raw_data.columns[df_raw_data.columns.str.contains('STRING_SUBSET')]\nFind rows in column Model based on a string\nSelect all row entries that start with Mac\ndf[df['model'].str.match('Mac')]\nSelect all row entries that contain ac in it\ndf[df['model'].str.contains('ac')]\nFilter entries in the column based on the threshold * Data has indian-inspired international cuisines which are not what we are interested in\ncuisin_counts = food_df['Cuisine'].value_counts()\ncuisin_counts_more_than_50 = cuisin_counts.iloc[np.where(cuisin_counts &gt; 50)]\nfood_df_top_cuisine = food_df.loc[ food_df['Cuisine'].isin(list(cuisin_counts_more_than_50.index))  ] \n#Dropping entries in `food_df` which have non-ind\nClean up entries with partial matches\ndf.loc[df['Store Name'].str.contains('Wal', case=False), 'Store_Group_1'] = 'Walmarts'\nsouth_indian_tag = ['Chettinad', 'Andhra', 'Karnataka', 'Tamil Nadu', 'Kerala Recipes', 'South Indian Recipes']\nfood_df_top_cuisine.loc[food_df_top_cuisine['Cuisine'].isin(south_indian_tag), 'Combined_cuisine'] = 'South Indian'\nWith or statements\nString_filter_option = ['cond_1', 'cond_2']\npandas_dataframe[ Pandas_dataframe[ 'columns' ].str.contains('|'.join(string_filter_option)) ] \nFilter rows in the pandas df with another list\nmonth_list = ['May','Jun','Jul','Aug','Sep']\ndf_pH.loc[df_pH['Month'].isin(month_list)]\nFilter out values using names: Making a separate list of those that DO NOT satisfy the constraint\nno_bands = halftime_musicians[ ~halftime_musicians.musician.str.contains('Marching') ]"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#statistics-distributions",
    "href": "posts/2021-06-13-pandas_resources.html#statistics-distributions",
    "title": "Pandas cookbook",
    "section": "Statistics & Distributions",
    "text": "Statistics & Distributions\nHistogram\ndf.hist('WTKG3')\nCDF and PDF\n# Functions for PMF and CDF, we will come to those later in the notebook \ndef pmf(pandas_series):\n    values, counts = np.unique(pandas_series, return_counts = True)\n    pmf = np.c_[ values, counts / sum(counts) ]\n\n    return pmf \n\ndef cdf(pandas_series):\n    values, counts = np.unique(pandas_series, return_counts = True)\n    pmf = np.c_[ values, counts / sum(counts) ]\n    cdf = np.zeros(shape=pmf.shape) \n    \n    for i in range(0, pmf.shape[0]):\n        cdf[i] = [pmf[i][0], np.sum(pmf[:i+1], axis=0)[-1]] \n        \n    return cdf\nConfidence interval\nA bootstrap analysis of the reduction of deaths due to handwashing\nboot_mean_diff = []\nfor i in range(3000):\n    boot_before = before_proportion.sample(frac=1, replace=True)\n    boot_after = after_proportion.sample(frac=1, replace=True)\n    boot_mean_diff.append( boot_after.mean() - boot_before.mean() )\nCalculating a 95% confidence interval from boot_mean_diff\nconfidence_interval = pd.Series(boot_mean_diff).quantile([0.025,0.975])"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#convert-variables",
    "href": "posts/2021-06-13-pandas_resources.html#convert-variables",
    "title": "Pandas cookbook",
    "section": "Convert variables",
    "text": "Convert variables\nConvert continuous variable to discrete\npd.cut \nExample 1:\nhousing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf], #bins around 2-5 income bracket\n                               labels=[1, 2, 3, 4, 5])\nUse cut when you need to segment and sort data values into bins. This function is also useful for going from a continuous variable to a categorical variable. For example, cut could convert ages to groups of age ranges. Supports binning into an equal number of bins, or a pre-specified array of bins.\nExample 2:\npd.cut(iris_df['sepal_length'], bins=3, right=True, labels=['low','med','high'], retbins=True)\nFine tune the labeling\ndef convert_to_cat(panda_series):\n    first_quarter = panda_series.describe()['25%']\n    third_quarter = panda_series.describe()['75%']\n    print(first_quarter, third_quarter)\n    \n    cat_list = ['temp'] * len(panda_series) \n\n    for i, entry in enumerate(panda_series):\n        if entry &lt;= first_quarter: \n            cat_list[i] = 'SMALL'\n        elif first_quarter &lt; entry &lt;= third_quarter:\n            cat_list[i] = 'MED'\n        else:\n            cat_list[i] = 'LARGE'\n    \n    return cat_list\nCateogorical variables to one-hot\n# Pandas get dummies is one option \npd.get_dummies(iris_df['sepal_width_cat'], prefix='sepal_width')\nOne-hot discrete variable with more granularity\ndef OHE_discreet(point, pandas_series, intervals):\n    '''\n    define range for one-hot, for every entry find the closest value in the one-hot\n    '''\n\n    z = np.linspace(min(pandas_series), max(pandas_series), intervals)\n    ohe = np.zeros(len(z))\n    ohe[np.argmin(abs(z - point)**2)] = 1\n    return ohe\n\niris_df['sepal_width_OHE'] = iris_df['sepal_width'].apply(OHE_discreet, args=(iris_df['sepal_width'], 11))"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#grouping-data-by-entries-in-a-row",
    "href": "posts/2021-06-13-pandas_resources.html#grouping-data-by-entries-in-a-row",
    "title": "Pandas cookbook",
    "section": "Grouping data by entries in a row:",
    "text": "Grouping data by entries in a row:\nExample 1\nlicenses_zip_ward.groupby('alderman').agg({'income':'median'})\nEstimate the statistic of ‘income’ after grouping the dataframe by row entries in column ‘alderman’\nExample 2\ncounted_df = licenses_owners.groupby('title').agg({'account':'count'})\nI want to know the number of account each unique title entry has in the df. Here the column account was counted and the total entries were reported when the data frame was first grouped by entries in the title column.\nExample 3\nGroupby multiple columns and show the counts\n# Create a column that will store the month\ndata['month'] = data['date'].dt.month\n\n# Create a column that will store the year\ndata['year'] = data['date'].dt.year\n\n# Group by the month and year and count the pull requests\ncounts = data.groupby(['month','year'])['pid'].count()\nExample 4\nGroup and pivot table. Find the number of pull_request for the repo every year for the two authors:\n# The developers we are interested in\nauthors = ['xeno-by', 'soc']\n\n# Get all the developers' pull requests\nby_author = pulls.loc[ pulls['user'].isin(authors) ]\nby_author['year'] = by_author['date'].dt.year \n\n# Count the number of pull requests submitted each year\ncounts = by_author.groupby(['user', 'year']).agg({'pid': 'count'}).reset_index()\n\n# Convert the table to a wide format\ncounts_wide = counts.pivot_table(index='year', columns='user', values='pid', fill_value=0)\n\n# Plot the results\ncounts_wide"
  },
  {
    "objectID": "posts/2021-05-23-brfss_eda.html",
    "href": "posts/2021-05-23-brfss_eda.html",
    "title": "Exploratory Data Analysis on Behavioral Risk Factor Surveillance System (BRFSS) dataset",
    "section": "",
    "text": "Before beginning with any sort of model building work it is important you get to know the data you’re handling. This includes not just understand the columns and row entries in the dataset but also the simple understanding on what each of the variable in the data means.\nThis step is a vital foundation for any successful analytics, modeling, and prediction task. It is called as the data exploratory analysis.\nThese are few some steps you can keep in mind when starting with an exploration of new dataset being presented: 1. Understand each descriptor in the data, type of data being encoded 2. Cleaning the data – look at null and NaN 3. Visualize variable distributions – use (appropriate) summary statistics * Primary analysis of data spread – histograms * Distribution functions 1. Probability mass functions 2. Cumulative distribution function 3. Kernel density estimates\n\nExplore relationship between variables\n\nScatter plots\nSimple (linear) correlations (Pearson statistics)\nSimple (linear) regression\n\nExplore multivariate relationships\n\nMultiple regression (for continuous variables)\nLogistic regression (for categorical variables)\n\n\nIn this notebook I will cover some of these steps as we explore the Behavioral Risk Factor Surveillance Survey (BRFSS) dataset and try to tease out simple correlations with the variables.\nBRFSS data obtained from: * https://www.kaggle.com/sakinak/behavioral-risk-factor-surveillance-survey-201619\nCode book: This is an extremely important document helping us make sense of the data we’ve imported * https://www.cdc.gov/brfss/annual_data/2019/pdf/codebook19_llcp-v2-508.HTML\n\nimport os\nimport numpy as np \nimport copy \nimport pandas as pd\n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns \n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 15,\n'axes.titlesize' : 20,\n'axes.labelsize' : 15,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 10,\n'ytick.labelsize' : 10,\n}\n \nplt.rcParams.update(plot_params)\nsns.set_palette(\"colorblind\")\nsns.color_palette('colorblind')\n\n\n\n\n\n# Functions for PMF and CDF, we will come to those later in the notebook \ndef pmf(pandas_series):\n    values, counts = np.unique(pandas_series, return_counts = True)\n    pmf = np.c_[ values, counts / sum(counts) ]\n    return pmf \n\ndef cdf(pandas_series):\n    values, counts = np.unique(pandas_series, return_counts = True)\n    pmf = np.c_[ values, counts / sum(counts) ]\n    cdf = np.zeros(shape=pmf.shape) \n    \n    for i in range(0, pmf.shape[0]):\n        cdf[i] = [pmf[i][0], np.sum(pmf[:i+1], axis=0)[-1]] \n        \n    return cdf \n\n\n# Read archive file -- considering only the 2019 dataset \ndf = pd.read_csv('./archive/2019.csv')\n\n\ndf.columns\n\nIndex(['Unnamed: 0', '_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR',\n       'DISPCODE', 'SEQNO', '_PSU',\n       ...\n       '_VEGESU1', '_FRTLT1A', '_VEGLT1A', '_FRT16A', '_VEG23A', '_FRUITE1',\n       '_VEGETE1', '_FLSHOT7', '_PNEUMO3', '_AIDTST4'],\n      dtype='object', length=343)\n\n\n\ndf.shape\n\n(418268, 343)\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 418268 entries, 0 to 418267\nColumns: 343 entries, Unnamed: 0 to _AIDTST4\ndtypes: float64(280), int64(63)\nmemory usage: 1.1 GB\n\n\n\ndf.columns[ df.isna().any() ]\n\nIndex(['CTELENM1', 'PVTRESD1', 'COLGHOUS', 'STATERE1', 'CELPHONE', 'LADULT1',\n       'COLGSEX', 'NUMADULT', 'LANDSEX', 'NUMMEN',\n       ...\n       'FRUTDA2_', 'GRENDA1_', 'FRNCHDA_', 'POTADA1_', 'VEGEDA2_', '_FRUTSU1',\n       '_VEGESU1', '_FLSHOT7', '_PNEUMO3', '_AIDTST4'],\n      dtype='object', length=275)\n\n\nThe data is too big to be visualized and described using traditional NaN and summary statistics, rather let’s just checkout key columns and understand their distribution"
  },
  {
    "objectID": "posts/2021-05-23-brfss_eda.html#key-ideas",
    "href": "posts/2021-05-23-brfss_eda.html#key-ideas",
    "title": "Exploratory Data Analysis on Behavioral Risk Factor Surveillance System (BRFSS) dataset",
    "section": "",
    "text": "Before beginning with any sort of model building work it is important you get to know the data you’re handling. This includes not just understand the columns and row entries in the dataset but also the simple understanding on what each of the variable in the data means.\nThis step is a vital foundation for any successful analytics, modeling, and prediction task. It is called as the data exploratory analysis.\nThese are few some steps you can keep in mind when starting with an exploration of new dataset being presented: 1. Understand each descriptor in the data, type of data being encoded 2. Cleaning the data – look at null and NaN 3. Visualize variable distributions – use (appropriate) summary statistics * Primary analysis of data spread – histograms * Distribution functions 1. Probability mass functions 2. Cumulative distribution function 3. Kernel density estimates\n\nExplore relationship between variables\n\nScatter plots\nSimple (linear) correlations (Pearson statistics)\nSimple (linear) regression\n\nExplore multivariate relationships\n\nMultiple regression (for continuous variables)\nLogistic regression (for categorical variables)\n\n\nIn this notebook I will cover some of these steps as we explore the Behavioral Risk Factor Surveillance Survey (BRFSS) dataset and try to tease out simple correlations with the variables.\nBRFSS data obtained from: * https://www.kaggle.com/sakinak/behavioral-risk-factor-surveillance-survey-201619\nCode book: This is an extremely important document helping us make sense of the data we’ve imported * https://www.cdc.gov/brfss/annual_data/2019/pdf/codebook19_llcp-v2-508.HTML\n\nimport os\nimport numpy as np \nimport copy \nimport pandas as pd\n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns \n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 15,\n'axes.titlesize' : 20,\n'axes.labelsize' : 15,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 10,\n'ytick.labelsize' : 10,\n}\n \nplt.rcParams.update(plot_params)\nsns.set_palette(\"colorblind\")\nsns.color_palette('colorblind')\n\n\n\n\n\n# Functions for PMF and CDF, we will come to those later in the notebook \ndef pmf(pandas_series):\n    values, counts = np.unique(pandas_series, return_counts = True)\n    pmf = np.c_[ values, counts / sum(counts) ]\n    return pmf \n\ndef cdf(pandas_series):\n    values, counts = np.unique(pandas_series, return_counts = True)\n    pmf = np.c_[ values, counts / sum(counts) ]\n    cdf = np.zeros(shape=pmf.shape) \n    \n    for i in range(0, pmf.shape[0]):\n        cdf[i] = [pmf[i][0], np.sum(pmf[:i+1], axis=0)[-1]] \n        \n    return cdf \n\n\n# Read archive file -- considering only the 2019 dataset \ndf = pd.read_csv('./archive/2019.csv')\n\n\ndf.columns\n\nIndex(['Unnamed: 0', '_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR',\n       'DISPCODE', 'SEQNO', '_PSU',\n       ...\n       '_VEGESU1', '_FRTLT1A', '_VEGLT1A', '_FRT16A', '_VEG23A', '_FRUITE1',\n       '_VEGETE1', '_FLSHOT7', '_PNEUMO3', '_AIDTST4'],\n      dtype='object', length=343)\n\n\n\ndf.shape\n\n(418268, 343)\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 418268 entries, 0 to 418267\nColumns: 343 entries, Unnamed: 0 to _AIDTST4\ndtypes: float64(280), int64(63)\nmemory usage: 1.1 GB\n\n\n\ndf.columns[ df.isna().any() ]\n\nIndex(['CTELENM1', 'PVTRESD1', 'COLGHOUS', 'STATERE1', 'CELPHONE', 'LADULT1',\n       'COLGSEX', 'NUMADULT', 'LANDSEX', 'NUMMEN',\n       ...\n       'FRUTDA2_', 'GRENDA1_', 'FRNCHDA_', 'POTADA1_', 'VEGEDA2_', '_FRUTSU1',\n       '_VEGESU1', '_FLSHOT7', '_PNEUMO3', '_AIDTST4'],\n      dtype='object', length=275)\n\n\nThe data is too big to be visualized and described using traditional NaN and summary statistics, rather let’s just checkout key columns and understand their distribution"
  },
  {
    "objectID": "posts/2021-05-23-brfss_eda.html#looking-at-individual-columns",
    "href": "posts/2021-05-23-brfss_eda.html#looking-at-individual-columns",
    "title": "Exploratory Data Analysis on Behavioral Risk Factor Surveillance System (BRFSS) dataset",
    "section": "1. Looking at individual columns",
    "text": "1. Looking at individual columns\nSex of the respondent\nData is provided in the column marked as _SEX and the label are: * MALE = 1 * FEMALE = 2\n\ndf['_SEX'].value_counts()\n\n2    228433\n1    189835\nName: _SEX, dtype: int64\n\n\nAnnual Income of the respondent\nINCOME2 Question: Is your annual household income from all sources\nValue of 77 or 99 in the row is either Refused or Not sure. So take them out\n_INCOMG Computed income categories\n\ndf['INCOME2'].value_counts()\n\n8.0     117793\n7.0      54252\n6.0      46572\n99.0     40246\n5.0      34496\n77.0     32654\n4.0      30001\n3.0      23391\n2.0      16122\n1.0      15860\nName: INCOME2, dtype: int64\n\n\n\ndf['_INCOMG'].value_counts()\n\n5    172045\n9     79781\n2     53392\n4     46572\n3     34496\n1     31982\nName: _INCOMG, dtype: int64\n\n\n\n# Replace 77 99 with NaN\ndf['INCOME2'].replace([77, 99], np.nan, inplace=True)\n\n\ndf['INCOME2'].value_counts()\n\n8.0    117793\n7.0     54252\n6.0     46572\n5.0     34496\n4.0     30001\n3.0     23391\n2.0     16122\n1.0     15860\nName: INCOME2, dtype: int64\n\n\n\ndf.shape\n\n(418268, 343)\n\n\nDrop the entries with NaN\n\ndf_income_no_nan = df.dropna(subset=['INCOME2'])\ndf_income_no_nan.shape\n\n(338487, 343)\n\n\n\ndf_income_no_nan['INCOME2'].value_counts()\n\n8.0    117793\n7.0     54252\n6.0     46572\n5.0     34496\n4.0     30001\n3.0     23391\n2.0     16122\n1.0     15860\nName: INCOME2, dtype: int64\n\n\n\npmf_income = pmf(df_income_no_nan['INCOME2'])\n\n\npmf_income\n\narray([[1.        , 0.04685557],\n       [2.        , 0.0476296 ],\n       [3.        , 0.06910457],\n       [4.        , 0.08863265],\n       [5.        , 0.10191233],\n       [6.        , 0.13758874],\n       [7.        , 0.16027794],\n       [8.        , 0.34799859]])\n\n\n\nplt.plot(pmf_income[:,0], pmf_income[:,1], marker='o')\nplt.xlabel('Income Classes')\nplt.ylabel('Frequency (normalized)')\n\nText(0, 0.5, 'Frequency (normalized)')\n\n\n\n\n\n\n\n\n\n\ncdf_income = cdf(df_income_no_nan['INCOME2'])\n\n\ncdf_income\n\narray([[1.        , 0.04685557],\n       [2.        , 0.09448516],\n       [3.        , 0.16358974],\n       [4.        , 0.25222239],\n       [5.        , 0.35413472],\n       [6.        , 0.49172346],\n       [7.        , 0.65200141],\n       [8.        , 1.        ]])\n\n\n\nplt.plot(cdf_income[:,0], cdf_income[:,1], marker='o')\nplt.xlabel('Income Classes')\nplt.ylabel('Cumulative Frequency (normalized)')\n\nText(0, 0.5, 'Cumulative Frequency (normalized)')\n\n\n\n\n\n\n\n\n\nLooking at annual income classes as per sex of the respondent\n\ndf_income_no_nan_male = df_income_no_nan.loc[ df_income_no_nan['_SEX'] == 1 ]\n\n\ndf_income_no_nan_female = df_income_no_nan.loc[ df_income_no_nan['_SEX'] == 2 ]\n\n\ncdf_income_male = cdf(df_income_no_nan_male['INCOME2'])\ncdf_income_female = cdf(df_income_no_nan_female['INCOME2'])\n\n\nplt.plot(cdf_income_male[:,0], cdf_income_male[:,1], marker='o', label='Male')\nplt.plot(cdf_income_female[:,0], cdf_income_female[:,1], marker='o', label='Female')\nplt.plot(cdf_income[:,0], cdf_income[:,1], linestyle='--', label='Total')\nplt.xlabel('Income Classes')\nplt.ylabel('Cumulative Frequency (normalized)')\nplt.legend()\n\n\n\n\n\n\n\n\nConsidering the education level of the respondents\nEDUCA What is the highest grade or year of school you completed?\n9 and BLANK == Missing and Refused\n_EDUCAG Computed level of education completed categories\n\ndf['EDUCA'].value_counts().sort_index()\n\n1.0       619\n2.0      9940\n3.0     19506\n4.0    111890\n5.0    116591\n6.0    157887\n9.0      1809\nName: EDUCA, dtype: int64\n\n\n\ndf['EDUCA'].replace([9], np.nan, inplace=True)\n\n\ndf['_EDUCAG'].value_counts()\n\n4    157887\n3    116591\n2    111890\n1     30065\n9      1835\nName: _EDUCAG, dtype: int64\n\n\n\ndf['_EDUCAG'].value_counts(normalize=True).sort_index()\n\n1    0.071880\n2    0.267508\n3    0.278747\n4    0.377478\n9    0.004387\nName: _EDUCAG, dtype: float64\n\n\n\ndf_education_no_na = df.dropna(subset = ['EDUCA'])\n\n\ndf_education_no_na.shape\n\n(416433, 343)\n\n\n\ndf_education_no_na_male = df_education_no_na.loc[ df_education_no_na['_SEX'] == 1 ]\ndf_education_no_na_female = df_education_no_na.loc[ df_education_no_na['_SEX'] == 2 ]\n\n\ncdf_educa_male = cdf(df_education_no_na_male['EDUCA'])\ncdf_educa_female = cdf(df_education_no_na_female['EDUCA'])\n\n\ncdf_educa = cdf(df_education_no_na['EDUCA'])\n\n\ncdf_educa\n\narray([[1.00000000e+00, 1.48643359e-03],\n       [2.00000000e+00, 2.53558195e-02],\n       [3.00000000e+00, 7.21964878e-02],\n       [4.00000000e+00, 3.40883167e-01],\n       [5.00000000e+00, 6.20858577e-01],\n       [6.00000000e+00, 1.00000000e+00]])\n\n\n\nplt.plot(cdf_educa_male[:,0], cdf_educa_male[:,1], marker='o', label='Male')\nplt.plot(cdf_educa_female[:,0], cdf_educa_female[:,1], marker='o', label='Female')\nplt.plot(cdf_educa[:,0], cdf_educa[:,1], linestyle='--', label='Total')\nplt.xlabel('Level of education')\nplt.ylabel('Cumulative Frequency (normalized)')\nplt.legend()\n\n\n\n\n\n\n\n\nHeight and Weight\n\n## Height in meters \ndf.hist('HTM4')\n\narray([[&lt;AxesSubplot:title={'center':'HTM4'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\n\n## Weight in kilograms:\ndf.hist('WTKG3')\n\narray([[&lt;AxesSubplot:title={'center':'WTKG3'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\n\ndf['WTKG3'] = df['WTKG3'] / 100\n\n\n## Weight in kilograms:\ndf.hist('WTKG3')\n\narray([[&lt;AxesSubplot:title={'center':'WTKG3'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\n\nwt_male = df.loc[ df['_SEX'] == 1 ]['WTKG3']\nwt_female = df.loc[ df['_SEX'] == 2 ]['WTKG3']\n\n\nplt.hist(wt_male, alpha=0.6, label='male')\nplt.hist(wt_female, alpha=0.6, label='female')\nplt.xlabel('Weight (kg)')\nplt.legend()\n\n\n\n\n\n\n\n\n\n## Age category -- divided in 5 year interval \ndf.hist('_AGEG5YR')\n\narray([[&lt;AxesSubplot:title={'center':'_AGEG5YR'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\n\nQuick plot for weight vs age-group\n\n## Quick plot for weight as per age \ndf_no_nans = df.dropna( subset=['_AGEG5YR', 'WTKG3'] )\n\n\nfig, ax = plt.subplots(1,1, figsize=(6,6))\nax.scatter( df_no_nans['_AGEG5YR'], df_no_nans['WTKG3'], marker='o', alpha=0.5)\nax.set_xlabel('Age group')\nax.set_ylabel('Weight (kg)')\n\nText(0, 0.5, 'Weight (kg)')\n\n\n\n\n\n\n\n\n\nIt makes much more sense to show these as either violin or box plot:\n\nViolin plot – KDE for that column around the y Each column is a graphical representation of the distribution of weight in one age group. The width of these shapes is proportional to the estimated density, so it’s like two vertical PDFs plotted back to back.  \nBox plot – Each box represents the interquartile range, or IQR, from the 25th to the 75th percentile. The line in the middle of each box is the median. The spines sticking out of the top and bottom show the minimum and maximum values. Looking at the medians, it seems like people in their 40s are the heaviest; younger and older people are lighter. Looking at the sizes of the boxes, it seems like people in their 40s have the most variability in weight, too. These plots also show how skewed the distribution of weight is; that is, the heaviest people are much farther from the median than the lightest people.\n\n\nimport seaborn as sns\nax = sns.boxplot(x = '_AGEG5YR', y = 'WTKG3', whis=10, data = df_no_nans)\nax.set_xlabel('AGE GROUP')\nax.set_ylabel('WEIGHT (Kgs)')\n\nText(0, 0.5, 'WEIGHT (Kgs)')\n\n\n\n\n\n\n\n\n\n\n\nQuick plot for height vs weight\n\ndf_height_wt = df.dropna( subset=['HTM4', 'WTKG3'] ).sample(50000)\n\n\nfig, ax = plt.subplots(1,1, figsize=(6,6))\nax.scatter( df_height_wt['HTM4'], df_height_wt['WTKG3'], marker='o', alpha=0.5)\nax.set_xlabel('Height (m)')\nax.set_ylabel('Weight (kg)')\n\nText(0, 0.5, 'Weight (kg)')\n\n\n\n\n\n\n\n\n\n\nheight_jitters = df_height_wt['HTM4'] + np.random.normal(0, 2, size=len(df_height_wt))\nweight_jitters = df_height_wt['WTKG3'] + np.random.normal(0, 2, size=len(df_height_wt))\n\n\nfig, ax = plt.subplots(1,1, figsize=(6,6))\nax.scatter( height_jitters, weight_jitters, marker='o', alpha=0.01)\nax.set_xlabel('Height (m)')\nax.set_ylabel('Weight (kg)')\n\nText(0, 0.5, 'Weight (kg)')\n\n\n\n\n\n\n\n\n\nFit a linear regression model\n\nfrom sklearn.linear_model import LinearRegression\nx = height_jitters.values.reshape(-1,1)\ny = weight_jitters.values.reshape(-1,1)\nreg = LinearRegression().fit(x, y)\n\n\nx.min()\n\n90.14298210689765\n\n\n\nprint(reg.coef_, reg.intercept_, reg.score(x,y))\n\n[[0.90102916]] [-71.05446729] 0.2163310658640062\n\n\n\nheight_test = np.linspace(x.min(), x.max()).reshape(-1, 1)\n\n\nfig, ax = plt.subplots(1,1, figsize=(6,6))\nax.plot( height_test, reg.predict(height_test), 'r--', alpha=0.5)\nax.scatter( height_jitters, weight_jitters, marker='o', alpha=0.01)\nax.set_xlabel('Height (m)')\nax.set_ylabel('Weight (kg)')\n\nText(0, 0.5, 'Weight (kg)')"
  },
  {
    "objectID": "posts/2021-01-10-pncbirthday.html",
    "href": "posts/2021-01-10-pncbirthday.html",
    "title": "Solving the birthday problem using simple counting",
    "section": "",
    "text": "This problem and discussion herein was adapted from Computational Thinking course offered by MIT. Link to course page\nQuestion from First Course in Probability (Sheldon Ross):\nGiven 20 people, what is the probability that, among the 12 months in the year, there are 4 months containing exactly 2 birthdays and 4 containing exactly 3 birthdays? Link to problem\n\nimport os \nimport time\nimport numpy as np \n\nnp.random.seed(42)\n\n\nProblem setup\nRather than using a formula to estimate the probability we can setup an experiment using for-loops to mimic the trials and then count the actual number of cases where the condition is met.\n\nmonth_number = np.arange(1, 13) # array of months \nnumber_of_people = 20 #Number of people considered\nsample = np.random.choice(month_number, size=number_of_people, replace=True, )\n\nHere sample is the randomized set of 20 birthdays. Each entry is a month. Length of sample is same as number of people in the experiment, 20 in this case.\nHighlight cases which satisfy the constraints: 1. 4 months have exactly 2 birthdays 2. 4 months have exactly 3 birthdays\nFor that first create an array with frequency of birthdays in each month:\n\nfrequency = np.zeros(len(month_number)) #This is zeros frequency array\nfor _entry in sample:\n    _index = _entry - 1\n    frequency[_index] = frequency[_index] + 1\n\n\nsample\n\narray([ 7,  4, 11,  8,  5,  7, 10,  3,  7, 11, 11,  8,  5,  4,  8,  8,  3,\n        6,  5,  2])\n\n\n\nfrequency\n\narray([0., 1., 2., 2., 3., 1., 3., 4., 0., 1., 3., 0.])\n\n\nfrequency array shows how many birthday are there in a month (Jan - Dec).\nOnce we have that, now we have to consider the conditions given in the problem. We can either do this using for/if statement or using numpy.argwhere, where the number of months satisfying the conditions is estimated directly.\n\nlen(np.argwhere(frequency == 2)) \n\n2\n\n\nNow putting it all together and doing multiple trials.\nIn this case, I do 1,500,000 trials and count the ratio of successes to the total trials. While this process takes time, it is better than remembering permutation and combination formulae ;P\nThis is a variant of monte-carlo simulation.\n\n%%time\n# putting it all togther \n_number_of_trials = 1_500_000\n_success = 0 \n  \nfor _ in range(_number_of_trials):\n\n    sample = np.random.choice(month_number, size=number_of_people, replace=True)\n    \n    frequency = np.zeros( len(month_number) )\n    for _entry in sample:\n        if _entry in month_number:\n            _index = _entry - 1\n            frequency[_index] = frequency[_index] + 1\n    \n    if ( len(np.argwhere(frequency == 2)) == 4 ) and ( len(np.argwhere(frequency == 3)) == 4 ): \n        _success = _success + 1\n\nprint('Probability of success = {}'.format(_success / _number_of_trials))\n\nProbability of success = 0.00106\nCPU times: user 3min 8s, sys: 2.08 s, total: 3min 10s\nWall time: 3min 10s\n\n\nThis answer is very close you’d get from using probablity counting and formula!"
  },
  {
    "objectID": "posts/IMDB-files/bollywood_imdb_scrapper.html",
    "href": "posts/IMDB-files/bollywood_imdb_scrapper.html",
    "title": "Web-scraping Hindi (Bollywood) movies from IMDb",
    "section": "",
    "text": "from requests import get \nimport numpy as np \nimport pandas as pd \nfrom bs4 import BeautifulSoup\nimport time as time \nfrom tqdm import tqdm\n\nfrom IPython.core.display import clear_output\n\n\nnames, year, imdb_rating, metascore, num_votes = [], [], [], [], [] \n\nstart_time = time.time()\nrequests = 0\n\nyears_url = [str(i) for i in range(1950,2006)]\npage_iter = [0, 51, 101, 151, 201]\n\n\nfor year_url in tqdm(years_url):\n    for page_num in tqdm(page_iter):\n        #URL to parse \n        url = 'https://www.imdb.com/search/title/?title_type=feature,&release_date={0},{0}&countries=in&languages=hi&sort=num_votes,desc&start={1}&ref_=adv_prv'.format(int(year_url), int(page_num))\n        response = get(url)\n        \n        #Sleep to carve out load \n        time.sleep(np.random.randint(1,5))\n        \n        #Estimate time elapsed per request\n        requests += 1\n        elapsed_time = time.time() - start_time\n        print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n        clear_output(wait = True)\n        \n        html_soup = BeautifulSoup(response.text, 'html.parser')\n        movie_containers = html_soup.find_all('div', class_='lister-item mode-advanced')\n        \n        for i, container in enumerate(movie_containers):\n            container_entry = movie_containers[i] \n            movie_name = container_entry.h3.a.text\n            names.append(movie_name)\n            \n            movie_year = container_entry.h3.find('span',class_='lister-item-year text-muted unbold').text.strip('()')\n            year.append(movie_year)\n            #print(movie_name, movie_year)\n            \n            try:\n                movie_rating = float(container_entry.strong.text)\n                imdb_rating.append(movie_rating)\n            except AttributeError:\n                imdb_rating.append(np.nan)\n            \n            try:\n                movie_votes = float(''.join(container_entry.find('span', attrs = {'name':'nv'}).text.split(',')))\n                num_votes.append(movie_votes)\n            except (AttributeError, ValueError):\n                num_votes.append(np.nan)\n                \n            try:\n                movie_metascore = float(container_entry.find('span', class_='metascore').text.strip())\n                metascore.append(movie_metascore)\n            except AttributeError:\n                metascore.append(np.nan)\n    \n    print('Making dataframe for year {}'.format(year_url))\n    df_movies = pd.DataFrame({'name':names,'year':year,'rating':imdb_rating,'metascore':metascore,'num_votes':num_votes})\n    df_movies.to_csv('./temp_imdb_files/bollywood_data_{}.csv'.format(year_url),sep=',',header=True, index=False)\n    del df_movies\n\n\n100%|██████████| 5/5 [00:30&lt;00:00,  6.14s/it]\n100%|██████████| 56/56 [20:00&lt;00:00, 21.44s/it]\n\n\nMaking dataframe for year 2005\n\n\n\n\n\n\ndf1 = pd.read_csv('./temp_imdb_files/bollywood_data_2005.csv',sep=',')\ndf2 = pd.read_csv('./temp_imdb_files/bollywood_data_2020.csv',sep=',')\n\n\ndf3 = pd.concat((df1, df2)).reset_index(drop=True)\n\n\ndf3.to_csv('./bollywood_movies_data_1950_2020_new.csv',sep=',',header=True, index=False)\n\n\ndf3.year.value_counts()\n\n2004           249\n2001           249\n2005           248\n2000           246\n1991           241\n              ... \nII) (1988        1\nII) (1957        1\nXVII) (2016      1\nIV) (2011        1\nI) (1954         1\nName: year, Length: 181, dtype: int64"
  },
  {
    "objectID": "posts/2020-10-19-pytorch_transfer_learning_basics.html",
    "href": "posts/2020-10-19-pytorch_transfer_learning_basics.html",
    "title": "Transfer learning walkthrough using Pytorch",
    "section": "",
    "text": "Transfer learning is a technique where a deep-learning model trained on another problem (which usually has lot of data and good accuracy for that task) is slightly modified to be used on a new problem. This is an important concept as building an entirely new model might not be take a long time or there might not be enough data for the training of that particular task. The idea is the weights/parameters of the model at the start of the layers have similar functionality and assist in better performance on the new task. Usually we freeze the weights training of the hidden layers an tweak the output layer slightly to account for the change in the task.\nSo for example, maybe you could have the neural network learn to recognize objects like cats and then use that knowledge or use part of that knowledge to help you do a better job reading x-ray scans. This is called transfer learning. Sometimes you can start with the weights and biases of a published netowrks as a starting point.\nMore details about Transfer Learning can be found on Stanford’s CS231 CNN course here\nIn this example I use a pre-trained convolutional neural network model (ResNet-18) and modify ONLY the last layers of the model to use for our case. This model is trained on millions on images with 1000 image categories.\nThese two major transfer learning scenarios look as follows:\n\nFinetuning the convnet: Instead of random initialization, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. Rest of the training looks as usual.\nConvNet as fixed feature extractor: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained.\n\nThis tutorial was adapted from PyTorch’s official documentation (Link)\n\nimport time \nimport os \nimport copy \nimport matplotlib.pyplot as plt\nimport numpy as np \n\nimport torch \nimport torch.nn as nn \nimport torch.optim as optim \nfrom torch.optim import lr_scheduler\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\n\n%matplotlib inline \n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\n\ndevice(type='cpu')\n\n\n\n# Define pre-processing steps for the image before being converted to Tensors\n# As defined on the tutorial page \n\nmean = np.array([0.5, 0.5, 0.5])\nstd = np.array([0.25, 0.25, 0.25])\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n}\n\n\ndata_dir = 'data/hymenoptera_data/'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\n\n\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=0)\n              for x in ['train', 'val']}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n\n\nclass_names = image_datasets['train'].classes\nprint(class_names)\n\n['ants', 'bees']\n\n\n\n# From the pytorch tutorial\ndef imshow(inp, title):\n    \"\"\"Imshow for Tensor.\"\"\"\n    fig, ax = plt.subplots(1,1, figsize=(10,10))\n    inp = inp.numpy().transpose((1, 2, 0))\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    ax.imshow(inp)\n    plt.title(title)\n    plt.show()\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])\n\n\n\n\n\n\n\n\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                scheduler.step() #Step in the scheduler \n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model for which val_acc is better \n            if phase == 'val' and epoch_acc &gt; best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    \n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    \n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\n\n\n\nDownload a pretrained model, tweak the model architecture for our use-case, and (re)train on the new dataset\n\n\nDownload the model (ResNet18 in this case)\nChange the output of the final layer – in this case from 1000 output nodes to 2 since we’re looking at only ‘bee’ and ‘ant’\nRe-train the model\n\nOther models available from PyTorch can be viewed (here)\n\n#Load a pre-trained model -- ResNet18 model \nmodel = torchvision.models.resnet18(pretrained=True)\nprint(model)\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\nWe’re interested to only change the final layer named fc – so we will look at that layers features, the attributes for each module in the model are stored as keys.\n\nnum_features = model.fc.in_features\n\n# Define a new linear layer as per our need -- 2 classes instead of 1000 as defined in the original \nmodel.fc = nn.Linear(num_features, len(class_names)) #Number of classes in the end \n\n# Send model to device \nmodel.to(device)\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)\n\n\n\ncriterion = nn.CrossEntropyLoss() \noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n#Scheduler to update the learning rate for the SGD \n'''\nAfter every 7 steps in the optimizer the learning rate will be multiplied by 0.1 \n'''\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1) \n\n\nmodel = train_model(model, criterion=criterion, optimizer=optimizer, scheduler=step_lr_scheduler, num_epochs=5)\n\nEpoch 0/4\n----------\ntrain Loss: 1.0695 Acc: 0.5000\nval Loss: 0.6179 Acc: 0.6340\n\nEpoch 1/4\n----------\ntrain Loss: 0.7267 Acc: 0.5820\nval Loss: 0.8217 Acc: 0.5948\n\nEpoch 2/4\n----------\ntrain Loss: 0.6941 Acc: 0.6230\nval Loss: 0.8131 Acc: 0.6667\n\nEpoch 3/4\n----------\ntrain Loss: 0.6948 Acc: 0.5902\nval Loss: 1.6474 Acc: 0.5882\n\nEpoch 4/4\n----------\ntrain Loss: 0.6834 Acc: 0.6270\nval Loss: 0.9145 Acc: 0.6275\n\nTraining complete in 5m 11s\nBest val Acc: 0.666667\n\n\n\n\n\nIn this case ONLY the weights of the final layer are trained. This might reduce the accuracy but would greatly reduce the amount of time taken to fit the model since the number of weights to be optimized is greatly reduced.\n\n#Load a pre-trained model -- ResNet18 model \nmodel = torchvision.models.resnet18(pretrained=True)\n\n\n#Method to freeze the layer parameters -- just get the require grad attribute to FALSE!  \nfor param in model.parameters(): \n    param.requires_grad = False \n\n\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 2) #Number of classes in the end \nmodel.to(device)\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)\n\n\nThis block is same as before\n\ncriterion = nn.CrossEntropyLoss() \noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n#Scheduler to update the learning rate for the SGD \n'''\nAfter every 7 steps in the optimizer the learning rate will be multiplied by 0.1 \n'''\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1) \n\nModel training\n\nmodel = train_model(model, criterion=criterion, optimizer=optimizer, scheduler=step_lr_scheduler, num_epochs=5)\n\nEpoch 0/4\n----------\ntrain Loss: 0.6937 Acc: 0.5615\nval Loss: 0.5267 Acc: 0.7974\n\nEpoch 1/4\n----------\ntrain Loss: 0.5915 Acc: 0.7008\nval Loss: 0.4388 Acc: 0.8627\n\nEpoch 2/4\n----------\ntrain Loss: 0.5249 Acc: 0.7623\nval Loss: 0.3686 Acc: 0.9216\n\nEpoch 3/4\n----------\ntrain Loss: 0.5079 Acc: 0.7664\nval Loss: 0.3188 Acc: 0.9477\n\nEpoch 4/4\n----------\ntrain Loss: 0.4556 Acc: 0.8115\nval Loss: 0.3007 Acc: 0.9281\n\nTraining complete in 2m 18s\nBest val Acc: 0.947712\n\n\nUsing fine-tuning and re-training all the weights for the new network take longer and may result in lower acceracy than having the weights fixed. When we keep the weights in earlier layers fixed, we save a lot of time in the model training aand the performance of the model is also better (provided the two tasks are quite similar). Given the network is deep, optimizing the weights for this network from scratch would have been difficult and time consuming. For such a case, transfer learning seems to be a good option."
  },
  {
    "objectID": "posts/2020-10-19-pytorch_transfer_learning_basics.html#what-is-transfer-learning",
    "href": "posts/2020-10-19-pytorch_transfer_learning_basics.html#what-is-transfer-learning",
    "title": "Transfer learning walkthrough using Pytorch",
    "section": "",
    "text": "Transfer learning is a technique where a deep-learning model trained on another problem (which usually has lot of data and good accuracy for that task) is slightly modified to be used on a new problem. This is an important concept as building an entirely new model might not be take a long time or there might not be enough data for the training of that particular task. The idea is the weights/parameters of the model at the start of the layers have similar functionality and assist in better performance on the new task. Usually we freeze the weights training of the hidden layers an tweak the output layer slightly to account for the change in the task.\nSo for example, maybe you could have the neural network learn to recognize objects like cats and then use that knowledge or use part of that knowledge to help you do a better job reading x-ray scans. This is called transfer learning. Sometimes you can start with the weights and biases of a published netowrks as a starting point.\nMore details about Transfer Learning can be found on Stanford’s CS231 CNN course here\nIn this example I use a pre-trained convolutional neural network model (ResNet-18) and modify ONLY the last layers of the model to use for our case. This model is trained on millions on images with 1000 image categories.\nThese two major transfer learning scenarios look as follows:\n\nFinetuning the convnet: Instead of random initialization, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. Rest of the training looks as usual.\nConvNet as fixed feature extractor: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained.\n\nThis tutorial was adapted from PyTorch’s official documentation (Link)\n\nimport time \nimport os \nimport copy \nimport matplotlib.pyplot as plt\nimport numpy as np \n\nimport torch \nimport torch.nn as nn \nimport torch.optim as optim \nfrom torch.optim import lr_scheduler\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\n\n%matplotlib inline \n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\n\ndevice(type='cpu')\n\n\n\n# Define pre-processing steps for the image before being converted to Tensors\n# As defined on the tutorial page \n\nmean = np.array([0.5, 0.5, 0.5])\nstd = np.array([0.25, 0.25, 0.25])\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n}\n\n\ndata_dir = 'data/hymenoptera_data/'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\n\n\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=0)\n              for x in ['train', 'val']}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n\n\nclass_names = image_datasets['train'].classes\nprint(class_names)\n\n['ants', 'bees']\n\n\n\n# From the pytorch tutorial\ndef imshow(inp, title):\n    \"\"\"Imshow for Tensor.\"\"\"\n    fig, ax = plt.subplots(1,1, figsize=(10,10))\n    inp = inp.numpy().transpose((1, 2, 0))\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    ax.imshow(inp)\n    plt.title(title)\n    plt.show()\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])\n\n\n\n\n\n\n\n\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                scheduler.step() #Step in the scheduler \n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model for which val_acc is better \n            if phase == 'val' and epoch_acc &gt; best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    \n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    \n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\n\n\n\nDownload a pretrained model, tweak the model architecture for our use-case, and (re)train on the new dataset\n\n\nDownload the model (ResNet18 in this case)\nChange the output of the final layer – in this case from 1000 output nodes to 2 since we’re looking at only ‘bee’ and ‘ant’\nRe-train the model\n\nOther models available from PyTorch can be viewed (here)\n\n#Load a pre-trained model -- ResNet18 model \nmodel = torchvision.models.resnet18(pretrained=True)\nprint(model)\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\nWe’re interested to only change the final layer named fc – so we will look at that layers features, the attributes for each module in the model are stored as keys.\n\nnum_features = model.fc.in_features\n\n# Define a new linear layer as per our need -- 2 classes instead of 1000 as defined in the original \nmodel.fc = nn.Linear(num_features, len(class_names)) #Number of classes in the end \n\n# Send model to device \nmodel.to(device)\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)\n\n\n\ncriterion = nn.CrossEntropyLoss() \noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n#Scheduler to update the learning rate for the SGD \n'''\nAfter every 7 steps in the optimizer the learning rate will be multiplied by 0.1 \n'''\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1) \n\n\nmodel = train_model(model, criterion=criterion, optimizer=optimizer, scheduler=step_lr_scheduler, num_epochs=5)\n\nEpoch 0/4\n----------\ntrain Loss: 1.0695 Acc: 0.5000\nval Loss: 0.6179 Acc: 0.6340\n\nEpoch 1/4\n----------\ntrain Loss: 0.7267 Acc: 0.5820\nval Loss: 0.8217 Acc: 0.5948\n\nEpoch 2/4\n----------\ntrain Loss: 0.6941 Acc: 0.6230\nval Loss: 0.8131 Acc: 0.6667\n\nEpoch 3/4\n----------\ntrain Loss: 0.6948 Acc: 0.5902\nval Loss: 1.6474 Acc: 0.5882\n\nEpoch 4/4\n----------\ntrain Loss: 0.6834 Acc: 0.6270\nval Loss: 0.9145 Acc: 0.6275\n\nTraining complete in 5m 11s\nBest val Acc: 0.666667\n\n\n\n\n\nIn this case ONLY the weights of the final layer are trained. This might reduce the accuracy but would greatly reduce the amount of time taken to fit the model since the number of weights to be optimized is greatly reduced.\n\n#Load a pre-trained model -- ResNet18 model \nmodel = torchvision.models.resnet18(pretrained=True)\n\n\n#Method to freeze the layer parameters -- just get the require grad attribute to FALSE!  \nfor param in model.parameters(): \n    param.requires_grad = False \n\n\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 2) #Number of classes in the end \nmodel.to(device)\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)\n\n\nThis block is same as before\n\ncriterion = nn.CrossEntropyLoss() \noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n#Scheduler to update the learning rate for the SGD \n'''\nAfter every 7 steps in the optimizer the learning rate will be multiplied by 0.1 \n'''\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1) \n\nModel training\n\nmodel = train_model(model, criterion=criterion, optimizer=optimizer, scheduler=step_lr_scheduler, num_epochs=5)\n\nEpoch 0/4\n----------\ntrain Loss: 0.6937 Acc: 0.5615\nval Loss: 0.5267 Acc: 0.7974\n\nEpoch 1/4\n----------\ntrain Loss: 0.5915 Acc: 0.7008\nval Loss: 0.4388 Acc: 0.8627\n\nEpoch 2/4\n----------\ntrain Loss: 0.5249 Acc: 0.7623\nval Loss: 0.3686 Acc: 0.9216\n\nEpoch 3/4\n----------\ntrain Loss: 0.5079 Acc: 0.7664\nval Loss: 0.3188 Acc: 0.9477\n\nEpoch 4/4\n----------\ntrain Loss: 0.4556 Acc: 0.8115\nval Loss: 0.3007 Acc: 0.9281\n\nTraining complete in 2m 18s\nBest val Acc: 0.947712\n\n\nUsing fine-tuning and re-training all the weights for the new network take longer and may result in lower acceracy than having the weights fixed. When we keep the weights in earlier layers fixed, we save a lot of time in the model training aand the performance of the model is also better (provided the two tasks are quite similar). Given the network is deep, optimizing the weights for this network from scratch would have been difficult and time consuming. For such a case, transfer learning seems to be a good option."
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html",
    "title": "Implement neural network from scratch for binary classification",
    "section": "",
    "text": "In this notebook I build a simple neural network, having a single hidden layer. Next, I compare this model for its classification accuracy to a boilerplate logistic regression.\nThis notebook was inspired by Andrew Ng’s Deep Learning Specialization tutorial on Coursera\n# Package imports\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn\nimport sklearn.datasets as datasets\nimport sklearn.linear_model\n\nimport copy as copy \n\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nnp.random.seed(42) # set a seed so that the results are consistent"
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#dataset",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#dataset",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Dataset",
    "text": "Dataset\nCode to make spirals is adapted from:\nhttp://cs231n.github.io/neural-networks-case-study/\n\nN = 400 # number of points per class\nD = 2 # dimensionality \nK = 2 # number of spokes\n\nX = np.zeros((N*K,D)) # data matrix (each row = single example)\nY = np.zeros(N*K, dtype='int') # class labels\n\nfor j in range(K):\n    ix = range(N*j,N*(j+1))\n    r = np.linspace(0, 1, N) # radius\n    t = np.linspace(j*4.2, (j+1)*4.2, N) + np.random.randn(N)*0.2 # theta\n    X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n    Y[ix] = (0 if j % 2 == 0 else 1)\n\nX = copy.deepcopy(X.T)\nY = copy.deepcopy(Y.reshape(-1,1).T)\n\n\nfig, ax = plt.subplots(1,1, figsize=(8,8))\n    \n# lets visualize the data:\nax.scatter(X[0, :], X[1, :], c=Y.ravel(), s=40, cmap=plt.cm.Spectral)\nax.set_xlabel('$X_1$')\nax.set_ylabel('$X_2$')\nax.set_title('Visualize data')\n\nText(0.5, 1.0, 'Visualize data')\n\n\n\n\n\n\n\n\n\n\nshape_X = X.shape\nshape_Y = Y.shape\n\nprint ('The shape of X is: ' + str(shape_X))\nprint ('The shape of Y is: ' + str(shape_Y))\n\nThe shape of X is: (2, 800)\nThe shape of Y is: (1, 800)"
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#simple-logistic-regression",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#simple-logistic-regression",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Simple Logistic Regression",
    "text": "Simple Logistic Regression\nBefore building a full neural network, lets first see how logistic regression performs on this problem. You can use sklearn’s built-in functions to do that. Run the code below to train a logistic regression classifier on the dataset.\n\n# Train the logistic regression classifier\nclf = sklearn.linear_model.LogisticRegression();\nclf.fit(X.T, Y.ravel());\n\nConvenience function to plot a decision boundary for the classification model\n\ndef plot_decision_boundary(func, x_input, y_input):\n    xx_1, xx_2 = np.mgrid[np.min(x_input[:,0]):np.max(x_input[:,0]):.01, np.min(x_input[:,1]):np.max(x_input[:,1]):.01]\n    grid = np.c_[xx_1.ravel(), xx_2.ravel()]\n    y_pred_grid = func(grid).reshape(xx_1.shape)\n    y_pred = func(x_input)\n    \n    fig, ax = plt.subplots(figsize=(10, 10))\n    contour = ax.contourf(xx_1, xx_2, y_pred_grid, alpha=0.7, cmap=\"Spectral\")\n    ax.scatter(x_input[:,0], x_input[:, 1], c=y_pred, s=50, cmap=\"Spectral\", edgecolor=\"white\", linewidth=1)\n    \n    lims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n            np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n            ]\n    ax.set(aspect='equal', \n           xlim=(np.min(x_input[:,0]), np.max(x_input[:,0])), ylim=(np.min(x_input[:,1]),np.max(x_input[:,1])),\n           xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n\n\nplot_decision_boundary(lambda x: clf.predict(x), X.T, Y.T)\nplt.title(\"Logistic Regression\")\n\nText(0.5, 1.0, 'Logistic Regression')\n\n\n\n\n\n\n\n\n\n\n# Print accuracy\nLR_predictions = clf.predict(X.T)\nprint ('Accuracy of logistic regression: %d ' % float((np.dot(Y, LR_predictions) + np.dot(1-Y, 1-LR_predictions))/float(Y.size)*100) +\n       '% ' + \"(percentage of correctly labelled datapoints)\")\n\nAccuracy of logistic regression: 66 % (percentage of correctly labelled datapoints)\n\n\nInterpretation: The dataset is not linearly separable, so logistic regression doesn’t perform well. Hopefully a neural network will do better."
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#neural-network-model",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#neural-network-model",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Neural Network model",
    "text": "Neural Network model\nLogistic regression did not work well on the dataset. Let’s train a Neural Network with a single hidden layer and see if it does any better.\nHere is basic framework for the model: \nMathematically:\nFor one example \\(x^{(i)}\\):\n\\[\nz^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}\\tag{1}\n\\]\n\\[\na^{[1] (i)} = \\tanh(z^{[1] (i)})\\tag{2}\n\\]\n\\[\nz^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}\\tag{3}\n\\]\n\\[\n\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})\\tag{4}\n\\]\n\\[\ny^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{if } a^{[2](i)} &gt; 0.5 \\\\ 0 & \\mbox{otherwise } \\end{cases}\\tag{5}\n\\]\nGiven the predictions on all the examples, you can also compute the cost \\(J\\) as follows:\n\\[\nJ = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right) \\small \\tag{6}\n\\]\nThe general methodology to build a Neural Network is to: 1. Define the neural network structure ( # of input units, # of hidden units, etc). 2. Initialize the model’s parameters 3. Loop: - Implement forward propagation - Compute loss - Implement backward propagation to get the gradients - Update parameters (gradient descent)\n\nDefining the neural network structure\nDefine three variables:\n- n_x: the size of the input layer\n- n_h: the size of the hidden layer (set this to 4) \n- n_y: the size of the output layer\n\ndef layer_sizes(X, Y, n_h=4):\n    \"\"\"\n    Arguments:\n    X -- input dataset of shape (input size, number of examples)\n    Y -- labels of shape (output size, number of examples)\n    \n    Returns:\n    n_x -- the size of the input layer\n    n_h -- the size of the hidden layer\n    n_y -- the size of the output layer\n    \"\"\"\n\n    n_x = X.shape[0] # size of input layer\n    n_h = n_h\n    n_y = Y.reshape(-1,1).T.shape[0] # size of output layer\n\n    return (n_x, n_h, n_y)\n\n\n(n_x, n_h, n_y) = layer_sizes(X, Y)\nprint(\"The size of the input layer is: n_x = \" + str(n_x))\nprint(\"The size of the hidden layer is: n_h = \" + str(n_h))\nprint(\"The size of the output layer is: n_y = \" + str(n_y))\n\nThe size of the input layer is: n_x = 2\nThe size of the hidden layer is: n_h = 4\nThe size of the output layer is: n_y = 1\n\n\n\n\nInitialize the model’s parameters\n\nInitialize the weights matrices with random values.\n\nUse: np.random.randn(a,b) * 0.01 to randomly initialize a matrix of shape (a,b).\n\nInitialize the bias vectors as zeros.\n\nUse: np.zeros((a,b)) to initialize a matrix of shape (a,b) with zeros.\n\n\n\ndef initialize_parameters(n_x, n_h, n_y):\n    \"\"\"\n    Argument:\n    n_x -- size of the input layer\n    n_h -- size of the hidden layer\n    n_y -- size of the output layer\n    \n    Returns:\n    params -- python dictionary containing your parameters:\n                    W1 -- weight matrix of shape (n_h, n_x)\n                    b1 -- bias vector of shape (n_h, 1)\n                    W2 -- weight matrix of shape (n_y, n_h)\n                    b2 -- bias vector of shape (n_y, 1)\n    \"\"\"\n    \n    np.random.seed(42) # we set up a seed so that your output matches ours although the initialization is random.\n\n    W1 = np.random.randn(n_h, n_x) * 0.01\n    b1 = np.zeros((n_h,1))\n    \n    W2 = np.random.randn(n_y, n_h) * 0.01\n    b2 = np.zeros((n_y,1))\n    \n    assert (W1.shape == (n_h, n_x))\n    assert (b1.shape == (n_h, 1))\n    assert (W2.shape == (n_y, n_h))\n    assert (b2.shape == (n_y, 1))\n    \n    parameters = {\"W1\": W1,\n                  \"b1\": b1,\n                  \"W2\": W2,\n                  \"b2\": b2}\n    \n    return parameters\n\n\n\nForward-pass\nImplement forward_propagation():\n\nRetrieve each parameter from the dictionary “parameters” (which is the output of initialize_parameters()) by using parameters[\"..\"].\nImplement Forward Propagation. Compute \\(Z^{[1]}, A^{[1]}, Z^{[2]}\\) and \\(A^{[2]}\\) (the vector of all your predictions on all the examples in the training set).\n\n\nValues needed in the backpropagation are stored in “cache”. The cache will be given as an input to the backpropagation function.\n\n\ndef sigmoid(x):\n    z = 1/(1 + np.exp(-x))\n    return z\n\n\ndef forward_propagation(X, parameters):\n    \"\"\"\n    Argument:\n    X -- input data of size (n_x, m)\n    parameters -- python dictionary containing your parameters (output of initialization function)\n    \n    Returns:\n    A2 -- The sigmoid output of the second activation\n    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n    \"\"\"\n    # Retrieve each parameter from the dictionary \"parameters\"\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    \n    ### END CODE HERE ###\n    \n    # Implement Forward Propagation\n    Z1 = np.dot(W1,X) + b1\n    A1 = np.tanh(Z1)\n    Z2 = np.dot(W2,A1) + b2\n    A2 = sigmoid(Z2)\n    \n    assert(A2.shape == (1, X.shape[1]))\n    \n    cache = {\"Z1\": Z1,\n             \"A1\": A1,\n             \"Z2\": Z2,\n             \"A2\": A2}\n    \n    return A2, cache"
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#loss-function",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#loss-function",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Loss function",
    "text": "Loss function\nCompute the cost function as follows:\n\\[\nJ = - \\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(} \\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right) \\large{)} \\small\\tag{13}\n\\]\n\ndef compute_cost(A2, Y):\n    \"\"\"\n    Computes the cross-entropy cost given in equation (13)\n    \n    Arguments:\n    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)\n    Y -- \"true\" labels vector of shape (1, number of examples)\n    \n    Returns:\n    cost -- cross-entropy cost given equation (13)\n    \"\"\"\n    \n    m = Y.shape[1] # number of example\n\n    # Compute the cross-entropy cost\n    logprobs = np.dot(Y,np.log(A2).T) + np.dot((1-Y),np.log((1-A2)).T)\n    cost = -logprobs/m\n\n    cost = float(np.squeeze(cost))  # makes sure cost is the dimension we expect. E.g., turns [[17]] into 17 \n    assert(isinstance(cost, float))\n    \n    return cost"
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#back-propogation",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#back-propogation",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Back-propogation",
    "text": "Back-propogation\nUsing the cache computed during forward propagation, now implement backward propagation.\n\\[\n\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } = \\frac{1}{m} (a^{[2](i)} - y^{(i)})\n\\]\n\\[\n\\frac{\\partial \\mathcal{J} }{ \\partial W_2 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } a^{[1] (i) T}\n\\]\n\\[\n\\frac{\\partial \\mathcal{J} }{ \\partial b_2 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)}}}\n\\]\n\\[\n\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} } =  W_2^T \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2})\n\\]\n\\[\n\\frac{\\partial \\mathcal{J} }{ \\partial W_1 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} }  X^T\n\\]\n\\[\n\\frac{\\partial \\mathcal{J} _i }{ \\partial b_1 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)}}}\n\\]\n\n\\(*\\) denotes elementwise multiplication.\nGradients for each later:\n\ndW1 = \\(\\frac{\\partial \\mathcal{J} }{ \\partial W_1 }\\)\ndb1 = \\(\\frac{\\partial \\mathcal{J} }{ \\partial b_1 }\\)\ndW2 = \\(\\frac{\\partial \\mathcal{J} }{ \\partial W_2 }\\)\ndb2 = \\(\\frac{\\partial \\mathcal{J} }{ \\partial b_2 }\\)\n\n\n\ndef backward_propagation(parameters, cache, X, Y):\n    \"\"\"\n    Implement the backward propagation using the instructions above.\n    \n    Arguments:\n    parameters -- python dictionary containing our parameters \n    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n    X -- input data of shape (2, number of examples)\n    Y -- \"true\" labels vector of shape (1, number of examples)\n    \n    Returns:\n    grads -- python dictionary containing your gradients with respect to different parameters\n    \"\"\"\n    m = X.shape[1]\n    \n    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n    W1 = parameters['W1']\n    W2 = parameters['W2']\n\n    # Retrieve also A1 and A2 from dictionary \"cache\".\n    A1 = cache['A1']\n    A2 = cache['A2']\n\n    # Backward propagation: calculate dW1, db1, dW2, db2. \n    dZ2 = A2 - Y\n    dW2 = (1/m) * np.dot(dZ2,A1.T)\n    db2 = (1/m) * np.sum(dZ2,axis=1, keepdims=True)\n    dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))\n    dW1 = (1/m) * np.dot(dZ1, X.T)\n    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n\n    grads = {\"dW1\": dW1,\n             \"db1\": db1,\n             \"dW2\": dW2,\n             \"db2\": db2}\n    \n    return grads\n\nGeneral gradient descent formalism: \\[ \\theta = \\theta - \\alpha \\frac{\\partial J }{ \\partial \\theta }\\]\nwhere: \\(\\alpha\\) is the learning rate and \\(\\theta\\) represents a parameter.\n\ndef update_parameters(parameters, grads, learning_rate = 1.2):\n    \"\"\"\n    Updates parameters using the gradient descent update rule given above\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters \n    grads -- python dictionary containing your gradients \n    \n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    \"\"\"\n    # Retrieve each parameter from the dictionary \"parameters\"\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n\n    # Retrieve each gradient from the dictionary \"grads\"\n    dW1 = grads['dW1']\n    db1 = grads['db1']\n    dW2 = grads['dW2']\n    db2 = grads['db2']\n\n    # Update rule for each parameter\n    W1 = W1 - learning_rate*dW1\n    b1 = b1 - learning_rate*db1\n    W2 = W2 - learning_rate*dW2\n    b2 = b2 - learning_rate*db2\n\n    parameters = {\"W1\": W1,\n                  \"b1\": b1,\n                  \"W2\": W2,\n                  \"b2\": b2}\n    \n    return parameters"
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#integrate-previous-parts-nn_model",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#integrate-previous-parts-nn_model",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Integrate previous parts nn_model()",
    "text": "Integrate previous parts nn_model()\n\ndef nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n    \"\"\"\n    Arguments:\n    X -- dataset of shape (2, number of examples)\n    Y -- labels of shape (1, number of examples)\n    n_h -- size of the hidden layer\n    num_iterations -- Number of iterations in gradient descent loop\n    print_cost -- if True, print the cost every 1000 iterations\n    \n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    \n    np.random.seed(42)\n    n_x, n_h, n_y = layer_sizes(X, Y, n_h=n_h)\n    \n    # Initialize parameters\n    parameters = initialize_parameters(n_x, n_h, n_y)\n\n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n         \n        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n        A2, cache = forward_propagation(X, parameters)\n        \n        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n        cost = compute_cost(A2, Y)\n \n        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n        grads = backward_propagation(parameters, cache, X, Y)\n \n        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n        parameters = update_parameters(parameters, grads, learning_rate = 1.2)\n\n        # Print the cost every 1000 iterations\n        if print_cost and i % 1000 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n\n    return parameters\n\n\nPredictions\nUse the model to predict: predict().\nUse forward propagation to predict results.\npredictions = \\(y_{prediction} = \\mathbb 1 \\text{{activation &gt; 0.5}} = \\begin{cases}\n      1 & \\text{if}\\ activation &gt; 0.5 \\\\\n      0 & \\text{otherwise}\n    \\end{cases}\\)\n\ndef predict(parameters, X):\n    \"\"\"\n    Using the learned parameters, predicts a class for each example in X\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters \n    X -- input data of size (n_x, m)\n    \n    Returns\n    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n    \"\"\"\n    \n    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n    A2, cache = forward_propagation(X, parameters)\n    threshold = 0.5 \n    predictions = (A2 &gt; threshold)\n    \n    return predictions\n\nIt is time to run the model and see how it performs on a planar dataset. Run the following code to test your model with a single hidden layer of \\(n_h\\) hidden units.\n\n# Build a model with a n_h-dimensional hidden layer\nparameters = nn_model(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)\n\nCost after iteration 0: 0.693141\nCost after iteration 1000: 0.052671\nCost after iteration 2000: 0.040765\nCost after iteration 3000: 0.032499\nCost after iteration 4000: 0.027457\nCost after iteration 5000: 0.023722\nCost after iteration 6000: 0.020082\nCost after iteration 7000: 0.016282\nCost after iteration 8000: 0.013001\nCost after iteration 9000: 0.010872\n\n\n\ndef plot_decision_boundary_NN(func, x_input, y_input, ax=None):\n    xx_1, xx_2 = np.mgrid[np.min(x_input[:,0]):np.max(x_input[:,0]):.01, np.min(x_input[:,1]):np.max(x_input[:,1]):.01]\n    grid = np.c_[xx_1.ravel(), xx_2.ravel()].T\n    y_pred_grid = func(grid).reshape(xx_1.shape)\n    y_pred = func(x_input.T)\n    \n    if ax == None:\n        fig, ax = plt.subplots(1,1, figsize=(10,10))\n        \n    contour = ax.contourf(xx_1, xx_2, y_pred_grid, alpha=0.7, cmap=\"Spectral\")\n    ax.scatter(x_input[:,0], x_input[:, 1], c=y_pred, s=50, cmap=\"Spectral\", edgecolor=\"white\", linewidth=1)\n    \n    lims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n            np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n            ]\n    ax.set(aspect='equal', \n           xlim=(np.min(x_input[:,0]), np.max(x_input[:,0])), ylim=(np.min(x_input[:,1]),np.max(x_input[:,1])),\n           xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n    return ax\n\n\n# Plot the decision boundary\nplot_decision_boundary_NN(lambda x: predict(parameters, x), X.T, Y.T)\nplt.title(\"Decision Boundary for hidden layer size \" + str(4))\n\nText(0.5, 1.0, 'Decision Boundary for hidden layer size 4')\n\n\n\n\n\n\n\n\n\n\n# Print accuracy\npredictions = predict(parameters, X)\nprint ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')\n\nAccuracy: 99%\n\n\nAccuracy is really high compared to Logistic Regression. The model has spirals! Neural networks are able to learn even highly non-linear decision boundaries, unlike logistic regression.\n\n\nTuning hidden layer size\nRun the following code to observe different behaviors of the model for various hidden layer sizes.\n\n# This may take about 2 minutes to run\nplt.figure(figsize=(16, 32))\nhidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]\nfor i, n_h in enumerate(hidden_layer_sizes):\n    ax = plt.subplot(5, 2,i+1)\n    parameters = nn_model(X, Y, n_h, num_iterations = 5000)\n    plot_decision_boundary_NN(lambda x: predict(parameters, x), X.T, Y.T, ax)\n    predictions = predict(parameters, X)\n    accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100)\n    ax.title.set_text('Hidden Layer of size {} | Accuracy: {}%'.format(n_h, accuracy))\n\n\n\n\n\n\n\n\n\n\nReference:\n\nhttp://scs.ryerson.ca/~aharley/neural-networks/\nhttp://cs231n.github.io/neural-networks-case-study/"
  },
  {
    "objectID": "posts/2020-02-19-svm_example.html",
    "href": "posts/2020-02-19-svm_example.html",
    "title": "Implement Support Vector Machines in scikit-learn",
    "section": "",
    "text": "This tutorial is borrowed from Jake VanderPlas’s example of SVM in his notebook: Python Data Science Handbook"
  },
  {
    "objectID": "posts/2020-02-19-svm_example.html#motivation-for-support-vector-machines",
    "href": "posts/2020-02-19-svm_example.html#motivation-for-support-vector-machines",
    "title": "Implement Support Vector Machines in scikit-learn",
    "section": "Motivation for Support Vector Machines",
    "text": "Motivation for Support Vector Machines\n\nWe want to find a line/curve (in 2D) or a manifold (in n-D) that divides the class from each other. This is a type of Discriminative Classification\nConsider a simple case of classification task, in which the two classes of points are well separated\n\n\n#importing necessary modules\nimport os \nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom scipy import stats \nrandom_state = 42 \n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns; sns.set() \n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 30,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'lines.linewidth' : 3,\n'lines.markersize' : 10,\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)\n\n\nfrom sklearn.datasets import make_blobs\n\nX, y = make_blobs(n_samples=200, centers=2, \n                 random_state=random_state,\n                 cluster_std=1.5)\n\n\n#---Check what is X and y ----# \nprint('X is a {} array with x-y coordinates of the cluster points\\n'.format(np.shape(X)))\nprint(X[:3])\nprint('\\n')\nprint('y is a {} array with a classification of the points to which cluster they belong to\\n'.format(np.shape(y)))\nprint(y[:3])\nprint('\\n')\nplt.scatter(X[:,0],X[:,1], c=y, s=50, cmap='autumn');\n\nX is a (200, 2) array with x-y coordinates of the cluster points\n\n[[2.24823735 1.07410715]\n [5.12395668 0.73232327]\n [4.6766441  2.72016712]]\n\n\ny is a (200,) array with a classification of the points to which cluster they belong to\n\n[1 1 1]\n\n\n\n\n\n\n\n\n\n\n\nFor two-dimensional data, as observed in this case, a linear discriminative classifier would attempt to draw a straight line separating the two data-sets and thereby creating a model for (binary) classification. For the 2D data like the shown above, this task could be done by hand. But there is more than one line that can divide this data in two halves!\n\nx_fit = np.linspace(min(X[:,0]),max(X[:,0]))\n\nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(X[:,0], X[:,1], c=y, s=50, cmap='autumn')\n\n# Random point in the 2D plain \nax.plot([-2],[4],'x',color='blue', markeredgewidth=2, markersize=10)\n\n# Plot various 2D planes separating the two 'blobs'\nfor m,b in [(3.5,5),(2,5),(0.9,5)]:\n    plt.plot(x_fit, x_fit*m+b, '-k')\n    \nplt.xlim(min(X[:,0]),max(X[:,0]))\nplt.ylim(min(X[:,1]),max(X[:,1]))\n\n\n\n\n\n\n\n\nWhat’s a better methodology to determine the cutting plane? Something like k-nearest neighbor clustering wherein you find the plane with best separation from the two clusters based on some distance metric. However, k-nearest neighbors is based on non-parametric method – needing to be estimated everytime a new data point is introduced.\nWhat if I want something which is learned and then used as a function every other time a new datum is to be classified. This is where support vector machines (SVM) are useful.\nSupport Vector Machines:\nRather than simply drawing a zero-width line between classes, we can draw round each line a margin of some width, up to the nearest point.\n\nx_fit = np.linspace(min(X[:,0]),max(X[:,0]))\nplt.scatter(X[:,0], X[:,1], c=y, s=50, cmap='autumn')\nplt.plot([-2],[4],'x',color='blue', markeredgewidth=2, markersize=10)\n\nfor m, b, d in [(3.5,5,0.33),(2,5,0.55),(0.9,5,0.8)]:\n    y_fit = x_fit*m + b \n    plt.plot(x_fit, y_fit, '-k')\n    plt.fill_between(x_fit, y_fit-d, y_fit+d, edgecolor='none',\n                    color='#AAAAAA', alpha=0.4)\n    \nplt.xlim(min(X[:,0]),max(X[:,0]))\nplt.ylim(min(X[:,1]),max(X[:,1]))\n\n\n\n\n\n\n\n\nIn support vector machines, the line that maximizes this margin is the one we will choose as the optimal model. Support vector machines are an example of such a maximum margin estimator.\n\nFitting a support vector machine model\nUsing Scikit-learn’s SVM module to train a classifier on the above data. We will use a linear-kernel and set C parameters to a very large value.\n\nfrom sklearn.svm import SVC\nmodel = SVC(kernel='linear',C=1E10)\nmodel.fit(X,y)\n\nSVC(C=10000000000.0, kernel='linear')\n\n\nTo better appreciate the SVM classification logic, we use a convenience function to visualize the decision boundary as made by the SVM module. Code is adopted from Jake’s tutorial.\n\ndef plot_svc_decision_function(model, ax=None, plot_support=True, list_vectors=False):\n    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n    if ax is None:\n        ax = plt.gca()\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n    \n    # create grid to evaluate model\n    x = np.linspace(xlim[0], xlim[1], 30)\n    y = np.linspace(ylim[0], ylim[1], 30)\n    Y, X = np.meshgrid(y, x)\n    xy = np.vstack([X.ravel(), Y.ravel()]).T\n    P = model.decision_function(xy).reshape(X.shape)\n    \n    # plot decision boundary and margins\n    ax.contour(X, Y, P, colors='k',\n               levels=[-1, 0, 1], alpha=0.5,\n               linestyles=['--', '-', '--'])\n    \n    # plot support vectors\n    if plot_support:\n        ax.scatter(model.support_vectors_[:, 0],\n                   model.support_vectors_[:, 1],\n                   s=100, facecolors='none', edgecolors='black',linestyle='--');\n    if list_vectors: \n        print(model.support_vectors_)\n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)\n\n\nplt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\nplot_svc_decision_function(model)\n\n\n\n\n\n\n\n\nThis is the dividing line that maximizes the margin between the two sets of points.\nNotice that a few of the training points just touch the margin: they are indicated by the black circles in this figure.\nThese points are the pivotal elements of this fit, and are known as the support vectors, and give the algorithm its name.\nIn Scikit-Learn, the identity of these points are stored in the support_vectors_ attribute of the classifier.\n\nmodel.support_vectors_\n\narray([[-0.40500616,  6.91150953],\n       [ 2.65952903,  4.72035783],\n       [ 2.07017704,  4.00397825]])\n\n\n\nA key to this classifier’s success is that for the fit, only the position of the support vectors matter; any points further from the margin which are on the correct side do not modify the fit!\n\nTechnically, this is because these points do not contribute to the loss function used to fit the model, so their position and number do not matter so long as they do not cross the margin.\nWe can see this, for example, if we plot the model learned from the first 60 points and first 120 points of this dataset:\n\ndef plot_svm(N=10, ax=None):\n    X, y = make_blobs(n_samples=200, centers=2,\n                      random_state=0, cluster_std=0.60)\n    X = X[:N]\n    y = y[:N]\n    model = SVC(kernel='linear', C=1E10)\n    model.fit(X, y)\n    \n    ax = ax or plt.gca()\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n    ax.set_xlim(-1, 4)\n    ax.set_ylim(-1, 6)\n    plot_svc_decision_function(model, ax)\n    \nfig, ax = plt.subplots(1, 2, figsize=(16, 6))\nfig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\nfor axi, N in zip(ax, [60, 120]):\n    plot_svm(N, axi)\n    axi.set_title('N = {0}'.format(N))\n\n\n\n\n\n\n\n\nIn spite of increasing the training points, once the margins and the corresponding support vectors are identified the model does not change. This is one of the strengths of this algorithm\n\nfrom ipywidgets import interact, fixed\ninteract(plot_svm, N=[10, 50, 100, 150, 200], ax=fixed(None));"
  },
  {
    "objectID": "posts/2020-02-19-svm_example.html#beyond-linear-kernels-kernel-svm",
    "href": "posts/2020-02-19-svm_example.html#beyond-linear-kernels-kernel-svm",
    "title": "Implement Support Vector Machines in scikit-learn",
    "section": "Beyond linear kernels: Kernel SVM",
    "text": "Beyond linear kernels: Kernel SVM\nKernels are helpful in projecting data into higher dimensional feature space. This can be useful in simplest case to fit non-linear data using linear regression models. Similarly in the case of SVM: Projecting the data into higher dimensions through either polynomial or gaussian kernels we can fit non-linear relationships to a linear classifier\nLet’s look at a data-set which is not linearly separated:\n\nfrom sklearn.datasets import make_circles\n\nX, y = make_circles(200, factor=0.1, noise=0.1)\nclf = SVC(kernel='linear').fit(X,y)\nplt.scatter(X[:,0], X[:,1], c=y, s=50, cmap='autumn')\nplot_svc_decision_function(clf, plot_support=False)\n\n\n\n\n\n\n\n\nThere is not straight forward way to separate this data however we can project the data into higher dimensions based on its properties in the current dimensional space and get more information about its spread. One way of doing so is computing a radial basis function centered at the middle lump\n\nr = np.exp(-(np.sum((X)**2,axis=1)))\n\nfrom mpl_toolkits import mplot3d\n\ndef plot_3D(elev=30, azim=30, X=X, y=y):\n    ax = plt.subplot(projection='3d')\n    ax.scatter3D(X[:, 0], X[:, 1], r, c=y, s=50, cmap='autumn')\n    ax.view_init(elev=elev, azim=azim)\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_zlabel('r')\n\ninteract(plot_3D, elev=[-90, -45, -30, 30, 45, 60, 90], azip=(-180, 180),\n         X=fixed(X), y=fixed(y));\n\n\n\n\nProjecting the data in an additonal dimensions we can see can having a plane at r=0.7 could give us good separation.\nHere we had to choose and carefully tune our projection: if we had not centered our radial basis function in the right location, we would not have seen such clean, linearly separable results.\nIn general, the need to make such a choice is a problem: we would like to somehow automatically find the best basis functions to use.\nOne strategy to this end is to compute a basis function centered at every point in the dataset, and let the SVM algorithm sift through the results. This type of basis function transformation is known as a kernel transformation, as it is based on a similarity relationship (or kernel) between each pair of points.\nA potential problem with this strategy—projecting N points into N dimensions—is that it might become very computationally intensive as N grows large. However, because of a neat little procedure known as the kernel trick, a fit on kernel-transformed data can be done implicitly—that is, without ever building the full N-dimensional representation of the kernel projection! This kernel trick is built into the SVM, and is one of the reasons the method is so powerful.\nIn Scikit-Learn, we can apply kernelized SVM simply by changing our linear kernel to an RBF (radial basis function) kernel, using the kernel model hyperparameter:\n\nclf = SVC(kernel='rbf', C=1E6)\nclf.fit(X, y)\n\nSVC(C=1000000.0)\n\n\n\nplt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\nplot_svc_decision_function(clf)\nplt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n            s=300, lw=1, facecolors='none');"
  },
  {
    "objectID": "posts/2020-02-19-svm_example.html#softer-margins",
    "href": "posts/2020-02-19-svm_example.html#softer-margins",
    "title": "Implement Support Vector Machines in scikit-learn",
    "section": "Softer margins",
    "text": "Softer margins\n\nX, y = make_blobs(n_samples=100, centers=2,\n                  random_state=0, cluster_std=1.2)\nplt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn');\n\n\n\n\n\n\n\n\nTo handle this case, the SVM implementation has a bit of a fudge-factor which “softens” the margin: that is, it allows some of the points to creep into the margin if that allows a better fit. The hardness of the margin is controlled by a tuning parameter, most often known as C.\nFor very large C, the margin is hard, and points cannot lie in it. For smaller C, the margin is softer, and can grow to encompass some points.\nThe plot shown below gives a visual picture of how a changing C parameter affects the final fit, via the softening of the margin:\n\nX, y = make_blobs(n_samples=100, centers=2,\n                  random_state=0, cluster_std=0.8)\n\nfig, ax = plt.subplots(1, 3, figsize=(16, 6))\n\nfor axi, C in zip(ax, [1E10, 10.0, 0.1]):\n    model = SVC(kernel='linear', C=C).fit(X, y)\n    axi.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n    plot_svc_decision_function(model, axi)\n    axi.scatter(model.support_vectors_[:, 0],\n                model.support_vectors_[:, 1],\n                s=300, facecolors='none', edgecolors='black',linestyle='--')\n    axi.set_title('C = {0:.1f}'.format(C), size=14)"
  },
  {
    "objectID": "posts/2021-10-10-Rdkit.html",
    "href": "posts/2021-10-10-Rdkit.html",
    "title": "Rdkit quick tips",
    "section": "",
    "text": "Rdkit code snippets and recipes that I revisit now and again. The snippets are adopted from different python scripts written over time, ignore the variable names.\nTutorials & Walkthroughs\n\nRSC_OpenScience\n\n*Mute warnings\nfrom rdkit import RDLogger   \nRDLogger.DisableLog('rdApp.*') \n\nFingerprints\nQuick ECFP fingerprint\nfrom rdkit.Chem import AllChem\nfrom rdkit import Chem, DataStructs\nfrom rdkit.Chem import rdFingerprintGenerator\n\n# Convert to Chem.Mol: \nmol = Chem.MolFromSmiles(smiles)\n\n# Counts by default - unfolded \nrdMolDescriptors.GetMorganFingerprint(mol, radius) \n\n# Folded counts \nrdMolDescriptors.GetHashedMorganFingerprint(mol, radius, nBits=num_bits)\n\n#Folded FP bit vectors as per the size of the bits \nmorgan_fp_bit_vect = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n\n# Convert to numpy \nfp = np.zeros((0,), dtype=np.int16)\nDataStructs.ConvertToNumpyArray(morgan_fp_bit_vect, fp)\n\n\nLoading data\nTanimoto similarity matrix\nAdapted from Andrew White:\nimport itertools\ndef tanimoto_matrix(slist):\n    '''\n    Compute pair-wise Tanimoto similarity between a list of smiles with ECFP4 FPs\n    '''\n    fp = [ AllChem.GetMorganFingerprint( Chem.MolFromSmiles(s), 2 ) for s in slist ]\n    ts = list(\n    DataStructs.cDataStructs.TanimotoSimilarity(x,y) for x, y, in itertools.product(fp, repeat=2)\n    )\n    return np.array(ts).reshape(len(fp), len(fp))\nLoading ZINC dataset\nAdapted from Andrew White:\ntranches = pd.read_csv('https://gist.githubusercontent.com/whitead/f47887e45bbd2f38332182d2d422da6b/raw/a3948beac9b9034dab432b697c5ec238503ac5d0/tranches.txt')\ndef get_mol_batch(batch_size = 32):\n  for t in tranches.values:\n    d = pd.read_csv(t[0], sep=' ')    \n    for i in range(len(d) // batch_size):\n      yield d.iloc[i * batch_size:(i + 1) * batch_size, 0].values\n\n\nViewing molecules\nSDF\n\nRDKit blog\n\nSimple implementation\ninf = open('./example.sdf','rb')\n#import gzip \n#inf = gzip.open('gzip_file')\nfsuppl = Chem.ForwardSDMolSupplier(inf)\nmol_list = []\nfor mol in fsuppl:\n  if mol is None:\n    continue\n  print(mol.GetNumAtoms())\n  mol_list.append(mol)\nAs a Pandas DataFrame\nsdf_df = PandasTools.LoadSDF('./example.sdf')\nsdf_df['NumHeavyAtoms']= sdf_df.apply(lambda x: x['ROMol'].GetNumHeavyAtoms(), axis=1)\nPandasTools.WriteSDF(sdf_df, 'out.sdf', molColName='ROMol', idName='ID', properties=list(sdf_df.columns), allNumeric=False)\nViewing molecules inline\nfrom rdkit.Chem.Draw import IPythonConsole\nfrom rdkit.Chem.Draw import MolsToGridImage \nIPythonConsole.ipython_useSVG=True  #SVG's tend to look nicer than the png counterparts\n\nsample_mol_list = [Chem.MolFromSmiles(x) for x  in smiles_list]\nMolsToGridImage(sample_mol_list, molsPerRow=5)\nViewing molecules in a grid\nimport pandas as pd\nfrom rdkit.Chem import PandasTools\n\n&gt;&gt; PandasTools.AddMoleculeColumnToFrame(df, smilesCol='smiles')\n&gt;&gt; esol_data.head(1)\n\n&gt;&gt; PandasTools.FrameToGridImage(df.head(8), legendsCol=\"logSolubility\", molsPerRow=4)\nAdding new values as a column\ndf[\"n_Atoms\"] = df['ROMol'].map(lambda x: x.GetNumAtoms())\ndf.head(1)\nMolecules in a xlsx file\nimport pandas as pd\nfrom rdkit import Chem\nfrom rdkit.Chem import PandasTools\n\n&gt;&gt; smiles = ['c1ccccc1', 'c1ccccc1O', 'c1cc(O)ccc1O']\n&gt;&gt; df = pd.DataFrame({'ID':['Benzene', 'Phenol', 'Hydroquinone'], 'SMILES':smiles})\n&gt;&gt; df['Mol Image'] = [Chem.MolFromSmiles(s) for s in df['SMILES']]\n&gt;&gt; PandasTools.SaveXlsxFromFrame(df, 'test.xlsx', molCol='Mol Image')\nViewing substructures\ndef viz_substruct(main_smile, substructure_smarts):\n    \n    mol_file = Chem.MolFromSmiles(main_smile)\n    sub_pattern = Chem.MolFromSmarts(substructure_smarts)\n    \n    hit_ats = list(mol_file.GetSubstructMatch(sub_pattern)) # Returns the indices of the molecule’s atoms that match a substructure query\n    hit_bonds = []\n\n    for bond in sub_pattern.GetBonds():\n        aid1 = hit_ats[bond.GetBeginAtomIdx()]\n        aid2 = hit_ats[bond.GetEndAtomIdx()]\n\n        hit_bonds.append( mol_file.GetBondBetweenAtoms(aid1, aid2).GetIdx() )\n\n    d2d = rdMolDraw2D.MolDraw2DSVG(400, 400) # or MolDraw2DCairo to get PNGs\n    rdMolDraw2D.PrepareAndDrawMolecule(d2d, mol_file, highlightAtoms=hit_ats,  highlightBonds=hit_bonds)\n    d2d.FinishDrawing()\n    return SVG(d2d.GetDrawingText())\n\n&gt;&gt; diclofenac = 'O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl'\n&gt;&gt; substruct_smarts = 'O=CCccN'\n&gt;&gt; viz_substruct(diclofenac, substruct_smarts)\nQuick substructure filter in-line to Pandas df\ndef NO_NO(smile):\n    ''' Detects a Tau binder fragment'''\n    mol = Chem.MolFromSmiles(smile)\n    smt1= Chem.MolFromSmarts('[NR1][OR1]')\n    if mol.HasSubstructMatch(smt1):\n      return True\n    else:\n      return False\n\n&gt;&gt; linker_2_stereos['Ring_NO'] = linker_2_stereos['SMILES'].apply(NO_NO)\nStandardize molecules\nBorrowed from here\nfrom rdkit.Chem.MolStandardize import rdMolStandardize\n\ndef standardize(mol):\n    # follows the steps in\n    # https://github.com/greglandrum/RSC_OpenScience_Standardization_202104/blob/main/MolStandardize%20pieces.ipynb\n    # as described **excellently** (by Greg) in\n    # https://www.youtube.com/watch?v=eWTApNX8dJQ\n    # removeHs, disconnect metal atoms, normalize the molecule, reionize the molecule\n    clean_mol = rdMolStandardize.Cleanup(mol) \n     \n    # if many fragments, get the \"parent\" (the actual mol we are interested in) \n    parent_clean_mol = rdMolStandardize.FragmentParent(clean_mol)\n         \n    # try to neutralize molecule\n    uncharger = rdMolStandardize.Uncharger() # annoying, but necessary as no convenience method exists\n    uncharged_parent_clean_mol = uncharger.uncharge(parent_clean_mol)\n     \n    # note that no attempt is made at reionization at this step\n    # nor at ionization at some pH (rdkit has no pKa caculator)\n    # the main aim to to represent all molecules from different sources\n    # in a (single) standard way, for use in ML, catalogue, etc.\n     \n    te = rdMolStandardize.TautomerEnumerator() # idem\n    taut_uncharged_parent_clean_mol = te.Canonicalize(uncharged_parent_clean_mol)\n     \n    return taut_uncharged_parent_clean_mol\nFind and change atoms in the molecule\ndef find_UI_change_to_12(smile, attach_type='UI'):\n  mol1 = Chem.MolFromSmiles(smile)\n  sub_pattern = Chem.MolFromSmarts('[U]*.[I]*')\n  hit_ats = list(mol1.GetSubstructMatch(sub_pattern))\n  emol = Chem.EditableMol(mol1) #Chem.RWMol()\n  emol.RemoveBond(hit_ats[0], hit_ats[1])\n  emol.RemoveBond(hit_ats[2], hit_ats[3])\n  mol2 = emol.GetMol()\n  \n  if attach_type == 'UI':\n    # Attached to U \n    mol2.GetAtomWithIdx(hit_ats[1]).SetIsotope(2)\n    # Attached to I \n    mol2.GetAtomWithIdx(hit_ats[3]).SetIsotope(1)\n  \n  else:\n    # Attached to U \n    mol2.GetAtomWithIdx(hit_ats[1]).SetIsotope(1)\n    # Attached to I\n    mol2.GetAtomWithIdx(hit_ats[3]).SetIsotope(2)\n    \n  mol2 = standardize(mol2)\n  return(mol2, Chem.MolToSmiles(mol2))\n\n\nReactions\nView a reaction\nrxn = AllChem.ReactionFromSmarts('[C:1]=[C:2].[C:3]=[*:4][*:5]=[C:6]&gt;&gt;[C:1]1[C:2][C:3][*:4]=[*:5][C:6]1')\nGet changed atoms in a reaction: https://greglandrum.github.io/rdkit-blog/tutorial/reactions/2021/11/26/highlighting-changed-bonds-in-reactions.html\nRun enumerations\nBorrowed and inspired from Pat Walters gist\nrxn = AllChem.ReactionFromSmarts(\"[#6:10]-[#7H2:9].[#7]-[c:4]1[c:5][c:6][c:7][c:8][c:3]1-[#6](-[OH])=O.[#6H:1](-[#6:2])=O&gt;&gt;[#6:10]-[#7:9]-c1n[c:1](-[#6:2])n[c:4]2[c:5][c:6][c:7][c:8][c:3]12\")\n\nreact_dict = {'R1':[],'R2':[],'R3':[], 'product':[]}\nfor r1, r2, r3 in product( *[primary_amines_list, amino_benzoic_list, aldehyde_list]):\n  react_dict['R1'].append(r1)\n  react_dict['R2'].append(r2)\n  react_dict['R3'].append(r3)\n  r1_mol = Chem.MolFromSmiles(r1)\n  r2_mol = Chem.MolFromSmiles(r2)\n  r3_mol = Chem.MolFromSmiles(r3)\n  for prod in rxn.RunReactants([r1_mol,r2_mol,r3_mol]):\n    prod_mol = prod[0]\n    Chem.SanitizeMol(prod_mol)\n    react_dict['product'].append(Chem.MolToSmiles(prod_mol))\n\nreact_df = pd.DataFrame(react_dict)\nZip molecules\nmolzip lets you take a molecule containing multiple fragments and ‘zip’ them together. Atoms which should be bonded to the final molecule are labelled by connecting them to dummy atoms. The code looks at matching dummy atoms (with same isotopic labels) in the fragment and adds bonds between them.\nsample = Chem.MolFromSmiles('[*:1]c1nc([*:2])nc([*:3])c1.CO[*:1].[*:2]N(CO)C.Cl[*:3]')\nsample\n\nChem.molzip(sample)\nRDKit documentation on Molzip and R-group decomposition\nMolZip documentation and early version here\nMore examples here\nEdit, merge, react molecules\nMolecule tinkering using Rdkit: http://asteeves.github.io/blog/2015/01/14/editing-in-rdkit/\nUsing mol2grid\nmols2grid is an interactive chemical viewer for 2D structures of small molecules, based on RDKit.\n\nJupyter notebook explaining simple application\n\nUseful set of functions in RDkit\nPat Walters has made a GitHub repo collecting useful RDKit functions here."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html",
    "title": "Material-informatics Literature and Resources",
    "section": "",
    "text": "Last update: 4th July 2021\nMaterial Informatics is the solid-state, inorganic chemistry focused cousin to its organic chemistry contemporary: Cheminformatics. In spirit, the aim of Material Informatics is similar to Cheminformatics; it offers a promising avenue to augment traditional material R&D processes. Amplify the conventional material discovery task using data, analytics, and identify chemical spaces, and structure in the data, which are interesting and probe those rigorously using first-principles techniques and/or experimentation.\nThe potential application of material informatics can be seen in: Microelectronics, aerospace, and automotive to defense, clean energy, and health services, where ever there’s a demand for new advanced materials at even greater rates and lower costs.\nApplication of material informatics in atomic-scale modeling:\nIn case of molecular-level modeling of material properties, concepts developed in material informatics, statistics, and ML can be used for:\nMachine learning in atomic-scale modeling is often used to replace expensive ab initio methods with cheaper approximations. While certainly lucractive an additional consideration for ML use-case is its utility as a surrogate model to help researchers identify interesting regions in the material space. It also helps to decode the ‘intuition’ and serendipity involved in material development and hopefully provide a rigorous data driven basis for a design decision.\nBelow are few reviews, articles, and resources I’ve found that document the state-of-the-art for material informatics. It goes without saying that this is a highly biased and a non-exhaustive listing of articles covering only the ones I’ve read. The idea with this document is to provide a starting point in understanding the general status of the field."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#special-issues-and-collections",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#special-issues-and-collections",
    "title": "Material-informatics Literature and Resources",
    "section": "Special Issues and Collections:",
    "text": "Special Issues and Collections:\n\nNature Materials collection of review articles discussing the role of computation for material design\nMatter journal’s Material prediction using data and ML prediction\nNature Communications compendium on ML for material modelling"
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#reviews",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#reviews",
    "title": "Material-informatics Literature and Resources",
    "section": "Reviews:",
    "text": "Reviews:\n\nC. Chen, Y. Zuo, W. Ye, X. Li, Z. Deng, and S. P. Ong, “A Critical Review of Machine Learning of Energy Materials,” Adv. Energy Mater., vol. 1903242, p. 1903242, Jan. 2020.\nJ. Schmidt, M. R. G. Marques, S. Botti, and M. A. L. Marques, “Recent advances and applications of machine learning in solid-state materials science,” npj Comput. Mater., vol. 5, no. 1, p. 83, Dec. 2019.\nJ. Noh, G. H. Gu, S. Kim, and Y. Jung, “Machine-enabled inverse design of inorganic solid materials: promises and challenges,” Chem. Sci., vol. 11, no. 19, pp. 4871–4881, 2020.\nS. M. Moosavi, K. M. Jablonka, and B. Smit, “The Role of Machine Learning in the Understanding and Design of Materials,” J. Am. Chem. Soc., no. Figure 1, p. jacs.0c09105, Nov. 2020.\nF. Häse, L. M. Roch, P. Friederich, and A. Aspuru-Guzik, “Designing and understanding light-harvesting devices with machine learning,” Nat. Commun., vol. 11, no. 1, pp. 1–11, 2020.\nM. Moliner, Y. Román-Leshkov, and A. Corma, “Machine Learning Applied to Zeolite Synthesis: The Missing Link for Realizing High-Throughput Discovery,” Acc. Chem. Res., vol. 52, no. 10, pp. 2971–2980, 2019.\nTao, H., Wu, T., Aldeghi, M. et al. Nanoparticle synthesis assisted by machine learning. Nat Rev Mater, 2021\n\n\nBest practices in material informatics:\nA. Y. T. Wang et al., “Machine Learning for Materials Scientists: An Introductory Guide toward Best Practices,” Chem. Mater., vol. 32, no. 12, pp. 4954–4965, 2020."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#featurizations-possible",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#featurizations-possible",
    "title": "Material-informatics Literature and Resources",
    "section": "Featurizations possible:",
    "text": "Featurizations possible:\nSimilar to other machine-learning development efforts – featurization or descriptors used to convert material entries in machine-readable format is crucial for the eventual performance of any statistical model. Over the years there has been tremendous progress in describing the periodic solid crystal structures. Some of the key articles I’ve liked are mentioned below:\nReviews:\n\nA. P. Bartók, R. Kondor, and G. Csányi, “On representing chemical environments,” Phys. Rev. B - Condens. Matter Mater. Phys., vol. 87, no. 18, pp. 1–16, 2013.\nA. Seko, H. Hayashi, K. Nakayama, A. Takahashi, and I. Tanaka, “Representation of compounds for machine-learning prediction of physical properties,” Phys. Rev. B, vol. 95, no. 14, pp. 1–11, 2017.\nK. T. Schütt, H. Glawe, F. Brockherde, A. Sanna, K. R. Müller, and E. K. U. Gross, “How to represent crystal structures for machine learning: Towards fast prediction of electronic properties,” Phys. Rev. B - Condens. Matter Mater. Phys., vol. 89, no. 20, pp. 1–5, 2014.\n\nArticles:\n1. Composition based:\n\nL. Ward et al., “Including crystal structure attributes in machine learning models of formation energies via Voronoi tessellations,” Phys. Rev. B, vol. 96, no. 2, 2017\n\nPredicting properties of crystalline compounds using a representation consisting of attributes derived from the Voronoi tessellation of its structure and composition based features is both twice as accurate as existing methods and can scale to large training set sizes. Also the representations are insensitive to changes in the volume of a crystal, which makes it possible to predict the properties of the crystal without needing to compute the DFT-relaxed geometry as input. Random forrest algorithm used for the prediction\n\nA. Wang, S. Kauwe, R. Murdock, and T. Sparks, “Compositionally-Restricted Attention-Based Network for Materials Property Prediction (CrabNet).” 20-Feb-2020.\n\nUsing attention-based graph networks on material composition to predict material properties.\n\nGoodall, R.E.A., Lee, A.A. Predicting materials properties without crystal structure: deep representation learning from stoichiometry (Roost). Nat Commun 11, 6280 (2020)\n\nSimilar to the previous article in spirit, here authors use material composition to generate weighted graphs and predict material properties. Consider ensemble-based uncertainty estimates.\n2. Structural based:\n\nT. Xie and J. C. Grossman, “Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties,” Phys. Rev. Lett., vol. 120, no. 14, p. 145301, 2018."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#material-modeling-benchmark-studies",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#material-modeling-benchmark-studies",
    "title": "Material-informatics Literature and Resources",
    "section": "Material modeling benchmark studies:",
    "text": "Material modeling benchmark studies:\n\nBartel, C.J., Trewartha, A., Wang, Q. et al. A critical examination of compound stability predictions from machine-learned formation energies. npj Comput Mater 6, 97 (2020)\n\nInvestigate if ML models can distinguish materials wrt thermodynamic stability and not just formation energies. Learning formation energy from composition alone is fine for MAE and RMSE representations. Propose that graph-based methods reduce the MAE by roughly 50% compared with the best performing compositional model. Show that including structural information is advantageous when predicting formation energies.\n\nA. J. Chowdhury, W. Yang, E. Walker, O. Mamun, A. Heyden, and G. A. Terejanu, “Prediction of Adsorption Energies for Chemical Species on Metal Catalyst Surfaces Using Machine Learning,” J. Phys. Chem. C, vol. 122, no. 49, pp. 28142–28150, 2018\n\nConsider various encoding scheme and machine learning models to predict single adsorbate binding energy for carbon-based adsorabtes on transition metal surfaces. They show linear methods and scaling relationship hold well compared to ML methods. They found that for ML models to succeed, it is not necessary to use advanced (geometric) coordinate-based descriptors; simple descriptors, such as bond count, can provide satisfactory results. As many catalysis and materials science problems require significant time to generate each data point, in many cases the ML models would need to work with a relatively small-sized dataset\n\nRosen, Andrew; Iyer, Shaelyn; Ray, Debmalya; Yao, Zhenpeng; Aspuru-Guzik, Alan; Gagliardi, Laura; et al. (2020): Machine Learning the Quantum-Chemical Properties of Metal–Organic Frameworks for Accelerated Materials Discovery with a New Electronic Structure Database. ChemRxiv. Preprint\nFung, V., Zhang, J., Juarez, E. et al. Benchmarking graph neural networks for materials chemistry. npj Comput Mater 7, 84 (2021)"
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#articles",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#articles",
    "title": "Material-informatics Literature and Resources",
    "section": "Articles:",
    "text": "Articles:\nThere is a rich and long history of using statistical model and data mining for predicting bulk inorganic crystal properties. The review articles mentioned in the above section discuss those areas quite nicely.\n\nThis section particularly focusses on works applying informatics to encode surfaces for modeling heterogeneous catalyst surfaces, which is fairly new and very active research direction:\n\n\nMa, X., Li, Z., Achenie, L.E.K., and Xin, H. (2015). Machine-learning-augmented chemisorption model for CO2 electroreduction catalyst screening. J. Phys. Chem. Lett. 6, 3528–3533.\nF. Liu, S. Yang, and A. J. Medford, “Scalable approach to high coverages on oxides via iterative training of a machine-learning algorithm,” ChemCatChem, vol. 12, no. 17, pp. 4317–4330, 2020.\nC. S. Praveen and A. Comas-Vives, “Design of an Accurate Machine Learning Algorithm to Predict the Binding Energies of Several Adsorbates on Multiple Sites of Metal Surfaces,” ChemCatChem, vol. n/a, no. n/a, 2020.\nZ. Li, L. E. K. Achenie, and H. Xin, “An Adaptive Machine Learning Strategy for Accelerating Discovery of Perovskite Electrocatalysts,” ACS Catal., vol. 10, no. 7, pp. 4377–4384, 2020.\nR. García-Muelas and N. López, “Statistical learning goes beyond the d-band model providing the thermochemistry of adsorbates on transition metals,” Nat. Commun., vol. 10, no. 1, p. 4687, Dec. 2019.\nM. Rueck, B. Garlyyev, F. Mayr, A. S. Bandarenka, and A. Gagliardi, “Oxygen Reduction Activities of Strained Platinum Core-Shell Electrocatalysts Predicted by Machine Learning,” J. Phys. Chem. Lett., 2020.\nW. Xu, M. Andersen, and K. Reuter, “Data-Driven Descriptor Engineering and Refined Scaling Relations for Predicting Transition Metal Oxide Reactivity,” ACS Catal., vol. 11, no. 2, pp. 734–742, Jan. 2021.\nLiu, F., Yang, S. & Medford, A. J. Scalable approach to high coverages on oxides via iterative training of a machine-learning algorithm. ChemCatChem 12, 4317–4330 (2020).\n\nGraph-network based approaches for encoding and predicting surface binding energies:\n\nBack, S. et al. Convolutional Neural Network of Atomic Surface Structures to Predict Binding Energies for High-Throughput Screening of Catalysts. J. Phys. Chem. Lett. 10, 4401–4408 (2019)\nLym, J., Gu, G. H., Jung, Y. & Vlachos, D. G. Lattice convolutional neural network modeling of adsorbate coverage effects. J. Phys. Chem. C 123, 18951–18959 (2019).\n\nAdsorbate binding predictions have been recently extended to cover high-entropy alloy surfaces as well:\n\nT. A. A. Batchelor et al., “Complex solid solution electrocatalyst discovery by computational prediction and high‐throughput experimentation,” Angew. Chemie Int. Ed., p. anie.202014374, Dec. 2020.\nJ. K. Pedersen, T. A. A. Batchelor, D. Yan, L. E. J. Skjegstad, and J. Rossmeisl, “Surface electrocatalysis on high-entropy alloys,” Curr. Opin. Electrochem., vol. 26, p. 100651, Apr. 2021.\nZ. Lu, Z. W. Chen, and C. V. Singh, “Neural Network-Assisted Development of High-Entropy Alloy Catalysts: Decoupling Ligand and Coordination Effects,” Matter, vol. 3, no. 4, pp. 1318–1333, 2020.\n\nMiscellaneous\n\nJang, Jidon, et al. “Structure-based synthesizability prediction of crystals using partially supervised learning.” Journal of the American Chemical Society 142.44 (2020): 18836-18843.\n\nCGCNN as a binary classification for synthesizability. The metric is identified only for the positive cases (that is experimental data) and used a proxy to train the model to learn what makes the material positive."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#global-optimization-methods",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#global-optimization-methods",
    "title": "Material-informatics Literature and Resources",
    "section": "Global optimization methods:",
    "text": "Global optimization methods:\n\nM. K. Bisbo and B. Hammer, “Efficient global structure optimization with a machine learned surrogate model,” Phys. Rev. Lett., vol. 124, no. 8, p. 86102, 2019.\nJ. Dean, M. G. Taylor, and G. Mpourmpakis, “Unfolding adsorption on metal nanoparticles: Connecting stability with catalysis,” Sci. Adv., vol. 5, no. 9, 2019."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#uncertainty-quantification-uq",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#uncertainty-quantification-uq",
    "title": "Material-informatics Literature and Resources",
    "section": "Uncertainty quantification (UQ):",
    "text": "Uncertainty quantification (UQ):\n\nA. Wang et al., “A Framework for Quantifying Uncertainty in DFT Energy Corrections.” 19-May-2021\n\nMethod to comment on the uncertainty of DFT errors which accounts for both sources of uncertainty: experimental and model parameters. Fit energy corrections using a set of 222 binary and ternary compounds for which experimental and computed values are present. Quantifying this uncertainty can help reveal cases wherein empirically-corrected DFT calculations are limited to differentiate between stable and unstable phases. Validate this approach on Sc-W-O phase diagram analysis.\n\nFeng, J., Lansford, J. L., Katsoulakis, M. A., & Vlachos, D. G. (2020). Explainable and trustworthy artificial intelligence for correctable modeling in chemical sciences. Science advances, 6(42)\n\nPropose Bayesian networks, type of probabilistic graphical models, to integrate physics- and chemistry-based data and uncertainty. Demonstrate this framework in searching for the optimal reaction rate and oxygen binding energy for the oxygen reduction reaction (ORR) using the volcano model. Their model is able to comment on the source of uncertainty in the model.\n\nK. Tran, W. Neiswanger, J. Yoon, Q. Zhang, E. Xing, and Z. W. Ulissi, “Methods for comparing uncertainty quantifications for material property predictions,” pp. 1–29, Dec. 2019\n\nHelpful overview and benchmark of various model flavors and metrics to understand ways of reporting the confidence in model predictions for material properties. Interesting convolution-Fed Gaussian Process (CFGP) model framework looked into which is a combination of CGCNN and GP: pooled outputs of the convolutional layers of the network as features in a new GP. This was also their best model from the collection. Nice overview of different metrics used for comparing methods for UQ."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#active-learning",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#active-learning",
    "title": "Material-informatics Literature and Resources",
    "section": "Active learning:",
    "text": "Active learning:\n\nA. Seko and S. Ishiwata, “Prediction of perovskite-related structures in ACuO3-x (A = Ca, Sr, Ba, Sc, Y, La) using density functional theory and Ba,” Phys. Rev. B, vol. 101, no. 13, p. 134101, Apr. 2020.\nK. Tran and Z. W. Ulissi, Active learning across intermetallics to guide discovery of electrocatalysts for CO2 reduction and H2 evolution, vol. 1, no. 9. Springer US, 2018.\nD. Xue, P. V. Balachandran, J. Hogden, J. Theiler, D. Xue, and T. Lookman, “Accelerated search for materials with targeted properties by adaptive design,” Nat. Commun., vol. 7, pp. 1–9, 2016.\nDeshwal A, Simon C, Doppa JR. Bayesian optimization of nanoporous materials. ChemRxiv. 2021\nJablonka, Kevin Maik, et al. “Bias free multiobjective active learning for materials design and discovery.” Nature communications 12.1 (2021): 1-10.\n\nActive learning algorithm to find Pareto front for multi-objective optimization. Apply algorithm to de-novo polymer design. Ranking materials in a multi-objective optimization tasks is sometimes biased. Instead of ranking the candidates, the authors want to identify an approximate pareto front. Selection of candidates happens based on their promixity to the pareto front, which itself is defined by following geometric rules."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#surrogate-optimizer-and-accelerating-ts-searches",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#surrogate-optimizer-and-accelerating-ts-searches",
    "title": "Material-informatics Literature and Resources",
    "section": "Surrogate optimizer and accelerating TS searches:",
    "text": "Surrogate optimizer and accelerating TS searches:\n\nO.-P. Koistinen, F. B. Dagbjartsdóttir, V. Ásgeirsson, A. Vehtari, and H. Jónsson, “Nudged elastic band calculations accelerated with Gaussian process regression,” J. Chem. Phys., vol. 147, no. 15, p. 152720, Oct. 2017.\nJ. A. Garrido Torres, P. C. Jennings, M. H. Hansen, J. R. Boes, and T. Bligaard, “Low-Scaling Algorithm for Nudged Elastic Band Calculations Using a Surrogate Machine Learning Model,” Phys. Rev. Lett., vol. 122, no. 15, pp. 1–6, 2019.\nE. Garijo del Río, J. J. Mortensen, and K. W. Jacobsen, “Local Bayesian optimizer for atomic structures,” Phys. Rev. B, vol. 100, no. 10, pp. 1–9, 2019."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#combining-experiments-theory",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#combining-experiments-theory",
    "title": "Material-informatics Literature and Resources",
    "section": "Combining experiments + theory:",
    "text": "Combining experiments + theory:\n\nE. O. Ebikade, Y. Wang, N. Samulewicz, B. Hasa, and D. Vlachos, “Active learning-driven quantitative synthesis–structure–property relations for improving performance and revealing active sites of nitrogen-doped carbon for the hydrogen evolution reaction,” React. Chem. Eng., 2020.\nA. Smith, A. Keane, J. A. Dumesic, G. W. Huber, and V. M. Zavala, “A machine learning framework for the analysis and prediction of catalytic activity from experimental data,” Appl. Catal. B Environ., vol. 263, no. October 2019, p. 118257, 2020.\nM. Zhong et al., Accelerated discovery of CO2 electrocatalysts using active machine learning, vol. 581, no. 7807. 2020.\nA. J. Saadun et al., “Performance of Metal-Catalyzed Hydrodebromination of Dibromomethane Analyzed by Descriptors Derived from Statistical Learning,” ACS Catal., vol. 10, no. 11, pp. 6129–6143, Jun. 2020.\nJ. L. Lansford and D. G. Vlachos, “Infrared spectroscopy data- and physics-driven machine learning for characterizing surface microstructure of complex materials,” Nat. Commun., vol. 11, no. 1, p. 1513, Dec. 2020\nAccelerated discovery of metallic glasses through iteration of machine learning and high-throughput experiments\nMaterials genes of heterogeneous catalysis from clean experiments and artificial intelligence\nN. Artrith, Z. Lin, and J. G. Chen, “Predicting the Activity and Selectivity of Bimetallic Metal Catalysts for Ethanol Reforming using Machine Learning,” ACS Catal., vol. 10, no. 16, pp. 9438–9444, Aug. 2020.\nS. Nellaiappan et al., “High-Entropy Alloys as Catalysts for the CO2 and CO Reduction Reactions: Experimental Realization,” ACS Catal., vol. 10, no. 6, pp. 3658–3663, 2020."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#reaction-network-predictions",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#reaction-network-predictions",
    "title": "Material-informatics Literature and Resources",
    "section": "Reaction Network Predictions:",
    "text": "Reaction Network Predictions:\n\n“Rational Solid-State Synthesis Routes for Inorganic Materials” Muratahan Aykol, Joseph H. Montoya, and Jens Hummelshøj Journal of the American Chemical Society 2021 143 (24), 9244-9259\nM. Liu et al., “Reaction Mechanism Generator v3.0: Advances in Automatic Mechanism Generation,” J. Chem. Inf. Model., May 2021.\n\nNewest version of RMG (v3) is updated to Python v3. It has ability to generate heterogeneous catalyst models, uncertainty analysis to conduct first order sensitivity analysis. RMG dataset for the thermochemical and kinetic parameters have been expanded.\n\nA Chemically Consistent Graph Architecture for Massive Reaction Networks Applied to Solid-Electrolyte Interphase Formation. ChemRxiv. Blau, Samuel; Patel, Hetal; Spotte-Smith, Evan; Xie, Xiaowei; Dwaraknath, Shyam; Persson, Kristin (2020)\n\nDevelop a multi-reactant representation scheme to look at arbitrary reactant product pairs. Apply this technique to understand electrochemical reaction network for Li-ion solid electrolyte interphase.\n\nMcDermott, M.J., Dwaraknath, S.S. & Persson, K.A. A graph-based network for predicting chemical reaction pathways in solid-state materials synthesis. Nat Commun 12, 3097 (2021)\n\nChemical reaction network model to predict synthesis pathway for exotic oxides. Solid-state synthesis procedures for YMnO3, Y2Mn2O7, Fe2SiS4, and YBa2Cu3O6.5 are proposed and compared to literature pathways. Finally apply the algorithm to search for a probable synthesis route to make MgMo3(PO4)3O, battery cathode material that has yet to be synthesized.\n\nDiscovering Competing Electrocatalytic Mechanisms and Their Overpotentials: Automated Enumeration of Oxygen Evolution Pathways, A. Govind Rajan and E. A. Carter, J. Phys. Chem. C, vol. 124, no. 45, pp. 24883–24898, Nov. 2020.\nAccurate Thermochemistry of Complex Lignin Structures via Density Functional Theory, Group Additivity, and Machine Learning, Q. Li, G. Wittreich, Y. Wang, H. Bhattacharjee, U. Gupta, and D. G. Vlachos, ACS Sustain. Chem. Eng., vol. 9, no. 8, pp. 3043–3049, Mar. 2021.\nZiyun Wang, Yuguang Li, Jacob Boes et al. CO2 Electrocatalyst Design Using Graph Theory, 21 September 2020, Preprint"
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#generative-models",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#generative-models",
    "title": "Material-informatics Literature and Resources",
    "section": "Generative Models:",
    "text": "Generative Models:\nReview:\nJ. Noh et al., “Inverse Design of Solid-State Materials via a Continuous Representation,” Matter, vol. 1, no. 5, pp. 1370–1384, 2019.\nArticles:\n\nS. Kim, J. Noh, G. H. Gu, A. Aspuru-Guzik, and Y. Jung, “Generative Adversarial Networks for Crystal Structure Prediction,” pp. 1–37, 2020\nB. Kim, S. Lee, and J. Kim, “Inverse design of porous materials using artificial neural networks,” Sci. Adv., vol. 6, no. 1, 2020\nZ. Yao et al., “Inverse Design of Nanoporous Crystalline Reticular Materials with Deep Generative Models,” 2020\n\nSemantically constrained graph-based code for presenting a MOFs. Target property directed optimization. Encode MOFs as edges, vertices, topologies. Edges are molecular fragments with two connecting points, verticies contain node information, topologies indicate a definite framework. Supramolecular Variational Autoencoder (SmVAE) with several corresponding components that oversee encoding and decoding each part of the MOF: Map the frameworks with discrete representations (RFcodes) into continuous vectors (z) and then back.\n\nDiscovering Relationships between OSDAs and Zeolites through Data Mining and Generative Neural Networks"
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#datasets",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#datasets",
    "title": "Material-informatics Literature and Resources",
    "section": "Datasets:",
    "text": "Datasets:\nWhile we can attribute the recent interest in material informatics to democratization of data analytics and ML packages, growing set of benchmark datasets of materials from multiple research institution has been crucial for development of new methods, algorithms and providing a consistent set of comparison.\n\nOC20 dataset (CMU + Facebook). Paper. Github\n\nDataset comprising of surface heterogeneous adsorbates.\n\nCatalysis Hub from SUNCAT. Website\n\nSurface Reactions database contains thousands of reaction energies and barriers from density functional theory (DFT) calculations on surface systems\n\nMaterials Project\n\nBesides providing a collection of over 130,000 inorganic compounds and 49,000 molecules and counting, with calculated phase diagrams, structural, thermodynamic, electronic, magnetic, and topological properties it also provides analysis tools for post-processing.\n\nOQMD from Chris Wolverton’s Group\n\n815,000+ materials with calculated thermodynamic and structural properties.\n\nICSD\n\n210,000+ inorganic crystal structures from literature. Requires subscription.\n\nJARVIS by NIST\n\nIncludes calculated materials properties, 2D materials, and tools for ML and high-throughput tight-binding.\n\nC2DB\n\nStructural, thermodynamic, elastic, electronic, magnetic, and optical properties of around 4000 two-dimensional (2D) materials distributed over more than 40 different crystal structures.\n\nAFLOW\n\nMillions of materials and calculated properties, focusing on alloys.\n\nCitrination\n\nContributed and curated datasets from Citrine Informatics\n\nMDPS\n\nFascinating resource linking scientific publications using the Pauling File database (relational database of published literature for material scientists)\n\nCurated list of material informatics packages"
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#packages",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#packages",
    "title": "Material-informatics Literature and Resources",
    "section": "Packages:",
    "text": "Packages:\n\nPerovskite oxide stability\nDOSNet\nOpen catalysis dataset\nAENet\nAMP\nAMPtorch (PyTorch implementation of AMP)\nFeature engineering for Perovskite’s electronic structure properties\nMEGNET\nSISSO\nCatlearn\nMatminer\nMat2Vec\nPyePAL\n\nActive learning approach to efficiently and confidently identify the Pareto front with any regression model that can output a mean and a standard deviation."
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "",
    "text": "Walkthrough on reading, visualizing, manipulating molecules and their properties using Pandas and RDKit for Cheminformatics-related tasks. In this file we will be primarly using SMILES to describe the molecules of choice."
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#install-necessary-modules",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#install-necessary-modules",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Install necessary modules",
    "text": "Install necessary modules\n\n# collapse_output\n# Install requirements for the tutorial\n!pip install pandas rdkit-pypi mols2grid matplotlib scikit-learn ipywidgets\n\nRequirement already satisfied: pandas in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (1.3.4)\nRequirement already satisfied: rdkit-pypi in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (2021.9.2.1)\nRequirement already satisfied: mols2grid in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (0.1.0)\nRequirement already satisfied: matplotlib in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (3.5.1)\nRequirement already satisfied: scikit-learn in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (1.0.2)\nRequirement already satisfied: pytz&gt;=2017.3 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from pandas) (2021.3)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: numpy&gt;=1.21.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from pandas) (1.21.4)\nRequirement already satisfied: jinja2 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from mols2grid) (3.0.3)\nRequirement already satisfied: pillow&gt;=6.2.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (8.4.0)\nRequirement already satisfied: cycler&gt;=0.10 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: pyparsing&gt;=2.2.1 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (3.0.6)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (4.28.3)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: packaging&gt;=20.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: joblib&gt;=0.11 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from scikit-learn) (1.1.0)\nRequirement already satisfied: scipy&gt;=1.1.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from scikit-learn) (1.7.3)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\nRequirement already satisfied: six&gt;=1.5 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas) (1.16.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from jinja2-&gt;mols2grid) (2.0.1)\n\n\n\nimport os \nimport pandas as pd\nimport numpy as np \n\nThe majority of the basic molecular functionality is found in module rdkit.Chem\n\n# RDkit imports\nimport rdkit\nfrom rdkit import Chem #This gives us most of RDkits's functionality\nfrom rdkit.Chem import Draw\nfrom rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\nIPythonConsole.ipython_useSVG=True  #SVG's tend to look nicer than the png counterparts\nprint(rdkit.__version__)\n\n# Mute all errors except critical\nChem.WrapLogs()\nlg = rdkit.RDLogger.logger() \nlg.setLevel(rdkit.RDLogger.CRITICAL)\n\n2021.09.2\n\n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 15,\n'axes.titlesize' : 15,\n'axes.labelsize' : 15,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 12,\n'ytick.labelsize' : 12,\n}\n \nplt.rcParams.update(plot_params)"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#basics",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#basics",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Basics",
    "text": "Basics\n\n# Beneze molecule using SMILES representation\nmol = Chem.MolFromSmiles(\"c1ccccc1\")\n\nmol is a special type of RDkit object\n\ntype(mol)\n\nrdkit.Chem.rdchem.Mol\n\n\nTo display the molecule:\n\nmol\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nBy default SMILES (atleast the ones we deal with RDkit) accounts H atoms connected with C atoms implicitly based on the valence of the bond. You can add H explicitly using the command below:\n\nChem.AddHs(mol)\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChem.RemoveHs(mol)\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n# Convenience function to get atom index\ndef mol_with_atom_index(mol):\n    for atom in mol.GetAtoms():\n        atom.SetAtomMapNum(atom.GetIdx())\n    return mol\n\n\n# With atom index\nmol_with_atom_index(mol)\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Another option using in-built index for atoms \nIPythonConsole.drawOptions.addAtomIndices = True\nmol = Chem.MolFromSmiles(\"c1ccccc1\")\nmol\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptors for molecules\nWe can find more information about the molecule using rdkit.Chem.Descriptors : More information here\n\nfrom rdkit.Chem import Descriptors\n\n\n# To get molecular weight\nmol_wt = Descriptors.ExactMolWt(mol)\nprint('Mol Wt: {:0.3f}'.format(mol_wt))\n\nMol Wt: 78.047\n\n\n\n# To get heavy atom weight, this ignore H atoms \nheavy_mol_wt = Descriptors.HeavyAtomMolWt(mol)\nprint('Heavy Mol Wt: {:0.3f}'.format(heavy_mol_wt))\n\nHeavy Mol Wt: 72.066\n\n\n\n# To get number of rings \nring_count = Descriptors.RingCount(mol)\nprint('Number of rings: {:0.3f}'.format(ring_count))\n\nNumber of rings: 1.000\n\n\n\n# To get number of rotational bonds \nrotatable_bonds = Descriptors.NumRotatableBonds(mol)\nprint('Number of rotatable bonds: {:0.3f}'.format(rotatable_bonds))\n\nNumber of rotatable bonds: 0.000\n\n\n\n# To get number of rings \nnum_aromatic_rings = Descriptors.NumAromaticRings(mol)\nprint('Number of aromatic rings: {:0.3f}'.format(num_aromatic_rings))\n\nNumber of aromatic rings: 1.000\n\n\nGet some more information about the molecule:\nMolToMolBlock: To get Coordinates and bonding details for the molecule. More details on this file type can be found here\n\nmol_block = Chem.MolToMolBlock(mol)\nprint(mol_block)\n\n\n     RDKit          2D\n\n  6  6  0  0  0  0  0  0  0  0999 V2000\n    1.5000    0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n    0.7500   -1.2990    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n   -0.7500   -1.2990    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n   -1.5000    0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n   -0.7500    1.2990    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n    0.7500    1.2990    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n  1  2  2  0\n  2  3  1  0\n  3  4  2  0\n  4  5  1  0\n  5  6  2  0\n  6  1  1  0\nM  END\n\n\n\n\nmol"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#little-more-on-the-molecule-drawing",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#little-more-on-the-molecule-drawing",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Little more on the molecule drawing",
    "text": "Little more on the molecule drawing\nAdditional discussion on different ways to represnt and draw molecules in RDkit. This section will work in RDkit version &gt; 2020.03.\nI am following the code introduced in the official RDkit blogpost\n\nNice example found on Pen’s blogpost\n\n\nfrom collections import defaultdict\nfrom rdkit.Chem.Draw import rdMolDraw2D\nfrom IPython.display import SVG\n\n\ndiclofenac = Chem.MolFromSmiles('O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl')\ndiclofenac\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubstructure highlights:\nLet’s look at the the C=O and the -NH species in the molecule\n\n# Code from : https://www.rdkit.org/docs/GettingStartedInPython.html?highlight=maccs#drawing-molecules\nsub_pattern = Chem.MolFromSmarts('O=CCccN')\nhit_ats = list(diclofenac.GetSubstructMatch(sub_pattern))\nhit_bonds = []\n\nfor bond in sub_pattern.GetBonds():\n    aid1 = hit_ats[bond.GetBeginAtomIdx()]\n    aid2 = hit_ats[bond.GetEndAtomIdx()]\n    \n    hit_bonds.append( diclofenac.GetBondBetweenAtoms(aid1, aid2).GetIdx() )\n\n\nd2d = rdMolDraw2D.MolDraw2DSVG(400, 400) # or MolDraw2DCairo to get PNGs\nrdMolDraw2D.PrepareAndDrawMolecule(d2d, diclofenac, highlightAtoms=hit_ats,  highlightBonds=hit_bonds)\nd2d.FinishDrawing()\nSVG(d2d.GetDrawingText())\n\n\n\n\n\n\n\n\nSpecify individual color and bonds\n\nrings = diclofenac.GetRingInfo()\ntype(rings)\n\nrdkit.Chem.rdchem.RingInfo\n\n\n\n# Code from: http://rdkit.blogspot.com/2020/04/new-drawing-options-in-202003-release.html\n    \ncolors = [(0.8,0.0,0.8),(0.8,0.8,0),(0,0.8,0.8),(0,0,0.8)]\n\nathighlights = defaultdict(list)\narads = {}\n\nfor i,rng in enumerate(rings.AtomRings()):\n    for aid in rng:\n        athighlights[aid].append(colors[i])\n        arads[aid] = 0.3\n\nbndhighlights = defaultdict(list)\nfor i,rng in enumerate(rings.BondRings()):\n    for bid in rng:\n        bndhighlights[bid].append(colors[i])\n\n\nd2d = rdMolDraw2D.MolDraw2DSVG(400,400)\nd2d.DrawMoleculeWithHighlights(diclofenac,'diclofenac',dict(athighlights),dict(bndhighlights),arads,{})\nd2d.FinishDrawing()\nSVG(d2d.GetDrawingText())"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#reading-dataset-of-molecules-from-a-csv-file",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#reading-dataset-of-molecules-from-a-csv-file",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Reading dataset of molecules from a csv file",
    "text": "Reading dataset of molecules from a csv file\nHere we will use Pandas, RDkit to make molecule object for the small sample of molecules."
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#sample-data",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#sample-data",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Sample data",
    "text": "Sample data\n\nsample_df = pd.read_csv('https://raw.githubusercontent.com/pgg1610/data_files/main/simple_sample_molecules.csv',  sep=',')\n\n\nsample_df.head(5)\n\n\n\n\n\n\n\n\nName\nSMILE\n\n\n\n\n0\nCyclopropane\nC1CC1\n\n\n1\nEthylene\nC=C\n\n\n2\nMethane\nC\n\n\n3\nt-Butanol\nCC(C)(C)O\n\n\n4\nethane\nCC\n\n\n\n\n\n\n\n\nsample_df.shape\n\n(115, 2)\n\n\n\n# Adding to Pandas dataframe\nfrom rdkit.Chem import PandasTools\n\nPandasTools module helps add mol molecule objects from RDKit as per the SMILES in the dataframe\n\nPandasTools.AddMoleculeColumnToFrame(sample_df, smilesCol='SMILE')\n\nCheck the new ROMol columns being appended in the dataframe\n\nsample_df.columns\n\nIndex(['Name', 'SMILE', 'ROMol'], dtype='object')\n\n\n\nsample_df.head(1)\n\n\n\n\n\n\n\n\nName\nSMILE\nROMol\n\n\n\n\n0\nCyclopropane\nC1CC1\n\n\n\n\n\n\n\n\nVisualize the dataframe, add properties of interest at the bottom, you can add index too if need\n\nPandasTools.FrameToGridImage(sample_df[:20], legendsCol='Name', molsPerRow=4)\n\n\n\n\n\n\n\n\n\nQuickly sort / search the dataset using a substructure search\n\nsub_pattern_to_match = Chem.MolFromSmarts('C(=O)N')\nsub_pattern_to_match\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmatch_df = pd.DataFrame()\nfor index, row in sample_df.iterrows():\n    mol = Chem.MolFromSmiles(row['SMILE'])\n    mol_sub_match = mol.HasSubstructMatch(sub_pattern_to_match)\n    if mol_sub_match == True: \n        match_df = match_df.append(row)\n\n\nPandasTools.FrameToGridImage(match_df, legendsCol='Name', molsPerRow=4)\n\n\n\n\n\n\n\n\n\n\nLogP Dataset\n(From Wikipedia) The partition coefficient, abbreviated P, is defined as the ratio of the concentrations of a solute between two immisible solvents at equilibrium. Most commonly, one of the solvents is water, while the second is hydrophobic, such as 1-octanol.\n\\[\\log P_\\text{oct/wat} = \\log\\left(\\frac{\\big[\\text{solute}\\big]_\\text{octanol}^\\text{un-ionized}}{\\big[\\text{solute}\\big]_\\text{water}^\\text{un-ionized}}\\right)\\]\nHence the partition coefficient measures how hydrophilic (“water-loving”) or hydrophobic (“water-fearing”) a chemical substance is. Partition coefficients are useful in estimating the distribution of drugs within the body. Hydrophobic drugs with high octanol-water partition coefficients are mainly distributed to hydrophobic areas such as lipid bilayers of cells. Conversely, hydrophilic drugs (low octanol/water partition coefficients) are found primarily in aqueous regions such as blood serum.\nThe dataset used in this notebook is obtained from Kaggle. This dataset features relatively simple molecules along with their LogP value. This is a synthetic dataset created using XLogP and does not contain experimental validation.\n\nlogP_df = pd.read_csv('https://raw.githubusercontent.com/pgg1610/data_files/main/logP_dataset.csv', sep=',', header=None, names=['SMILES', 'LogP'])\n\n\nlogP_df.head(5)\n\n\n\n\n\n\n\n\nSMILES\nLogP\n\n\n\n\n0\nC[C@H]([C@@H](C)Cl)Cl\n2.3\n\n\n1\nC(C=CBr)N\n0.3\n\n\n2\nCCC(CO)Br\n1.3\n\n\n3\n[13CH3][13CH2][13CH2][13CH2][13CH2][13CH2]O\n2.0\n\n\n4\nCCCOCCP\n0.6\n\n\n\n\n\n\n\n\nlogP_df.shape\n\n(14610, 2)\n\n\n\n\nVisualize the SMILE string\n\nmol_temp = logP_df.iloc[420]\n\n\nmol_temp\n\nSMILES    [2H][C]([2H])[Cl+]Cl\nLogP                       1.6\nName: 420, dtype: object\n\n\n\nmol_obj = Chem.MolFromSmiles(mol_temp['SMILES'])\nmol_obj\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# To output x y z of the molecule \nprint(Chem.MolToMolBlock(mol_obj))\n\n\n     RDKit          2D\n\n  5  4  0  0  0  0  0  0  0  0999 V2000\n    1.2990    0.7500    0.0000 H   0  0  0  0  0  0  0  0  0  0  0  0\n    0.0000    0.0000    0.0000 C   0  0  0  0  0  3  0  0  0  0  0  0\n   -1.2990    0.7500    0.0000 H   0  0  0  0  0  0  0  0  0  0  0  0\n   -0.0000   -1.5000    0.0000 Cl  0  0  0  0  0  2  0  0  0  0  0  0\n   -1.2990   -2.2500    0.0000 Cl  0  0  0  0  0  0  0  0  0  0  0  0\n  1  2  1  0\n  2  3  1  0\n  2  4  1  0\n  4  5  1  0\nM  CHG  1   4   1\nM  RAD  1   2   2\nM  ISO  2   1   2   3   2\nM  END\n\n\n\nTake a small sample from QM9 dataset\n\nlogP_df_smol = logP_df.sample(20).reset_index(drop=True)\n\n\nlogP_df_smol.head(2)\n\n\n\n\n\n\n\n\nSMILES\nLogP\n\n\n\n\n0\nC(CCCN)CCN\n-0.2\n\n\n1\nCC(CF)CBr\n2.1\n\n\n\n\n\n\n\n\nlogP_df_smol.shape\n\n(20, 2)\n\n\nPandasTools module helps add mol molecule objects from RDKit as per the SMILES in the dataframe\n\nPandasTools.AddMoleculeColumnToFrame(logP_df_smol, smilesCol='SMILES')\n\nCheck the new ROMol columns being appended in the dataframe\n\nlogP_df_smol.columns\n\nIndex(['SMILES', 'LogP', 'ROMol'], dtype='object')\n\n\n\nlogP_df_smol['ROMol'][0]\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize the dataframe, add properties of interest at the bottom, you can add index too if need\n\nimport mols2grid \n\n\n#collapse_output\n#mols2grid.display(logP_df_smol['ROMol'])\n\n\nPandasTools.FrameToGridImage(logP_df_smol, legendsCol='LogP', molsPerRow=3, subImgSize=(200,200))"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#vanilla-linear-regression",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#vanilla-linear-regression",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Vanilla linear regression",
    "text": "Vanilla linear regression\nLet’s try building a model to predict a molecule’s logP value given other descriptors. We will try simple molecular descriptors and check the performance. Some molecule discriptors we will consider: 1. Molecular weight 2. Number of rotatable bonds 3. Number of aromatic compounds\n\nlogP_df.head(4)\n\n\n\n\n\n\n\n\nSMILES\nLogP\n\n\n\n\n0\nC[C@H]([C@@H](C)Cl)Cl\n2.3\n\n\n1\nC(C=CBr)N\n0.3\n\n\n2\nCCC(CO)Br\n1.3\n\n\n3\n[13CH3][13CH2][13CH2][13CH2][13CH2][13CH2]O\n2.0\n\n\n\n\n\n\n\nAs before we will first convert the SMILES string into a rdkit.Chem.rdchem.Mol object, let’s write a convenience function to do so\n\n# Getting count of aromatic elements \n_count = 0\nfor i in range(mol.GetNumAtoms()):\n    if mol.GetAtomWithIdx(i).GetIsAromatic():\n        _count = _count + 1\nprint(_count)\n\n6\n\n\n\ndef generate_variables(smiles_list):\n    \n    variable_array = {'SMILES':[], 'ROMol':[], 'Mol_Wt':[],'Num_Aromatic_rings':[], 'Num_rotate_bonds':[], 'Ratio_Aromatic':[], 'Valence_electrons':[]} \n    \n    for smile_entry in smiles_list: \n        mol_object = Chem.MolFromSmiles(smile_entry)\n        \n        mol_wt = Descriptors.MolWt(mol_object)\n        mol_aromatic_rings = Descriptors.NumAromaticRings(mol_object)\n        mol_rotatable_bonds = Descriptors.NumRotatableBonds(mol_object)\n        \n        # Calculate % of aromatic atoms in the compd\n        mol_num_heavy_atom = Descriptors.HeavyAtomCount(mol_object)\n        \n        _count_aromatic = 0 \n        for i in range(mol_object.GetNumAtoms()):\n            if mol_object.GetAtomWithIdx(i).GetIsAromatic() == True:\n                _count_aromatic = _count_aromatic + 1 \n        \n        mol_aromatic_ratio = _count_aromatic / mol_num_heavy_atom\n        \n        mol_val_electrons = Descriptors.NumValenceElectrons(mol_object)\n        \n        variable_array['SMILES'].append(smile_entry)\n        variable_array['ROMol'].append(mol_object)\n        variable_array['Mol_Wt'].append(mol_wt)\n        variable_array['Num_Aromatic_rings'].append(mol_aromatic_rings)\n        variable_array['Num_rotate_bonds'].append(mol_rotatable_bonds)\n        variable_array['Ratio_Aromatic'].append(mol_aromatic_ratio)\n        variable_array['Valence_electrons'].append(mol_val_electrons)\n        \n    return variable_array\n\n\nLook at a subset from the total logP data\n\nlogP_df.shape\n\n(14610, 2)\n\n\n\n# Look at random 10_000 entries to keep the analysis tractable \ndf_10k = logP_df.sample(10_000, random_state=42)\n\n\nvariable_dict = generate_variables(df_10k.SMILES)\nvariable_df = pd.DataFrame(variable_dict, columns=variable_dict.keys())\n\n\ndf_var_10k = df_10k.merge(variable_df, on='SMILES')\ndf_var_10k.head(2)\n\n\n\n\n\n\n\n\nSMILES\nLogP\nROMol\nMol_Wt\nNum_Aromatic_rings\nNum_rotate_bonds\nRatio_Aromatic\nValence_electrons\n\n\n\n\n0\nCNCSC\n0.5\n\n91.179\n0\n2\n0.0\n32\n\n\n1\nCNCSC=C\n1.0\n\n103.190\n0\n3\n0.0\n36\n\n\n\n\n\n\n\n\n\nSetup model\n\ndf_var_10k.columns\n\nIndex(['SMILES', 'LogP', 'ROMol', 'Mol_Wt', 'Num_Aromatic_rings',\n       'Num_rotate_bonds', 'Ratio_Aromatic', 'Valence_electrons'],\n      dtype='object')\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\ndf_var_10k.hist(ax = ax);\n\n/var/folders/_r/6hhq_8ps5118p6sqqz231j480000gq/T/ipykernel_26421/2485801931.py:2: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared\n  df_var_10k.hist(ax = ax);\n\n\n\n\n\n\n\n\n\nSplit into train and validation set\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(df_var_10k, test_size=0.3, random_state=42)\n\n\nprint(df_train.shape, df_test.shape)\n\n(7000, 8) (3000, 8)\n\n\nDrop some columns that arent that useful for prediction\n\nX_train = df_train.drop(columns = ['LogP','ROMol','SMILES', 'Ratio_Aromatic', 'Num_Aromatic_rings']).values\ny_train = df_train.LogP.values\n\nPre-process input data to normalize the scale of the descriptors\n\n# Standard Scaling X\nstd_scaler_X = StandardScaler()\nX_train_std = std_scaler_X.fit_transform(X_train)\n\n\nfrom sklearn.linear_model import LinearRegression\n\n\nmodel = LinearRegression()\nmodel.fit(X_train_std, y_train)\n\nLinearRegression()\n\n\n\n# predict use the trained model -- we are still using training set here \ny_pred = model.predict(X_train_std)\n\n\nplt.scatter(y_train, y_pred, alpha=0.6)\nplt.xlabel('True Value')\nplt.ylabel('Predicted')\n\nText(0, 0.5, 'Predicted')\n\n\n\n\n\n\n\n\n\n\n# Fancier looking plot \nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(y_train, y_pred, alpha=0.6, label='Linear Regression')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n# Linear fit\nreg = np.polyfit(y_train, y_pred, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='Linear Fit')\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='Parity Line')\nax.set_aspect('equal')\n        \nax.set_xlabel('True value')\nax.set_ylabel('Model predicted')\nax.legend(loc='best');\n\n\n\n\n\n\n\n\n\n\nEvaluate model success\nOne of the simplest ways we can evaluate the success of a linear model is using the coefficient of determination (R2) which compares the variation in y alone to the variation remaining after we fit a model. Another way of thinking about it is comparing our fit line with the model that just predicts the mean of y for any value of x.\nAnother common practice is to look at a plot of the residuals to evaluate our ansatz that the errors were normally distributed.\nIn practice, now that we have seen some results, we should move on to try and improve the model. We won’t do that here, but know that your work isn’t done after your first model (especially one as cruddy as this one). It’s only just begun!\nCalculate R2 using: \\[R^2 =1 -  \\frac{\\sum (y_i - \\hat{y})^2}{\\sum (y_i - \\bar{y})^2}\\]\n\n# R2 score evaluation\nSS_residuals = np.sum( (y_train - y_pred)**2 ) \nSS_total = np.sum( (y_train - np.mean(y_train))**2 )\nr2 = 1 - SS_residuals / SS_total\nprint(r2)\n\n0.13532814881109834\n\n\n\nfrom sklearn.metrics import r2_score\nprint('R2 score: {}'.format(r2_score(y_train, y_pred)))\n\nR2 score: 0.13532814881109834"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#using-ensemble-based-model",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#using-ensemble-based-model",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Using ensemble-based model",
    "text": "Using ensemble-based model\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n\nmodel = RandomForestRegressor()\nmodel.fit(X_train_std, y_train)\n\nRandomForestRegressor()\n\n\n\ny_pred = model.predict(X_train_std)\n\n\n# Fancier looking plot \nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(y_train, y_pred, alpha=0.6, label='Linear Regression')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n# Linear fit\nreg = np.polyfit(y_train, y_pred, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='Linear Fit')\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='Parity Line')\nax.set_aspect('equal')\n        \nax.set_xlabel('True value')\nax.set_ylabel('Model predicted')\nax.legend(loc='best');\n\n\n\n\n\n\n\n\n\ndef display_performance(y_true, y_pred):\n    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n    r2 = r2_score(y_true, y_pred)\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    \n    print('R2: {0:0.2f}\\n'\n          'MAE: {1:0.2f}\\n'\n          'RMSE: {2:0.2f}'.format(r2, mae, rmse))\n    return(r2, mae, rmse)\n\n\ndisplay_performance(y_train,y_pred);\n\nR2: 0.91\nMAE: 0.29\nRMSE: 0.40"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#fingerprints",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#fingerprints",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Fingerprints",
    "text": "Fingerprints\nCompress molecules into vectors for mathetical operations and comparisons. First we will look at MorganFingerprint method. For this method we have to define the radius and the size of the vector being used.\nMore information on different Circular Fingerprints can be read at this blogpost. Highly recommended\n\nPresentation by Gregory Landrum (creator of RDkit) on Fingerprints\nRDkit Blog entry of visualizing the fingerprint bitvectors. Using the new fingerprint bit rendering code\n\n\n# Fingerprints\nfrom rdkit.Chem import AllChem\n\n\nradius = 2 # How far from the center node should we look at? \necfp_power = 10 # Size of the fingerprint vectors  \nECFP = [ np.array(AllChem.GetMorganFingerprintAsBitVect(m, radius, nBits = 2**ecfp_power)) for m in df_train['ROMol'] ]\n\n\nlen(ECFP)\n\n7000\n\n\n\ndf_train['ECFP'] = ECFP\n\n\ndf_train.sample(2)\n\n\n\n\n\n\n\n\nSMILES\nLogP\nROMol\nMol_Wt\nNum_Aromatic_rings\nNum_rotate_bonds\nRatio_Aromatic\nValence_electrons\nECFP\n\n\n\n\n6160\nC[NH+](C)CCl\n1.0\n\n94.565\n0\n1\n0.0\n32\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n\n\n1564\nCCCNCO\n0.1\n\n89.138\n0\n3\n0.0\n38\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n\n\n\n\n\n\n\n\nX_train = df_train.ECFP.values\nX_train = np.stack(X_train, axis=0)\n\ny_train = df_train.LogP.values\n\n\n# Standard Scaling\nstd_scaler = StandardScaler()\nX_train_std = std_scaler.fit_transform(X_train)\n\n\nmodel = RandomForestRegressor()\nmodel.fit(X_train_std, y_train)\n\nRandomForestRegressor()\n\n\n\ny_pred = model.predict(X_train_std)\n\n\n# Fancier looking plot \nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(y_train, y_pred, alpha=0.6, label='Linear Regression')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n# Linear fit\nreg = np.polyfit(y_train, y_pred, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='Linear Fit')\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='Parity Line')\nax.set_aspect('equal')\n        \nax.set_xlabel('True value')\nax.set_ylabel('Model predicted')\nax.legend(loc='best');\n\n\n\n\n\n\n\n\n\ndisplay_performance(y_train,y_pred);\n\nR2: 0.97\nMAE: 0.15\nRMSE: 0.22"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#similarity",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#similarity",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Similarity",
    "text": "Similarity\nRDKit provides tools for different kinds of similarity search, including Tanimoto, Dice, Cosine, Sokal, Russel… and more. Tanimoto is a very widely use similarity search metric because it incorporates substructure matching. Here is an example\n\nref_mol = df_var_10k.iloc[4234]['ROMol']\n\n\nref_mol\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Generate finger print based representation for that molecule \nref_ECFP4_fps = AllChem.GetMorganFingerprintAsBitVect(ref_mol, radius=2)\n\n\ndf_var_10k_ECFP4_fps = [AllChem.GetMorganFingerprintAsBitVect(x,2) for x in df_var_10k['ROMol']]\n\nEstimate the similarity of the molecules in the dataset to the reference dataset, there are multiple ways of doing it: we are using Tanimoto fingerprints\n\nfrom rdkit import DataStructs\nsimilarity_efcp4 = [DataStructs.FingerprintSimilarity(ref_ECFP4_fps, x) for x in df_var_10k_ECFP4_fps]\n\n\ndf_var_10k['Tanimoto_Similarity (ECFP4)'] = similarity_efcp4\ndf_var_10k['Tanimoto_Similarity (ECFP4)'] = df_var_10k['Tanimoto_Similarity (ECFP4)'].round(3)\nPandasTools.FrameToGridImage(df_var_10k[:10], legendsCol=\"Tanimoto_Similarity (ECFP4)\", molsPerRow=4)\n\n\n\n\n\n\n\n\nSorting the molecule similarity for clarity:\n\ndf_var_10k = df_var_10k.sort_values(['Tanimoto_Similarity (ECFP4)'], ascending=False)\nPandasTools.FrameToGridImage(df_var_10k[:10], legendsCol=\"Tanimoto_Similarity (ECFP4)\", molsPerRow=4)"
  },
  {
    "objectID": "posts/2019-10-04-lambda_map.html",
    "href": "posts/2019-10-04-lambda_map.html",
    "title": "Lambda, Filter, and Map functions in Python",
    "section": "",
    "text": "Lambda is an important function/operator to create anonymous in-line functions in pyhton.\n\n\nlamda arguments: expression\n\n#This is our usual function where we have to define a name for the function\ndef func(x,y):\n    return(x+y)\nfunc(2,3)\n\n5\n\n\n\n#Lambda function \nadd=lambda x,y:x+y\nadd(2,3)\n\n5\n\n\nlambda functions can be used in place of a iterator when sorting – this allows for selecting the column or the varible according to which sorting has to be done\n\nimport numpy as np \nnp.random.seed(42)\na1=np.random.choice(10,5,replace=False)\nfile_list=[]\nfor i in a1: \n    file_list.append('{0}-{1}'.format('Filename',i))\n\n\nprint(file_list)\n\n['Filename-8', 'Filename-1', 'Filename-5', 'Filename-0', 'Filename-7']\n\n\n\nfile_list=sorted(file_list, key=lambda x:x.split('-')[-1])\n\n\nfile_list\n\n['Filename-0', 'Filename-1', 'Filename-5', 'Filename-7', 'Filename-8']"
  },
  {
    "objectID": "posts/2019-10-04-lambda_map.html#lambda",
    "href": "posts/2019-10-04-lambda_map.html#lambda",
    "title": "Lambda, Filter, and Map functions in Python",
    "section": "",
    "text": "Lambda is an important function/operator to create anonymous in-line functions in pyhton.\n\n\nlamda arguments: expression\n\n#This is our usual function where we have to define a name for the function\ndef func(x,y):\n    return(x+y)\nfunc(2,3)\n\n5\n\n\n\n#Lambda function \nadd=lambda x,y:x+y\nadd(2,3)\n\n5\n\n\nlambda functions can be used in place of a iterator when sorting – this allows for selecting the column or the varible according to which sorting has to be done\n\nimport numpy as np \nnp.random.seed(42)\na1=np.random.choice(10,5,replace=False)\nfile_list=[]\nfor i in a1: \n    file_list.append('{0}-{1}'.format('Filename',i))\n\n\nprint(file_list)\n\n['Filename-8', 'Filename-1', 'Filename-5', 'Filename-0', 'Filename-7']\n\n\n\nfile_list=sorted(file_list, key=lambda x:x.split('-')[-1])\n\n\nfile_list\n\n['Filename-0', 'Filename-1', 'Filename-5', 'Filename-7', 'Filename-8']"
  },
  {
    "objectID": "posts/2019-10-04-lambda_map.html#map",
    "href": "posts/2019-10-04-lambda_map.html#map",
    "title": "Lambda, Filter, and Map functions in Python",
    "section": "Map",
    "text": "Map\nWhen you want to have multiple outputs for the functions but do not want to write a for all explicitly you can use map function for pseeding things up\n\ndef square(x):\n    return(x**2)\n\nprint(a1)\nans=[square(i) for i in a1]\nprint(ans)\n\n[8 1 5 0 7]\n[64, 1, 25, 0, 49]\n\n\n\n#Using map function\nmap(square,a1)\n\n&lt;map at 0x7f85058e5eb8&gt;\n\n\n\n#You'd have to first converrt it to list \nlist(map(square,a1))\n\n[64, 1, 25, 0, 49]\n\n\n\nCombining the two:\n\na=np.random.choice(10,5,replace=False)\nb=np.random.choice(50,5,replace=False)\nresult=map(lambda x,y:x*y,a,b)\nprint(a)\nprint(b)\nprint(np.asarray(list(result)))\n\n[0 1 8 5 3]\n[36 16  4  9 45]\n[  0  16  32  45 135]"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html",
    "href": "posts/2020-08-23-imdb_bollywood.html",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "",
    "text": "import os \nfrom requests import get \nimport numpy as np \nimport pandas as pd \nfrom bs4 import BeautifulSoup\nimport time as time \nfrom tqdm.notebook import tqdm\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns\n\nsns.set(style=\"whitegrid\")\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 22,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#load-dataset",
    "href": "posts/2020-08-23-imdb_bollywood.html#load-dataset",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Load Dataset",
    "text": "Load Dataset\nThe data set for the movie was scrapped from IMDB using BeautifulSoup. A template for the code used for scrapping the data is shown in the cell below.\n\n\nCode\nnames, year, imdb_rating, metascore, num_votes = [], [], [], [], [] \n\nstart_time = time.time()\nrequests = 0\n\nyears_url = [str(i) for i in range(1950,2006)]\npage_iter = [0, 51, 101, 151, 201]\n\nfor year_url in tqdm(years_url):\n    for page_num in tqdm(page_iter):\n        #URL to parse \n        url = 'https://www.imdb.com/search/title/?title_type=feature,&release_date={0},{0}&countries=in&languages=hi&sort=num_votes,desc&start={1}&ref_=adv_prv'.format(int(year_url), int(page_num))\n        response = get(url)\n        \n        #Sleep to carve out load \n        time.sleep(np.random.randint(1,5))\n        \n        #Estimate time elapsed per request\n        requests += 1\n        elapsed_time = time.time() - start_time\n        print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n        clear_output(wait = True)\n        \n        html_soup = BeautifulSoup(response.text, 'html.parser')\n        movie_containers = html_soup.find_all('div', class_='lister-item mode-advanced')\n        \n        for i, container in enumerate(movie_containers):\n            container_entry = movie_containers[i] \n            movie_name = container_entry.h3.a.text\n            names.append(movie_name)\n            \n            movie_year = container_entry.h3.find('span',class_='lister-item-year text-muted unbold').text.strip('()')\n            year.append(movie_year)\n            #print(movie_name, movie_year)\n            \n            try:\n                movie_rating = float(container_entry.strong.text)\n                imdb_rating.append(movie_rating)\n            except AttributeError:\n                imdb_rating.append(np.nan)\n            \n            try:\n                movie_votes = float(''.join(container_entry.find('span', attrs = {'name':'nv'}).text.split(',')))\n                num_votes.append(movie_votes)\n            except (AttributeError, ValueError):\n                num_votes.append(np.nan)\n                \n            try:\n                movie_metascore = float(container_entry.find('span', class_='metascore').text.strip())\n                metascore.append(movie_metascore)\n            except AttributeError:\n                metascore.append(np.nan)\n    \n    print('Making dataframe for year {}'.format(year_url))\n    df_movies = pd.DataFrame({'name':names,'year':year,'rating':imdb_rating,'metascore':metascore,'num_votes':num_votes})\n    df_movies.to_csv('./temp_imdb_files/bollywood_data_{}.csv'.format(year_url),sep=',',header=True, index=False)\n    del df_movies\n\n\n\ndf_movies = pd.read_csv('./IMDB-files/bollywood_movies_data_1950_2020_new.csv',sep=',', skipinitialspace=True)\n\n\ndf_movies.columns\n\nIndex(['name', 'year', 'rating', 'metascore', 'num_votes'], dtype='object')\n\n\n\ndf_movies.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 11876 entries, 0 to 11875\nData columns (total 5 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   name       11876 non-null  object \n 1   year       11875 non-null  object \n 2   rating     7427 non-null   float64\n 3   metascore  91 non-null     float64\n 4   num_votes  7427 non-null   float64\ndtypes: float64(3), object(2)\nmemory usage: 464.0+ KB"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#cleaning-the-data",
    "href": "posts/2020-08-23-imdb_bollywood.html#cleaning-the-data",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Cleaning the data",
    "text": "Cleaning the data\nSince we are particularly interested in release year of the movies, we can sanitize that column first. To begin, we see what are different possible strings/elements in the year.\n\ndf_movies['year'].unique()\n\narray(['1950', '1951', 'I) (1951', '1952', '1957', 'II) (1952', '1953',\n       'II) (1953', 'III) (1953', 'I) (1953', '1954', 'I) (1954',\n       'III) (1954', '1955', '1956', 'II) (1957', '1958', 'I) (1958',\n       '1959', 'II) (1959', '1960', 'I) (1960', '1961', '1962', '1963',\n       'I) (1964', '1964', '1965', '1966', '1967', '1968', 'I) (1968',\n       '1969', 'I) (1969', '1979', '1970', 'II) (1970', '1971',\n       'I) (1971', 'II) (1971', '1972', 'II) (1972', '1973', '1974',\n       'II) (1974', '1975', 'I) (1975', 'II) (1975', '1976', '1977',\n       'I) (1977', '1978', 'II) (1978', 'I) (1979', 'II) (1979', '1980',\n       'I) (1980', '1981', '1982', 'I) (1982', '1983', 'I) (1983',\n       'II) (1983', '1984', 'II) (1984', '1985', 'I) (1985', '1986',\n       'I) (1986', 'II) (1986', '1987', 'I) (1987', '1988', 'I) (1988',\n       'II) (1988', '1989', 'I) (1989', '1990', 'II) (1990', 'I) (1990',\n       '1991', 'I) (1991', '1992', '1993', 'I) (1992', 'II) (1992',\n       'I) (1993', 'II) (1993', '1994', 'II) (1994', 'I) (1994', '1995',\n       '1996', 'I) (1996', '1997', 'I) (1997', '1998', 'II) (1998',\n       '2005', '1999', 'II) (1999', '2000', 'II) (2000', 'I) (2000',\n       '2001', 'I) (2001', 'I) (2002', '2002', '2003', 'I) (2003', '2004',\n       '2007', 'I) (2005', 'II) (2005', '2006', 'I) (2006', 'II) (2006',\n       'I) (2007', 'III) (2007', '2008', 'I) (2008', 'II) (2008', '2009',\n       'I) (2009', '2012', 'II) (2009', '2010', 'I) (2010', 'II) (2010',\n       'IV) (2010', '2011', 'I) (2011', 'II) (2011', 'IV) (2011',\n       'II) (2012', 'I) (2012', '2013', 'I) (2013', 'II) (2013',\n       'V) (2013', '2014', 'I) (2014', 'III) (2014', 'VIII) (2014',\n       'II) (2014', 'IV) (2014', '2015', 'I) (2015', 'V) (2015',\n       'III) (2015', 'VI) (2015', 'II) (2015', 'IV) (2015', '2016',\n       'I) (2016', 'III) (2016', 'XVII) (2016', 'IV) (2016', 'V) (2016',\n       'X) (2016', 'II) (2016', 'VII) (2016', 'VI) (2016', '2017',\n       'I) (2017', 'II) (2017', 'III) (2017', 'IV) (2017', '2018',\n       'III) (2018', 'I) (2018', 'II) (2018', '2019', 'III) (2019',\n       'I) (2019', 'II) (2019', 'IV) (2019', '2020', 'I) (2020',\n       'II) (2020', 'VI) (2020', nan], dtype=object)\n\n\nData pulled from the website has phantom characters alongside the dates. Hence this would need some cleaning from our end to ensure all the dates are in consistent format.\n\ndf_movies.shape\n\n(11876, 5)\n\n\nI am using strip to loop each date entry in the dataset and strip off any residual characters which coincide with the those mentioned in the filter. Another option is to use replace in pandas using regex filters\n\ndf_movies['year'] = df_movies['year'].astype('str')\n\n\ndf_movies['year']=[i.strip('IIII) XVII) ( (  TV Special  TV Mov') for i in df_movies['year'].tolist()]\n\nPrinting the data again to check for the date entries:\n\ndf_movies['year'].unique()\n\narray(['1950', '1951', '1952', '1957', '1953', '1954', '1955', '1956',\n       '1958', '1959', '1960', '1961', '1962', '1963', '1964', '1965',\n       '1966', '1967', '1968', '1969', '1979', '1970', '1971', '1972',\n       '1973', '1974', '1975', '1976', '1977', '1978', '1980', '1981',\n       '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989',\n       '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997',\n       '1998', '2005', '1999', '2000', '2001', '2002', '2003', '2004',\n       '2007', '2006', '2008', '2009', '2012', '2010', '2011', '2013',\n       '2014', '2015', '2016', '2017', '2018', '2019', '2020', 'nan'],\n      dtype=object)\n\n\nConsistency check for the dataframe shape to ensure no funny business\n\ndf_movies.shape\n\n(11876, 5)"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#filtering-out-movies",
    "href": "posts/2020-08-23-imdb_bollywood.html#filtering-out-movies",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Filtering out movies",
    "text": "Filtering out movies\nSince IMDb is a fairly recent rating portal there are lot of movies especially those realeased pre 1980s which have low votes. Also IMDb lists every possible movie that was released in Hindi language. To better focus on credible movies I would filter out movies with low votes\n\nvotes_filter = df_movies['num_votes'] &gt; 50 #Filter out movies which have got less than 100 votes from IMDb users \ndf_movies_filter_votes = df_movies.loc[votes_filter].reset_index(drop=True) #Reset the indices of the new dataframe and drop the old ones -- if not done a different column with old index is appended \n\n\ndf_movies_filter_votes.shape\n\n(3912, 5)"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#convert-year-data-entry-to-pandas-datetime-object-for-convenience",
    "href": "posts/2020-08-23-imdb_bollywood.html#convert-year-data-entry-to-pandas-datetime-object-for-convenience",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Convert year data entry to pandas Datetime object for convenience",
    "text": "Convert year data entry to pandas Datetime object for convenience\n\ndf_movies_filter_votes['year'] = pd.to_datetime(df_movies_filter_votes['year'],format='%Y').dt.year"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#analyze-annual-movie-releases",
    "href": "posts/2020-08-23-imdb_bollywood.html#analyze-annual-movie-releases",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Analyze annual movie releases",
    "text": "Analyze annual movie releases\nDefining a separate dataframe for doing per-year analysis\n\nstat_list = ['year', 'total_movies_year', 'highest_rated_movie', 'movie_rating','avg_num_votes', 'avg_movie_rating']\nannual_movie_stats = {keys:[] for keys in stat_list} \n\nfor year_entry in df_movies_filter_votes['year'].unique():\n    per_year_column = df_movies_filter_votes.loc[df_movies_filter_votes['year'] == year_entry]\n    \n    try:\n        movie_entry_with_max_ratings = df_movies_filter_votes.loc[per_year_column['rating'].idxmax()]\n        higest_movie_rating = movie_entry_with_max_ratings['rating']\n        highest_rated_movie = movie_entry_with_max_ratings['name']\n        avg_movie_rating = per_year_column['rating'].mean()\n        total_movies = len(per_year_column)\n        avg_num_votes = per_year_column['num_votes'].mean()\n    except ValueError:\n        higest_movie_rating = np.nan\n        highest_rated_movie = np.nan\n        total_movies = np.nan\n        avg_movie_rating = np.nan \n    \n    annual_movie_stats['year'].append(year_entry)\n    annual_movie_stats['highest_rated_movie'].append(highest_rated_movie)\n    annual_movie_stats['movie_rating'].append(higest_movie_rating)\n    annual_movie_stats['avg_movie_rating'].append(avg_movie_rating)\n    annual_movie_stats['total_movies_year'].append(total_movies)\n    annual_movie_stats['avg_num_votes'].append(avg_num_votes)\n\n\ndf_annual_movie_stats = pd.DataFrame(annual_movie_stats, columns=annual_movie_stats.keys())\n\n\ndf_annual_movie_stats.sample(5)\n\n\n\n\n\n\n\n\nyear\ntotal_movies_year\nhighest_rated_movie\nmovie_rating\navg_num_votes\navg_movie_rating\n\n\n\n\n49\n1999\n67\nSarfarosh\n8.1\n2201.328358\n5.583582\n\n\n3\n1953\n9\nDo Bigha Zamin\n8.4\n293.000000\n7.388889\n\n\n69\n2019\n141\n99 Songs\n8.8\n4041.056738\n6.002128\n\n\n9\n1959\n11\nKaagaz Ke Phool\n8.0\n329.454545\n7.172727\n\n\n34\n1984\n36\nSaaransh\n8.2\n286.055556\n6.427778\n\n\n\n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(2, 1, figsize=(30,20), sharex=True)\nyear_list = [\"'{}\".format(str(value)[2:]) for value in df_annual_movie_stats.year.to_list()]\nsns.barplot(x=year_list, y='total_movies_year', color='k', alpha=0.8, data=df_annual_movie_stats, ax=ax1)\nax1.set_ylabel('Average movies released')\n\nsns.scatterplot(year_list, 'avg_movie_rating', size='avg_num_votes', color='k', sizes=(40, 400), data=df_annual_movie_stats, ax=ax2);\nax2.set_xlabel('Year')\nax2.set_ylabel('Average movie rating')\nax2.get_legend()\nfor item in ax2.get_xticklabels():\n    item.set_rotation(45)\n    \nplt.tight_layout()\n\n/Users/pghaneka/miniconda3/envs/doodle/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\nThe two plots show the number of films released each year and the average IMDb rating for the movies released in that year. Now we might conclude that movies are getting selectively worse in spite of there being more movies being released, however the confidence in that statement is difficult to justify since the number of votes casted in these movies is an important parameter to keep in mind."
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#sort-the-movies-released-as-per-decades",
    "href": "posts/2020-08-23-imdb_bollywood.html#sort-the-movies-released-as-per-decades",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Sort the movies released as per decades",
    "text": "Sort the movies released as per decades\nDefine a new column here as per decade to condense the analysis\n10 * (df_annual_movie_stats['year']//10)\nThis line converts years to a decade entry\n\ndf_annual_movie_stats['decade'] = 10 * (df_annual_movie_stats['year']//10)\n\n\ndf_annual_movie_stats_decade = df_annual_movie_stats.groupby(['decade']).mean()\n\n\ndf_annual_movie_stats_decade.sample(5)\n\n\n\n\n\n\n\n\nyear\ntotal_movies_year\nmovie_rating\navg_num_votes\navg_movie_rating\n\n\ndecade\n\n\n\n\n\n\n\n\n\n2000\n2004.5\n94.0\n8.46\n5160.443252\n5.399690\n\n\n2010\n2014.5\n126.2\n8.44\n6305.900985\n5.748150\n\n\n2020\n2020.0\n102.0\n8.90\n7485.009804\n5.785294\n\n\n1960\n1964.5\n17.6\n8.15\n326.809100\n7.104778\n\n\n1970\n1974.5\n30.4\n8.18\n820.688426\n6.876870\n\n\n\n\n\n\n\n\ndf_annual_movie_stats_decade.index\n\nInt64Index([1950, 1960, 1970, 1980, 1990, 2000, 2010, 2020], dtype='int64', name='decade')\n\n\n\ndecade_list = [\"{}s\".format(str(value)[2:]) for value in df_annual_movie_stats_decade.index.to_list()]\n\n\nfig, (ax1,ax2) = plt.subplots(2, 1, figsize=(15,10), sharex=True)\n\nsns.barplot(x=decade_list, y='total_movies_year', data=df_annual_movie_stats_decade, color='k', alpha=0.8, ax=ax1)\nax1.set_ylabel('Average movies released annually')\n\nsns.scatterplot(decade_list, 'avg_movie_rating', size='avg_num_votes', sizes=(100, 400), data=df_annual_movie_stats_decade, ax=ax2);\nsns.despine()\n\nax2.set_xlabel('Decade')\nax2.set_ylabel('Average movie rating')\nax2.get_legend().remove()\n\nplt.tight_layout()\n\n/Users/pghaneka/miniconda3/envs/doodle/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  warnings.warn("
  },
  {
    "objectID": "posts/2019-08-13-pytorch_mnist_classification.html",
    "href": "posts/2019-08-13-pytorch_mnist_classification.html",
    "title": "Neural network implementation in PyTorch",
    "section": "",
    "text": "This notebook is inspired by the Andrew Ng’s amazing Coursera course on Deep learning. The dataset we will be using the train the model on is the MNIST dataset which one of the default datasets in PyTorch.\n\nimport numpy as np \nimport torch \nimport torch.nn as nn \nimport torchvision \nimport torchvision.transforms as transforms \nimport matplotlib.pyplot as plt \nimport matplotlib as mpl\n\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\ndevice = 'cpu' #torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\ncpu\n\n\n\n#Import MNIST dataset\ntrain_dataset = torchvision.datasets.MNIST(root='data/',\n                                           train=True,\n                                           transform=torchvision.transforms.ToTensor(),\n                                           download=True)\n\nval_dataset = torchvision.datasets.MNIST(root='data/',\n                                           train=False,\n                                           transform=torchvision.transforms.ToTensor(),\n                                           download=True)\ninput_tensor, label = train_dataset[0]\nprint('MNIST dataset with {} train data and {} test data'.format(len(train_dataset), len(val_dataset)))\nprint('Type of data in dataset: {} AND {}'.format(type(input_tensor), type(label)))\nprint('Input tensor image dimensions: {}'.format(input_tensor.shape))\n\nMNIST dataset with 60000 train data and 10000 test data\nType of data in dataset: &lt;class 'torch.Tensor'&gt; AND &lt;class 'int'&gt;\nInput tensor image dimensions: torch.Size([1, 28, 28])\n\n\n\n#Model hyper-parameters for the fully connected Neural network \ninput_size = 784 # Image input for the digits - 28 x 28 x 1 (W-H-C) -- flattened in the end before being fed in the NN \nnum_hidden_layers = 1\nhidden_layer_size = 50\nnum_classes = 10 \nnum_epochs = 50\nbatch_size = 64 \nlearning_rate = 10e-4\n\n\n#Convert dataset to a dataloader class for ease of doing batching and SGD operations \nfrom torch.utils.data import Dataset, DataLoader\ntrain_loader = DataLoader(dataset = train_dataset,\n                          batch_size = batch_size,\n                          shuffle=True,\n                          num_workers = 2)\n\ntest_loader = DataLoader(dataset = val_dataset,\n                        batch_size = batch_size, \n                        num_workers = 2)\n\n#Take a look at one batch \nexamples = iter(train_loader)\nsamples, labels = examples.next()\nprint(samples.shape, labels.shape)\n\n#Plotting first 4 digits in the dataset: \nfor i in range(4):\n    plt.subplot(2, 2, i+1)\n    plt.imshow(samples[i][0], cmap=mpl.cm.binary, interpolation=\"nearest\")\n    plt.title('Digit:{}'.format(labels[i]))\n    plt.axis(\"off\");\n\ntorch.Size([64, 1, 28, 28]) torch.Size([64])\n\n\n\n\n\n\n\n\n\nAbove, we have defined a batch-size of 100 for the training dataset with the samples as seen here to be of size = 100 x 1 x 28 x 28\n\n#Define a model \nclass NeuralNet(nn.Module):\n    def __init__(self, input_size, num_hidden_layers, hidden_layer_size, num_classes):\n        super(NeuralNet, self).__init__()\n        self.L1 = nn.Linear(in_features = input_size, out_features = hidden_layer_size)\n        self.relu = nn.ReLU()\n        self.num_hidden_layers = num_hidden_layers\n        \n        if (self.num_hidden_layers-1) &gt; 1:\n            self.L_hidden = nn.ModuleList( [nn.Linear(in_features = hidden_layer_size, out_features = hidden_layer_size) for _ in range(num_hidden_layers-1)] )\n            self.relu_hidden = nn.ModuleList( [nn.ReLU() for _ in range(num_hidden_layers-1)] )\n        else:\n            self.L2 = nn.Linear(in_features = hidden_layer_size, out_features = hidden_layer_size)\n            \n        self.L_out = nn.Linear(in_features = hidden_layer_size, out_features = num_classes)\n    \n    def forward(self, x):\n        out = self.relu(self.L1(x))\n        \n        if (self.num_hidden_layers-1) &gt; 1:\n            for L_hidden, relu_hidden in zip(self.L_hidden, self.relu_hidden):\n                out = relu_hidden(L_hidden(out))\n        else:\n            out = self.relu(self.L2(out))\n        out = self.L_out(out) #No softmax or cross-entropy activation just the output from linear transformation\n        return out\n\n\nmodel = NeuralNet(input_size=input_size, \n                  num_hidden_layers=num_hidden_layers, \n                  hidden_layer_size=hidden_layer_size, \n                  num_classes=num_classes)\n\n\nmodel\n\nNeuralNet(\n  (L1): Linear(in_features=784, out_features=50, bias=True)\n  (relu): ReLU()\n  (L2): Linear(in_features=50, out_features=50, bias=True)\n  (L_out): Linear(in_features=50, out_features=10, bias=True)\n)\n\n\nCrossEntropyLoss in Pytorch implementes Softmax activation and NLLLoss in one class.\n\n#Loss and optimizer \ncriterion = nn.CrossEntropyLoss() #This is implement softmax activation for us so it is not implemented in the model \noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n#Training loop \ntotal_batches = len(train_loader)\nlosses = []\nepochs = []\nfor epoch in range(num_epochs):\n    for i, (image_tensors, labels) in enumerate(train_loader):\n        running_loss = 0\n        batch_count = 0\n        \n        #image tensor = 100, 1, 28, 28 --&gt; 100, 784 input needed \n        image_input_to_NN = image_tensors.view(-1,28*28).to(device)\n        labels = labels.to(device)\n        \n        #Forward pass \n        outputs = model(image_input_to_NN)\n        loss = criterion(outputs, labels)\n        \n        running_loss += loss.item()\n        batch_count += 1\n        \n        #Backward \n        optimizer.zero_grad() #Detach and flush the gradients \n        loss.backward() #Backward gradients evaluation \n        optimizer.step() #To update the weights/parameters in the NN \n        \n        if (epoch) % 10 == 0 and (i+1) % 500 == 0: \n            print(f'epoch {epoch+1} / {num_epochs}, batch {i+1}/{total_batches}, loss = {loss.item():.4f}')\n    \n    loss_per_epoch = running_loss / batch_count\n    epochs.append(epoch)\n    losses.append(loss_per_epoch)\n\nepoch 1 / 50, batch 500/938, loss = 0.2568\nepoch 11 / 50, batch 500/938, loss = 0.0431\nepoch 21 / 50, batch 500/938, loss = 0.0141\nepoch 31 / 50, batch 500/938, loss = 0.0032\nepoch 41 / 50, batch 500/938, loss = 0.0518\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nax.plot(epochs, losses)\nplt.title('Loss Curve (Training)')\nax.set_xlabel('Epochs')\nax.set_ylabel('Loss Value')\n\nText(0, 0.5, 'Loss Value')\n\n\n\n\n\n\n\n\n\n\n#Test \nwith torch.no_grad():\n    n_correct = 0 \n    n_samples = 0 \n    for images, labels in test_loader:\n        images = images.view(-1, 28*28).to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        \n        _, predictions = torch.max(outputs, 1)\n        n_samples += labels.shape[0]\n        n_correct += (predictions == labels).sum().item() #For each correction prediction we add the correct samples \n    acc = 100 * n_correct / n_samples\n    print(f'Accuracy = {acc:.2f}%')\n\nAccuracy = 97.54%"
  },
  {
    "objectID": "posts/2021-06-25-ML_resources.html",
    "href": "posts/2021-06-25-ML_resources.html",
    "title": "Resources list",
    "section": "",
    "text": "Below is a non-exhaustive list of resources including blogs, courses, books, podcasts, and video lectures which I have found extremely useful in learning python, statstics, and machine-learning concepts.\n\nHighly recommended machine-learning starting point:\nFor practical purposes, I’ve noticed, it is not always necessary dive super deep in a concept, rather its helpful to get a concise version of the concept, understand the core assumptions, and start applying the concept right away figuring out your knowledge gaps along the way. I strongly believe in the 80-20 rule (80% output from 20% input). In that spirit, following are the top five sources to get upto speed on learning the basics of ML.\n\nHands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Github\n\nI started to read on ML and data analysis using this wonderful book by Aurélien Géron. This is one of the best, if not the best, introductory books for machine learning. It is concise and simple to read and has jupyter notebooks to apply the concepts taught in it. Initial chapters (Part 1) of the book offer a strong foundation for traditional ML algorithms.\n\nData science from scratch\n\nBesides just focusing on ML, having experience with data wrangling using PyData stack (NumPy, Pandas, and friends) is always a plus. In fact, most of the time the limitation in setting up any ML model is massaging data into machine readable format.\n\nPractical Deep Learning for coders from Fast.AI (using PyTorch)\n\nDeep Learning is the most popular sub-branch of ML and something you should have a general understanding of. Jeremy Howard and team have setup this wonderful didactic coursework using PyTorch (personal preference) comprising of useful collection of walkthroughs and practical examples.\n\nIntroduction to Statistical Learning + Elements of Statistical Learning\n\nFantastic high-level math focussed introduction to algorithms.\n\n100 page ML\n\nApproachable compendium of key ML concepts boiled down to key insights, offers a nice way to articulate concepts in a concise way.\n\n\nSeminal AI papers\n\nWord2Vec\nAttention Is All You Need\nBERT Model\nReACT\n\n\n\nNice (free) online courses:\nMachine Learning\n\nMIT’s Intro to Deep Learning\nGoogle’s ML crash course\nStanford’s CS - CNN course\nNYU’s PyTorch Deep learning\nAI Summer\n\nData Science and Computation\n\nMIT’s course on Computational Thinking\nHarvard’s CS 109\n\nMiscellaneous\n\nCMU’s course on Computer Graphics\n\n\n\nPython in general\nLearning Python\n\nAutomate Boring Stuff with Python\nScientific programing with Python\nVisual Guide to Numpy\nPython DataScience Handbook\nChris Albon’s notes\nNumpy Visual Introduction\n\nTutorials / Projects\n\nPynative\nPython Workout\nReuven Lerner’s Python Interview Prep\nProject Euler\nCalm code tips on python code\n\nWriting better code * Corey Schafer’s Tips for writing better code * Refactory blog * RealPython blog\nDatasets\n\nFiveThreeEight\nPudding data\nOur world in data\nUS Federal Reserve dataset with visualization\nIndia centric dataset\nMisc collection\n\n\n\nBooks and websites\nStatstics & Exploratory Analysis\n\nThink Stats by Allen Downley\nTelling stories with data\n\nData Science\n\nJakevdp Python Datascience Notebook\nIntroduction to Cultural Analytics & Python Nice collection of tips for web scraping, network analysis, geotagging, language processing using python.\n\nData Visualization\n\nFundamentals of Data Visualization\nCompendium of different charting types and python code\n\nMachine-Learning\n\nML Online notebook\nML interview book by Chip Huyen\nAndrew White’s Deep Learning for Molecules and Materials Notebook\nOnline deep learning book by Ian Goodfellow\nInterpretable Machine Learning\n\n\n\nMachine-learning focused key commentaries, perspectives, and reviews\nArea reviews\n\nA Survey of Deep Learning for Scientific Discovery\nThe Discipline of Machine Learning\n\nGeneral tips\n\nHow to avoid machine learning pitfalls: a guide for academic researchers\nScikit-learn documentation on common pitfalls\nMachine Learning that Matters\nThree pitfalls to avoid in machine learning\nA Few Useful Things to Know about Machine Learning\n\nCommentaries\n\nStatistical Modeling: The Two Cultures\nThe Hardware Lottery\nMachine Learning that Matters\nWhy is AI harder than we think\n\nIn Chemical Sciences:\n\nA. Y. T. Wang et al., “Machine Learning for Materials Scientists: An Introductory Guide toward Best Practices,” Chem. Mater., vol. 32, no. 12, pp. 4954–4965, 2020\n\nMolecular science:\n\nF. Strieth-Kalthoff, F. Sandfort, M. H. S. Segler, and F. Glorius, Machine learning the ropes: principles, applications and directions in synthetic chemistry, Chem. Soc. Rev\n\nGraph networks\n\nGraph networks: Relational inductive biases, deep learning, and graph networks\nMedium blog on graph neural networks\nAn attempt at demystifying graph deep learning\nGraphML substack\n\n\n\nCheat Sheets\nI’ve compiled some nice cheat-sheets discussing basics of ML, Data Science, Statistics concepts alongside some tips on NumPy, Pandas, and Scikit-learn. These compilations are particularly useful when brushing up details before a potential job interview. Link to dataset repository\n\n\nVideo series\nExplanations\n\nNeural networks series by 3Blue1Brown\nMachine learning zero to hero\nAli Godsi’s video lecture series (highly recommend his lecture on Variational Auto Encoders)\nKhan Academy’s Multivariate Calculus\nKhan Academy Statsitics + Probability\n\nPyCon talks\n\nStatistics for Hackers, Jake Vanderplas\nStatistical Thinking for Data Science, Chris Fonnesbeck\n\nAI talks / commentaries\n\nDangers of AI is weirder than you think\nMachine learning and algorithmic fairness in public and population health\nHundreds of AI tools have been built to catch covid. None of them helped.\n\n\n\nBlogs\nData Science focused\n\nNate Silver’s 538\nJim Vallandingham\nPudding’s data viz\nFlowing Data\nMike Bostock\nSpurious Correlations\nUnderstanding uncertainty\nMath3ma Blog\nMax Wolfe\nChris Albon\nCaitlin Hudson\n\nStatistics Blogs * Statistics by Jim * Probably overthinking it by Allen Downley\nML inclined * Chris Olah * Andrej Karpathy, wonderfully didactic posts * Jay Alammer’s NLP focussed\nML code examples and tutorials * Keras Code Examples * Tensorflow Examples * PyTorch Examples\nGeneral compilations * Distill Blog * KDNuggets\n\n\nData-inspired Podcasts\nFanstastic resource, you can be a fly on the wall and listen to experts talk about a topic that interests you\n\nAI in Business\nMcKinsey AI\nAZ16 podcast\nData Skeptic\nLex Friedman / AI podcast\nMicrosoft Research Podcast\n\n\n\nYouTubers\nList of YouTuber channels that never fail to inspire me\n1. Science and Technology\n\nVsauce\nSixty Symbols\nTom Scott\n3Blue1Brown\nVertisasium\nApplied Science\nMKBHD\n\nStatistics\n\nStatQuest\nCorey Schafer\n\n2. Food\n\nJ Kenji Lopez-Alt\nBinging with Babish\nAdam Ragusea\nFood Wishes\n\n3.Videography and Design\n\nCasey Neistat\nDan Mace\nPeter McKinnon\nAndrew Price - Blender\nCGMatter\nCG Figures - Scientific visualization in Blender\n\n4. Journalism\n\nDhruv Rahtee\nJohnny Harris\nFaye D’Souza\n\n\n\nDiversity & Inclusion\n\nDelotte’s Woman in AI\nAccount from Dow employees going from R&D to D&I\nDiversity in STEM: What it is and Why it Matters\nHow Diversity Makes Us Smarter\nIncreasing Gender Diversity in the STEM Research Workforce\nWithout Inclusion, Diversity Initiatives May Not Be Enough\nWork organization and mental health problems in PhD students\n\n\n\nMisc\n\nPaul Graham\nSam Altman\nBeauty of Science\nFarnam Street\nLess Wrong\nMaria Popova’s Brain Pickings\nWait But Why\nBrad Feld’s Personal Blog\nMelthing Asphalt\nRobert Heaton\nAstral Codex Ten\nAntonio García Martínez\n\n\n\nComics\n\nXkcd\nOatmeal\nCatana Comics"
  },
  {
    "objectID": "posts/2021-12-05-ML_interpretability.html",
    "href": "posts/2021-12-05-ML_interpretability.html",
    "title": "On machine learning model interpretability",
    "section": "",
    "text": "Process mindset vs outcome mindset argument – understanding right decision and right outcomes.\nHelpful notebook on simple and useful tips on model interpretations in chemical science from ever-amazing Patrick Walters."
  },
  {
    "objectID": "posts/2021-12-05-ML_interpretability.html#future-reading-additional-links",
    "href": "posts/2021-12-05-ML_interpretability.html#future-reading-additional-links",
    "title": "On machine learning model interpretability",
    "section": "Future Reading / Additional Links",
    "text": "Future Reading / Additional Links\n\nOnline Jupyter book on Interpretable Machine Learning(https://christophm.github.io/interpretable-ml-book/index.html) – highly recommended\n\nFantastic book commenting on the mathematics and idea for different method for ML model interpretatability.\n\nExplainable AI Cheetsheet. Video discussion on the general idea by Jay Alammar.\nGradient Blog Commentary on ML interpretability\nZoom in on circuits of a Neural Network\nNeptune Blog article on interpretable models\nModule for incorporating model interpretatbility for PyTorch models"
  },
  {
    "objectID": "posts/2021-12-05-ML_interpretability.html#few-key-work-horses",
    "href": "posts/2021-12-05-ML_interpretability.html#few-key-work-horses",
    "title": "On machine learning model interpretability",
    "section": "Few key work horses:",
    "text": "Few key work horses:\n\n1. SHAP\nSHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model.Github\nConsidering cooperative prediction - the value added by the feature contribution to the final output and compare it to its individual output if that feature was active.\nGiven the current set of feature values, the contribution of a feature value to the difference between the actual prediction and the mean prediction is the estimated Shapley value.\n\n\n2. Counterfactuals\n\nIf X had not occured, would have Y occured?\n\nA counterfactual is a idea of relating an action to a consequence.\n“Would I have got a cold, if I had not eaten the ice-cream?”\nUsually a model agnostic approach is implemented, wherein the input(s) of the model is varied and its effect on the prediction is analyzed. Mind here that we dont really care how the model predicts tthe output but just if the output changes by changing the input.\nThe idea echoes with the concept of degree of rate control first proposed by Charles Campbell to propose kinetic pathways and intermediates which have most impact on the final chemical reaction rate.\nCounterfactual have an important drawback - they suffer from the possibility of multiple truths. Explain on why that molecule: Andrew White Lab. Github\nPen’s blog on implementation of Exmol\nExplainerDashboard python package\nAutomate model design and NN architecture search?\n\n\n3. Canonical Correlation Analysis\nVideo from Jay Alammar."
  },
  {
    "objectID": "posts/2022-01-10-cheminfo_basics_smarts.html",
    "href": "posts/2022-01-10-cheminfo_basics_smarts.html",
    "title": "Cheminformatics basics - A SMARTS way to filter molecules",
    "section": "",
    "text": "The code in this notebook is inspired from: * iwatobipen * PatWalters"
  },
  {
    "objectID": "posts/2022-01-10-cheminfo_basics_smarts.html#pattern-matching",
    "href": "posts/2022-01-10-cheminfo_basics_smarts.html#pattern-matching",
    "title": "Cheminformatics basics - A SMARTS way to filter molecules",
    "section": "Pattern matching",
    "text": "Pattern matching\n\nIn molecules\nThe SMART way\nSMARTS (SMiles ARbitrary Target Specification) is a lanuguage used to search, select, and match a substructure pattern in a molecule SMILE. The idea of SMARTS is reminiscent of regular expressions (regex) for texts. Following some pre-defined rules for searching, SMARTS offer a powerful way to systematically search though a large corpus of molecules for a particular chemical phenotype.\nMore details on the SMARTS and its ‘grammar’ can be found on the Daylight’s official page\nFew words of caution: * SMILES represent whole molecule (graph), SMARTS identify a substructure (subgraph). * All SMILES are valid SMARTS * It is better to be precise with your query than be general (you dont know what it might hit if not meticulous) &gt; For instance, the SMILES O means an aliphatic oxygen with zero charge and two hydrogens, i.e. water. In SMARTS, the same expression means any aliphatic oxygen regardless of charge, hydrogen count, etc, e.g. it will match the oxygen in water, but also those in ethanol, acetone, molecular oxygen, hydroxy and hydronium ions, etc. Specifying [OH2] limits the pattern to match only water (this is also the fully specified SMILES for water).\n\n\nSMARTS Atomic Primitives\n\n\n\n\nSymbol\n\n\nSymbol name\n\n\nAtomic property requirements\n\n\nDefault\n\n\n\n\n\n\n\nwildcard\n\n\nany atom\n\n\n(no default)\n\n\n\n\n\na\n\n\naromatic\n\n\naromatic\n\n\n(no default)\n\n\n\n\nA\n\n\naliphatic\n\n\naliphatic\n\n\n(no default)\n\n\n\n\nD&lt;n&gt;\n\n\ndegree\n\n\n&lt;n&gt; explicit connections\n\n\nexactly one\n\n\n\n\nH&lt;n&gt;\n\n\ntotal-H-count\n\n\n&lt;n&gt; attached hydrogens\n\n\nexactly one1\n\n\n\n\nh&lt;n&gt;\n\n\nimplicit-H-count\n\n\n&lt;n&gt; implicit hydrogens\n\n\nat least one\n\n\n\n\nR&lt;n&gt;\n\n\nring membership\n\n\nin &lt;n&gt; SSSR rings\n\n\nany ring atom\n\n\n\n\nr&lt;n&gt;\n\n\nring size\n\n\nin smallest SSSR ring of size &lt;n&gt;\n\n\nany ring atom2\n\n\n\n\nv&lt;n&gt;\n\n\nvalence\n\n\ntotal bond order &lt;n&gt;\n\n\nexactly one2\n\n\n\n\nX&lt;n&gt;\n\n\nconnectivity\n\n\n&lt;n&gt; total connections\n\n\nexactly one2\n\n\n\n\nx&lt;n&gt;\n\n\nring connectivity\n\n\n&lt;n&gt; total ring connections\n\n\nat least one2\n\n\n\n\n\n&lt;n&gt;\n\n\nnegative charge\n\n\n-&lt;n&gt; charge\n\n\n-1 charge (– is -2, etc)\n\n\n\n\n\n+&lt;n&gt;\n\n\npositive charge\n\n\n+&lt;n&gt; formal charge\n\n\n+1 charge (++ is +2, etc)\n\n\n\n\n#n\n\n\natomic number\n\n\natomic number &lt;n&gt;\n\n\n(no default)2\n\n\n\n\n@\n\n\nchirality\n\n\nanticlockwise\n\n\nanticlockwise, default class2\n\n\n\n\n@@\n\n\nchirality\n\n\nclockwise\n\n\nclockwise, default class2\n\n\n\n\n@&lt;c&gt;&lt;n&gt;\n\n\nchirality\n\n\nchiral class &lt;c&gt; chirality &lt;n&gt;\n\n\n(nodefault)\n\n\n\n\n@&lt;c&gt;&lt;n&gt;?\n\n\nchiral or unspec\n\n\nchirality &lt;c&gt;&lt;n&gt; or unspecified\n\n\n(no default)\n\n\n\n\n&lt;n&gt;\n\n\natomic mass\n\n\nexplicit atomic mass\n\n\nunspecified mass\n\n\n\n\n\nExamples1:\n\n\n\n\nC\n\n\naliphatic carbon atom\n\n\n\n\nc\n\n\naromatic carbon atom\n\n\n\n\na\n\n\naromatic atom\n\n\n\n\n[#6]\n\n\ncarbon atom\n\n\n\n\n[Ca]\n\n\ncalcium atom\n\n\n\n\n[++]\n\n\natom with a +2 charge\n\n\n\n\n\n\n[R]\n\n\natom in any ring\n\n\n\n\n[D3]\n\n\natom with 3 explicit bonds (implicit H’s don’t count)\n\n\n\n\n[X3]\n\n\natom with 3 total bonds (includes implicit H’s)\n\n\n\n\n[v3]\n\n\natom with bond orders totaling 3 (includes implicit H’s)\n\n\n\n\nCC@HO\n\n\nmatch chirality (H-F-O anticlockwise viewed from C)\n\n\n\n\nCC@?HO\n\n\nmatches if chirality is as specified or is not specified\n\n\n\n\n\n\n\n\n\n\ncc\n\n\nany pair of attached aromatic carbons\n\n\n\n\nc:c\n\n\naromatic carbons joined by an aromatic bond\n\n\n\n\nc-c\n\n\naromatic carbons joined by a single bond (e.g. biphenyl).\n\n\n\n\nO\n\n\nany aliphatic oxygen\n\n\n\n\n[O;H1]\n\n\nsimple hydroxy oxygen\n\n\n\n\n[O;D1]\n\n\n1-connected (hydroxy or hydroxide) oxygen\n\n\n\n\n[O;D2]\n\n\n2-connected (etheric) oxygen\n\n\n\n\n[C,c]\n\n\nany carbon\n\n\n\n\nF,Cl,Br,I]\n\n\nthe 1st four halogens.\n\n\n\n\n[N;R]\n\n\nmust be aliphatic nitrogen AND in a ring\n\n\n\n\n[!C;R]\n\n\n( NOTaliphatic carbon ) AND in a ring\n\n\n\n\n[n;H1]\n\n\nH-pyrrole nitrogen\n\n\n\n\n[n&H1]\n\n\nsame as above\n\n\n\n\n[c,n&H1]\n\n\nany arom carbon OR H-pyrrole nitrogen\n\n\n\n\n[c,n;H1]\n\n\n(arom carbon OR arom nitrogen) and exactly one H\n\n\n\n\n*!@*\n\n\ntwo atoms connected by a non-ringbond\n\n\n\n\n@;!:\n\n\ntwo atoms connected by a non-aromatic ringbond\n\n\n\n\n[C,c]=,#[C,c]\n\n\ntwo carbons connected by a double or triple bond\n\n\n\n\n\nQuery files\nGreg Landrum of Rdkit on query files\nPre-defined filters\n\n\nIn chemical reactions\nThe Reaction SMARTS way\nSMIRKS\n\n&lt;tr&gt;\n  &lt;td align=\"center\"&gt;C&gt;&gt;C&lt;/td&gt;\n  &lt;td align=\"center\"&gt;CC&gt;&gt;CC&lt;/td&gt;\n  &lt;td align=\"center\"&gt;4&lt;/td&gt;\n  &lt;td&gt;No maps, normal match.&lt;/td&gt;\n&lt;/tr&gt;     \n&lt;tr&gt;\n  &lt;td align=\"center\"&gt;C&gt;&gt;C&lt;/td&gt;\n  &lt;td align=\"center\"&gt;[CH3:7][CH3:8]&gt;&gt; [CH3:7][CH3:8]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;4&lt;/td&gt;\n  &lt;td&gt;No maps in query, maps in target are ignored.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n  &lt;td align=\"center\"&gt;[C:1]&gt;&gt;C&lt;/td&gt;\n  &lt;td align=\"center\"&gt;[CH3:7][CH3:8]&gt;&gt; [CH3:7][CH3:8]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;4&lt;/td&gt;\n  &lt;td&gt;Unpaired map in query ignored.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n  &lt;td align=\"center\"&gt;[C:1]&gt;&gt;[C:1]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;CC&gt;&gt;CC&lt;/td&gt;\n  &lt;td align=\"center\"&gt;0&lt;/td&gt;\n  &lt;td&gt;No maps in target, hence no matches.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n  &lt;td align=\"center\"&gt;[C:?1]&gt;&gt;[C:?1]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;CC&gt;&gt;CC&lt;/td&gt;\n  &lt;td align=\"center\"&gt;4&lt;/td&gt;\n  &lt;td&gt;Query says mapped as shown or not present.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n  &lt;td align=\"center\"&gt;[C:1]&gt;&gt;[C:1]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;[CH3:7][CH3:8]&gt;&gt;[CH3:7][CH3:8]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;2&lt;/td&gt;\n  &lt;td&gt;Matches for target 7,7 and 8,8 atom pairs.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n  &lt;td align=\"center\"&gt;[C:1]&gt;&gt;[C:2]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;[CH3:7][CH3:8]&gt;&gt; [CH3:7][CH3:8]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;4&lt;/td&gt;\n  &lt;td&gt;When a query class is not found on both&lt;br&gt;sides of the query, it is\n  ignored;&lt;br&gt;this query does NOT say that the atoms&lt;br&gt;are in different\n  classes. &lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n  &lt;td align=\"center\"&gt;[C:1][C:1]&gt;&gt;[C:1]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;[CH3:7][CH3:7]&gt;&gt; [CH3:7][CH3:7]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;4&lt;/td&gt;\n  &lt;td&gt;Atom maps match with \"or\" logic.  All atoms&lt;br&gt;get bound to\n  class 7.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n  &lt;td align=\"center\"&gt;[C:1][C:1]&gt;&gt;[C:1]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;[CH3:7][CH3:8]&gt;&gt; [CH3:7][CH3:8]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;4&lt;/td&gt;\n  &lt;td&gt;The reactant atoms are bound to classes 7&lt;br&gt;and 8. Note that having\n  the first query atom&lt;br&gt;bound to class 7 does not preclude&lt;br&gt;binding the\n  second atom. Next, the product&lt;br&gt;atom can bind to classes 7 or 8.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n  &lt;td align=\"center\"&gt;[C:1][C:1]&gt;&gt;[C:1]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;[CH3:7][CH3:7]&gt;&gt; [CH3:7][CH3:8]&lt;/td&gt;\n  &lt;td align=\"center\"&gt;2&lt;/td&gt;\n  &lt;td&gt;The reactants are bound to class 7.  The&lt;br&gt;product atom can bind to\n  class 7 only.&lt;/td&gt;\n&lt;/tr&gt;\n\n\n\nExample Reaction SMARTS:\n\n\n\n\nQuery:\n\n\nTarget:\n\n\nMatches:\n\n\nComment:\n\n\n\n\n\n\n\n\nOther resources:\n\nDaylight SMART Examples\nSMARTS.plus - to visualize the smart strings\n\nRelevant literature\n\nRules for Identifying Potentially Reactive or Promiscuous Compounds | Journal of Medicinal Chemistry (acs.org)\nBaell, J. B.; Holloway, G. A. New Substructure Filters for Removal of Pan Assay Interference Compounds (PAINS) from Screening Libraries and for Their Exclusion in Bioassays. J. Med. Chem. 2010.\nVidler, L. R.; Watson, I. A.; Margolis, B. J.; Cummins, D. J.; Brunavs, M. Investigating the Behavior of Published PAINS Alerts Using a Pharmaceutical Company Dataset. ACS Med. Chem. Lett. 2018.\nSchuffenhauer, A. et al. Evolution of Novartis’ small molecule screening deck design, J. Med. Chem. (2020)\nGomez-Sanchez, Ruben et al. “Maintaining a High-Quality Screening Collection: The GSK Experience.” SLAS discovery : advancing life sciences R & D vol. 26,8 (2021): 1065-1070. doi:10.1177/24725552211017526"
  },
  {
    "objectID": "posts/2022-01-10-cheminfo_basics_smarts.html#install-necessary-modules",
    "href": "posts/2022-01-10-cheminfo_basics_smarts.html#install-necessary-modules",
    "title": "Cheminformatics basics - A SMARTS way to filter molecules",
    "section": "Install necessary modules",
    "text": "Install necessary modules\n\n# collapse_output\n# Install requirements for the tutorial\n!pip install pandas rdkit-pypi mols2grid matplotlib scikit-learn ipywidgets\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pandas in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (1.1.5)\nRequirement already satisfied: rdkit-pypi in /home/l017301/.local/lib/python3.8/site-packages (2021.9.4)\nRequirement already satisfied: mols2grid in /home/l017301/.local/lib/python3.8/site-packages (0.2.1)\nRequirement already satisfied: matplotlib in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (3.3.0)\nRequirement already satisfied: scikit-learn in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (0.23.2)\nRequirement already satisfied: ipywidgets in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (7.5.1)\nRequirement already satisfied: numpy&gt;=1.15.4 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pandas) (1.18.5)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: pytz&gt;=2017.2 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pandas) (2020.1)\nRequirement already satisfied: Pillow in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from rdkit-pypi) (7.2.0)\nRequirement already satisfied: jinja2&gt;=2.11.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from mols2grid) (2.11.2)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.3 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from matplotlib) (2.4.7)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from matplotlib) (0.10.0)\nRequirement already satisfied: joblib&gt;=0.11 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from scikit-learn) (0.16.0)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\nRequirement already satisfied: scipy&gt;=0.19.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from scikit-learn) (1.4.1)\nRequirement already satisfied: traitlets&gt;=4.3.1 in /home/l017301/.local/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\nRequirement already satisfied: ipython&gt;=4.0.0; python_version &gt;= \"3.3\" in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (7.17.0)\nRequirement already satisfied: widgetsnbextension~=3.5.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (3.5.1)\nRequirement already satisfied: nbformat&gt;=4.2.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (5.0.7)\nRequirement already satisfied: ipykernel&gt;=4.5.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (5.3.4)\nRequirement already satisfied: six&gt;=1.5 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas) (1.15.0)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jinja2&gt;=2.11.0-&gt;mols2grid) (1.1.1)\nRequirement already satisfied: decorator in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (4.4.2)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /home/l017301/.local/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (3.0.24)\nRequirement already satisfied: jedi&gt;=0.10 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.17.1)\nRequirement already satisfied: pexpect; sys_platform != \"win32\" in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (4.8.0)\nRequirement already satisfied: pickleshare in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.7.5)\nRequirement already satisfied: backcall in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.2.0)\nRequirement already satisfied: pygments in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (2.6.1)\nRequirement already satisfied: setuptools&gt;=18.5 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (47.1.0)\nRequirement already satisfied: notebook&gt;=4.4.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0-&gt;ipywidgets) (6.1.1)\nRequirement already satisfied: jupyter-core in /home/l017301/.local/lib/python3.8/site-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets) (4.9.1)\nRequirement already satisfied: jsonschema!=2.5.0,&gt;=2.4 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets) (3.2.0)\nRequirement already satisfied: ipython-genutils in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbformat&gt;=4.2.0-&gt;ipywidgets) (0.2.0)\nRequirement already satisfied: tornado&gt;=4.2 in /home/l017301/.local/lib/python3.8/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets) (6.1)\nRequirement already satisfied: jupyter-client in /home/l017301/.local/lib/python3.8/site-packages (from ipykernel&gt;=4.5.1-&gt;ipywidgets) (7.1.2)\nRequirement already satisfied: wcwidth in /home/l017301/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.2.5)\nRequirement already satisfied: parso&lt;0.8.0,&gt;=0.7.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jedi&gt;=0.10-&gt;ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.7.0)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pexpect; sys_platform != \"win32\"-&gt;ipython&gt;=4.0.0; python_version &gt;= \"3.3\"-&gt;ipywidgets) (0.6.0)\nRequirement already satisfied: terminado&gt;=0.8.3 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.8.3)\nRequirement already satisfied: prometheus-client in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.8.0)\nRequirement already satisfied: argon2-cffi in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (20.1.0)\nRequirement already satisfied: Send2Trash in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (1.5.0)\nRequirement already satisfied: pyzmq&gt;=17 in /home/l017301/.local/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (22.3.0)\nRequirement already satisfied: nbconvert in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (5.6.1)\nRequirement already satisfied: pyrsistent&gt;=0.14.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.2.0-&gt;ipywidgets) (0.16.0)\nRequirement already satisfied: attrs&gt;=17.4.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.2.0-&gt;ipywidgets) (19.3.0)\nRequirement already satisfied: nest-asyncio&gt;=1.5 in /home/l017301/.local/lib/python3.8/site-packages (from jupyter-client-&gt;ipykernel&gt;=4.5.1-&gt;ipywidgets) (1.5.4)\nRequirement already satisfied: entrypoints in /home/l017301/.local/lib/python3.8/site-packages (from jupyter-client-&gt;ipykernel&gt;=4.5.1-&gt;ipywidgets) (0.3)\nRequirement already satisfied: cffi&gt;=1.0.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from argon2-cffi-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (1.14.1)\nRequirement already satisfied: defusedxml in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.6.0)\nRequirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.8.4)\nRequirement already satisfied: testpath in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.4.4)\nRequirement already satisfied: pandocfilters&gt;=1.4.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (1.4.2)\nRequirement already satisfied: bleach in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (3.1.5)\nRequirement already satisfied: pycparser in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from cffi&gt;=1.0.0-&gt;argon2-cffi-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (2.20)\nRequirement already satisfied: packaging in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from bleach-&gt;nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (20.4)\nRequirement already satisfied: webencodings in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from bleach-&gt;nbconvert-&gt;notebook&gt;=4.4.1-&gt;widgetsnbextension~=3.5.0-&gt;ipywidgets) (0.5.1)\nWARNING: You are using pip version 20.2.2; however, version 22.2.2 is available.\nYou should consider upgrading via the '/lrlhps/apps/python/python-3.8.5/bin/python -m pip install --upgrade pip' command.\n\n\n\nimport os \nimport pandas as pd\nimport numpy as np \n\nThe majority of the basic molecular functionality is found in module rdkit.Chem\n\n# RDkit imports\nimport rdkit\nfrom rdkit import Chem #This gives us most of RDkits's functionality\nfrom rdkit.Chem import Draw\nfrom rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\nIPythonConsole.ipython_useSVG=True  #SVG's tend to look nicer than the png counterparts\nprint(rdkit.__version__)\n\n# Mute all errors except critical\nChem.WrapLogs()\nlg = rdkit.RDLogger.logger() \nlg.setLevel(rdkit.RDLogger.CRITICAL)\n\n2021.09.3\n\n\n\nfrom collections import defaultdict\nfrom rdkit.Chem.Draw import rdMolDraw2D\nfrom IPython.display import SVG\n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 15,\n'axes.titlesize' : 15,\n'axes.labelsize' : 15,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 12,\n'ytick.labelsize' : 12,\n}\n \nplt.rcParams.update(plot_params)\n\n\ndiclofenac = Chem.MolFromSmiles('O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl')\ndiclofenac\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code from : https://www.rdkit.org/docs/GettingStartedInPython.html?highlight=maccs#drawing-molecules\nsub_pattern = Chem.MolFromSmarts('O=CCccN')\nhit_ats = list(diclofenac.GetSubstructMatch(sub_pattern))\nhit_bonds = []\n\nfor bond in sub_pattern.GetBonds():\n    aid1 = hit_ats[bond.GetBeginAtomIdx()]\n    aid2 = hit_ats[bond.GetEndAtomIdx()]\n    \n    hit_bonds.append( diclofenac.GetBondBetweenAtoms(aid1, aid2).GetIdx() )\n\n\nd2d = rdMolDraw2D.MolDraw2DSVG(400, 400) # or MolDraw2DCairo to get PNGs\nrdMolDraw2D.PrepareAndDrawMolecule(d2d, diclofenac, highlightAtoms=hit_ats,  highlightBonds=hit_bonds)\nd2d.FinishDrawing()\nSVG(d2d.GetDrawingText())\n\n\n\n\n\n\n\n\nDefining a function to make it easy and reproducible:\n\ndef viz_substruct(main_smile, substructure_smarts):\n    \n    mol_file = Chem.MolFromSmiles(main_smile)\n    sub_pattern = Chem.MolFromSmarts(substructure_smarts)\n    \n    hit_ats = list(mol_file.GetSubstructMatch(sub_pattern)) # Returns the indices of the molecule’s atoms that match a substructure query\n    hit_bonds = []\n\n    for bond in sub_pattern.GetBonds():\n        aid1 = hit_ats[bond.GetBeginAtomIdx()]\n        aid2 = hit_ats[bond.GetEndAtomIdx()]\n\n        hit_bonds.append( mol_file.GetBondBetweenAtoms(aid1, aid2).GetIdx() )\n\n    d2d = rdMolDraw2D.MolDraw2DSVG(400, 400) # or MolDraw2DCairo to get PNGs\n    rdMolDraw2D.PrepareAndDrawMolecule(d2d, mol_file, highlightAtoms=hit_ats,  highlightBonds=hit_bonds)\n    d2d.FinishDrawing()\n    return SVG(d2d.GetDrawingText())\n\n\nviz_substruct('C1=NC(=NC(=C1)C)C2=CC=CC=N2','[ar]!@[ar]')\n\n\n\n\n\n\n\n\n\nOnline resource to visualize the SMARTS.\nThis code is inspired from Pen Taka’s blogpost\nSMARTS.plus is a nice web GUI to visualize different SMART queries real-time.\n\nfrom rdkit import Chem\nfrom IPython.display import Image\nimport requests\nimport urllib\nfrom time import time \n\n\nbaseurl = \"https://smarts.plus/smartsview/download_rest?\"\n\n\n# Function to get a request for SMART query\ndef get_img(query):\n    url = baseurl+query\n    start = time()\n    res = requests.get(url)\n    _img = Image(res.content, embed=True, retina=True)\n    print('Time taken: {0:0.2f} secs'.format(time() - start))\n    return _img\n\n\nim0 = get_img(\"smarts=[ar]!@[ar]\")\nim0\n\nTime taken: 4.04 secs\n\n\n\n\n\n\n\n\n\n\nim1 = get_img(\"smarts=[CX3](=[OX1])[OX2][CX3](=[OX1])\")\nim1\n\nTime taken: 1.95 secs\n\n\n\n\n\n\n\n\n\n\n\nSMARTS.plus now handles reaction SMARTS, SMIRKS too!\nPaper talking about the update\n\nim0 = get_img(\"smarts=[CH1:1][OH:2].[OH][C:3]=[O:4]&gt;&gt;[C:1][O:2][C:3]=[O:4]\")\nim0\n\nTime taken: 2.00 secs"
  },
  {
    "objectID": "posts/2021-01-11-simple_dropout.html",
    "href": "posts/2021-01-11-simple_dropout.html",
    "title": "Estimating prediction confidence through dropout",
    "section": "",
    "text": "Adapted from Deep Learning online course notes from NYU. Note link\nPaper about using Dropout as a Bayesian Approximation\n\nAnother notebook which uses PyTorch dropout: Link\n\nNew paper on evidential deep learning for guided molecular property prediction\n\nIn addition to predicting a value from a model it is also important to know the confidence in that prediction. Dropout is one way of estimating this. After multiple rounds of predictions, the mean and standard deviation in the prediction can be viewed as the prediction value and the corresponding confidence in the prediction. It is important to note that this is different from the error in the prediction. The model may have error in the prediction but could be precise in that value. It is similar to the idea of accuracy vs precision.\nWhen done with dropout – the weights in the NN are scale by \\(\\frac{1}{1-r}\\) to account for dropping of the weights\nType of uncertainties: Aleaotric and Epistemic uncertainty\n\nAleatoric uncertainty captures noise inherent in the observations\nEpistemic uncertainty accounts for uncertainty in the model\n\nThe ideal way to measure epistemic uncertainty is to train many different models, each time using a different random seed and possibly varying hyperparameters. Then use all of them for each input and see how much the predictions vary. This is very expensive to do, since it involves repeating the whole training process many times. Fortunately, we can approximate the same effect in a less expensive way: by using dropout – effectively training a huge ensemble of different models all at once. Each training sample is evaluated with a different dropout mask, corresponding to a different random subset of the connections in the full model. Usually we only perform dropout during training and use a single averaged mask for prediction. But instead, let’s use dropout for prediction too. We can compute the output for lots of different dropout masks, then see how much the predictions vary. This turns out to give a reasonable estimate of the epistemic uncertainty in the outputs\n\nimport torch \nfrom torch import nn, optim\nimport numpy as np \n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 22,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'lines.linewidth' : 3,\n'lines.markersize' : 10,\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)\n\n\n# Check if GPU present: \nprint(torch.cuda.device_count())\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\n0\ncpu\n\n\n\n# Training set\nm = 40\nx = (torch.rand(m) - 0.5) * 20 #Returns a tensor filled with random numbers from a uniform distribution on the interval [0, 1)\ny = x * torch.sin(x) \n#y = 2 * torch.exp( - torch.sin( (x/2)**2 ))\n\n\nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.plot(x.numpy(), y.numpy(), 'o')\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.axis('equal');\n\n\n\n\n\n\n\n\n\n# Define a simple NN \nclass MLP(nn.Module):\n    def __init__(self, hidden_layers=[20, 20], droprate=0.2, activation='relu'):\n        super(MLP, self).__init__()\n        \n        self.model = nn.Sequential()\n        self.model.add_module('input', nn.Linear(1, hidden_layers[0]))\n        \n        if activation == 'relu':\n            self.model.add_module('relu0', nn.ReLU())\n        \n        elif activation == 'tanh':\n            self.model.add_module('tanh0', nn.Tanh())\n            \n        for i in range(len(hidden_layers)-1):\n            self.model.add_module('dropout'+str(i+1), nn.Dropout(p=droprate))\n            self.model.add_module('hidden'+str(i+1), nn.Linear(hidden_layers[i], hidden_layers[i+1]))\n            \n            if activation == 'relu':\n                self.model.add_module('relu'+str(i+1), nn.ReLU())\n                \n            elif activation == 'tanh':\n                self.model.add_module('tanh'+str(i+1), nn.Tanh())\n                \n        self.model.add_module('dropout'+str(i+2), nn.Dropout(p=droprate))\n        self.model.add_module('final', nn.Linear(hidden_layers[i+1], 1))\n        \n    def forward(self, x):\n        return self.model(x)\n\n\n# Define the model \nnet = MLP(hidden_layers=[200, 100, 80], droprate=0.1).to(device) #Move model to the GPU \nprint(net)\n\nMLP(\n  (model): Sequential(\n    (input): Linear(in_features=1, out_features=200, bias=True)\n    (relu0): ReLU()\n    (dropout1): Dropout(p=0.1, inplace=False)\n    (hidden1): Linear(in_features=200, out_features=100, bias=True)\n    (relu1): ReLU()\n    (dropout2): Dropout(p=0.1, inplace=False)\n    (hidden2): Linear(in_features=100, out_features=80, bias=True)\n    (relu2): ReLU()\n    (dropout3): Dropout(p=0.1, inplace=False)\n    (final): Linear(in_features=80, out_features=1, bias=True)\n  )\n)\n\n\n\n# Objective and optimizer \ncriterion = nn.MSELoss()\noptimizer = optim.Adam(net.parameters(), lr=0.005, weight_decay=0.00001)\n\n\nx_dev = x.view(-1, 1).to(device)\n\n\n# Training loop \nfor epoch in range(6000):\n    x_dev = x.view(-1, 1).to(device)\n    y_dev = y.view(-1, 1).to(device)\n    y_hat = net(x_dev)\n    loss = criterion(y_hat, y_dev)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    if epoch % 500 == 0:\n        print('Epoch[{}] - Loss:{}'.format(epoch, loss.item()))\n\nEpoch[0] - Loss:12.69531536102295\nEpoch[500] - Loss:1.740363359451294\nEpoch[1000] - Loss:1.177356243133545\nEpoch[1500] - Loss:1.9534406661987305\nEpoch[2000] - Loss:1.0815060138702393\nEpoch[2500] - Loss:0.5457165837287903\nEpoch[3000] - Loss:0.24786725640296936\nEpoch[3500] - Loss:0.38788101077079773\nEpoch[4000] - Loss:0.7004671096801758\nEpoch[4500] - Loss:0.4352916181087494\nEpoch[5000] - Loss:0.5015718936920166\nEpoch[5500] - Loss:0.44577136635780334\n\n\nDefine a separate continuous vector XX\n\nXX = torch.linspace(-11, 11, 1000)\n\n\ndef predict_reg(model, X, T=10):\n    '''\n    Running the model in training mode. \n    model = torch.model: NN implemented in pytorch\n    X = torch.tensor: Input vector \n    T = int: number of samples run \n    \n    OUT:\n    Y_hat = sample of predictions from NN model\n    Y_eval = average prediction value from NN model\n    '''\n    \n    model = model.train()\n    Y_hat = list()\n    \n    with torch.no_grad():\n        for t in range(T):\n            X_out = model(X.view(-1,1).to(device))\n            Y_hat.append(X_out.cpu().squeeze())\n            \n    Y_hat = torch.stack(Y_hat)\n    \n    model = model.eval()\n    with torch.no_grad():\n        X_out = model(X.view(-1,1).to(device))\n        Y_eval = X_out.cpu().squeeze()\n\n    return Y_hat, Y_eval\n\n\n%%time \ny_hat, y_eval = predict_reg(net, XX, T=1000)\nmean_y_hat = y_hat.mean(axis=0)\nstd_y_hat = y_hat.std(axis=0)\n\nCPU times: user 11.9 s, sys: 94 ms, total: 12 s\nWall time: 3.04 s\n\n\n\n# Visualise mean and mean ± std -&gt; confidence range\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nax.plot(XX.numpy(), mean_y_hat.numpy(), 'C1', label='prediction')\nax.fill_between(XX.numpy(), (mean_y_hat + std_y_hat).numpy(), (mean_y_hat - std_y_hat).numpy(), alpha=0.5, color='C2', label='confidence')\nax.plot(x.numpy(), y.numpy(), 'oC0', zorder=1, label='ground truth')\nax.plot(XX.numpy(), (XX * torch.sin(XX)).numpy(), 'k--', alpha=0.4, zorder=0, label='original function')\nax.set_title('Plotting the NN predictions and ground truth')\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.axis('equal')\nplt.legend(loc='best', fontsize=10)\n\n\n\n\n\n\n\n\nThe plot above is the combination of ground truth points (blue), original function (grey) and the predicted function (orange) with corresponding confidence interval at each ML-prediction (green). It is seen that the ML model does well for the region of X in the range of original points. Another interesting observation is the uncertainity of the model prediction, which is seen to increase in the space where training points dont exist e.g. X=(5,10) and X &gt; 10 or X &lt; -10. This shows that the model is highly uncertain outside the domain of training data (extrapolation) but does a decent job within the range of training data (interpolation)."
  },
  {
    "objectID": "posts/10_04-fingerprints.html",
    "href": "posts/10_04-fingerprints.html",
    "title": "Fingerprints on fingertips",
    "section": "",
    "text": "Fingerprints are a low resolution representations of molecules. Historically they were devised, primarily, as a representation scheme to better estimate the similarity of molecules. Currently, besides the similairty and diversity estimations, fingerprints are the workhorses for most of the data-driven predictive models.\nKey papers in this field: * Willett, Peter, John M. Barnard, and Geoffrey M. Downs. “Chemical similarity searching.” Journal of chemical information and computer sciences 38.6 (1998): 983-996 * PubChem Atom Environments\nBlogs from Greg Landrum (RDKit creator): * Bit collisions in Rdkit * Simulating count fingerprints * Number of Fingerprint Bits * Number of unique fingerprint bits * RSC Open Science Standardization Talk\nResources to consider: * Depth-first on Fingerprints * Applied AI for materials online course by Logan Ward (Argonne National Lab) * Example scripts in GHOST implementation\nimport os \nimport pandas as pd\nimport numpy as np \nimport tqdm.notebook as tqdm\n# RDkit imports\nimport rdkit\nfrom rdkit import Chem\nfrom rdkit.Chem import Draw\nfrom rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\n\nprint(rdkit.__version__)\n\nChem.WrapLogs()\nlg = rdkit.RDLogger.logger() \nlg.setLevel(rdkit.RDLogger.CRITICAL)\n\n2021.09.3\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# \"Infinite\" DPI vector output -- overkill \n#%config InlineBackend.figure_format = 'svg'\n \n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n# Load a test dataset\nurl = 'https://raw.githubusercontent.com/pgg1610/data_files/main/delaney.smi'\nx = pd.read_csv(url, header=0, names=['SMILES', 'logP'])\nx.head(3)\n\n\n\n\n\n\n\n\nSMILES\nlogP\n\n\n\n\n0\nOCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...\n-0.77\n\n\n1\nCc1occc1C(=O)Nc2ccccc2\n-3.30\n\n\n2\nCC(C)=CCCC(C)=CC(=O)\n-2.06\nfrom rdkit.Chem import PandasTools\nPandasTools.AddMoleculeColumnToFrame(x, smilesCol='SMILES')\nx.sample(2)\n\n\n\n\n\n\n\n\nSMILES\nlogP\nROMol\n\n\n\n\n1076\nCCCC(O)CCC\n-1.40\n\n\n\n469\nCc1cccc(C)c1O\n-1.29"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#morgan-fingerprints",
    "href": "posts/10_04-fingerprints.html#morgan-fingerprints",
    "title": "Fingerprints on fingertips",
    "section": "1. Morgan fingerprints",
    "text": "1. Morgan fingerprints\nSome discussion on Bit Collisions here: https://rdkit.blogspot.com/2014/02/colliding-bits.html"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#unfolded-type-or-sparse-type",
    "href": "posts/10_04-fingerprints.html#unfolded-type-or-sparse-type",
    "title": "Fingerprints on fingertips",
    "section": "Unfolded type or Sparse type",
    "text": "Unfolded type or Sparse type\n\nfrom rdkit.Chem import AllChem\nfrom rdkit import DataStructs\n\n\nmol_obj = x.iloc[42]['ROMol']\n\n\nmol_obj\n\n\n\n\n\n\n\n\n\n#Default class to generate FPs - this will make it unfolded by default\nmorgan_fp_default = AllChem.GetMorganFingerprint(mol_obj, radius = 2) # Counts are used by default \n\n\n#Check the use_counts in Get Morgan Fingerprint this is used by default \nmorgan_fp_default_counts = AllChem.GetMorganFingerprint(mol_obj, radius = 2, useCounts=True) # This is used by default \n\n#Feature-based invariants, similar to those used for the FCFP fingerprints, can also be used.\n# https://www.rdkit.org/docs/GettingStartedInPython.html#feature-definitions-used-in-the-morgan-fingerprints\n# Here the atoms are grouped into functional classes before substructures are enumerated \nmorgan_fp_features = AllChem.GetMorganFingerprint(mol_obj, 2, useFeatures=True)\n\n\nmorgan_fp_default\n\n&lt;rdkit.DataStructs.cDataStructs.UIntSparseIntVect at 0x2b5a80661ad0&gt;\n\n\nYou can also use the rdMolDescriptor module in Rdkit for generating the fingerprints. What is the advatange of either?\n\nfrom rdkit.Chem import rdMolDescriptors\n\n\nmorgan_fp_default_rdmoldesc = rdMolDescriptors.GetMorganFingerprint(mol_obj, radius=2)\n\n\nmorgan_fp_default_rdmoldesc.GetNonzeroElements()\n\n{10565946: 3,\n 123085743: 1,\n 354000409: 1,\n 864942730: 3,\n 1451062712: 1,\n 2004727027: 2,\n 2119439498: 2,\n 2132511834: 2,\n 2142032900: 1,\n 2296493092: 2,\n 2422851564: 1,\n 2809361097: 2,\n 2968968094: 3,\n 2976816164: 1,\n 3038691098: 1,\n 3113921857: 2,\n 3217380708: 3,\n 3255046070: 1}\n\n\nTo get a list of bits being ‘active’ in the FPs:\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetNonzeroElements(morgan_fp_default)\n\n{10565946: 3,\n 123085743: 1,\n 354000409: 1,\n 864942730: 3,\n 1451062712: 1,\n 2004727027: 2,\n 2119439498: 2,\n 2132511834: 2,\n 2142032900: 1,\n 2296493092: 2,\n 2422851564: 1,\n 2809361097: 2,\n 2968968094: 3,\n 2976816164: 1,\n 3038691098: 1,\n 3113921857: 2,\n 3217380708: 3,\n 3255046070: 1}\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetNonzeroElements(morgan_fp_default) == morgan_fp_default_rdmoldesc.GetNonzeroElements()\n\nTrue\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetLength(morgan_fp_default)\n\n4294967295\n\n\n\n2**32\n\n4294967296\n\n\n\nmorgan_fp_default_counts\n\n&lt;rdkit.DataStructs.cDataStructs.UIntSparseIntVect at 0x2b5a8066e620&gt;\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetNonzeroElements(morgan_fp_default_counts)\n\n{10565946: 3,\n 123085743: 1,\n 354000409: 1,\n 864942730: 3,\n 1451062712: 1,\n 2004727027: 2,\n 2119439498: 2,\n 2132511834: 2,\n 2142032900: 1,\n 2296493092: 2,\n 2422851564: 1,\n 2809361097: 2,\n 2968968094: 3,\n 2976816164: 1,\n 3038691098: 1,\n 3113921857: 2,\n 3217380708: 3,\n 3255046070: 1}\n\n\n\nmorgan_fp_features\n\n&lt;rdkit.DataStructs.cDataStructs.UIntSparseIntVect at 0x2b5a8066e7b0&gt;\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetNonzeroElements(morgan_fp_features)\n\n{0: 7,\n 1: 2,\n 2: 3,\n 613660066: 1,\n 614173363: 2,\n 1250412363: 2,\n 2407443532: 1,\n 2419043133: 1,\n 3064147743: 1,\n 3205496824: 3,\n 3208849907: 1,\n 3664239091: 2,\n 3766528779: 2,\n 3766532888: 3,\n 4203103696: 1}\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetLength(morgan_fp_features)\n\n4294967295"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#folded-type",
    "href": "posts/10_04-fingerprints.html#folded-type",
    "title": "Fingerprints on fingertips",
    "section": "Folded type",
    "text": "Folded type\n\n#Counts Folded FPs \nmorgan_fp_counts_folded = AllChem.GetMorganFingerprint(mol_obj, 2, useCounts=True, nBits=1024) # This will throw an error - cannot fold the full FPs instead call them separately\n\n\n---------------------------------------------------------------------------\nArgumentError                             Traceback (most recent call last)\n/node/scratch/90082368.1.all.normal.q/ipykernel_22557/3053734452.py in &lt;module&gt;\n      1 #Counts Folded FPs\n----&gt; 2 morgan_fp_counts_folded = AllChem.GetMorganFingerprint(mol_obj, 2, useCounts=True, nBits=1024) # This will throw an error - cannot fold the full FPs instead call them separately\n\nArgumentError: Python argument types in\n    rdkit.Chem.rdMolDescriptors.GetMorganFingerprint(Mol, int)\ndid not match C++ signature:\n    GetMorganFingerprint(RDKit::ROMol mol, unsigned int radius, boost::python::api::object invariants=[], boost::python::api::object fromAtoms=[], bool useChirality=False, bool useBondTypes=True, bool useFeatures=False, bool useCounts=True, boost::python::api::object bitInfo=None, bool includeRedundantEnvironments=False)\n\n\n\nCount-based Morgan FPs\n\n#Hashed FPs - using counts \nmorgan_fp_hashed_folded = AllChem.GetHashedMorganFingerprint(mol_obj, 2, nBits=1024) #Default is 2048 and be used without folding here \n\n\nmorgan_fp_hashed_folded\n\n&lt;rdkit.DataStructs.cDataStructs.UIntSparseIntVect at 0x2b5a8066ef30&gt;\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetLength(morgan_fp_hashed_folded)\n\n1024\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetNonzeroElements(morgan_fp_hashed_folded)\n\n{4: 1,\n 36: 3,\n 90: 2,\n 138: 2,\n 243: 2,\n 314: 3,\n 321: 2,\n 356: 3,\n 440: 1,\n 537: 1,\n 650: 3,\n 713: 2,\n 794: 1,\n 926: 3,\n 943: 1,\n 950: 1,\n 1004: 1}\n\n\nBit-vector based Morgan FP\n\n#Folded FP bit vectors as per the size of the bits \nmorgan_fp_bit_vect = AllChem.GetMorganFingerprintAsBitVect(mol_obj, 2, nBits=1024)\n\n\nmorgan_fp_bit_vect\n\n&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x2b5a8066e4e0&gt;\n\n\n\nDataStructs.cDataStructs.ExplicitBitVect.GetNumBits(morgan_fp_bit_vect)\n\n1024\n\n\n\nDataStructs.cDataStructs.ExplicitBitVect.GetNumOnBits(morgan_fp_bit_vect)\n\n17\n\n\n\nConverting to friendly data type\n\nmorgan_fp_hashed_folded_array = np.zeros((1,))\nmorgan_fp_bit_vect_array = np.zeros((1,))\n\n\nDataStructs.ConvertToNumpyArray(morgan_fp_hashed_folded, morgan_fp_hashed_folded_array) \n\n\nnp.nonzero(morgan_fp_hashed_folded_array)\n\n(array([   4,   36,   90,  138,  243,  314,  321,  356,  440,  537,  650,\n         713,  794,  926,  943,  950, 1004]),)\n\n\n\nnp.unique(morgan_fp_hashed_folded_array)\n\narray([0., 1., 2., 3.])\n\n\n\nmorgan_fp_bit_vect\n\n&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x2b5a8066e4e0&gt;\n\n\n\nDataStructs.ConvertToNumpyArray(morgan_fp_bit_vect, morgan_fp_bit_vect_array) \n\n\nnp.nonzero(morgan_fp_bit_vect_array)\n\n(array([   4,   36,   90,  138,  243,  314,  321,  356,  440,  537,  650,\n         713,  794,  926,  943,  950, 1004]),)\n\n\n\nnp.unique(morgan_fp_bit_vect_array)\n\narray([0., 1.])\n\n\nConverting the Morgan FPs between counts and bit-wise representation: https://stackoverflow.com/questions/54809506/how-can-i-compute-a-count-morgan-fingerprint-as-numpy-array\n\nfp = AllChem.GetMorganFingerprintAsBitVect(mol_obj, 2, nBits=1024)\narray = np.zeros((0, ), dtype=np.int16)\nDataStructs.ConvertToNumpyArray(fp, array)\n\n\narray\n\narray([0, 0, 0, ..., 0, 0, 0], dtype=int16)\n\n\n\nbitstring = \"\".join(array.astype(str))\nfp2 = DataStructs.cDataStructs.CreateFromBitString(bitstring)\n\n\nfp2\n\n&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x2b5a80688b20&gt;\n\n\n\nlist(fp.GetOnBits()) == list(fp2.GetOnBits())\n\nTrue\n\n\n\nfp3 = AllChem.GetHashedMorganFingerprint(mol_obj, 2, nBits=1024)\narray = np.zeros((0,), dtype=np.int8)\nDataStructs.ConvertToNumpyArray(fp3, array)\nprint(array.nonzero())\n\n(array([   4,   36,   90,  138,  243,  314,  321,  356,  440,  537,  650,\n        713,  794,  926,  943,  950, 1004]),)\n\n\nAlternate way:\n\ndef numpy_2_fp(array):\n    fp = DataStructs.cDataStructs.UIntSparseIntVect(len(array))\n    for ix, value in enumerate(array):\n        fp[ix] = int(value)\n    return fp\n\nfp4 = numpy_2_fp(array)\n\n\nfp3.GetNonzeroElements() == fp4.GetNonzeroElements()\n\nTrue"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#maccs",
    "href": "posts/10_04-fingerprints.html#maccs",
    "title": "Fingerprints on fingertips",
    "section": "2. MACCS",
    "text": "2. MACCS\nThere is a SMARTS-based implementation of the 166 public MACCS keys.\n\nfrom rdkit.Chem import MACCSkeys\n\n\nmaccs_fp = MACCSkeys.GenMACCSKeys(mol_obj)\n\n\nmaccs_fp\n\n&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x2b5a99f013a0&gt;\n\n\n\nmaccs_fp_array = np.zeros((0,))\n\n\nDataStructs.ConvertToNumpyArray(maccs_fp, maccs_fp_array) \n\n\nmaccs_fp_array.shape\n\n(167,)\n\n\n\nnp.nonzero(maccs_fp_array)\n\n(array([ 11,  37,  43,  53,  66,  77,  80,  89,  90,  91,  92,  97,  98,\n        105, 106, 110, 112, 117, 118, 120, 121, 127, 131, 136, 137, 142,\n        143, 146, 147, 151, 154, 156, 158, 159, 161, 163, 164, 165]),)\n\n\n\nnp.unique(maccs_fp_array)\n\narray([0., 1.])"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#atom-pairs",
    "href": "posts/10_04-fingerprints.html#atom-pairs",
    "title": "Fingerprints on fingertips",
    "section": "3. Atom Pairs",
    "text": "3. Atom Pairs\n\nfrom rdkit.Chem.AtomPairs import Pairs, Torsions\n\nap_full = Pairs.GetAtomPairFingerprint(mol_obj) # Fully unfolded ones  - The standard form is as fingerprint including counts for each bit instead of just zeros and ones\nap_bit = Pairs.GetAtomPairFingerprintAsBitVect(mol_obj) # Bit vector \nap_counts = Pairs.GetHashedAtomPairFingerprint(mol_obj, nBits=1024) #These are count based AP, default = 2048\n\n\nap_full\n\n&lt;rdkit.DataStructs.cDataStructs.IntSparseIntVect at 0x2b5a9a0e82b0&gt;\n\n\n\nDataStructs.cDataStructs.IntSparseIntVect.GetLength(ap_full)\n\n8388608\n\n\n\nDataStructs.cDataStructs.IntSparseIntVect.GetNonzeroElements(ap_full)\n\n{558145: 2,\n 558146: 1,\n 590913: 2,\n 590914: 1,\n 705602: 4,\n 705603: 2,\n 705604: 2,\n 705605: 1,\n 705665: 2,\n 705667: 1,\n 705890: 3,\n 1082435: 4,\n 1082436: 2,\n 1082498: 2,\n 1082721: 4,\n 1082723: 2,\n 1083458: 1,\n 1721411: 4,\n 1721412: 2,\n 1721413: 2,\n 1721414: 1,\n 1721474: 2,\n 1721476: 1,\n 1721697: 3,\n 1721699: 6,\n 1722434: 4,\n 1722436: 2,\n 1723684: 3}\n\n\n\nap_bit\n\n&lt;rdkit.DataStructs.cDataStructs.SparseBitVect at 0x2b5a99f2ca70&gt;\n\n\n\nap_bit_array = np.zeros((0,), dtype=np.int32)\n\n\nDataStructs.ConvertToNumpyArray(ap_bit, ap_bit_array) \n\n\n---------------------------------------------------------------------------\nArgumentError                             Traceback (most recent call last)\n/node/scratch/90082368.1.all.normal.q/ipykernel_22557/642796328.py in &lt;module&gt;\n----&gt; 1 DataStructs.ConvertToNumpyArray(ap_bit, ap_bit_array)\n\nArgumentError: Python argument types in\n    rdkit.DataStructs.cDataStructs.ConvertToNumpyArray(SparseBitVect, numpy.ndarray)\ndid not match C++ signature:\n    ConvertToNumpyArray(RDKit::SparseIntVect&lt;unsigned long&gt; bv, boost::python::api::object destArray)\n    ConvertToNumpyArray(RDKit::SparseIntVect&lt;unsigned int&gt; bv, boost::python::api::object destArray)\n    ConvertToNumpyArray(RDKit::SparseIntVect&lt;long&gt; bv, boost::python::api::object destArray)\n    ConvertToNumpyArray(RDKit::SparseIntVect&lt;int&gt; bv, boost::python::api::object destArray)\n    ConvertToNumpyArray(RDKit::DiscreteValueVect bv, boost::python::api::object destArray)\n    ConvertToNumpyArray(ExplicitBitVect bv, boost::python::api::object destArray)\n\n\n\n\nap_counts_array = np.array((1,))\n\n\nDataStructs.ConvertToNumpyArray(ap_counts, ap_counts_array) \n\n\nap_counts_array.shape\n\n(1024,)"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#rdkit-fingerprint",
    "href": "posts/10_04-fingerprints.html#rdkit-fingerprint",
    "title": "Fingerprints on fingertips",
    "section": "4. RDKIT Fingerprint",
    "text": "4. RDKIT Fingerprint\na Daylight-like fingerprint based on hashing molecular subgraphs\n\nrdkit_fp = Chem.RDKFingerprint(mol_obj) \n\n\nrdkit_fp\n\n&lt;rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x2b5aa2582350&gt;\n\n\n\nrdkit_fp_array = np.zeros((0,))\n\n\nDataStructs.ConvertToNumpyArray(rdkit_fp, rdkit_fp_array) \n\n\nnp.unique(rdkit_fp_array)\n\narray([0., 1.])"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#descriptors",
    "href": "posts/10_04-fingerprints.html#descriptors",
    "title": "Fingerprints on fingertips",
    "section": "5. Descriptors",
    "text": "5. Descriptors\nCompute the RDKit2D fingerprint (200 topological properties) using the descriptastorus library. Adopted from https://github.com/rinikerlab/GHOST/blob/main/notebooks/library_example.ipynb\n\nfrom descriptastorus.descriptors import rdDescriptors, rdNormalizedDescriptors\n\nCan be looped with different methods\nfps1 = [Chem.RDKFingerprint(x, fpSize=1024, minPath=1, maxPath=4) for x in suppl]\nfps2 = [Chem.GetHashedMorganFingerprint(x, radius=2, nBits=1024) for x in suppl]\nfps3 = [Chem.GetMorganFingerprint(x, radius=2, useCounts= True) for x in suppl]\nfps4 = [Pairs.GetAtomPairFingerprintAsIntVect(x) for x in suppl]\narr = np.zeros((4,1024), dtype = np.int8)\nfor i in range(0,len(suppl)):\n    DataStructs.ConvertToNumpyArray(fps2[i], arr[i])\nprint(arr)\n\nCombine it together\nGeneral purpose function to generate morgan fingerprints using BaseEstimator and TransformerMixin from Scikit-learn to use all the wonderful scikit-learn routines\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom rdkit.Chem import rdFingerprintGenerator\nfrom rdkit.Chem import AllChem\nfrom rdkit import Chem, DataStructs\nfrom rdkit.Chem import MACCSkeys\nfrom rdkit.Chem.AtomPairs import Pairs, Torsions\nfrom rdkit import DataStructs\nfrom rdkit.Chem import rdMolDescriptors\n\ndef mol_to_smiles(mol: Chem.Mol, canonical: bool = True) -&gt; str:\n    \"\"\"Generate Smiles from mol.\n    :param mol: the input molecule\n    :param canonical: whether to return the canonical Smiles or not\n    :return: The Smiles of the molecule (canonical by default). NAN for failed molecules.\"\"\"\n\n    if mol is None:\n        return np.nan\n    try:\n        smi = Chem.MolToSmiles(mol, canonical=canonical)\n        return smi\n    except:\n        return np.nan\n\n\ndef smiles_to_mol(smiles: str) -&gt; Chem.Mol:\n    \"\"\"Generate a RDKit Molecule from a Smiles.\n    :param smiles: the input string\n    :returns: The RDKit Molecule. If the Smiles parsing failed, NAN is returned instead.\n    \"\"\"\n\n    try:\n        mol = Chem.MolFromSmiles(smiles)\n        if mol is not None:\n            return mol\n        return np.nan\n    except:\n        return np.nan\n    \ndef transform_to_mol(smiles: list, smiles_column : str = None, to_binary : bool = False) -&gt; Chem.Mol:\n    \"\"\"\n    Converts a list of smiles to RDKit mol object. \n    Provision to preserve molecules in form a binary object\n    Refer: https://www.rdkit.org/docs/GettingStartedInPython.html#preserving-molecules\n    \"\"\"\n    \n    try: \n        if isinstance(smiles, list):\n            mol_ls = [Chem.MolFromSmiles(x) for x in smiles]\n            return mol_ls \n        \n        elif isinstance(smiles, pd.DataFrame):\n            smiles = smiles.copy() # To ensure I am using another instance \n            smiles[\"Mol\"] = smiles.apply(Chem.MolFromSmiles)\n            return smiles\n\n        elif isinstance(smiles, str):\n            mol_ls = Chem.MolFromSmiles(smiles)\n            return mol_ls \n        else: \n            return np.nan \n    except:\n        return np.nan \n    \n    if to_binary:\n        if type(smiles) == list:\n            binary_out = [mol.ToBinary() for mol in mol_ls] # m2 = Chem.Mol(binStr) to convert back \n        else:\n            binary_out = mol_ls.ToBinary() \n            \n        return binary_out \n\n\n    \n# Descriptor generation from RDKIT \n\ndef compute_fingerprint(smiles: str, type_fp: str = 'Morgan', sub_type: str = 'bv', radius: int = 2, num_bits: int = 2048) -&gt; np.ndarray:\n    \"\"\"\n    Generates a fingerprint for a smiles string or mol object.\n    fp_type = {'Morgan', 'Morgan_sparse', 'FeatMorgan', 'FeatMorgan_sparse', 'AtomPair', 'AtomPair_sparse', 'RDkit', 'TT'}\n    sub_type = {'sparse', 'bv', 'counts', 'object'}\n    \n    :param smiles: A smiles string for a molecule.\n    :param radius: The radius of the fingerprint.\n    :param num_bits: The number of bits to use in the fingerprint.\n    :param use_counts: Whether to use counts or just a bit vector for the fingerprint\n    :return: A 1-D numpy array containing the morgan fingerprint.\n    \"\"\"\n    if isinstance(smiles, str):\n        mol = Chem.MolFromSmiles(smiles)\n \n    else:\n        mol = smiles\n    \n    if type_fp == 'Morgan': \n        if sub_type == 'sparse' or sub_type == 'object':\n            fp_vect = rdMolDescriptors.GetMorganFingerprint(mol, radius) # Counts by default\n        if sub_type == 'counts':\n            fp_vect = rdMolDescriptors.GetHashedMorganFingerprint(mol, radius, nBits=num_bits)\n        if sub_type == 'bv':\n            fp_vect = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n    \n    if type_fp == 'FeatMorgan':\n        if sub_type == 'sparse' or sub_type == 'object':\n            fp_vect = rdMolDescriptors.GetMorganFingerprint(mol, radius, useFeatures=True)\n        if sub_type == 'counts':\n            fp_vect = rdMolDescriptors.GetHashedMorganFingerprint(mol, radius, nBits=num_bits, useFeatures=True)\n        if sub_type == 'bv':\n            fp_vect = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits, useFeatures=True)\n    \n    if type_fp == 'AtomPair':\n        if sub_type == 'sparse' or sub_type == 'object':\n            fp_vect = rdMolDescriptors.GetAtomPairFingerprint(mol)\n        if sub_type == 'counts':\n            fp_vect = rdMolDescriptors.GetHashedAtomPairFingerprint(mol, nBits=num_bits)\n        if sub_type == 'bv':\n            fp_vect = rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(mol, nBits=num_bits)\n        \n    if type_fp == 'MACCS': \n        fp_vect = MACCSkeys.GenMACCSKeys(mol)\n        \n    if type_fp == 'Rdkit':\n        fp_vect = Chem.RDKFingerprint(mol)\n    \n    if type_fp == 'TT':\n        if sub_type == 'counts':\n            fp_vect = rdMolDescriptors.GetHashedTopologicalTorsionFingerprint(mol, nBits=num_bits) #2048 by default\n        if sub_type == 'bv':\n            fp_vect = rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(mol, nBits=num_bits)\n            \n    # Compute the RDKit2D fingerprint (200 topological properties) using the descriptastorus library\n    # Adopted from https://github.com/rinikerlab/GHOST/blob/main/notebooks/library_example.ipynb\n    if type_fp == 'Rdkit2D' or type_fp == 'Rdkit2D_norm':\n        try:\n            from descriptastorus.descriptors import rdDescriptors, rdNormalizedDescriptors\n            generator =  rdNormalizedDescriptors.RDKit2DNormalized() if type_fp == 'Rdkit2D_norm' else rdDescriptors.RDKit2D()\n\n            # process needs input as smiles\n            assert isinstance(smiles, str)\n            \n            smi = smiles \n            data = generator.process(smi)\n            \n            if data[0] == True:\n                data.pop(0)\n            if data[0] == False:\n                data.pop(0)\n                \n            data = np.float32(data)\n            data[np.isposinf(data)] = np.finfo('float32').max\n            data[np.isneginf(data)] = np.finfo('float32').min\n            fp_vect = np.nan_to_num(data)\n\n        except:\n            print('Failed to process the smiles using RDKit 2D features.')        \n            fp_vect = np.zeros(shape=(200))\n        \n    if sub_type == 'object':\n        return fp_vect \n    \n    elif sub_type == 'sparse':\n        try:\n            key_dict, len_arry = fp_vect.GetNonzeroElements() , fp_vect.GetLength()\n            sparse_row = np.zeros(len(list(key_dict.keys())))\n            sparse_col = np.array(list(key_dict.keys()))\n            sparse_data = np.array(list(key_dict.values()), dtype=np.int16)\n            fp = sp.sparse.csr_matrix((sparse_data, (sparse_row, sparse_col)), shape=(1, len_arry))\n            assert isinstance(fp, sp.sparse.csr_matrix)\n            \n        except: \n            key_dict, len_arry = fp_vect.GetNumOnBits(), fp_vect.GetNumBits()\n            key_dict, len_arry = fp\n            sparse_row = np.zeros(len(list(key_dict.keys())))\n            sparse_col = np.array(list(key_dict.keys()))\n            sparse_data = np.array(list(key_dict.values()), dtype=np.int16)\n            fp = sp.sparse.csr_matrix((sparse_data, (sparse_row, sparse_col)), shape=(1, len_arry))\n            assert isinstance(fp, sp.sparse.csr_matrix)\n\n    else:\n        try: \n            fp = np.zeros((0,), dtype=np.int16)\n            DataStructs.ConvertToNumpyArray(fp_vect, fp)\n        except: \n            fp = fp_vect \n    return fp\n\n## Have a dataframe output like Logan Ward does? \n\nclass FingerprintTransformer(BaseEstimator):\n    \"\"\"Class that converts SMILES strings to fingerprint vectors\"\"\"\n    \n    def __init__(self, smiles_column: str = 'SMILES', type_fp: str = 'Morgan', sub_type: str = 'bv', radius: int = 2, num_bits: int = 1024):\n        self.smiles_column = smiles_column\n        self.type_fp = type_fp\n        self.sub_type = sub_type \n        self.num_bits = num_bits\n        self.radius = radius\n    \n    def fit(self, X, y=None):\n        return self  # Do need to do anything\n    \n    def transform(self, X, y=None):\n        \"\"\"\n        Compute the fingerprints\n        :param X: List of SMILES strings\n        :return: Array of fingerprints\n        \"\"\"\n        if isinstance(X, list):\n            X_input = transform_to_mol(X) if isinstance(X[0], Chem.Mol) else X\n            fing = [ compute_fingerprint(m, type_fp = self.type_fp, sub_type = self.sub_type, radius = self.radius, num_bits = self.num_bits) for m in X_input ]\n            return np.vstack(fing)\n        \n        elif isinstance(X, pd.DataFrame): \n            \n            X = X.copy() # To ensure I am changing a separate array instance \n            X_mol_list = list(X[self.smiles_column])\n            fing = []\n\n            for i, entry in enumerate(X_mol_list):\n                fing.append( compute_fingerprint(entry, type_fp = self.type_fp, sub_type = self.sub_type, radius = self.radius, num_bits = self.num_bits) )\n            \n            if self.type_fp == 'Rdkit2D' or self.type_fp == 'Rdkit2D_norm':\n                X['{0}'.format(self.type_fp)] = fing\n            else: \n                X['{0}-{1}'.format(self.type_fp, self.sub_type)] = fing\n            return X\n        \n        else: #If it is a single entry \n            X_mol = X if isinstance(X, str) else transform_to_mol(X)\n            fing = compute_fingerprint(X_mol, type_fp = self.type_fp, sub_type = self.sub_type, radius = self.radius, num_bits = self.num_bits)\n            return fing\n\n\nfp_transform = FingerprintTransformer(num_bits=1024,\n radius=3,\\\n smiles_column = 'SMILES',\\\n sub_type = 'counts',\\\n type_fp = 'Morgan')\n\n\nfp_transform.get_params()\n\n{'num_bits': 1024,\n 'radius': 3,\n 'smiles_column': 'SMILES',\n 'sub_type': 'counts',\n 'type_fp': 'Morgan'}\n\n\n\nx_fp = fp_transform.transform(x)\n\n\nx_fp.sample(3)\n\n\n\n\n\n\n\n\nSMILES\nlogP\nROMol\nMorgan-counts\n\n\n\n\n846\nO=C1CNC(=O)N1\n-0.40\n\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n\n\n159\nCc1ccc(Cl)cc1\n-3.08\n\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n\n\n502\nCn2c(=O)on(c1ccc(Cl)c(Cl)c1)c2=O\n-2.82\n\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..."
  },
  {
    "objectID": "posts/2020-07-18-creating_meshes.html",
    "href": "posts/2020-07-18-creating_meshes.html",
    "title": "Plotting surface in matplotlib",
    "section": "",
    "text": "This is adapted from the following Tutorial: Link\nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom mpl_toolkits.mplot3d import axes3d\n\n%matplotlib inline \n%config InlineBackend.figure_format = 'retina'\nfig = plt.figure(1, clear=True)\nax = fig.add_subplot(1,1,1, projection='3d')\n\nx = np.array([[1, 3], [2, 4]]) #Array format: [[a,b],[c,d]] -- a b are in row; c d are in row  \ny = np.array([[5, 6], [7, 8]])\nz = np.array([[9, 12], [10, 11]])\n\nax.plot_surface(x, y, z)\nax.set(xlabel='x', ylabel='y', zlabel='z')\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2020-07-18-creating_meshes.html#meshgrid",
    "href": "posts/2020-07-18-creating_meshes.html#meshgrid",
    "title": "Plotting surface in matplotlib",
    "section": "Meshgrid",
    "text": "Meshgrid\nMesh is important to create a surface since just looking at the x, y vector by themselves what you would look at is the diagonal of the matrix formed by combination of all the possible x values with y values. For the given x and y vector, every entry in x vector can have the entire y vector as a possible point. So it is important to generate an array which captures all these possible pairing.\nSo using mesh-grid if x-vector is of dimensions M and y-vector is of dimensions N – the final resulting matrix is NxM dimensions where every \\(n^{th}\\) entry in y all the entries of x are added. Finally the ouput is given as x coordinate of that matrix and y coordinate of that matrix.\nExample: * \\(X\\) : \\(\\begin{bmatrix} x_{1} & x_{2} & x_{3} \\end{bmatrix}\\) * \\(Y\\) : \\(\\begin{bmatrix} y_{1} & y_{2} \\end{bmatrix}\\)\nThen resulting mesh would be: \\[ X-Y-Mesh = \\begin{bmatrix} x_{1}y_{1} & x_{2}y_{1} & x_{3}y_{1} \\\\ x_{1}y_{2} & x_{2}y_{2} & x_{3}y_{2}  \\end{bmatrix}\\]\n\\[ X-path = \\begin{bmatrix} x_{1} & x_{2} & x_{3} \\\\ x_{1} & x_{2} & x_{3}  \\end{bmatrix}\\]\n\\[ X-path = \\begin{bmatrix} y_{1} & y_{1} & y_{1} \\\\ y_{2} & y_{2} & y_{2}  \\end{bmatrix}\\]\n\n#Setting the bounds of the x and y axis \nx_axis_range = np.arange(-2,2.1,1)\ny_axis_range = np.arange(-4,4.1,1)\n\n#Make the meshgrid for the x and y \n(x,y) = np.meshgrid(x_axis_range, y_axis_range, sparse=True)\n\n\nz = x + y \n\n\nfig = plt.figure(1, clear=True)\nax = fig.add_subplot(1,1,1, projection='3d')\nax.plot_surface(x, y, z)\nfig.tight_layout()\n\n\n\n\n\n\n\n\nPlotting this 2D function: \\[ z = e^{-\\sqrt {x^2 + y^2}}cos(4x)cos(4y) \\] using the surface\n\nimport matplotlib.cm as cm \n\nx_axis_bound = np.linspace(-1.8,1.8,100)\ny_axis_bound = np.linspace(-1.8,1.8,100)\n\n(x,y) = np.meshgrid(x_axis_bound, y_axis_bound, sparse=True)\n\ndef f(x,y):\n    return np.exp(-np.sqrt( x**2 + y**2 )) * np.cos(4*x) * np.cos(4*y)\n\nZ = f(x,y)\n\nfig = plt.figure(1, clear=True)\nax = fig.add_subplot(1,1,1, projection='3d')\nax.plot_surface(x, y, Z, cmap=cm.hot)\nax.set_xlabel('x')\nax.set_ylabel('y')\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2020-09-18-smiles_from_pubchem.html",
    "href": "posts/2020-09-18-smiles_from_pubchem.html",
    "title": "Get SMILES from PubChem using DASK",
    "section": "",
    "text": "Dask implementation to acquire CanonicalSMILES from PubChem using the pubchem API. At the end of the notebook there is another dask based implementation of using RDKit to get InChIKey from the SMILES. While Dask is not necessary required in the case of InChIKeys it is a much more elegant implementation of dask.dataframes and map_partitions\nimport time\nimport pubchempy as pcp\nfrom pubchempy import Compound, get_compounds\nimport pandas as pd\nimport numpy as np\nimport re\nimport copy\n\n/depot/jgreeley/apps/envs/ml_torch/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n  warnings.warn(msg)"
  },
  {
    "objectID": "posts/2020-09-18-smiles_from_pubchem.html#get-smiles-from-pubchem",
    "href": "posts/2020-09-18-smiles_from_pubchem.html#get-smiles-from-pubchem",
    "title": "Get SMILES from PubChem using DASK",
    "section": "Get SMILES from Pubchem",
    "text": "Get SMILES from Pubchem\n\nUpdate: Parallelized using dask\n\n\ndf_100 = pd.read_csv('./DASK_SMILES/sample_chemical_names.csv', sep=',', header=0)\n\n\ndf_100.shape\n\n(147, 1)\n\n\n\nfrom dask.distributed import Client, progress\nimport dask.dataframe as dd\nfrom dask import delayed, compute\nfrom dask.multiprocessing import get\nclient = Client()\nclient\n\n\n\n\n\n\n\n\nClient\n\nScheduler: tcp://127.0.0.1:45859\nDashboard: http://127.0.0.1:8787/status\n\nCluster\n\nWorkers: 4\nCores: 8\nMemory: 39.85 GB\n\n\n\n\n\n\n\ndef get_smile(cmpd_name):\n    try:\n        #delayed(f)(x, args=a)\n        name = delayed(pcp.get_properties)(['CanonicalSMILES'], cmpd_name, 'name')\n        time.sleep(5)\n        smile = name[0]['CanonicalSMILES']\n    except:\n        smile = 'X'\n        print(cta_name, smile)\n    return smile\n\ndef dask_smiles(df):\n    df['CanonicalSMILES'] = df['CTA'].map(get_smile)\n    return df #Map paritions works here -- but not with to_list() in the previous implementation \n\n\ndf_dask = dd.from_pandas(df_100, npartitions=10)\n\n\ndf_dask\n\nDask DataFrame Structure:\n\n\n\n\n\n\n\nCTA\n\n\nnpartitions=10\n\n\n\n\n\n0\nobject\n\n\n15\n...\n\n\n...\n...\n\n\n135\n...\n\n\n146\n...\n\n\n\n\n\nDask Name: from_pandas, 10 tasks\n\n\ndf_dask.visualize()\n\n%time ddf_out  = df_dask.map_partitions(dask_smiles)\n\nCPU times: user 567 ms, sys: 92.3 ms, total: 660 ms\nWall time: 10 s\n\n\n\nddf_out.iloc[:,0]\n\nDask Series Structure:\nnpartitions=10\n0      object\n15        ...\n        ...  \n135       ...\n146       ...\nName: CTA, dtype: object\nDask Name: getitem, 30 tasks\n\n\nddf_out.visualize()\n\n%time results = ddf_out.persist(scheduler=client).compute()\n\nCPU times: user 9.42 s, sys: 1.27 s, total: 10.7 s\nWall time: 2min 43s\n\n\n\ntype(results)\n\npandas.core.frame.DataFrame\n\n\n\nresults.loc[0]\n\nCTA                                                     Cyclopropane\nCanonicalSMILES    Delayed('getitem-e98dc8d7261c3d694a3c944735b3c...\nName: 0, dtype: object\n\n\n\ncompute(results['CanonicalSMILES'].iloc[0])[0] #Compute result for one entry \n\n'C1CC1'\n\n\n\n%time results['CanonicalSMILES'] = [value[0] for value in results['CanonicalSMILES'].map(compute)]\n\nCPU times: user 3.73 s, sys: 443 ms, total: 4.17 s\nWall time: 31.1 s\n\n\n\ntype(results)\n\npandas.core.frame.DataFrame\n\n\n\nresults[results['CanonicalSMILES'] == 'X']\n\n\n\n\n\n\n\n\nCTA\nCanonicalSMILES\n\n\n\n\n\n\n\n\n\n\nresults\n\n\n\n\n\n\n\n\nCTA\nCanonicalSMILES\n\n\n\n\n0\nCyclopropane\nC1CC1\n\n\n1\nEthylene\nC=C\n\n\n2\nMethane\nC\n\n\n3\nt-Butanol\nCC(C)(C)O\n\n\n4\nethane\nCC\n\n\n...\n...\n...\n\n\n142\nCyclohexane-1,3-dicarbaldehyde\nC1CC(CC(C1)C=O)C=O\n\n\n143\nisobutene\nCC(=C)C\n\n\n144\npropanal\nCCC=O\n\n\n145\nmethyl methacrylate\nCC(=C)C(=O)OC\n\n\n146\nvinyl acetate\nCC(=O)OC=C\n\n\n\n\n147 rows × 2 columns\n\n\n\nresults.to_pickle(“cta_smiles_table_100_less.pkl”)"
  },
  {
    "objectID": "posts/2020-09-18-smiles_from_pubchem.html#dask-to-get-inchikey",
    "href": "posts/2020-09-18-smiles_from_pubchem.html#dask-to-get-inchikey",
    "title": "Get SMILES from PubChem using DASK",
    "section": "## Dask to get InChIKey",
    "text": "## Dask to get InChIKey\nThis implementation in my opinion is more elegant use of dask’s apply command wrapper around conventional pandas apply. Also here we are defining the meta key for the variable since the code doesn’t seem to recognise the type of entries we expect in the final output\nMore information about meta here: https://docs.dask.org/en/latest/dataframe-api.html\n\nimport rdkit\nfrom rdkit import Chem\nfrom rdkit.Chem import PandasTools\nfrom rdkit.Chem import Draw\n\nChem.WrapLogs()\nlg = rdkit.RDLogger.logger() \nlg.setLevel(rdkit.RDLogger.CRITICAL)\n\n\ndef get_InChiKey(x):\n    try:\n        inchi_key =  Chem.MolToInchiKey(Chem.MolFromSmiles(x))\n    except:\n        inchi_key = 'X'\n    return inchi_key\n\ndef dask_smiles(df):\n    df['INCHI'] = df['smiles'].map(get_name)\n    return df\n\n\nresults_dask = dd.from_pandas(results, npartitions=10)\n\n\ninchi = results_dask['CanonicalSMILES'].apply(lambda x: Chem.MolToInchiKey(Chem.MolFromSmiles(x)), meta=('inchi_key',str))\n\n\ninchi\n\nDask Series Structure:\nnpartitions=10\n0      object\n15        ...\n        ...  \n135       ...\n146       ...\nName: inchi_key, dtype: object\nDask Name: apply, 30 tasks\n\n\ninchi.visualize()\ninchi is a new Pandas series which has the delayed graphs for computing InChIKeys. We can compute it directly in the results dataframe as a new column. This is slightly different from the SMILES implementation above.\n\n%time results['INCHI'] = compute(inchi, scheduler = client)[0]\n\nCPU times: user 125 ms, sys: 17.3 ms, total: 142 ms\nWall time: 1.02 s\n\n\n\nresults\n\n\n\n\n\n\n\n\nCTA\nCanonicalSMILES\nINCHI\n\n\n\n\n0\nCyclopropane\nC1CC1\nLVZWSLJZHVFIQJ-UHFFFAOYSA-N\n\n\n1\nEthylene\nC=C\nVGGSQFUCUMXWEO-UHFFFAOYSA-N\n\n\n2\nMethane\nC\nVNWKTOKETHGBQD-UHFFFAOYSA-N\n\n\n3\nt-Butanol\nCC(C)(C)O\nDKGAVHZHDRPRBM-UHFFFAOYSA-N\n\n\n4\nethane\nCC\nOTMSDBZUPAUEDD-UHFFFAOYSA-N\n\n\n...\n...\n...\n...\n\n\n142\nCyclohexane-1,3-dicarbaldehyde\nC1CC(CC(C1)C=O)C=O\nWHKHKMGAZGBKCK-UHFFFAOYSA-N\n\n\n143\nisobutene\nCC(=C)C\nVQTUBCCKSQIDNK-UHFFFAOYSA-N\n\n\n144\npropanal\nCCC=O\nNBBJYMSMWIIQGU-UHFFFAOYSA-N\n\n\n145\nmethyl methacrylate\nCC(=C)C(=O)OC\nVVQNEPGJFQJSBK-UHFFFAOYSA-N\n\n\n146\nvinyl acetate\nCC(=O)OC=C\nXTXRWKRVRITETP-UHFFFAOYSA-N\n\n\n\n\n147 rows × 3 columns"
  },
  {
    "objectID": "posts/2023-01-16-auto3d.html",
    "href": "posts/2023-01-16-auto3d.html",
    "title": "Auto3D to make optimize tautomers and 3D conformers",
    "section": "",
    "text": "import os\nimport sys\nimport copy\nroot = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\nsys.path.append(root)"
  },
  {
    "objectID": "posts/2023-01-16-auto3d.html#view-the-test-molecules",
    "href": "posts/2023-01-16-auto3d.html#view-the-test-molecules",
    "title": "Auto3D to make optimize tautomers and 3D conformers",
    "section": "View the test molecules",
    "text": "View the test molecules\n\nimport pandas as pd\nimport numpy as np \nfrom rdkit.Chem import PandasTools\nimport rdkit\nfrom rdkit import Chem #This gives us most of RDkits's functionality\nfrom rdkit.Chem import Draw\nfrom rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\nIPythonConsole.ipython_useSVG=True  #SVG's tend to look nicer than the png counterparts\nprint(rdkit.__version__)\n\n# Mute all errors except critical\nChem.WrapLogs()\nlg = rdkit.RDLogger.logger() \nlg.setLevel(rdkit.RDLogger.CRITICAL)\n\n2021.09.4\n\n\n\ntest_smi = pd.read_csv('./tauto.smi', sep=' ', header=None, names=['SMILES','Name'])\n\n\ntest_smi.sample(2)\n\n\n\n\n\n\n\n\nSMILES\nName\n\n\n\n\n1\nC1(=CC(=NC(=C1)Cl)Cl)O\nCl-pyridone\n\n\n4\nN=C(C1=C(OCC2=C(F)C=CC=C2)C=CC=C1)O\nboo\n\n\n\n\n\n\n\n\nPandasTools.AddMoleculeColumnToFrame(test_smi, smilesCol='SMILES')\nPandasTools.FrameToGridImage(test_smi, legendsCol='Name', molsPerRow=4)"
  },
  {
    "objectID": "posts/2023-01-16-auto3d.html#read-the-sdf-files",
    "href": "posts/2023-01-16-auto3d.html#read-the-sdf-files",
    "title": "Auto3D to make optimize tautomers and 3D conformers",
    "section": "Read the SDF files",
    "text": "Read the SDF files\n\nimport mols2grid\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\n\n\nsdf_df = PandasTools.LoadSDF(out)\n\n\nsdf_df\n\n\n\n\n\n\n\n\nID\nE_tot\nfmax\nConverged\nE_rel(kcal/mol)\nROMol\n\n\n\n\n0\nCl-pyridone@taut1\n-1242.4485217285633\n0.0028711010236293077\nTrue\n0.0\n&lt;img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/&gt;\n\n\n1\nCl-pyridone@taut2\n-1242.4576208991289\n0.0029037443455308676\nTrue\n0.0\n&lt;img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/&gt;\n\n\n2\nbenzene-fused@taut1\n-646.5230541429044\n0.0028541951905936003\nTrue\n0.0\n&lt;img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/&gt;\n\n\n3\nbenzene-fused@taut2\n-646.5449096909285\n0.00297327502630651\nTrue\n0.0\n&lt;img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/&gt;\n\n\n4\nbenzene-fused@taut3\n-646.5199764570714\n0.0022692130878567696\nTrue\n0.0\n&lt;img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/&gt;\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n228\nsildenafil@taut9\n-1883.1668644994259\n0.0027246379759162664\nTrue\n2.6457204767372136\n&lt;img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/&gt;\n\n\n229\nsildenafil@taut9\n-1883.166294679022\n0.0028603156097233295\nTrue\n3.0032881786646404\n&lt;img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/&gt;\n\n\n230\nsildenafil@taut9\n-1883.1660918444156\n0.002793555613607168\nTrue\n3.130568815727958\n&lt;img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAABmJLR0QA/wD/AP+gvaeTAAAe+0lEQVR4nO2dfVyN9//HX+d030k3Ine5lxJlMuGbm20StqKZNnyXm8bC170t25eN8bUxjM3YN8TiO7+JlduISSSUSpSbIUluOpJTnU516pzz/v1xtaSR6lyXq9rn+fDH1Tnnel/vTk+f63N9biVEBAaDb6RiJ8BonDCxGILAxGIIAhOLIQhMLIYgMLEYgsDEYggCE4shCEwshiAwsRiCwMRiCAITiyEITCyGIDCxGILAxGIIAhOLIQhMLIYgMLEYgsDEYggCE4shCEwshiAwsRiCwMRiCAITiyEITCyGIDCxGILAxGIIAhOLIQhMLIYgMLEYgsDEYggCE4shCEwshiAwsRiCwMRiCAITqwEgl8uHDBmydetWsROpBYZiJ8B4OadPn46Ojj537tzrr7/+2muviZ1OjWAlVgPAz89v/vz5xcXFI0eOzMnJETudGiFhy3E3CDQajaen56lTp956662oqChDw/p+q2ElVsPA0NBw9+7dbdq0iY6OXrx4sdjpvBxWYjUkzp8/P3jw4LKyst27d/v5+YmdTnWwEqsh0a9fv2+//ZaIAgICrl69KnY61cFKrIbHxIkTd+zY4ejomJCQYGlpKXY6z4eJ1fBQqVT9+vVLS0sbNWpURESERCIRO6PnwG6FDQ+ZTBYeHm5lZbV///41a9aInc7zYSVWQ+XgwYOjRo2SSqWRkZFeXl5ip1MVVmI1VHx8fD777DOtVjt+/Pg7d+6InU5VmFgNkmvXrn366aeLFy/u06dPfn5+SkqK2BlVpb434DL+Sl5enq+v740bN2QymUKh0Gq1RUVFYidVlVdRx7pw4cLFixfrdq6Pj0+rVq34zadBo9Fohg8ffuLEiUGDBhkZGZ04caJPnz6nT582NTUVO7VnIYEJCgp655136pze1KlTY2JihE6yATF37lwA9vb2M2bMAGBnZ5eZmSl2Us9B2BIrMTGxb9++BgYGY8aMadKkSW1PT0lJSUhIGDFiRGRkpBDpNThCQkKmTJliZma2ePHiRYsWGRsbR0dHe3h4iJ3X8xDOWa1W27t3bwCLFi2qWwSFQmFhYQHg8uXL/ObWEImPj+fud0uXLuUOfvzxR7GTeiECirV37yMnJ7cWLVrk5+fXOQhX4AcGBvKYWANlwYIFAMaPH9+uXTsAU6dOFTuj6hBKLJWK2rYlqVS7a9cNfeLcuHFDKpWamZk9fvyYr9waKDqdbsuWLf379wcwcODA0tJSsTOqDqHasb7+GllZ6NNHOnasgz5xHBwcvLy8iouLt2zZwlduDRSJRJKSknLu3Dl7e/uwsDAjIyOxM6oWIWwtKaE2bUgiodOneYh25MgRAG3atKnn/0eFRqvV+vj4SKXSBvGYzGeJdf8+pk+HTgcTEwQGYuNGDBzIQ1gvLy8HBwcbmxFRUXk8hGuwENH169d1Ol1MTIzYubyc6pobzpw5U1JSYmBgwA36MTU1NTMzA2Bh0crIyEwigbX1M5+/fh1eXvj8c0yfjjFjsHVr1Q/Umc2bCwMDLQYOxOnT/ARsoFSMII2IiBg1apTY6VRLNaVZixYtnnuKq+tpgCr+GRmRjQ3Z2NCqVTRrFg0dSnI5vfceKRS8lasqFdnaEkDx8bzFbKCsXr0agI2Nze3bt8XOpTqq6yv8xz/+oVQqNRqNUqkEUFxcXFJSAsDMzNLGBkTIywOAsjIoFAAgkUAqxfLl+Pxznu03N0dAAFavxg8/4H//4zl4w2LBggXnzp0LDw8fO3ZsbGyssbGx2Bm9AP3dVKvpyRN68oQuX6Y5c4iIpk2jzp35LLGIKDOTDA3JyIiysvgM2xBRKBSdOnUCMHv2bLFzeSE8VN6NjWFjAxsbmJrCzAwAVqyATgd+R8y2awdfX5SVITj4eW8/fIjCQj6vV4+xtrYODw83MzP74Ycf9uzZI3Y6L0AIWw8fppEj6dw5nsPGxhJAzZtTUVGlV3Ny6O23ac4cGjOGVq7k+ZL1mJ9++gmAhYXFtWvXxM7lOQgi1qJFBJAQXQ6vvUZmZnT2bKWXgoLo99/Lj/386NYt/q9aX5kwYQIAFxcXlUoldi5VEUSsGzdIIiFLy2eLFj44cYKWLSs//vlnUquJRox4WptbuZL27eP5kqKiUCgOHTrEHUdHR9+/f7/yu4WFhc7OzgACAgLEyK46BOnScXBAnz4oKMCBAzxHbt4c69cjPBwAwsNRVgY0bYpHj8rfzs6GrS3PlxSV3Nzc3377jTs+evTo3bt3K7/LTddp0qTJtm3btm/fLkaCL0SovkJ/fwDYuZP/yP/8JzZuhFIJACgpwaRJ+Pxz3LmD339HUhL69eP/kqKiUqmysrKysrKU5b/zMzg6Om7evBnAjBkz9uzZQ/VmzpVQYn3wAYyMEBWF7GyeI5uYICgIS5cCKhW6dkVCAj75BKGhuHIFBw+i3i/DUlv++OOP4ODg4ODgF82YGDt2rIuLi1Qqff/99y0tLYcOHbpq1aqkpCSRJRPuLuvjQwB99x2fMS9fpk8+ISIaO5Z6WN0thIwmT6ZOnejrr0mj4fNK9YNbt25NnjyZOw4KCtr3vBrkihUrAEilUjs7u8p/2Xbt2k2dOnfHDrp379UmTUTCDZsBMH48mjfXJSef5zFmaWn5wZpJaXfybWBmhiZNcPs2Tp2CgQGPF6pXXLly5csvv9y6dauvry/3JFhBUFDQokWLjIyMwsLC5HL5w4cPw8LCPv744w4dOty9ezclxWrCBNjbo3VrvP8+Nm9GZiYAdO+OM2cAICQEBw8Kk7RwzqpUpba2LQFcvXqVl4A7d1KXLrRyJfXrR58Ghj/y89IFfkwyGUkklJjIyyXqGxqNhhs1VIGZmVnFu9yYUiMjo99++63KiTqd7tKlS1u3XvfxIUvLpx27Uil5e9OAATR0KKnVtHEj7d0rSOYClljm5kbvvTcSQGhoqP7R7t3DzJm4dQvp6Th/Huk5Ofc+j8uZ1rTU0xUjfdC7t/6XqIcYGBikpqZWfkWtVnMH8+fPX7t2rYmJSURExOjRowGUlpb26NFjypQpu3btksvlrq6uH33keOAA8vORno7gYPj5wcoKLVtCJsPEiVi7VsjUBdH1T2JjYwG0bt1ao3cFyNubAHrvPbpw4eiKFbO3b++XlTUvOVmWmCgpUqbwkm39pLi4uMqCtiUlJdOmTQNgYmJS0cpFRKefHVTUt++w2bNp375nOm1LSujRIxo2jHQ6GjGCFi8WqsQSViydTte5c2cAv1c0jteJfft+79o1xcqK7t2ju3dnJiYiKck0I+OjxETcvj2Wr2zrLZcvX+ZGwnFMnjyZs+rw4cNVPpmenh4cHOzn52dra9uv3zfc7c/AgNzdac2apx8bNowLS02bNkyxiGjJkiUAJk6cWOcIubm5LVu2NDIy+uWXC0SUm/vrnTvTnjzZd+1a/8REaVFRGm+51mO2bdtWuTQyNTWNjIys5vOlpaXnzuV89RUNHkwmJgRQ5b/Af/5TfrBsGe3fL0jCgouVkZEhkUhkMplSqaxbhLFjxwIYOXIkEeXnH79xY+iDB0sfPfovka6wkO+O7vqKRqN54403OKsMDQ25ttAaolJRVBQlJVV9fft2MjAggXqDXsXaDf379z9//nyXLl2srKy4V8zMzCqvNWBubm5iYlLxo0wmqxi/du/evcjISJnM5PDhNwYPPpqdvcrQsHmzZgFC51xPKC0tjYqK2rNnz8GDB/Py8gAYGBh06NAhISGhadOmegbPzETHjjA3R3Y2LCz4SLcyguj6LOfOnZs1a1adM3zjDdOgICQmQqmMLSuT37497tYtX5Xq4ivIXCw0GoqJOTd9+vTKo8OdnZ3nz5/fsWNHAE5OTvf4aPccNIgA2rFD/0hVeUUr+j18+PDBgwcVP1aMcuYoKiqqeIoGoFKp1OpCpfJkQcExrbZwwAB07jykdeulFhYDuA+Ult7LyBjn6Bj7CjJ/lZSWIioKe/bg0CH07PnvmJhvALi5uU2YMGHUqFEdOnQAIJfLhw4dmpqa2rFjxxMnTnCe1ZmQEEyZAk9PHD/Oy29QCf5d1ZOSEtq0STvkH8kJhomJuHatb15e+bNPWdmjx4+3FxTEKBT7b958p7T0vkIhTM1TYDZtovPniYgyMig8nLRaOnWKZs6kVq2etmQOHHhp3rx58c+bPZKbm9unTx8A7du3v6Xf+DOFgkxNycCAnh2PwwP1SaziYvrxR7K3575axfYJ+flHuHfU6qw7dz5OSjK+cqVHTs6Wx4+3qdX3UlM7JiUZKhQNbwCWry95epJaTQkJNHXqMz61aUNz5tCZM6TVVhdBoVBwc+1btWqVlqbXc/GUKRQSQjod3b9PlRrF9KV+iFVcTN9/T23alH+77u50pFyp0tLsrKwFycmyxEQkJkpv3x6r1ZY/Xcrl3ycmIinJKC/voHip1wVfX9q+nb7+mhISaOFCsrOjrl1pyRKqlSGFhYVvvfUWgBYtWuizGo+fH735JpWV0cWLtGBBncNUpX6IpVCQtTUB9OabFBtb/mJ2dv6x5cnJ5pxS6el+f22yun9/cWIikpPNCgpOvuKU9cHXl4qKyMeHwsLos8/o5s2XlE8vQqVScesl29jYJCQk1C0ZPz/68Udas6YxiXXhAgUGUkAAHT9OmzbRvn2k0xER3btHH39Mxsa6tq0vxpvdufNxSckLJ2dmZc1PTERyskypPPPqMtcPTqzr18nFhT77TK9QarXa19cXgLW19blaTl+Ryyk6mvz8KC+Phg2jQ4dowQIKCyNeZsKKJ1ZWFg0aRNnZlJ9PPj7E/YfLyaGFC0kmI4AkEho5Un3vpf2Aujt3PkpMxMWL1ipVsvB588A//0nFxURES5bQV1/pG620tJTbsEkmk0VHR9fklOPHydubpFKytqZ336X8fEpJIXd3mj6djI0JoN69KThYrykL4okVHEw//1x+fPIk/fvfdPQoNWlSXs16+226cKGGkXQ6TXq6X2IiUlLsiovr41yoKuTn0+jRT/tV9Eej0UyaNAmAubn5sWPHXvwxCg+nwYOpog/Rz4+8vYlbGG/+fJo2jWbOJCur8g+0bk1ffEF1W+JUPLHWraPdu8uPz5+nOXMoN5csLcnPj1JTaxtMq1Vdvz4wMRGXL/e+f1+MEZO14cIFAsjFhc+YOp1u5syZAExMTPb/pf+voKBg3bp13t6HOWMsLWnePMrIICIqLCyvgJSVlRdRKhWFhJC7+1P/Jk++fuDAgVoNURFPrLNnacqU8uPly8sl02P+vEaTl5rqOWRIJ2dn55ycHD5SFIr/+z8CaPRoIiK5nLKyyv+0eqLT6ebNmwfA1tg4ado0Cg6msLCrV6/6+/tzPWZOTm7OzhQaSiUlNQr4xx+0cCE1a0YDBkzmHj8XLlyYnp5ek3NFrbyvXEmjRtGYMTRvHi9fbV5enpubGwAXF5f6vLTk8uUEUFAQEdEXXxBAX37JW/AlS5bEVFoM6DNp+VhODw+PsLCwsrJaf89KJYWEhHJfLABDQ0NfX9/IyEhttY+y9aO5gT8ePXrUrVs3AO7u7gUFBXULkp2dLejc4okTCaDNm4mIxo4lgHbu5DO+2tiYAE6v3YC1tfUvv/yif9gLFy5MmTJFJpNxhnXo0CHrxXeYxiYWEWVlZXHdah4eHoWFhTU5JTc398CBA0uWLPH29m7ZsiWAwMDATz/9VKAMPTwIIO4B7vXXCSjv4eENCwsC7vwplq2t7cWLvPXZFxcXh4WFeXp6urq6VvOxRigWEd28eZPbKMXLy6vkBRWKGzdu7Ny5c9asWe7u7lUWirWysuJeCeJuV3wzcKDC0lLHPW1xj2D83reVp0+rAAJ0QKCpad++fXkUq4LqK7KNUywiSk1NtbW1BTB69OiysjIiysjICA0NnT17toeHh8Wz44/Mzc09PT2XLFly4MABbn2EY8eOcSPG5s6dy29iBQUFAExNTbVabU7OkwEDtgwfHsfvJY4ePdoL6A10l0qPHj06e/ZsIcSqnkYrFhGdOXOGqxD06NHDycmpyha37dq18/PzW7t2bWxsbNHzmgKjoqI4t+bNm8djVklJSVxKRHT27FkAffr04TE+EX3xxRcAunfvzrXFM7H459SpUxYWFtbW1gCaN2/u7e29cuXK2NjYl26WwX3gyJEj3IP6Av560Xbv3g3A19eXiHbs2AFg/PjxfAXn4Dqnw8PDuR91vDRm1JLGttJBFVQqVWFhYefOnU+fPu3s7GxQg9nSRDRjxowjR47ExMQMHz48IiLi3XffXbt2rUwm++qrr/RP6ebNmwAcHBwA3Lp1C0CXLl30D1tBWVlZfHy8RCIZ+Odi6KLsRt7Id1jl1gCaOHGii4tLTawCUFRUFB8fn5mZ+c4778jl8hEjRuzatcvIyGjZsmXLli3TP6X09HQA3Ky4goICIyMjbkFRvrh06ZJKpXJwcGjWrBmPYWvNqy8kXxllZWVc/f3KlStEVPNpQnl5ee7u7gAcHBy4uvzevXsNDQ0BLF++vM75aLXas2fPtm/fHkBUVFRFkvzuuLFu3TrUg6XYGrNYv//+O4Bu3boR0e3bt42Njf38/Gp4bl5eHjf8t2vXrpxbYWFhnFsrVqyoVRoKhSI0NNTb27uiaVEmk3l4eNS5/bZ6xowZAyAkJESI4DWnMYs1ffp0AIsXLyaiVatWAfjwww9rfrpCoXj99dcBODo6PnjwgIh2797N3U+/+eabl57+4MGDzZs3e3t7V57E3L59+3HjxnHrDQ0aNCgvL6/Ov92L4Bp4r1+/znvkWtFoxdJoNNzcKe5Jm7u1RURE1CqIQqHg9vJ0cnJ6+PAhEf38889SqRTAqlWr/vp5rVYbGxs7e/bsytUmY2Njb2/v4ODgir0kMjMzu3btCsDZ2ZmXWVwVcBU4Ozs7UZ4EK9NoxeLWI+ncuTMRZWZmSiQSCwuL57ZXVU9OTo6LiwsAFxcXrq1527ZtUqlUIpFs2LCB+4xSqQwLC/P392/evHmFTzY2Nv7+/gcOHHhut1J2dnbPnj0BdOzY8ebNm/r9rk/h2i9GjRrFV8A602jF4jbl5vr71q9fD6DmFawqPHr0qEePHgBcXV05t0JCQji3Jk+e/MEHH1TM8AbQtm3b6dOnHzlypJgbJPpi5HI5t4xM9+4uN2/WadD7XwgMDATw7bff8hJNHxqnWDqdzt7eHsD58+eJiGvR+fXXX+sc8N69e1zLk7u7O2fMmjVrJBIJty+akZGRp6fn+vXrazhWqYInT54MGvSms/PJpk352X+qe/fuAM4+sxC+ODROseLj4wG0a9dOp9M9ePCA2/y3zquScMjl8u7du69evZr7kbu9mpiYbNq0iat+1Q2lkt58kwCyta35YOznk5ubK5FITE1NX9Tv/ippnGIFBQUBmDNnDv25NQi3WI2eVO4IWrt2LYBx48bpH1atpjFjCCBzc3rxgPWXc+jQIQADBw7UPyX9aZwt79zWRe+99x7+bHznjvWEu/FxhIeHA+DWaNQTY2P8+ismT0ZREXx8EBFRxzhxcXEA3N3dExIS9M9KX8Q2m38uXrwIoFWrVlqtNicnx9DQ0NjYWMHrJnf379+XSqXm5uY8DjTVaGjyZALIxIQuXSp/saSE1OqXnFhQUJCSkhIREcH1OTo5OVlYWCT9dTmsV0sj7ITmiihfX1+pVHrw4EGNRjNs2DBrvnYRBgDs27dPp9N5eXmZm5vzFdPAACEhsLCAnR1GjsTq1fDzQ2gorKzwwQcAUFaGu3dx+zYyMpCTo7h8eVpGRkZGRsbjx48rggQGBmq12q1btw4bNiwuLo5rLRMHcb0WAm7MO7fqaVhYmJub23//+19+LzFkyBAAO4RYV4qIiDw9ycuL8vMpOJiWL6c33qD27cnA4OnaIba22oq/oImJSdeuXfv37+/s7Jydna3RaLgbdKdOneRyuUAZvpTGJlZOTk6zZs3Mzc2FezLKyckxMDDg/fZamWHDKDqaZs0qF4uTSSKh1q1pwADy96clSyg0dOepU6eysrK0Wm1JSQnXvMKNd1UqlVxn1KBBg0pFekJsbGIR0ciRIwFMnTpVoG4Nbp3Z4cOHCxGcg1vVeMIEmjGDQkPp8GG6do2qb3CNj4/n7stcP+bjx4979ehxfeBA8vamsjLhUn0RjVCss2fPckPaAwIChHDL29sbwGZu9pYwcGI9fEi2tlTzZt0DBw4YGBhIJJLQ0FAiUt+6Rc2bE1C+U/erpRGKRUQnTpzghqvP4fs7zc/PNzExMTQ0FHSydcXaA1FRVKuNeVeuXAnAwc6umGt8T0ripoKRHsPI6kbjFIuIjh49yg1X/5LHWcZEu3btAjB48GAeY/6Vt98uP9i7l2o7sOqbTz4p7tqVmjYlbgujyEgyNCSJpNaB9KPRikVEv/32Gzc0rybDp2oIN4zu+++/5yvgcxk0qPxg1y7atKmWJ+t05O9fvljMnTtERD/8QADx0UlQcxqzWES0Y8cObvjU2rVra3Vifn5+TEzMunXr/P39U1LK1+hSqVTm5uYSiYTfQVR/pVMn+te/6F//Ii+v2otFRGo1eXoSQM7OlJtLRLRvXx1XDawrjVwsIgoJCZFIJBKJpPrqdlpaWmho6MKFC729vblZ1BVUjLuKiIgA0LdvX6FzHjCACgqooIC2bauTWET0+DE5ORFAQ4aUL7hy5Qpt20YnTvCztM3LaIQt71UICAhQKpVz586dPn26hYXFuHHjKt5SqVTfffddcnJycnJylX28DQ0NnZycevXq5ebm5unpyb3IY/9g9UilaNIEAExNUWk9/Npga4sTJzBkCGbNgkSCvXuxdy8mTkRcHPbswU8/8Zrv83gF8tYHli5dCsDIyKjyomRarbZirj03wWH27NmhoaFpaWllz7b9aDSaS5cuNWnSBACPAz5fxMqV5Qfnz1PNFn98ARWto2++SRUDWYcOJcGadiv4u4hFRAsXLgRgbGxced+sb7/9duvWrUlJSepnO3uVSmVsbOz69ev9/f2dnZ25h4BWrVqZm5un1n7BQfHp1+/p8aRJtWvDqBN/I7F0Ot2MGTMAmJubx8TEVHlXqVTGxcVt2LAhICCgV69eVdafkUqljo6O3P4i9vb2eu4HIQJeXlTRb+jhQTVb3UkfXtFeOvUEIgoMDNyyZYulpWVoaKiBgUHSnzx8+LDyJ2Uy2Wuvvdb7TxwdHQ0NDUtLS999993IyMgWLVrExMQ4OTmJ9YvUmpgYrFqFDz5AXBw6dcLnnwt9wb+XWADKysr8/Pz2799vYmJSeWcoc3NzV1dXNze3Xr169erVy8XFpWJru8oUFxd7e3tHR0fb29ufOnWK39nxwvLkCVJT0b49OnR4BVf724kFQK1Wb9y4MS4uTqFQcM99vXr1cnR0rOHiDgUFBV5eXvHx8Q4ODhdPnZI92zbB4Pg7iqU/KpXK+513NhI5Z2YiJubVlAENCyZWHVHn5pp4eiIlBd26IToaLVuKnVH9gomlB/n58PJCQgIcHHDyJNq0ETuhegQTSz/y8zF0KC5cgIMDYmLQurXYCdUXGuf0r1eHlRUOH0aPHrh5Ex99JHY29QhWYvHBo0eYNAkbNqBdO0REQKlE377o0UPstMSElVh8YGeHyEh07oyxY6FWw9kZS5fi5Emx0xITJhZ/pKXB0hL+/ujfH999hw0bxE5ITJhY/CGXP30wbNMGjx6Jmo3IMLH4o2tXXLlSfpyaigbUkygArPLOK4sXIz8fjo44eBA//ggHB7ETEg0mFq+EhUEqRadO6NEDz+vD/vvAxOIPIrRqBbkcV6+iWzexsxEZVsfij9RUyOVo25ZZBSYWnxw/DgBDhoidR72AicUfnFhDh4qdR72A1bF4Qq1G06YoLkZ2NuzsxM5GfFiJxRNxcSgqgqsrs4qDicUPJ5OT47t317L74J8wsfhhYVhYvytXjrOa+5+wOhYP5OTktGzZ0sTE5MmTJ9y6XAxWYvHAyZMndTqdh4cHs6oCJhYPHD9+HMBQVsGqBBOLB44dOwYm1rOwOpa+3Lhxw9HR0c7OLjs7W5T94usnjX99LKHZvXt3ly5d3NzcmFWVYSWWXty+fdvV1VWtVl++fLkb63uuBKtj1R2tVvvhhx+qVKqPPvqIWVUFVmLVne+//37u3Lnt2rVLTU2tvOMcA0ysOnPr1q2ePXsWFxcfP358CGtw/wvsVlgXiGjKlClFRUUBAQHMqufCSqy6sHHjxpkzZ7Zt2zYtLY3dBJ8LE6vWpKen9+zZU6VSHT58+O233xY7nXoKuxXWDiKaOnWqSqWaOHEis6oaWIlVO4KDg6dNm2Zvb5+WlmZlZSV2OvUXJlYtyM7O7tatW15e3p49e7jdmhgvgolVC3Q63U8//XTx4sWtW7eKnUt9h4nFEARWeWcIAhOLIQhMLIYgMLEYgsDEYggCE4shCEwshiAwsRiCwMRiCAITiyEITCyGIDCxGILAxGIIAhOLIQhMLIYgMLEYgsDEYggCE4shCEwshiAwsRiCwMRiCAITiyEITCyGIDCxGILAxGIIAhOLIQhMLIYgMLEYgsDEYggCE4shCEwshiAwsRiCwMRiCAITiyEITCyGIPw/Qz50vQirpvgAAALrelRYdHJka2l0UEtMIHJka2l0IDIwMjEuMDkuNAAAeJxlj2tIFFEUx+/cmZ2ddd1V96Xuujrlo0UqKfP1YedeX4hrWBkURtEikvshkB5UpImWUSSmJFTEYj4KXTMj0sqwnYtJ6jf7YBjpYi/7oKylGFGUja3row4cfueee///c8+s+74HSKECqxEtZZyUlRQL7BIpmgUOiTRNrSksSwUj95H2c0XBx0iEjP8d5yOU+wzgigGL/fQ7LzeCAS+R9QtXDZbay3Mg9HNdm/rveo37P2P8vusV1OpCy4tQf8+A8lMJKIahYDykoaSmYxiasUBGxstYIJMDOQc4hQVyAXyAklcG8sooCwxUOaBKbVcHAXW4AwYFczAoREoN0GiBVgd0eqA3AH0oCA0DYRoQbrQbTQ5oiuBNgfYIMzBHgige8DTgJfcNDMVvZCgdI6MZmZxnuQBlFC9nVepwoymQ1er0oWGa0C5K+ibwJYgOGbThN4cr8AmHnihMZ3GZLgNTnmdiZsR+vKnfgBtc7915Q1WYT+9FPSljQukXFx5V1KNPIy1CS3Y3diaeF2xlrejFggdnj9W7ty66UHNJHcbaKvdg3iKq+1iNp7pGRa5zADkHGqV+LPFOD6H5qyn4yOVpcSahBjUZZ1HCRLFoHq5Fw6d+C97yNrHJiNCuyG/urpxm9+efhSivcEo8qggXv/fr0M2d6WTSuQ3RChvyHrhCbp2OsHLWCyitmyfJ916jkqx3KMNuJUPy50g7ly5Gvz1E4l2JyHNsTjSn3iat0Wmo9RokBbkPSFUci+v2MuRJ0QT5dYnDB+vUpP1lM/HAJDzusIsdX4uIc2AHrr0hiDnHVWTfOa+Y/2qPAEqbRdedZHI9s8baONtmzfoRSyINHcJDsRqllhQTl3a30J60BW2fchJvOXJfLA8WPgw+JhXmM2ihF2JLRadQ3/QUFeQW4pmEPHQ3fwTpTzbgnvlH7kpbNh7fbMN9k32oOteMDX8AZdnkZ3S0znQAAAOKelRYdE1PTCByZGtpdCAyMDIxLjA5LjQAAHicfZbJbhw3EIbvegq+wDRYK1mHALEkbwg8AmI5dwNJAAFGLlHe31XFnm5Sh0yrBz3VH8m/Vujflx9//vXP979ffvz6+v2/V7sr8fn98beX13J86PHO7fV//sys/EG11rsvJR7K/fuPn6/l4fnd/c3y8PTt+vy1kBTqvsavlX33/PTlZoHyUGgD7VyrP1hj9YcLbkQsdVqKCVptlmAljNcX2FjMZpASJAVwq+8jkjvWjRnbDLKDvFWRsPo+3Cheb4xIMyflWmQjqJocoAyOoNeZ0+SUKHVvKEy5AFvDmWt+rm6mTYYu7GgJEnaYwZ4CuQPvoCAkaDZiUx4+fPwFb7glDpK7eWBUjRMX0iWUUMuTk6YgI9bSbEgVtSVEAO4Tbl1TmO/paRoSam+8kJEfCLIOsT0Oz3jVtu4ZCfIox0m5J9U+Iua5X3VGhiJxvbaxKYXiQLvAikqgsDWzPdtirScqHZaogpav5eIVhHXkUY0G2botiYLmcbqw54U0gUodh/d7DRxkD9IDGUcFoK2NOLU31QnmEXXSxAbJLUIWips0XSq+hk+0seoenwp9T4Px4hNGG7lSazKUNiQcua1cF6cQQ4D4uZkWB7wOdlTfCIhMXbxUoVOiQEQDRWxrd2aqJLpJEu2Ya6IQmq67ynBLotMHynsnNH7T8xqonwb1Vn+afnkvVF7iim0UACrsjnfZ01p17VPsWYA1cjnK34hHRxOusTJPq2ebMpmhWXvfj6eFjKkXpTR8jUxUguEU9LYcT5AocJalx6wBpCvekGv9EWb3VUbd5antowqX5qN95pnAyL7RmGmKo0vXQUFcPnn/q89SHG0lwGoxVTtqw2ljcdLHs3TrPYvV66u7JvZahQl8f31cxvoY9PdP18dz0Md1aMC86Bza4Defoxn9lnMCg996Dlrwu53zNH72c2qC33ZORfQb5uEHYYBpxkF+HdrcMcivQ57PLAwLnQy7QDfDodlHEIcZDtkQQt0Mh3KfKAF4YU+TAxM83AHbLYdHmNFzy+EUpmYH57aGAPHwCyOmDuIZcw6Lx/3wC2W3HF5gaHYQDy8w4hvgeXqPBKm/mRqFA8RDc2bcQTxWed1zWM6oUmr2upsLGUqyU61CgHSuCs00FQvpMJxntywBXxplf27VB+cbLPao3blS4/ft3xl/vvsJggm43urtBHYAAAHrelRYdFNNSUxFUyByZGtpdCAyMDIxLjA5LjQAAHicJVI5biNBEPvKhhIgtes+MDCwwCSO5GBDQZG+4ccvqx0IA7HrIFl8fr2e598Xy+PzvLz1/b78u3x+X+f3sPN8XM7redr1/X7r93leH+e8oAMtl+fX6zoFaJWP8/P8OP/8XHSxV/eNl6UH32SZZ/ChS9v5RitbE68haYcsMgmAqrFbTOzgVVG3O61qA8aUedCyztudl1L5DLHwAyVWlFOqPGg5A2Ws6BjUOwuwF/Nx10VCir/ROmhWy3G3paLDgLQE20hcj7ssZx6SmfNJ7x6w/VfXL72ErhlrEZsScQ1DsOaZ25A/sKjc7iOUsM7RnQlTqOHNwDFDYjWXAmZVHVgkfarJ3QGX4HUcydgr3WKj5puImQ89YeLNILCSlpD1uCHBm0H51k1RsJNqY95q234R+E4KuTM+qvYAFZSCIdyEIFKedVxzDzY4BIbJ3KjtgJsyl/ulYDTGUeHIhkRIDxqxL+qK42Fe4GjDAYkYNDqBWrHNFnGZCd02tUHZsg/tbIiKjoDIw1eojvviNkMkUw64GbmdkZK5mEoxSpUpJlA48WjmwmAYnDt4OZiJ6CQ1eIKr7jtGSGUCbXCYxSo+YmxCgbRHGdBGIkeMqvn15z9NT60+Pms0lwAAAABJRU5ErkJggg==\" alt=\"Mol\"/&gt;\n\n\n231\nsildenafil@taut9\n-1883.1657381802559\n0.002911796560510993\nTrue\n3.3524964267405757\n&lt;img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/&gt;\n\n\n232\nsildenafil@taut9\n-1883.1640510409832\n0.0027946573682129383\nTrue\n4.411192304313834\n&lt;img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/&gt;\n\n\n\n\n233 rows × 6 columns\n\n\n\n\nsdf_df = sdf_df.sort_values('E_tot', ascending=False)\nsdf_df = sdf_df.drop_duplicates(subset=['ID'])\nsdf_df['parent_id'] = [x.split('@')[0] for x in sdf_df['ID']]\nsdf_df['tauto_id'] = [x.split('@')[1] for x in sdf_df['ID']]\nsdf_df['SMILES'] = [Chem.MolToSmiles(x) for x in sdf_df['ROMol']]\nsdf_df['E_tot'] = sdf_df['E_tot'].astype(float)\n\n\nsdf_df.columns\n\nIndex(['ID', 'E_tot', 'fmax', 'Converged', 'E_rel(kcal/mol)', 'ROMol',\n       'parent_id', 'tauto_id', 'SMILES'],\n      dtype='object')\n\n\n\nsdf_format = sdf_df[['parent_id','tauto_id', 'ID', 'SMILES', 'E_tot', 'fmax', 'Converged', 'E_rel(kcal/mol)']]\n\n\n# convert Hatrees to kcal/mol http://wild.life.nctu.edu.tw/class/common/energy-unit-conv-table.html\nE_rel = []\nfor parent_id in set(list(sdf_format['parent_id'])):\n  sdf_format_per_parent = sdf_format.loc[ sdf_format['parent_id'] == parent_id ]\n  sdf_format_per_parent.loc[sdf_format_per_parent.index, 'E_rel_tauto(kcal/mol)'] = (sdf_format_per_parent['E_tot'] - min(sdf_format_per_parent['E_tot'])) * 627.5095\n  E_rel.append(sdf_format_per_parent)\nsdf_format = pd.concat(E_rel)\n\n/node/scratch/106404095.1.all.normal.q/ipykernel_28232/475714180.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  sdf_format_per_parent.loc[sdf_format_per_parent.index, 'E_rel_tauto(kcal/mol)'] = (sdf_format_per_parent['E_tot'] - min(sdf_format_per_parent['E_tot'])) * 627.5095\n\n\n\nsdf_format\n\n\n\n\n\n\n\n\nparent_id\ntauto_id\nID\nSMILES\nE_tot\nfmax\nConverged\nE_rel(kcal/mol)\nE_rel_tauto(kcal/mol)\n\n\n\n\n167\nsildenafil\ntaut26\nsildenafil@taut26\nCCCc1nn(C)c2c(=O)[nH]c(-c3cc(S(=O)(=O)N4CCN(C)...\n-1883.237851\n0.0027714346069842577\nTrue\n0.0\n0.000000\n\n\n174\nsildenafil\ntaut27\nsildenafil@taut27\nCCCc1nn(C)c2c(=O)nc(-c3cc(S(=O)(=O)N4CCN(C)CC4...\n-1883.217860\n0.0029108182061463594\nTrue\n0.0\n12.544642\n\n\n183\nsildenafil\ntaut28\nsildenafil@taut28\nCCCc1nn(C)c2c(O)nc(-c3cc(S(=O)(=O)N4CCN(C)CC4)...\n-1883.211783\n0.002911168849095702\nTrue\n0.0\n16.358181\n\n\n155\nsildenafil\ntaut24\nsildenafil@taut24\nCC/C=C1/NN(C)c2c1nc(-c1cc(S(=O)(=O)N3CCN(C)CC3...\n-1883.198682\n0.002975363051518798\nTrue\n0.0\n24.578853\n\n\n119\nsildenafil\ntaut20\nsildenafil@taut20\nC/C=C/c1nn(C)c2c1N[C@@H](c1cc(S(=O)(=O)N3CCN(C...\n-1883.195765\n0.002867447677999735\nTrue\n0.0\n26.409780\n\n\n210\nsildenafil\ntaut5\nsildenafil@taut5\nC/C=C/C1=C2NC(c3cc(S(=O)(=O)N4CCN(C)CC4)ccc3OC...\n-1883.185570\n0.0029683925677090883\nTrue\n0.0\n32.806838\n\n\n91\nsildenafil\ntaut17\nsildenafil@taut17\nC/C=C/c1nn(C)c2c1N=C(c1cc(S(=O)(=O)N3CCN(C)CC3...\n-1883.185264\n0.002987172920256853\nTrue\n0.0\n32.998937\n\n\n151\nsildenafil\ntaut23\nsildenafil@taut23\nCC/C=C1/NN(C)c2c1[nH]c(-c1cc(S(=O)(=O)N3CCN(C)...\n-1883.183689\n0.0029540995601564646\nTrue\n0.0\n33.987148\n\n\n96\nsildenafil\ntaut18\nsildenafil@taut18\nC/C=C/c1nn(C)c2c1NC(c1cc(S(=O)(=O)N3CCN(C)CC3)...\n-1883.178366\n0.0029339187312871218\nTrue\n0.0\n37.327788\n\n\n81\nsildenafil\ntaut15\nsildenafil@taut15\nC/C=C/[C@@H]1NN(C)c2c1nc(-c1cc(S(=O)(=O)N3CCN(...\n-1883.176364\n0.0029547689482569695\nTrue\n0.0\n38.583651\n\n\n143\nsildenafil\ntaut22\nsildenafil@taut22\nCC/C=C1/NN(C)c2c(O)nc(-c3cc(S(=O)(=O)N4CCN(C)C...\n-1883.173366\n0.0019200812093913555\nTrue\n0.0\n40.464996\n\n\n101\nsildenafil\ntaut19\nsildenafil@taut19\nC/C=C/c1nn(C)c2c1N[C@@H](c1cc(S(=O)(=O)N3CCN(C...\n-1883.172031\n0.00290022068656981\nTrue\n0.0\n41.302550\n\n\n227\nsildenafil\ntaut9\nsildenafil@taut9\nC/C=C/C1=NN(C)[C@@H]2C(=O)NC(c3cc(S(=O)(=O)N4C...\n-1883.171081\n0.0029343736823648214\nTrue\n0.0\n41.899119\n\n\n160\nsildenafil\ntaut25\nsildenafil@taut25\nCCCC1=NN(C)[C@@H]2C(=O)N=C(c3cc(S(=O)(=O)N4CCN...\n-1883.169082\n0.0029732126276940107\nTrue\n0.0\n43.153355\n\n\n187\nsildenafil\ntaut3\nsildenafil@taut3\nC/C=C/C1=C2N=C(c3cc(S(=O)(=O)N4CCN(C)CC4)ccc3O...\n-1883.166379\n0.002880740910768509\nTrue\n0.0\n44.849577\n\n\n111\nsildenafil\ntaut2\nsildenafil@taut2\nC/C=C/C1=C2N=C(c3cc(S(=O)(=O)N4CCN(C)CC4)ccc3O...\n-1883.164880\n0.0029965881258249283\nTrue\n0.0\n45.789950\n\n\n222\nsildenafil\ntaut8\nsildenafil@taut8\nC/C=C/C1=NN(C)[C@@H]2C(=O)N=C(c3cc(S(=O)(=O)N4...\n-1883.164851\n0.0029544399585574865\nTrue\n0.0\n45.808576\n\n\n213\nsildenafil\ntaut6\nsildenafil@taut6\nC/C=C\\C1=NN(C)C2=C(O)N=C(c3cc(S(=O)(=O)N4CCN(C...\n-1883.164151\n0.0029395974706858397\nTrue\n0.0\n46.247307\n\n\n88\nsildenafil\ntaut16\nsildenafil@taut16\nC/C=C/c1nn(C)c2c1=N[C@@H](c1cc(S(=O)(=O)N3CCN(...\n-1883.159181\n0.0029624311719089746\nTrue\n0.0\n49.366394\n\n\n72\nsildenafil\ntaut14\nsildenafil@taut14\nC/C=C\\[C@@H]1NN(C)c2c1[nH]c(-c1cc(S(=O)(=O)N3C...\n-1883.159030\n0.002975861541926861\nTrue\n0.0\n49.460966\n\n\n55\nsildenafil\ntaut13\nsildenafil@taut13\nC/C=C\\[C@@H]1NN(C)c2c(O)nc(-c3cc(S(=O)(=O)N4CC...\n-1883.148282\n0.002590285148471594\nTrue\n0.0\n56.205456\n\n\n193\nsildenafil\ntaut4\nsildenafil@taut4\nC/C=C/C1=C2NC(c3cc(S(=O)(=O)N4CCN(C)CC4)ccc3OC...\n-1883.144197\n0.002940340666100383\nTrue\n0.0\n58.768723\n\n\n217\nsildenafil\ntaut7\nsildenafil@taut7\nC/C=C/C1=NN(C)C2=C(O)NC(c3cc(S(=O)(=O)N4CCN(C)...\n-1883.144103\n0.0029915182385593653\nTrue\n0.0\n58.827650\n\n\n21\nsildenafil\ntaut10\nsildenafil@taut10\nC/C=C/C1=NN(C)[C@@H]2C(O)=NC(c3cc(S(=O)(=O)N4C...\n-1883.142340\n0.0029348309617489576\nTrue\n0.0\n59.933997\n\n\n17\nsildenafil\ntaut1\nsildenafil@taut1\nC/C=C/C1=C2N=C(c3cc(S(=O)(=O)N4CCN(C)CC4)ccc3O...\n-1883.142246\n0.0026598710101097822\nTrue\n0.0\n59.993093\n\n\n29\nsildenafil\ntaut11\nsildenafil@taut11\nC/C=C/C1=NN(C)[C@@H]2C1=NC(c1cc(S(=O)(=O)N3CCN...\n-1883.141071\n0.002974058734253049\nTrue\n0.0\n60.730651\n\n\n129\nsildenafil\ntaut21\nsildenafil@taut21\nCC/C=C1/NN(C)[C@@H]2C(=O)N=C(c3cc(S(=O)(=O)N4C...\n-1883.140111\n0.0025039315223693848\nTrue\n0.0\n61.333093\n\n\n37\nsildenafil\ntaut12\nsildenafil@taut12\nC/C=C\\[C@@H]1NN(C)[C@H]2C(=O)N=C(c3cc(S(=O)(=O...\n-1883.124047\n0.002953974064439535\nTrue\n0.0\n71.413043\n\n\n9\nboo\ntaut2\nboo@taut2\nNC(=O)c1ccccc1OCc1ccccc1F\n-845.393300\n0.002969717374071479\nTrue\n0.0\n0.000000\n\n\n5\nboo\ntaut1\nboo@taut1\nN=C(O)c1ccccc1OCc1ccccc1F\n-845.367714\n0.002988976426422596\nTrue\n0.0\n16.055548\n\n\n15\npyridone\ntaut1\npyridone@taut1\nO=c1cc[nH]cc1\n-323.358696\n0.002931158524006605\nTrue\n0.0\n0.000000\n\n\n16\npyridone\ntaut2\npyridone@taut2\nOc1ccncc1\n-323.357830\n0.0027759429067373276\nTrue\n0.0\n0.543535\n\n\n3\nbenzene-fused\ntaut2\nbenzene-fused@taut2\nO=c1ccnc2ccc3ccc[nH]c3c12\n-646.544910\n0.00297327502630651\nTrue\n0.0\n0.000000\n\n\n2\nbenzene-fused\ntaut1\nbenzene-fused@taut1\nO=c1cc[nH]c2ccc3cccnc3c12\n-646.523054\n0.0028541951905936003\nTrue\n0.0\n13.714564\n\n\n4\nbenzene-fused\ntaut3\nbenzene-fused@taut3\nOc1ccnc2ccc3cccnc3c12\n-646.519976\n0.0022692130878567696\nTrue\n0.0\n15.645841\n\n\n1\nCl-pyridone\ntaut2\nCl-pyridone@taut2\nOc1cc(Cl)nc(Cl)c1\n-1242.457621\n0.0029037443455308676\nTrue\n0.0\n0.000000\n\n\n0\nCl-pyridone\ntaut1\nCl-pyridone@taut1\nO=c1cc(Cl)[nH]c(Cl)c1\n-1242.448522\n0.0028711010236293077\nTrue\n0.0\n5.709816\n\n\n\n\n\n\n\n\nmols2grid.display(sdf_format, \n                  # set what's displayed on the grid\n                  subset=[\"parent_id\", \"img\", \"tauto_id\",\"E_rel_tauto(kcal/mol)\"],\n                  # set what's displayed on the hover tooltip\n                  tooltip=[\"parent_id\", \"E_tot\", \"fmax\", \"E_rel_tauto(kcal/mol)\"],\n                  transform={\"E_rel_tauto(kcal/mol)\": lambda x: r\"del_E_tauto: {0:0.3f} kcal/mol\".format(x)},\n                  size=(250,250))"
  },
  {
    "objectID": "posts/2023-01-16-auto3d.html#saving-and-viewing-the-sd-files",
    "href": "posts/2023-01-16-auto3d.html#saving-and-viewing-the-sd-files",
    "title": "Auto3D to make optimize tautomers and 3D conformers",
    "section": "Saving and viewing the SD files",
    "text": "Saving and viewing the SD files\nHere I am looking at the 3D conformers of the original and tautomers\n\ninf = open(os.path.join(out_folder, 'job1','smi_taut_3d.sdf'),'rb')\nwith Chem.ForwardSDMolSupplier(inf) as fsuppl:\n    ms = [x for x in fsuppl if x is not None]\n\n\n## Combine all the conformers for a given molecule in 1 molecule object \nmol_dict = []\nget_og_name = [x.GetProp('ID').split('@')[0] for x in ms]\nfor index, row in test_smi.iterrows():\n  item_index = []\n  for entry_index, og_name in enumerate(get_og_name):\n    if str(row['Name']) == og_name:\n      item_index.append(entry_index)\n  list_sdf = [ms[i] for i in item_index]\n  sdf_dict = {}\n  sdf_dict['parent'] = row['Name']\n  sdf_dict['conformers'] = list_sdf \n  mol_dict.append(sdf_dict)\n\n\ndef to_sdf(mol_dict):\n  parent_id = mol_dict['parent']\n  w = Chem.SDWriter(f'{out_folder}/conformers_{parent_id}.sdf')\n  sdfs = mol_dict['conformers']\n  for entries in sdfs:\n    w.write(entries)\n  w.close()\n\ndef append_conformers_to_mol(mol_dict):\n  parent_id = mol_dict['parent']\n  sdfs = mol_dict['conformers']\n  ref = copy.deepcopy(sdfs[0])\n  for mol in sdfs:\n    conf_mol = mol.GetConformer()\n    mol_props = mol.GetPropsAsDict()\n    for key, value in mol_props.items():\n      conf_mol.SetProp(str(key), str(value))\n    ref.AddConformer(conf_mol, assignId=True)\n  \n  for name in ref.GetPropNames():\n    ref.ClearProp(name)\n  \n  ref.SetProp('_Name',str(parent_id))\n  Chem.rdMolAlign.AlignMolConformers(ref)\n  return ref \n\n\nfor mol_list in mol_dict:\n  print(mol_list['parent'], len(mol_list['conformers']))\n\npyridone 2\nCl-pyridone 2\nbenzene-fused 3\nsildenafil 216\nboo 10\n\n\n\nmol_dict[1]\n\n{'parent': 'Cl-pyridone',\n 'conformers': [&lt;rdkit.Chem.rdchem.Mol at 0x2b29365373a0&gt;,\n  &lt;rdkit.Chem.rdchem.Mol at 0x2b2936537030&gt;]}\n\n\n\nto_sdf(mol_dict[1])\n\n\nref = append_conformers_to_mol(mol_dict[-1])\n\n\n# http://rdkit.blogspot.com/2016/07/using-ipywidgets-and-py3dmol-to-browse.html\nimport py3Dmol\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom ipywidgets import interact, interactive, fixed\n\n\nref.GetNumConformers()\n\n11\n\n\nWhat I want to do is generate a set of conformers for a molecule and scroll through them interactively. Here’s some code for doing that:\n\n# https://birdlet.github.io/2019/10/02/py3dmol_example/\n# http://rdkit.blogspot.com/2016/07/using-ipywidgets-and-py3dmol-to-browse.html\n\nimport py3Dmol\n\ndef MolTo3DView(mol, confId, size=(400, 400), style=\"stick\", surface=False, opacity=0.5):\n    \"\"\"Draw molecule in 3D\n    \n    Args:\n    ----\n        mol: rdMol, molecule to show\n        size: tuple(int, int), canvas size\n        style: str, type of drawing molecule\n               style can be 'line', 'stick', 'sphere', 'carton'\n        surface, bool, display SAS\n        opacity, float, opacity of surface, range 0.0-1.0\n    Return:\n    ----\n        viewer: py3Dmol.view, a class for constructing embedded 3Dmol.js views in ipython notebooks.\n    \"\"\"\n    assert style in ('line', 'stick', 'sphere', 'carton')\n    mblock = Chem.MolToMolBlock(mol, confId=confId)\n    viewer = py3Dmol.view(width=size[0], height=size[1])\n    viewer.addModel(mblock, 'sdf')\n    viewer.setStyle({style:{}})\n    if surface:\n        viewer.addSurface(py3Dmol.SAS, {'opacity': opacity})\n    viewer.zoomTo()\n    return viewer\n\n\nref.GetProp('_Name')\n\n'boo'\n\n\n\nfor conf in ref.GetConformers():\n    print(conf.GetId())\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\nfrom ipywidgets import interact,fixed,IntSlider\nimport ipywidgets\n\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\n\ndef conf_viewer(mol, confId=-1):\n    return MolTo3DView(mol, confId).show()\n\ninteract(conf_viewer, mol=fixed(ref), confId=ipywidgets.IntSlider(min=0,max=ref.GetNumConformers()-1, step=1))\n\n\n        You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: \n        jupyter labextension install jupyterlab_3dmol\n        \n\n\n\n\n\n\n&lt;function __main__.conf_viewer(mol, confId=-1)&gt;\n\n\n\nsdf_mol_info = sdf_format.loc[ sdf_format['parent_id'] == ref.GetProp('_Name')]\n\n\nmols2grid.display(sdf_mol_info, \n                  # set what's displayed on the grid\n                  subset=[\"parent_id\", \"img\", \"tauto_id\",\"E_rel_tauto(kcal/mol)\"],\n                  # set what's displayed on the hover tooltip\n                  tooltip=[\"parent_id\", \"E_tot\", \"fmax\", \"E_rel_tauto(kcal/mol)\"],\n                  transform={\"E_rel_tauto(kcal/mol)\": lambda x: f'del_E_tauto: {round(x, 3)} kcal/mol'},\n                  size=(250,250))"
  },
  {
    "objectID": "posts/2021-03-18-autoencoder.html",
    "href": "posts/2021-03-18-autoencoder.html",
    "title": "Anamoly detection using autoencoders",
    "section": "",
    "text": "An autoencoder is a type of unsupervised learning method. More than that, it is a type of ‘generative’ model which once trained can potentially help generate synthetic data. In essense, it is a non-linear dimensionality reduction technique to learn the internal low-dimensional structure of the data.\nAn autoencoder model contains two components:\n1. An encoder: that takes an image as input, and outputs a low-dimensional embedding (representation) of the image.\n2. A decoder: that takes the low-dimensional embedding, and reconstructs the image.\nIn esence autoencoder can be viewed as a dimensionality reduction tool for embedding the data in low-dimensional latent space which is non-linear.\nRelationship to PCA\nAutoencoder can be seen as a generalisation of principal component analysis to nonlinear manifolds. If we remove the nonlinearity (brought about by the activation functions) then the result of autoencoder will be in (some sense) equivalent to PCA. Now, however, the component vectors encoded by weights will not be orthogonal, like with PCA.\nAnamoly Detection\nBesides being used a generative model, it can be used as a anamoly detection method by considering the loss value between the decoded object and the encoded entity. By setting a threshold on the acceptable loss values we can train the model to flag any instances wherein the model’s loss value exceed that limit and potentially is an anamolous digit.\nSuch an anamoly detection could be used in processes where images, sound, or signal is scanned and flagged for being out of spec. Google I/O in 2021 had a nice workshop on introducing Autoencoder and their utility in anomaly detection for detecting abnormal heart rhythm. Video\nA simple autoencoder based on a CNN architecture will be built to encode and embed MNIST hand-written digit data.\nModel Development\nFor the CNN stride and filter size is chose to ensure final vector in the bottleneck is commensurate with a single vector. To understand more on the how the stride and filter is chosen, or the effect of those parameters on the convolution, there’s a helpful visualization and documentation here: https://github.com/vdumoulin/conv_arithmetic\nimport os \nimport copy \nimport numpy as np \n\nimport torch \nimport torch.nn as nn \nimport tqdm.notebook as tqdm\nimport torch.nn.functional as F\ntorch.manual_seed(42);\nnp.random.seed(42);\nimport matplotlib.pyplot as plt \nfrom matplotlib.pyplot import cm\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\nplot_params = {\n'image.cmap':'binary',\n'image.interpolation':'nearest'\n}\n \nplt.rcParams.update(plot_params)\nfrom torchvision import datasets, transforms\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\n\ndevice(type='cuda')\ntransform_data = transforms.ToTensor()\n\ntrain_dataset = datasets.MNIST(root='input/',\n                           train=True,\n                           transform=transform_data,\n                           download=True)\nval_dataset = datasets.MNIST(root='input/',\n                            train=False,\n                            transform=transform_data,\n                            download=True)\ninput_tensor, label = train_dataset[0]\nprint('MNIST dataset with {} train data and {} validation data'.format(len(train_dataset), len(val_dataset)))\nprint('Type of data in dataset: {} AND {}'.format(type(input_tensor), type(label)))\nprint('Input tensor image dimensions: {}'.format(input_tensor.shape))\n\nMNIST dataset with 60000 train data and 10000 validation data\nType of data in dataset: &lt;class 'torch.Tensor'&gt; AND &lt;class 'int'&gt;\nInput tensor image dimensions: torch.Size([1, 28, 28])\nclass AutoEncoder(nn.Module):\n    def __init__(self, latent_dimensions=10):\n        super(AutoEncoder, self).__init__()\n        \n        self.encoder_module = nn.Sequential(\n            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, 7, stride=1, padding=0)\n            )\n        \n        self.decoder_module = nn.Sequential(\n            nn.ConvTranspose2d(64, 32, 7, stride=1, padding=0),\n            nn.ReLU(),\n            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n            nn.Sigmoid()\n        )\n        \n        self.NN_encode_to_latent = nn.Linear(64,latent_dimensions)\n        self.NN_latent_to_decode = nn.Linear(latent_dimensions,64)\n        \n    def encoder(self, x):\n        #Encode the points \n        encode_x = self.encoder_module(x)\n        batch_size, _, _, _ = encode_x.shape\n        \n        #Bottle neck layer - dont need this but useful when converting it to variational type\n        encode_x = encode_x.view(batch_size, -1)\n        \n        x_encode_to_latent = self.NN_encode_to_latent(encode_x)\n        \n        return(x_encode_to_latent, batch_size)\n    \n    def decoder(self, x_encode_to_latent, batch_size):\n        x_latent_to_decode = self.NN_latent_to_decode(x_encode_to_latent)\n        \n        # Decode the points \n        latent_x_reshape = x_latent_to_decode.view(batch_size, -1, 1, 1)\n        reconst = self.decoder_module(latent_x_reshape)\n        \n        return(reconst)\n        \n    def forward(self, x):\n        latent_vector, batch_size = self.encoder(x)\n        reconst = self.decoder(latent_vector, batch_size)\n        return(reconst, latent_vector)\ndef train(model, data_loader, epoch, criterion, optimizer): \n    counter = 0\n    epoch_loss_list = []\n    model.train()\n    \n    for i, data_batch in enumerate(data_loader):\n\n        data, label = data_batch \n        data = data.to(device)\n\n        reconstruction, latent_x = model(data)\n\n        loss = criterion(reconstruction, data)\n        loss.backward()\n        \n        optimizer.step()\n        optimizer.zero_grad()\n        \n        counter = counter + 1 \n        epoch_loss_list.append(loss.item())\n        \n        if i == 0: #Only append first batch \n            outputs = (epoch, label, data.cpu().detach(), latent_x, reconstruction.cpu().detach())\n    \n    mean_train_loss = sum(epoch_loss_list) / counter \n    \n    if epoch % 5 == 0:  \n        print('Training: Epoch: {0}, Loss: {1:0.3f}'.format(epoch+1, mean_train_loss))\n    \n\n    return outputs, epoch_loss_list, mean_train_loss \n\ndef validation(model, data_loader, epoch, criterion):    \n    counter = 0\n    epoch_loss_list = []\n    model.eval()\n    for i, data_batch in enumerate(data_loader):\n        with torch.no_grad():\n            data, label = data_batch \n            data = data.to(device)\n\n            reconstruction, latent_x = model(data)\n\n            loss = criterion(reconstruction, data)\n            \n            counter = counter + 1 \n            epoch_loss_list.append(loss.item())\n            \n        if i == 0: #Only append first batch \n            outputs = (epoch, label, data.cpu().detach(), latent_x, reconstruction.cpu().detach())\n    \n    mean_val_loss = sum(epoch_loss_list) / counter\n    \n    if epoch % 5 == 0:        \n        print('** Validation: Epoch: {0}, Loss: {1:0.3f}'.format(epoch+1, mean_val_loss))\n        print('-'*10)\n\n\n    return outputs, epoch_loss_list, mean_val_loss\nmodel = AutoEncoder(latent_dimensions=20)\nmodel = model.to(device)    \nmodel\n\nAutoEncoder(\n  (encoder_module): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    (3): ReLU()\n    (4): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1))\n  )\n  (decoder_module): Sequential(\n    (0): ConvTranspose2d(64, 32, kernel_size=(7, 7), stride=(1, 1))\n    (1): ReLU()\n    (2): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (3): ReLU()\n    (4): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n    (5): Sigmoid()\n  )\n  (NN_encode_to_latent): Linear(in_features=64, out_features=20, bias=True)\n  (NN_latent_to_decode): Linear(in_features=20, out_features=64, bias=True)\n)\nnum_epochs=20\nbatch_size=64\nlearning_rate=1e-3\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), \n                            lr = learning_rate,\n                            weight_decay=1e-5)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, \n                                          batch_size = batch_size,\n                                          shuffle = True)\n\nval_loader = torch.utils.data.DataLoader(val_dataset, \n                                          batch_size = batch_size,\n                                          shuffle = True)\n%%time\ntrain_output_array, val_output_array = [], [] \ntrain_loss_array, val_loss_array = [], []\n\nfor epoch in tqdm.tqdm(range(num_epochs)):\n    train_out, train_loss_list, epoch_train_loss = train(model, train_loader, epoch, criterion, optimizer)\n    val_out, val_loss_list, epoch_val_loss = validation(model, val_loader, epoch, criterion)\n\n    train_loss_array.append(epoch_train_loss)\n    val_loss_array.append(epoch_val_loss)\n    \n    train_output_array.append(train_out)\n    val_output_array.append(val_out)\n    \n    # Append loss values for train and validation in the final epoch\n    # Another option is to taken loss values for the epoch when the validation loss is lowest \n    if epoch == num_epochs - 1:\n        final_train_loss = train_loss_list\n        final_val_loss = val_loss_list\n\n\n\n\nTraining: Epoch: 1, Loss: 0.047\n** Validation: Epoch: 1, Loss: 0.022\n----------\nTraining: Epoch: 6, Loss: 0.009\n** Validation: Epoch: 6, Loss: 0.008\n----------\nTraining: Epoch: 11, Loss: 0.008\n** Validation: Epoch: 11, Loss: 0.008\n----------\nTraining: Epoch: 16, Loss: 0.008\n** Validation: Epoch: 16, Loss: 0.008\n----------\nCPU times: user 4min 14s, sys: 3.15 s, total: 4min 17s\nWall time: 4min 17s\n# Plot loss curve \nplt.plot(train_loss_array, label='Train loss')\nplt.plot(val_loss_array, label='Validation loss')\nplt.xlabel('Epoch')\nplt.ylabel('MSE Loss')\nplt.legend(loc='best');\nlen(train_output_array)\n\n20\nfor k in range(0, num_epochs, 4):\n\n    digit_out = val_output_array[k][2].detach().numpy()\n    label_out = val_output_array[k][1].detach().numpy()\n    reconst_out = val_output_array[k][4].detach().numpy()\n    \n    fig, ax = plt.subplots(2,9, figsize=(9,2))\n    ax = ax.flatten()\n    \n    print('Epoch: {}'.format(k))\n    for i, item in enumerate(digit_out):\n        if i &lt; 9:\n            ax[i].imshow(item[0], cmap=cm.binary, interpolation='nearest')\n            ax[i].set_title('Digit:{}'.format(label_out[i]))\n            ax[i].set_xticks([])\n            ax[i].set_yticks([])\n            \n    for i, item in enumerate(reconst_out):\n        if i &lt; 9:\n            ax[i+9].imshow(item[0], cmap=cm.binary, interpolation='nearest')\n            ax[i+9].set_xticks([])\n            ax[i+9].set_yticks([])\n    plt.show()\n\nEpoch: 0\n\n\n\n\n\n\n\n\n\nEpoch: 4\n\n\n\n\n\n\n\n\n\nEpoch: 8\n\n\n\n\n\n\n\n\n\nEpoch: 12\n\n\n\n\n\n\n\n\n\nEpoch: 16\nWith subsequent epochs the reconstruction of the images becomes better.\nimg_temp = val_output_array[num_epochs-1][2].detach().numpy()\n\nprint(img_temp.shape)\n\nmodel = model.cpu()\n\necode_img, vector_img = model(torch.tensor(img_temp))\n\n\nprint(criterion(ecode_img, torch.tensor(img_temp)).item())\n\nprint(ecode_img.shape, vector_img.shape)\n\nvector_img = vector_img.detach().numpy()\nprint(vector_img.shape)\n\necode_img = ecode_img.detach().numpy()\nprint(ecode_img.shape)\n\n(64, 1, 28, 28)\n0.007447564974427223\ntorch.Size([64, 1, 28, 28]) torch.Size([64, 20])\n(64, 20)\n(64, 1, 28, 28)\nVisualizing the reconstruction of a random validation data digit\nfig, ax = plt.subplots(1,2,figsize=(5,5))\nax[0].imshow(img_temp[0][0], cmap=cm.binary, interpolation='nearest')\nax[0].set_title('Digit Input')\nax[1].imshow(ecode_img[0][0], cmap=cm.binary, interpolation='nearest')\nax[1].set_title('Reconstructed Input')\nax[0].set_xticks([])\nax[0].set_yticks([])\n\nax[1].set_xticks([])\nax[1].set_yticks([]);\n# Final loss values for each batch of train and validation set \nprint(len(final_train_loss), len(final_val_loss))\n\n938 157\nVisualize the distribution of epoch losses for train and validation set from the last epoch. The statistics from this distribution will be used to set the threshold for the anamoly detection in the later section\nfig, ax = plt.subplots(2,1, figsize=(10,5), sharex=True)\nax[0].hist(final_train_loss, bins=100)\nax[0].axvline(x = np.median(final_train_loss), color='red', linestyle='--', linewidth=2.0, label='Median')\nax[0].axvline(x = np.mean(final_train_loss), color='cyan', linestyle='--', linewidth=2.0, label='Mean')\n\nax[1].hist(final_val_loss, bins=100)\nax[1].axvline(x = np.median(final_val_loss), color='red', linestyle='--', linewidth=2.0,label='Median')\nax[1].axvline(x = np.mean(final_val_loss), color='cyan', linestyle='--', linewidth=2.0,label='Mean')\n\nplt.legend();\nprint('Mean Train Loss: {:0.6f}'.format(np.mean(final_train_loss)))\nprint('Mean Val Loss: {:0.6f}'.format(np.mean(final_val_loss)))\n\nMean Train Loss: 0.007515\nMean Val Loss: 0.007516\nthreshold_loss = np.mean(final_val_loss) + np.std(final_val_loss)\nprint('Threshold loss is set at: {:0.6f}'.format(threshold_loss))\n\nThreshold loss is set at: 0.008046"
  },
  {
    "objectID": "posts/2021-03-18-autoencoder.html#visualize-latent-space",
    "href": "posts/2021-03-18-autoencoder.html#visualize-latent-space",
    "title": "Anamoly detection using autoencoders",
    "section": "Visualize latent space",
    "text": "Visualize latent space\n\nlabel_collection = np.array([])\nlatent_space_collection = np.zeros((0,20))\nfor i, data_batch in enumerate(val_loader):\n    with torch.no_grad():\n        data, label = data_batch \n        reconstruction, latent_x = model(data)\n        label_collection = np.concatenate((label.numpy(), label_collection))\n        latent_space_collection = np.vstack((latent_x.numpy(), latent_space_collection))\n\n\nprint(label_collection.shape, latent_space_collection.shape)\n\n(10000,) (10000, 20)\n\n\n\ntSNE plots\n\nimport openTSNE as openTSNE\nprint('openTSNE', openTSNE.__version__)\n\nopenTSNE 0.6.0\n\n\n\n%%time\n# BH and PCA_init by default\nZ1 = openTSNE.TSNE(n_jobs=-1, negative_gradient_method='bh').fit(latent_space_collection)\n\nCPU times: user 2min 46s, sys: 2min 11s, total: 4min 57s\nWall time: 39 s\n\n\n\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\ncmap = ListedColormap(sns.husl_palette(len(np.unique(label_collection))))\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nim = ax.scatter(Z1[:,0], Z1[:,1], s=10, c=label_collection, cmap=cmap, edgecolor='none')\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlabel('tSNE component 1')\nax.set_ylabel('tSNE component 2')\nax.set_title('t-SNE on Latent Space (MNIST data)')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.25, 0.01, 0.5], label='digit')\ncbar = fig.colorbar(im, cax=cbar_ax, label='Digit')\n\n/depot/jgreeley/apps/envs/gpu_env1/lib/python3.7/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n  warnings.warn(msg)\n\n\n\n\n\n\n\n\n\nEmbedding 20 dimensions in 2 dimensional tSNE space, the clusters for each digit become quite clear. It is interesting to see that cluster for 1 and 7 are quite close to another, similarly cluster for 5 and 3 which have been traditionally challenging to distinguish in the classifers"
  },
  {
    "objectID": "posts/2021-03-18-autoencoder.html#linear-interpolation-in-the-latent-space",
    "href": "posts/2021-03-18-autoencoder.html#linear-interpolation-in-the-latent-space",
    "title": "Anamoly detection using autoencoders",
    "section": "Linear interpolation in the latent space",
    "text": "Linear interpolation in the latent space\n\nprint(latent_space_collection.shape)\n\n#Select random points for start and ending \nstart_point_index = 4121\nend_point_index = 9832\n\nstart_point_latent_vectors = latent_space_collection[start_point_index]\nend_point_latent_vectors = latent_space_collection[end_point_index]\n\n(10000, 20)\n\n\n\nnum_steps = 10\ntrajectory_points = np.zeros((0,20))\nfor i in range(num_steps):\n    z = start_point_latent_vectors * i/num_steps + end_point_latent_vectors * (num_steps - i) / num_steps \n    trajectory_points = np.vstack((z, trajectory_points))\n    \nprint(trajectory_points.shape)\n\n(10, 20)\n\n\n\ntrajectory_latent_tensor = torch.tensor(trajectory_points)\n\n\nreconstruction_images = model.decoder(trajectory_latent_tensor.float(), trajectory_latent_tensor.shape[0])\nreconstruction_images.shape\n\ntorch.Size([10, 1, 28, 28])\n\n\n\nreconstruction_images = reconstruction_images.detach()\n\n\nfig, ax = plt.subplots(1,num_steps, figsize=(num_steps+10,4))\nax = ax.flatten()\n\nfor i in range(0, reconstruction_images.shape[0]):\n    ax[i].imshow(reconstruction_images[i][0], cmap=cm.binary, interpolation='nearest')\n    ax[i].set_title('Step: {}'.format(i+1))\n    ax[i].set_xticks([])\n    ax[i].set_yticks([]);\n\n\n\n\n\n\n\n\nVisualizing the image generated from each embedding iterated in a linear fashion from start to finish shows the transition between end points"
  },
  {
    "objectID": "posts/2021-03-18-autoencoder.html#denoising-images",
    "href": "posts/2021-03-18-autoencoder.html#denoising-images",
    "title": "Anamoly detection using autoencoders",
    "section": "Denoising images",
    "text": "Denoising images\nAn autoencoder trained on cleaned image can be used to clear out blurry inputs from outside training set\n\n# Add artificial noise to a random image \nrand_idx = 420\ndigit_image, label = val_dataset[rand_idx]\ndigit_image = digit_image[0]\n\nplt.imshow(digit_image)\nplt.title('Image of {}'.format(label))\nplt.axis('off');\n\n\n\n\n\n\n\n\nAdd gaussian noise to the image. Code taken from Github\n\nrandom_noise = np.random.randn(digit_image.shape[0], digit_image.shape[1])\ndigit_image_noise = np.clip( digit_image + random_noise * 0.2, 0, 1)\nplt.imshow(digit_image_noise)\nplt.title('Image of {}'.format(label))\nplt.axis('off');\n\n\n\n\n\n\n\n\n\ndigit_input_tensor = torch.tensor(digit_image_noise[np.newaxis, np.newaxis, ...]).float();\n\n/depot/jgreeley/apps/envs/gpu_env1/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\ndigit_input_tensor.shape\n\ntorch.Size([1, 1, 28, 28])\n\n\n\npredicted_image, _ = model(digit_input_tensor)\npredicted_image = predicted_image.detach().numpy()\n\n\nplt.imshow(predicted_image[0][0])\nplt.title('Image of {}'.format(label))\nplt.axis('off');\n\n\n\n\n\n\n\n\nThe results are much more useful in the case of variational autoencoder which is more robust to noise in the input data since the latent is less sparse due to the variational part"
  },
  {
    "objectID": "posts/2021-03-18-autoencoder.html#anomaly-detection",
    "href": "posts/2021-03-18-autoencoder.html#anomaly-detection",
    "title": "Anamoly detection using autoencoders",
    "section": "Anomaly Detection",
    "text": "Anomaly Detection\n\ndef reconstruction_loss(input_image, _model=model, _criterion=criterion, plot=True):\n    model = _model.cpu()\n    input_image_tensor = torch.tensor(input_image)\n    \n    encoded_image, _ = model(input_image_tensor)\n    \n    loss_value = _criterion(encoded_image, input_image_tensor).item()\n    \n    encoded_image = encoded_image.detach().numpy()\n    \n    if plot == True:\n        fig, ax = plt.subplots(1,3,figsize=(10,5))\n        ax[0].imshow(input_image[0][0], cmap=cm.binary, interpolation='nearest')\n        ax[0].set_title('Input Image')\n        \n        ax[1].imshow(encoded_image[0][0], cmap=cm.binary, interpolation='nearest')\n        ax[1].set_title('Reconstructed Input')\n        \n        ax[2].imshow(input_image[0][0] - encoded_image[0][0], cmap=cm.binary, interpolation='nearest')\n        ax[2].set_title('Image Difference')\n        \n        ax[0].set_xticks([])\n        ax[0].set_yticks([])\n        ax[1].set_xticks([])\n        ax[1].set_yticks([])\n        ax[2].set_xticks([])\n        ax[2].set_yticks([])\n        \n    return(loss_value)\n\n\nrandom_entry_from_val_set = val_output_array[num_epochs-4][2].detach().numpy()[0]\nprint(random_entry_from_val_set.shape)\n\n(1, 28, 28)\n\n\n\ninput_image = random_entry_from_val_set[np.newaxis, ...]\nprint(input_image.shape)\n\n(1, 1, 28, 28)\n\n\n\nloss_value = reconstruction_loss(input_image)\ncompare_value = ('Higher' if loss_value &gt; threshold_loss else 'lower')\nanamoly_tag = ('anomaly' if compare_value == 'Higher' else 'not an Anomaly')\nprint('Loss value is {0:6f} which is {1} than set threshold, so this image is {2}'.format(loss_value, compare_value, anamoly_tag))\n\nLoss value is 0.001904 which is lower than set threshold, so this image is not an Anomaly\n\n\n\n\n\n\n\n\n\n\nExample\n\nplt.imshow(input_image[0][0])\nplt.axis('off');\n\n\n\n\n\n\n\n\n\n# Rotate by 90: \ntemp_image_rotate = np.rot90(input_image, k=1, axes=(2,3)).copy() # To get rid of negative stride error \n\n\nplt.imshow(temp_image_rotate[0][0])\nplt.axis('off');\n\n\n\n\n\n\n\n\n\nloss_value = reconstruction_loss(temp_image_rotate)\ncompare_value = ('Higher' if loss_value &gt; threshold_loss else 'lower')\nanamoly_tag = ('anomaly' if compare_value == 'Higher' else 'not an Anomaly')\nprint('Loss value is {0:6f} which is {1} than set threshold, so this image is {2}'.format(loss_value, compare_value, anamoly_tag))\n\nLoss value is 0.028646 which is Higher than set threshold, so this image is anomaly"
  },
  {
    "objectID": "posts/2019-09-07-pca_tutorial.html",
    "href": "posts/2019-09-07-pca_tutorial.html",
    "title": "Principal component analysis",
    "section": "",
    "text": "Principal component analysis is one of the oldest tools to be implemented for analyzing feature sets in the data. It is fundamentally a dimensionality reduction technique targeted to reduce noise, feature reduction/extraction and engineering. It can also allow for providing ‘new’ features where are not necessarily correlated ensuring indenpedent treatment on the model."
  },
  {
    "objectID": "posts/2019-09-07-pca_tutorial.html#general-idea",
    "href": "posts/2019-09-07-pca_tutorial.html#general-idea",
    "title": "Principal component analysis",
    "section": "General idea:",
    "text": "General idea:\nPCA introduces a new set of variables (called principal components, PCs) by linear combination of the original variables in the data, standardized to zero mean and unit variance (see Figure 12.8 for a toy example in two dimensions). The PCs are chosen such that they are uncorrelated, and they are ordered such that the first component captures the largest possible amount of variation in the data, and subsequent components capture increasingly less. Usually, key features in the data can be seen from only the first two or three PCs.\nExample: If we are trying to understand the effect of weight, age, and height in humans, the weight of the subject is an correlated variable to other two. Height is, in some way, related to weight and that is in a way related to age of the person. Hence understanding effect of one variable on the output without the effect on another is difficult if not impossible. Here, we can use PCA to project the age and weight in a new 2-D space where now the height can be related to THESE two variables independently. Now the drawback is that we do not necessarily know what do these two variables means. For understanding the inherent logic of the variables there are techniques like vari-max rotation used to recapture the projection that MIGHT be used to get the new variables.\nWhen should you use PCA?\n\nDo you want to reduce the number of variables, but aren’t able to identify variables to completely remove from consideration?\nDo you want to ensure your variables are independent of one another?\nAre you comfortable making your independent variables less interpretable?"
  },
  {
    "objectID": "posts/2019-09-07-pca_tutorial.html#useful-resources",
    "href": "posts/2019-09-07-pca_tutorial.html#useful-resources",
    "title": "Principal component analysis",
    "section": "Useful Resources:",
    "text": "Useful Resources:\n\nJake VanderPlas’s Python Data Science Handbook Chapter\nTutorial on Principal Component Analysis by Jonathan Shlens (Google Research)\n\nCurrently, PCA, when categorizing it from ML-terminology standpoint, is considered as a dimensionality reduction and a fast-flexible unsupervised learning method. Let’s look at simplified example:\n\nTwo dimensional data-set\n\n\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns; sns.set()\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\nrng = np.random.RandomState(42)\nx1=rng.randn(2,200) #Normally distributed 200 entries with 2 rows\nfactor=rng.rand(2,2) #factor to multiply the entries \n\n\n#Defining the vectors as column vectors \nX = np.dot(factor, x1).T\nplt.scatter(X[:,0],X[:,1])\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.axis('equal');\n\n\n\n\n\n\n\n\nIn principal component analysis, this relationship is quantified by finding a list of the principal axes in the data, and using those axes to describe the dataset. Using Scikit-Learn’s PCA estimator, we can compute this as follows:\n\nfrom sklearn.decomposition import PCA \npca=PCA(n_components=2, random_state=42)\npca.fit(X)\n\nPCA(n_components=2, random_state=42)\n\n\n\nprint(pca.components_)\n\n[[ 0.41224135  0.91107468]\n [ 0.91107468 -0.41224135]]\n\n\n\nprint(pca.explained_variance_)\n\n[0.86789943 0.11361735]\n\n\nPCA analysis learns some quantities in the data. To visualize the ‘Principal components’ we can look at the Components which are the directions of the vector and Explained Variance is the square-length magnitude of the vector.\n\ndef draw_vector(v0, v1, ax=None):\n    ax = ax or plt.gca()\n    arrowprops=dict(arrowstyle='-&gt;',\n                    linewidth=2.5,\n                    color='k',\n                    shrinkA=0, shrinkB=0)\n    ax.annotate('',v1,v0,arrowprops=arrowprops)\n\nplt.scatter(X[:,0], X[:,1], alpha=0.6)\nfor length, vector in zip(pca.explained_variance_, pca.components_):\n    v = vector * 4. * np.sqrt(length) #vector enhanced by a factor of 5 and the sqrt(lenght)\n    print(v)\n    draw_vector(pca.mean_, pca.mean_+v) #Pre PCA dataset mean\n\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.axis('equal');\n\n[1.53619465 3.3950695 ]\n[ 1.22839009 -0.55581963]\n\n\n\n\n\n\n\n\n\nThe vectors above represent the principal axes of the data. Length of the vector is how imporatant are they. That is given by how much variance is explained by that axes. The projection of each data point onto the principal axes are the “principal components” of the data. If we plot the original data and the data being transformed such that the principal components are now the unit axes (through translation, rotation, and scaling of the data) we will get something like this\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6))\n\n# plot data\nax[0].scatter(X[:, 0], X[:, 1], alpha=0.6)\n\nfor length, vector in zip(pca.explained_variance_, pca.components_):\n    v = vector * 3 * np.sqrt(length)\n    draw_vector(pca.mean_, pca.mean_ + v, ax=ax[0])\nax[0].axis('equal');\nax[0].set(xlabel='x', ylabel='y', title='input')\n\n# plot principal components\nX_pca = pca.transform(X)\nax[1].scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.6)\ndraw_vector([0, 0], [0, 3], ax=ax[1])\ndraw_vector([0, 0], [3, 0], ax=ax[1])\nax[1].axis('equal')\nax[1].set(xlabel='Component 1', ylabel='Component 2',\n          title='principal components',\n          xlim=(-5, 5), ylim=(-3, 3.1));"
  },
  {
    "objectID": "posts/2019-09-07-pca_tutorial.html#going-to-higher-dimensions",
    "href": "posts/2019-09-07-pca_tutorial.html#going-to-higher-dimensions",
    "title": "Principal component analysis",
    "section": "Going to higher dimensions",
    "text": "Going to higher dimensions\nThe usefulness of the dimensionality reduction may not be entirely apparent in only two dimensions, but becomes much more clear when looking at high-dimensional data. We can appreciate it more for classifying the feature sets used to predict the handwriten digits\n\nfrom sklearn.datasets import load_digits\ndigits = load_digits()\ndigits.data.shape\n\n(1797, 64)\n\n\nThe data consists of 8×8 pixel images, meaning that they are 64-dimensional. To gain some intuition into the relationships between these points, we can use PCA to project them to a more manageable number of dimensions, say two\n\npca = PCA(n_components=2)  # project from 64 to 2 dimensions\nprojected = pca.fit_transform(digits.data)\nprint(digits.data.shape)\nprint(projected.shape)\n\n(1797, 64)\n(1797, 2)\n\n\nWe can now plot the dataset on the transformed space along the two components\n\nplt.figure(figsize=(10,10))\nplt.scatter(projected[:, 0], projected[:, 1],\n            c=digits.target, edgecolor='none', alpha=0.5,\n            cmap=plt.cm.get_cmap('Spectral', 10))\nplt.xlabel('component 1')\nplt.ylabel('component 2')\nplt.colorbar();\n\n\n\n\n\n\n\n\nInitially the data set for each image was a 64 dimensional entry. We now project that 64 dimensional data on a two component principal axes. The PCA routine has found the optimal stretch and rotation in the 64 dimensional space that allows us to see the layout of the digits in two dimensions. This was done in unsupervised manner."
  },
  {
    "objectID": "posts/2019-09-07-pca_tutorial.html#important-featuresconsiderations",
    "href": "posts/2019-09-07-pca_tutorial.html#important-featuresconsiderations",
    "title": "Principal component analysis",
    "section": "Important features/considerations:",
    "text": "Important features/considerations:\n\nLinearity: The underlying idea of PCA is to find another basis for representing the data. This makes PCA is a change of basis problem.\nVariance: To identify which direction to project the data on, signal-to-noise ratio calculated by variance is assumed to model the interesting nature. Hence principal components with larger variance represent the interesting structure.\nOrthogonality: The principal components are orthonormal basis vectors. This allows PCA to provide an intuitive simplification\n\nCovariance matrix is a symmetric matrix that measures the degree of pair-wise linear relationship in the data. - The diagonal entries estimate the variance of the variable - while the off-diagonal entries estimate the covariance between a given pair of variables.\nIdeally, for the case to reduce dimensions and correlations the resulting covariance for the data from change of basis should have off-diagonal elements as 0 and only diagonal elements which are ordered magnitude-wise.\nIn practice computing PCA of dataset following steps: 1. Recast the data as zero mean dataset 2. Compute eigenvectors for the covariance matrix for the dataset – these are the principal components of the data 3. Those eigenvectors would diagonalize the covariance matrix of the original dataset 4. The diagonal entries of the new covariance matrix will give the variance along each principal component\nThe diagonalised matrix from the above transformation is the covariance matrix for the projected data-set. This is made of the eigenvalues of the covariance matrix of original data\n\\[\\begin{align*}\nC_{Y}&=\\frac{YY^{T}}{n} \\\\\n&=\\frac{(PX)(PX)^{T}}{n} \\\\\n&=\\frac{PXP^{T}X^{T}}{n} \\\\\n&=\\frac{P(XX)^{T}P^{T}}{n} \\\\\n&=PC_{X}P^{T} \\\\\n\\end{align*}\\]\nHere P is the eigenvector of Cov(X) matrix\nLet’s use the first example as a basis for explanation:\n\nrng = np.random.RandomState(42)\nx1=rng.randn(2,200) #Normally distributed 200 entries with 2 rows\nfactor=rng.rand(2,2) #factor to multiply the entries \n\nX = np.dot(factor, x1)\nplt.scatter(X[0,:],X[1,:])\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.axis('equal');\n\n\n\n\n\n\n\n\n\n# Standarize the data \nX_center = np.empty(shape=X.shape)\nX_center[0,:]=X[0,:]-np.mean(X[0,:])\nX_center[1,:]=X[1,:]-np.mean(X[1,:])\n\n\n#Estimate covariance of orginal data\ncov_X = np.dot(X,X.T)/(X_center.shape[1]-1)\nprint(cov_X)\n\n[[0.24184557 0.28376997]\n [0.28376997 0.74491787]]\n\n\n\n# Eigendecomposition of the covariance matrix\neigen_values, eigen_vectors = np.linalg.eig(cov_X) #eigen_values[i] is eigenvalue of eigen_vector[:,i]\nprint(eigen_vectors)\n\n[[-0.91195569 -0.4102887 ]\n [ 0.4102887  -0.91195569]]\n\n\n\nvalues_vectors = [(np.abs(eigen_values[i]), eigen_vectors[:,i]) for i in range(len(eigen_values))]\n\n\n#sort the vectors based on the values\nvalues_vectors = sorted(values_vectors, key=lambda x:x[0], reverse=True)\nprint(values_vectors)\n\n[(0.8725859273634107, array([-0.4102887 , -0.91195569])), (0.11417751236536822, array([-0.91195569,  0.4102887 ]))]\n\n\n\nfig, ax_new = plt.subplots(1, 2, figsize=(16, 6))\n\n# plot data\nax_new[0].scatter(X[0, :], X[1, :], alpha=0.6)\nax_new[0].axis('equal');\nax_new[0].set(xlabel='x', ylabel='y', title='input')\n\n# plot principal components\nX_transform = np.dot(eigen_vectors.T,X)\nax_new[1].scatter(X_transform[0, :], X_transform[1, :], alpha=0.6)\nax_new[1].axis('equal')\nax_new[1].set(xlabel='component 1', ylabel='component 2',\n          title='principal components',\n          xlim=(-5, 5), ylim=(-3, 3.1))\n\n[Text(0.5, 0, 'component 1'),\n Text(0, 0.5, 'component 2'),\n Text(0.5, 1.0, 'principal components'),\n (-5.0, 5.0),\n (-3.0, 3.1)]\n\n\n\n\n\n\n\n\n\n\npca=PCA(n_components=2, random_state=42)\npca.fit(X.T)\npca_results = [(np.abs(pca.explained_variance_[i]), pca.components_[:,i]) for i in range(len(pca.explained_variance_))]\npca_results = sorted(pca_results, key=lambda x:x[0], reverse=True)\nprint(pca_results)\n\n[(0.867899431633577, array([0.41224135, 0.91107468])), (0.11361735469514019, array([ 0.91107468, -0.41224135]))]\n\n\n\ncov_Y = np.dot(eigen_vectors.T,np.dot(cov_X,eigen_vectors))\n\n\nnp.around(cov_Y,4)\n\narray([[0.1142, 0.    ],\n       [0.    , 0.8726]])"
  },
  {
    "objectID": "posts/2019-10-11-vectorisation_and_tf_example.html",
    "href": "posts/2019-10-11-vectorisation_and_tf_example.html",
    "title": "Vectorisation in python using numpy",
    "section": "",
    "text": "import numpy as np \nimport time \n\na = np.random.randint(10E6,size=(50,1000))\nprint(np.shape(a))\n\nw = np.random.randint(100,size=(50,1))\nprint(np.shape(w))\n\n(50, 1000)\n(50, 1)\n#Vectorisation\nt_start = time.time()\nz = np.dot(w.T,a).T\nt_stop = time.time()\nprint('Time take: {} ms'.format(1000*(t_stop-t_start)))\n\n#Non vectorized version \nz_for = []\nt_start = time.time()\nfor j in range(np.shape(a)[1]):\n    _count = 0.0\n    for i in range(np.shape(a)[0]):\n        _count+=w[i,0]*a[i,j]\n    z_for.append(_count)\nt_stop = time.time()\nprint('Time take for for-loop: {} ms'.format(1000*(t_stop-t_start)))\n\n#Check the output \nprint('Check sum: {}'.format(np.sum(np.asarray(z_for).reshape(np.shape(z))-z)))\n\nTime take: 0.3979206085205078 ms\nTime take for for-loop: 33.74624252319336 ms\nCheck sum: 0.0\n#Valued function evaluation \n#If I want to have expoenential of different values in the array\na = np.random.randint(10,size=(10,2))\n#With for loops:\nimport math\nexp_a = np.zeros(np.shape(a))\nfor j in range(np.shape(a)[1]):\n    for i in range(np.shape(a)[0]):\n        exp_a[i,j] = math.exp(a[i,j])\n#without for loop \nexp_a_numpy = np.exp(a) #Vector already setup -- element-wise exponential\n\n#Other vectorized functions: \n# np.log(x)\n# np.abs(x)\n# np.maximum(x,0) -- computes element-wise maximum comparing to 0 \n# x**2 for numpy array \n# 1/x for numpy array\nexp_a_numpy - exp_a\n\narray([[0., 0.],\n       [0., 0.],\n       [0., 0.],\n       [0., 0.],\n       [0., 0.],\n       [0., 0.],\n       [0., 0.],\n       [0., 0.],\n       [0., 0.],\n       [0., 0.]])\n#Broadcasting \nfood_cal = np.array([[56.0,0.0,4.4,68.0],\n                     [1.2, 104, 52, 8.],\n                     [1.8, 135.,99., 0.9]])\n#Calculate % of calories from Carb, Protein, Fat for each food \ncarb = np.array([food_cal[0,i]/np.sum(food_cal[:,i])*100 for i in range(4)])\nprotein = np.array([food_cal[1,i]/np.sum(food_cal[:,i])*100 for i in range(4)])\nfat = np.array([food_cal[2,i]/np.sum(food_cal[:,i])*100 for i in range(4)])\n\ncal = np.array([carb,protein,fat])\nprint(cal)\n\n[[94.91525424  0.          2.83140283 88.42652796]\n [ 2.03389831 43.51464435 33.46203346 10.40312094]\n [ 3.05084746 56.48535565 63.70656371  1.17035111]]\n#Andrew Ng's \ncal = food_cal.sum(axis=0) \n#AXIS = 0 is sum vertically -- along column\n#AXIS = 1 is sum horizontally -- along row \n\nprint(cal)\n\n[ 59.  239.  155.4  76.9]\n#Example of broadcasting here: \n#Here the cal is BROADCASTING from 1,4 to 4,4 \npercentage = 100*food_cal/cal.reshape(1,4)\nprint(percentage)\n\n[[94.91525424  0.          2.83140283 88.42652796]\n [ 2.03389831 43.51464435 33.46203346 10.40312094]\n [ 3.05084746 56.48535565 63.70656371  1.17035111]]\n#More examples of broadcasting  \n#Example 1 \nA = np.linspace(1,5,5)\nprint(A.shape)\nB = A+10.\nprint(A, B, B.shape)\n# Here 10. was broadcasted into 5x1 vector \n\n(5,)\n[1. 2. 3. 4. 5.] [11. 12. 13. 14. 15.] (5,)\n#Example 2\nA = np.array([[1,2,3],\n              [4,5,6]])\nprint(A.shape)\nB = np.array([100,200,300])\nprint(B.shape)\nC = A + B \nprint(C.shape)\nprint(A,B)\nprint(C)\n# Here B was broadcasted from (3,) to 2x3!\n\n(2, 3)\n(3,)\n(2, 3)\n[[1 2 3]\n [4 5 6]] [100 200 300]\n[[101 202 303]\n [104 205 306]]"
  },
  {
    "objectID": "posts/2019-10-11-vectorisation_and_tf_example.html#general-principle",
    "href": "posts/2019-10-11-vectorisation_and_tf_example.html#general-principle",
    "title": "Vectorisation in python using numpy",
    "section": "General principle",
    "text": "General principle\n(m,n) matrix with (+, -, *, /) with (1,n) or (m,1) lead of copying it to (m,n) before conducting computing."
  },
  {
    "objectID": "posts/07_28-uspto_rxn.html",
    "href": "posts/07_28-uspto_rxn.html",
    "title": "Classifying reactions using machine-learning",
    "section": "",
    "text": "Using data-driven methods to classify reactions in different categories."
  },
  {
    "objectID": "posts/07_28-uspto_rxn.html#viewing-it-as-pandas-dataframe",
    "href": "posts/07_28-uspto_rxn.html#viewing-it-as-pandas-dataframe",
    "title": "Classifying reactions using machine-learning",
    "section": "Viewing it as Pandas dataframe",
    "text": "Viewing it as Pandas dataframe\n\ncolumn_names = ['SMILES', 'Patent No', 'Rxn Class']\ndf_rxn = pd.DataFrame(rxn_data_list, columns=column_names)\n\n\ndf_rxn\n\n\n\n\n\n\n\n\nSMILES\nPatent No\nRxn Class\n\n\n\n\n0\n[CH3:17][S:14](=[O:15])(=[O:16])[N:11]1[CH2:10...\nUS06887874\n6.1.5\n\n\n1\nO.O.[Na+].[CH3:1][c:2]1[cH:7][c:6]([N+:8](=O)[...\nUS07056926\n7.1.1\n\n\n2\n[CH3:1][O:2][c:3]1[cH:4][cH:5][c:6](-[c:9]2[cH...\nUS08492378\n1.8.5\n\n\n3\nCl.[CH3:43][CH2:42][S:44](=[O:45])(=[O:46])Cl....\nUS08592454\n2.2.3\n\n\n4\n[CH3:25][O:24][c:21]1[cH:22][cH:23][c:17]([O:1...\nUS06716851\n1.3.7\n\n\n...\n...\n...\n...\n\n\n49995\n[BH4-].[Na+].[CH3:25][O:24][c:19]1[cH:18][c:17...\nUS08324216\n7.3.1\n\n\n49996\n[BH4-].[Na+].[N:30]#[C:29][c:26]1[cH:25][cH:24...\nUS07595398\n7.3.1\n\n\n49997\n[N:15]#[C:14][CH2:13][c:1]1[cH:2][n:3][n:4]2[c...\nUS08273761\n7.3.1\n\n\n49998\nB.Cl.CO.[CH3:12][C:8]([OH:13])([CH2:9][C:10]#[...\nUS08609849\n7.3.1\n\n\n49999\n[CH3:2][CH2:1][O:3][C:4](=[O:5])[C:6]1([C:14]#...\nUS07030267\n7.3.1\n\n\n\n\n50000 rows × 3 columns\n\n\n\n\ndf_rxn.dtypes\n\nSMILES       object\nPatent No    object\nRxn Class    object\ndtype: object\n\n\n\ndf_rxn['Rxn Class'].value_counts()\n\n6.1.5     1000\n3.3.1     1000\n1.3.8     1000\n1.3.6     1000\n3.1.5     1000\n6.2.3     1000\n3.4.1     1000\n6.1.3     1000\n1.7.6     1000\n10.1.2    1000\n9.1.6     1000\n10.1.5    1000\n10.4.2    1000\n7.1.1     1000\n6.3.1     1000\n1.7.7     1000\n7.9.2     1000\n8.1.5     1000\n1.7.4     1000\n7.2.1     1000\n8.1.4     1000\n8.2.1     1000\n7.3.1     1000\n2.1.7     1000\n9.3.1     1000\n6.1.1     1000\n6.3.7     1000\n2.1.2     1000\n1.8.5     1000\n2.2.3     1000\n1.3.7     1000\n1.7.9     1000\n6.2.2     1000\n2.7.2     1000\n2.6.1     1000\n1.6.8     1000\n3.1.1     1000\n1.6.2     1000\n1.2.1     1000\n1.6.4     1000\n1.2.5     1000\n2.3.1     1000\n5.1.1     1000\n10.1.1    1000\n2.1.1     1000\n2.6.3     1000\n6.2.1     1000\n10.2.1    1000\n1.2.4     1000\n3.1.6     1000\nName: Rxn Class, dtype: int64\n\n\n\ndf_rxn.iloc[42069]\n\nSMILES       [H][H].[O:32]=[C:18]1[NH:17][C:16](=[O:33])[C@...\nPatent No                                           US08377927\nRxn Class                                                6.3.1\nName: 42069, dtype: object\n\n\n\ndf_rxn.SMILES[42069]\n\n'[H][H].[O:32]=[C:18]1[NH:17][C:16](=[O:33])[C@@H:15]([c:12]2[cH:11][cH:10][c:9]([O:8]Cc3ccccc3)[cH:14][cH:13]2)[C@@H:19]1[c:20]1[cH:21][n:22]2[c:31]3[c:30]1[cH:29][cH:28][cH:27][c:26]3[CH2:25][CH2:24][CH2:23]2&gt;&gt;[O:32]=[C:18]1[NH:17][C:16](=[O:33])[C@@H:15]([c:12]2[cH:13][cH:14][c:9]([OH:8])[cH:10][cH:11]2)[C@@H:19]1[c:20]1[cH:21][n:22]2[c:31]3[c:30]1[cH:29][cH:28][cH:27][c:26]3[CH2:25][CH2:24][CH2:23]2'\n\n\n\ndisplay_rxn(df_rxn.SMILES[42069])\n\n\n\n\n\n\n\n\nGenerate Chemical Entries object in Rdkit from the RXN SMILES\n\n%%time \n# Convert Smiles strings to reaction objects - this takes the most time and might be helpful if parallelized \nfrom rdkit.Chem import rdChemReactions # Main reaction analysis class \ndf_rxn['rxn_obj'] = df_rxn['SMILES'].apply(rdChemReactions.ReactionFromSmarts)\n\nCPU times: user 13.9 s, sys: 1.61 s, total: 15.5 s\nWall time: 15.5 s\n\n\n\ndf_rxn['rxn_obj'][42069]\n\n\n\n\n\n\n\n\n\ntemp_rxn = df_rxn['rxn_obj'][42069]\n\n\ntype(temp_rxn)\n\nrdkit.Chem.rdChemReactions.ChemicalReaction"
  },
  {
    "objectID": "posts/07_28-uspto_rxn.html#convert-the-rxn-objects-to-fps-and-save-pickle",
    "href": "posts/07_28-uspto_rxn.html#convert-the-rxn-objects-to-fps-and-save-pickle",
    "title": "Classifying reactions using machine-learning",
    "section": "Convert the rxn objects to FPs and save pickle",
    "text": "Convert the rxn objects to FPs and save pickle\n\ndf_rxn.sample(2)\n\n\n\n\n\n\n\n\nSMILES\nPatent No\nRxn Class\nrxn_obj\n\n\n\n\n37512\n[OH-].[Na+].Cl.[K+].[BH3-]C#N.[CH3:5][CH2:4][N...\nUS06964966\n1.2.5\n&lt;rdkit.Chem.rdChemReactions.ChemicalReaction o...\n\n\n934\n[OH-].[K+].[CH3:14][C@H:5]([CH2:6][c:7]1[cH:8]...\n05166218\n1.7.9\n&lt;rdkit.Chem.rdChemReactions.ChemicalReaction o...\n\n\n\n\n\n\n\n\n%%time\ndf_rxn['FP_Morgan_wo_agents'] = df_rxn['rxn_obj'].apply(diff_fpgen)\n\nCPU times: user 18.5 s, sys: 1.05 s, total: 19.5 s\nWall time: 19.6 s\n\n\nAdding in agents is giving me problem right now - debug it eventually\ndf_rxn[‘Agent_Morgan_FP2’] = df_rxn[‘rxn_obj’].apply(create_agent_feature_FP)"
  },
  {
    "objectID": "posts/07_28-uspto_rxn.html#make-training-and-test-set",
    "href": "posts/07_28-uspto_rxn.html#make-training-and-test-set",
    "title": "Classifying reactions using machine-learning",
    "section": "Make training and test set",
    "text": "Make training and test set\n\n%%time \nX_FPs = np.array( [hashedFPToNPfloat(x) for x in df_rxn['FP_Morgan_wo_agents']] )\n\nCPU times: user 3.38 s, sys: 591 ms, total: 3.97 s\nWall time: 4 s\n\n\n\nY_class = np.array( df_rxn['Rxn Class'] )\n\n\nrtypes = sorted(list(reaction_types))\n\n\nrtype_int = [int(''.join(entry.split('.'))) for entry in rtypes]\n\n\nlen(set(rtype_int))\n\n50\n\n\nNote on multi-class classification:\nhttps://scikit-learn.org/stable/modules/multiclass.html#multiclass-classification\nLabelBinarizer is not needed if you are using an estimator that already supports multiclass data.\nhttps://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets\n\nOption 1: OHE\nCreate one hot encoding – does it help to create OHE now? Not sure but doing it here as a first pass.\nY_class_labels = [ rtypes.index(i) for i in Y_class]\nY_class_OHE = np.zeros(shape=(len(Y_class_labels), len(rtypes)), dtype=int) for i, j in enumerate(Y_class_labels): Y_class_OHE[i][j] = 1\nrxn_dict = {i:0 for i in rtypes} for i, j in enumerate(Y_train): rxn_class_id = int(np.argmax(j)) rxn_dict[ rtypes[rxn_class_id] ] += 1\nrxn_dict\n\n\nOption 2: Leave as is\n\nleave_as_is = True \nif leave_as_is == True:\n    Y_target = Y_class\nelse: \n    Y_target = Y_class_OHE \n\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nstratSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n\n\nfor train_idx, test_idx in stratSplit.split(X_FPs, Y_target):\n    X_train = X_FPs[train_idx]\n    Y_train = Y_target[train_idx]\n    \n    X_test = X_FPs[test_idx]\n    Y_test = Y_target[test_idx]"
  },
  {
    "objectID": "posts/2022-11-20-cheminfo-clustering.html",
    "href": "posts/2022-11-20-cheminfo-clustering.html",
    "title": "Cheminformatics basics - Clustering molecules",
    "section": "",
    "text": "This tutorials is made using references from : * https://github.com/PatWalters/practical_cheminformatics_tutorials * https://doc.datamol.io/stable/tutorials/Clustering.html * https://greglandrum.github.io/rdkit-blog/similarity/tutorial/2020/11/18/sphere-exclusion-clustering.html\nimport os \nimport sys\nimport pandas as pd\nimport numpy as np\nimport operator\nfrom rdkit import Chem\nfrom rdkit import DataStructs\n\nfrom rdkit.Chem import Draw\nfrom rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\nIPythonConsole.ipython_useSVG=True  #SVG's tend to look nicer than the png counterparts\n\nfrom rdkit.Chem.Draw import IPythonConsole\nfrom rdkit.Chem import rdDepictor, rdMolDescriptors\nimport time\nrdDepictor.SetPreferCoordGen(True)\nimport rdkit\n%matplotlib inline\nprint(rdkit.__version__)\n\n2022.03.5\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# \"Infinite\" DPI vector output -- overkill \n%config InlineBackend.figure_format = 'svg'\n \n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 22,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)\n# clustering specific imports from Rdkit \nfrom rdkit.Chem import DataStructs \nfrom rdkit.ML.Cluster import Butina\nfrom rdkit.SimDivFilters.rdSimDivPickers import MaxMinPicker\nx = pd.read_csv('./data/small_molecule_data/tox21.csv')\nx.sample(5)\n\n\n\n\n\n\n\n\nsmiles\nNR-AR\nNR-AR-LBD\nNR-AhR\nNR-Aromatase\nNR-ER\nNR-ER-LBD\nNR-PPAR-gamma\nSR-ARE\nSR-ATAD5\nSR-HSE\nSR-MMP\nSR-p53\n\n\n\n\n439\nCC(Cl)(Cl)C(=O)O\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n5205\nNc1ccc([As](=O)(O)O)cc1\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n7260\nCCCCOC(=O)CC\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2195\nCOC(=O)c1ccccc1S(=O)(=O)NC(=O)Nc1nc(C)cc(C)n1\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n5563\nCc1ccc(C)c(OCCCC(C)(C)C(=O)O)c1\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\nmol_obj = [Chem.MolFromSmiles(smi, sanitize=True) for smi in list(x['smiles'])]\nlen(mol_obj)\n\n[16:41:47] WARNING: not removing hydrogen atom without neighbors\n\n\n7831\nGenerate fingerprints for the molecules - using Morgan FP2\nfrom rdkit.Chem import rdMolDescriptors\nfps = [rdMolDescriptors.GetMorganFingerprintAsBitVect(m, 3, nBits=2048) for m in mol_obj]\nCalculate distance matrix for the molecules\ndists  = [] \nn_fps = len(fps)\nfor i in range(1, n_fps):\n    sim = DataStructs.cDataStructs.BulkTanimotoSimilarity(fps[i], fps[:i])\n    dists.extend([ 1-x for x in sim ])\nplt.hist(dists);\nClustering the molecules based on the FPs and the distance matrix\ncutoff_distance = 0.35 # Any molecules closer than this are kept in one cluster so &lt;= cutoff_distance\nmol_clusters = Butina.ClusterData(dists, n_fps, distThresh=cutoff_distance, isDistData=True)\ncluster_id_list = [0]*n_fps\n\nfor idx, cluster in enumerate(mol_clusters, 1):\n    for member in cluster:\n        cluster_id_list[member] = idx\n# Add the cluster_id to the dataframe \nx['cluster'] = cluster_id_list\nx['cluster'].value_counts(sort=True, ascending=False)\n\n2       21\n1       21\n3       15\n5       13\n4       13\n        ..\n4643     1\n4644     1\n4645     1\n4646     1\n689      1\nName: cluster, Length: 6675, dtype: int64\nCalculate intra cluster similarity for the molecules\nx_42 = x.loc[ x['cluster'] ==  1]\nx_42.shape\n\n(21, 14)\nDraw.MolsToGridImage( [mol_obj[x] for x in x_42.index], subImgSize=(200, 200), molsPerRow=4)\n# intra-cluster similarity \nres = []\ncfps = [ fps[i] for i in x_42.index ]\nfor i in range(1, x_42.shape[0]):\n    sim = DataStructs.cDataStructs.BulkTanimotoSimilarity(cfps[i], cfps[:i])\n    res.extend( [1-x for x in sim] )\nplt.hist(res)\n\n(array([26.,  8., 24.,  0., 40., 14., 58., 16., 14., 10.]),\n array([0.        , 0.04901961, 0.09803922, 0.14705882, 0.19607843,\n        0.24509804, 0.29411765, 0.34313725, 0.39215686, 0.44117647,\n        0.49019608]),\n &lt;BarContainer object of 10 artists&gt;)"
  },
  {
    "objectID": "posts/2022-11-20-cheminfo-clustering.html#pick-the-most-diverse-molecules-from-the-cluster",
    "href": "posts/2022-11-20-cheminfo-clustering.html#pick-the-most-diverse-molecules-from-the-cluster",
    "title": "Cheminformatics basics - Clustering molecules",
    "section": "Pick the most diverse molecules from the cluster",
    "text": "Pick the most diverse molecules from the cluster\nImplementation of Sphere exclusion algorithm (also called Leader) from Roger Sayles.\n\nfrom rdkit.SimDivFilters import rdSimDivPickers\nlp = rdSimDivPickers.LeaderPicker()\n\n\nthreshold = 0.65 # &lt;- minimum distance between clusters \npicks = lp.LazyBitVectorPick(fps, len(fps), threshold)\nlen(picks)\n\n3291"
  },
  {
    "objectID": "posts/2020-12-21-central_limit_theorem.html",
    "href": "posts/2020-12-21-central_limit_theorem.html",
    "title": "Central limit theorem",
    "section": "",
    "text": "The distribution of the sum of independent samples consisting of n points drawn from an arbitrary distribution approach a normal distribution as n increases.\nIf the distribution of the values has a mean and standard deviation, the distribution of sum is approximately given by $ N(n, n^2)$\nSome points to keep in mind: - The values are to be drawn independently - The values have to come from same distribution - The underlying distribution should have finite mean and variance - The rate convergence to the normal distribution depends on the skewness of the parent distribution.\nWe start with some crazy distribution that has got nothing to do with a normal distribution. Sample points from that distribution with some arbitrary sample size, following which we plot the sample mean (or sample sum) on a frequency table – repeat this lot of times (tending to infinity) we end up getting a normal distribution of sample means!\nThe Central Limit Theorem explains the prevalence of normal distributions in the natural world. This limit is central to the ideas of hypothesis testing and helpful for estimating confidence intervals.\n\nKhan Academy video explaining this\n\nBelow a simple python experiment to show this in action.\n\nimport random as rand \nimport numpy as np \nfrom scipy import stats \n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nplot_params = {\n'font.size' : 10,\n'axes.titlesize' : 10,\n'axes.labelsize' : 10,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 10,\n'ytick.labelsize' : 10,\n}\n \nplt.rcParams.update(plot_params)\n\nsns.color_palette('colorblind')\n\n\n\n\n\nfrom numpy.random import default_rng\nrng = default_rng(42)\n\n\n\nFor this case let’s assume we have a dice which is unfair and does not ever land on 3 and 5, and lands more on 2 and 6. We can build this skewed probability into the dice using the weights.\n\ndice = np.arange(1,7) # Dice numbers possible \nprobabilities = [0.2, 0.3, 0.0, 0.2, 0.0, 0.3] #Weighted probabilites for the numbers \n\nDefine a function to draw samples from the dice and calculate the mean.\n\n# Draw sample size = n, take the mean and plot the frequencies \ndef sample_draw_mean(_trials=1000, _sample_size=1):\n    sample_mean_trials = []\n    # Sample a number from the distribution equal to trials\n    for i in range(_trials):\n        sample = rng.choice(dice, size=_sample_size, p=probabilities, replace=True)\n        sample_mean_trials.append(np.mean(sample))\n    return sample_mean_trials\n\nDrawing sample_size=1 from the distribution multiple times, i.e. equal to num_of_trials variable\n\nnum_of_trials = 1000\nsample_size = 1\nsns.histplot(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size), bins=len(dice), stat='density', kde=True);\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\n\n\n\n\n\n\n\n\nFor sample size of 1, the frequency of numbers rolled by the unfair dice relates to the probability we have set above. However we can start to define samples from that distribution wherein, instead of single number we draw (for example 4).\n\n\n\nnum_of_trials = 1000\nsample_size = 4\nsns.histplot(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size), bins=len(dice), stat='density', kde=True);\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\n\n\n\n\n\n\n\n\n\nnum_of_trials = 1000\nsample_size = 20\nsns.histplot(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size), bins=len(dice), stat='density', kde=True);\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\n\n\n\n\n\n\n\n\nAs we keep plotting the frequency distribution for the sample mean it starts to approach the normal distribution!\n\ndef normal_distribution(x, mean=0, sigma=1):\n    out = (1/np.sqrt(2 * np.pi * sigma ** 2)) * np.exp(-1/2 * ((x - mean)/sigma)**2)\n    return(out)\n\n\nnum_of_trials = 1000\nsample_size = 20\n\nfig, ax = plt.subplots(1,1, figsize=(5,5))\nsample_means = np.sort(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size))\n# Plot histogram density\nsns.histplot(sample_means, bins=len(dice), stat='density', kde=False, ax=ax)\n# Plot normal distribution\nax.plot(sample_means, normal_distribution(sample_means, np.mean(sample_means), np.std(sample_means)), color='black', linestyle='--', label='Normal Distribution')\n# Plot sample mean\nax.axvline(np.mean(sample_means), color='red', linestyle='--', linewidth=2.0, label='Sample Mean')\nax.set_xlabel('Dice number')\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Define an exponential distribution\nbeta = 5.0 \nnum_of_trials = 1000\nsample_size_list = [1, 10, 100, 500]\n\n\ndef generate_mean_samples(_beta, _iter, _sample_size):\n    samples_mean = []\n    for i in range(_iter):\n        sample_numbers = np.random.exponential(_beta, _sample_size)\n        samples_mean.append(np.mean(sample_numbers))\n    return(samples_mean)\n\n\nsample_plot_list = []\nfor n in sample_size_list:\n    sample_plot_list.append((n, generate_mean_samples(beta, num_of_trials, n)))\n\n\nfig, ax = plt.subplots(2,2, figsize=(10,10))\nax = ax.flatten()\nfor i, entry in enumerate(sample_plot_list): \n    sns.histplot(entry[1], stat='density', alpha=0.6, kde=False, ax=ax[i])\n    ax[i].set_title('Sample size: {}'.format(entry[0]))\n    sample_mean = np.mean(entry[1])\n    sample_std = np.std(entry[1])\n    normal_x = np.sort(entry[1])\n    # Plot normal distribution \n    ax[i].plot(normal_x, normal_distribution(normal_x,sample_mean,sample_std), linewidth=4.0, color='black', linestyle='--', label='Normal Distribution')\n    \n    # Sample mean\n    ax[i].axvline(sample_mean, color='red', linestyle='--', linewidth=4.0, label='Sample Mean')\n    ax[i].set_xlabel('Sample Mean')\nplt.suptitle(r'Visualize sample mean distribution for Exponential distribution $\\beta$={}, Sampled {} times'.format(beta, num_of_trials));\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n#plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\nEstimate coin toss probability\nA coin is flipped 30 times, you get 22 heads. Find if the coin is fair or not. That is, if the probability of getting heads-tails is 50%.\nThis can be solved by estimating the probability of getting heads / tails provided the above condition is met.\nSince we can model the coin toss process (a priori model) using Bernoulli’s distribution, we will estimate the probability of 22 heads considering a fair coin. This will be our Null Hypothesis.\nNull hypothesis: The null hypothesis is a model of the system based on the assumption that the apparent effect was actually due to chance.\nAssuming a bernoulli distribution:\n\\[X_{i} \\sim B(p)\\]\n\\[ P(N_H=22) = \\binom nx p^{22}(1-p)^{30-22} \\]\nBy central limit theorem: \\[ \\sum_{i=1}^{30}{X_{i}} \\sim N(30p, 30(1-p)) \\]\nFrom maximum likelihood estimate, more detailts on MLE can be found here.:\n\\[ \\hat{p} = 0.73 \\]\nEstimate 95% confidence interval: * Assuming a normal distribution: \\[ \\mu \\pm 1.96 \\sigma \\]\n\\[ 30\\hat{p} \\pm 1.96 \\sqrt{ 30 * (1-\\hat{p}) } \\]\n\\[ 22 \\pm 1.96 \\sqrt{( 30 * 0.26 )} = (16.4, 27.58) \\]\n\nrng = np.random.default_rng(42)\n\nDefine a numpy.random.choice function to simulate coin tosses. This can repeated to 30 times.\n\nsampling_30 = rng.choice([0,1], replace=True, size=30) # we can randint(2) here as well. \n\nnp.where is used to find the entries with heads, that way for each 30 coin tosses we can estimate how many heads are there. In this case we are treating heads as 1 and tails as 0\n\nlen(np.where(sampling_30 == 1)[0]) # or just sum the list since all we have is 1 / 0 \n\n15\n\n\n\nsum(sampling_30)\n\n15\n\n\nSetup the problem to perform multiple trails of 30 coin tosses, when done with the trials we will keep an account of how many of those trials had 22 heads.\n\nheads_condition = 22\nnum_heads_list = []\nconstraint_satisy = 0\nnum_trials = 5000\n\n\nfor _ in range(num_trials):\n    sampling_30 = rng.choice([0,1], replace=True, size=30, p=[0.50,0.50]) # A-priori fair coin toss model \n    number_of_heads = len(np.where(sampling_30 == 1)[0])\n    num_heads_list.append(number_of_heads)\n    \n    if number_of_heads == heads_condition:\n        constraint_satisy = constraint_satisy + 1  \n        \nnum_heads_list = np.array(num_heads_list)\n\n\nlen(num_heads_list)\n\n5000\n\n\nDefining a normal distribution function from scipy or we could also use the function defined previously.\n\nfrom scipy.stats import norm\nx = np.linspace(min(num_heads_list), max(num_heads_list))\nstd_norm_coin = norm(np.mean(num_heads_list), np.std(num_heads_list))\n\n\nquantiles_95_confidence = np.quantile(num_heads_list, [0.025, 0.975])\n\n\nfig, ax = plt.subplots(1,1, figsize=(8,5))\n\n# Plot histogram density\nsns.histplot(num_heads_list, stat='density', kde=False, ax=ax)\n\n# Plot normal distribution\nax.plot(x, std_norm_coin.pdf(x), color='black', linestyle='--', label='Normal Distribution')\n\n# Plot sample mean\nax.axvline(np.mean(num_heads_list), color='red', linestyle='--', linewidth=2.0, label='Sample Mean')\nax.axvline(heads_condition, color='blue', linestyle='-', linewidth=2.0, label='Experiment condition')\n\n\n# Plot confidence interval \nax.axvspan(quantiles_95_confidence[0], quantiles_95_confidence[1], alpha=0.15, color='yellow',label='95% confidence interval')\n\nax.set_xlabel('Number of heads in 30 coin tosses')\nplt.title('Visualize distribution of number of heads for 30 coin tosses sampled {} times'.format(num_trials), fontsize=15);\nplt.legend(loc=\"upper left\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\np-value estimate\n\np_value = constraint_satisy / num_trials\nprint(p_value)\n\n0.0042\n\n\nSince p-value is less than 0.05, this means the coin is not fair\nFor most problems, we only care about the order of magnitude: if the p-value is smaller that 1/100, the effect is likely to be real; if it is greater than 1/10, probably not. If you think there is a difference between a 4.8% (significant!) and 5.2% (not significant!), you are taking it too seriously."
  },
  {
    "objectID": "posts/2020-12-21-central_limit_theorem.html#what-is-central-limit-theorem",
    "href": "posts/2020-12-21-central_limit_theorem.html#what-is-central-limit-theorem",
    "title": "Central limit theorem",
    "section": "",
    "text": "The distribution of the sum of independent samples consisting of n points drawn from an arbitrary distribution approach a normal distribution as n increases.\nIf the distribution of the values has a mean and standard deviation, the distribution of sum is approximately given by $ N(n, n^2)$\nSome points to keep in mind: - The values are to be drawn independently - The values have to come from same distribution - The underlying distribution should have finite mean and variance - The rate convergence to the normal distribution depends on the skewness of the parent distribution.\nWe start with some crazy distribution that has got nothing to do with a normal distribution. Sample points from that distribution with some arbitrary sample size, following which we plot the sample mean (or sample sum) on a frequency table – repeat this lot of times (tending to infinity) we end up getting a normal distribution of sample means!\nThe Central Limit Theorem explains the prevalence of normal distributions in the natural world. This limit is central to the ideas of hypothesis testing and helpful for estimating confidence intervals.\n\nKhan Academy video explaining this\n\nBelow a simple python experiment to show this in action.\n\nimport random as rand \nimport numpy as np \nfrom scipy import stats \n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nplot_params = {\n'font.size' : 10,\n'axes.titlesize' : 10,\n'axes.labelsize' : 10,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 10,\n'ytick.labelsize' : 10,\n}\n \nplt.rcParams.update(plot_params)\n\nsns.color_palette('colorblind')\n\n\n\n\n\nfrom numpy.random import default_rng\nrng = default_rng(42)\n\n\n\nFor this case let’s assume we have a dice which is unfair and does not ever land on 3 and 5, and lands more on 2 and 6. We can build this skewed probability into the dice using the weights.\n\ndice = np.arange(1,7) # Dice numbers possible \nprobabilities = [0.2, 0.3, 0.0, 0.2, 0.0, 0.3] #Weighted probabilites for the numbers \n\nDefine a function to draw samples from the dice and calculate the mean.\n\n# Draw sample size = n, take the mean and plot the frequencies \ndef sample_draw_mean(_trials=1000, _sample_size=1):\n    sample_mean_trials = []\n    # Sample a number from the distribution equal to trials\n    for i in range(_trials):\n        sample = rng.choice(dice, size=_sample_size, p=probabilities, replace=True)\n        sample_mean_trials.append(np.mean(sample))\n    return sample_mean_trials\n\nDrawing sample_size=1 from the distribution multiple times, i.e. equal to num_of_trials variable\n\nnum_of_trials = 1000\nsample_size = 1\nsns.histplot(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size), bins=len(dice), stat='density', kde=True);\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\n\n\n\n\n\n\n\n\nFor sample size of 1, the frequency of numbers rolled by the unfair dice relates to the probability we have set above. However we can start to define samples from that distribution wherein, instead of single number we draw (for example 4).\n\n\n\nnum_of_trials = 1000\nsample_size = 4\nsns.histplot(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size), bins=len(dice), stat='density', kde=True);\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\n\n\n\n\n\n\n\n\n\nnum_of_trials = 1000\nsample_size = 20\nsns.histplot(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size), bins=len(dice), stat='density', kde=True);\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\n\n\n\n\n\n\n\n\nAs we keep plotting the frequency distribution for the sample mean it starts to approach the normal distribution!\n\ndef normal_distribution(x, mean=0, sigma=1):\n    out = (1/np.sqrt(2 * np.pi * sigma ** 2)) * np.exp(-1/2 * ((x - mean)/sigma)**2)\n    return(out)\n\n\nnum_of_trials = 1000\nsample_size = 20\n\nfig, ax = plt.subplots(1,1, figsize=(5,5))\nsample_means = np.sort(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size))\n# Plot histogram density\nsns.histplot(sample_means, bins=len(dice), stat='density', kde=False, ax=ax)\n# Plot normal distribution\nax.plot(sample_means, normal_distribution(sample_means, np.mean(sample_means), np.std(sample_means)), color='black', linestyle='--', label='Normal Distribution')\n# Plot sample mean\nax.axvline(np.mean(sample_means), color='red', linestyle='--', linewidth=2.0, label='Sample Mean')\nax.set_xlabel('Dice number')\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Define an exponential distribution\nbeta = 5.0 \nnum_of_trials = 1000\nsample_size_list = [1, 10, 100, 500]\n\n\ndef generate_mean_samples(_beta, _iter, _sample_size):\n    samples_mean = []\n    for i in range(_iter):\n        sample_numbers = np.random.exponential(_beta, _sample_size)\n        samples_mean.append(np.mean(sample_numbers))\n    return(samples_mean)\n\n\nsample_plot_list = []\nfor n in sample_size_list:\n    sample_plot_list.append((n, generate_mean_samples(beta, num_of_trials, n)))\n\n\nfig, ax = plt.subplots(2,2, figsize=(10,10))\nax = ax.flatten()\nfor i, entry in enumerate(sample_plot_list): \n    sns.histplot(entry[1], stat='density', alpha=0.6, kde=False, ax=ax[i])\n    ax[i].set_title('Sample size: {}'.format(entry[0]))\n    sample_mean = np.mean(entry[1])\n    sample_std = np.std(entry[1])\n    normal_x = np.sort(entry[1])\n    # Plot normal distribution \n    ax[i].plot(normal_x, normal_distribution(normal_x,sample_mean,sample_std), linewidth=4.0, color='black', linestyle='--', label='Normal Distribution')\n    \n    # Sample mean\n    ax[i].axvline(sample_mean, color='red', linestyle='--', linewidth=4.0, label='Sample Mean')\n    ax[i].set_xlabel('Sample Mean')\nplt.suptitle(r'Visualize sample mean distribution for Exponential distribution $\\beta$={}, Sampled {} times'.format(beta, num_of_trials));\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n#plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\nEstimate coin toss probability\nA coin is flipped 30 times, you get 22 heads. Find if the coin is fair or not. That is, if the probability of getting heads-tails is 50%.\nThis can be solved by estimating the probability of getting heads / tails provided the above condition is met.\nSince we can model the coin toss process (a priori model) using Bernoulli’s distribution, we will estimate the probability of 22 heads considering a fair coin. This will be our Null Hypothesis.\nNull hypothesis: The null hypothesis is a model of the system based on the assumption that the apparent effect was actually due to chance.\nAssuming a bernoulli distribution:\n\\[X_{i} \\sim B(p)\\]\n\\[ P(N_H=22) = \\binom nx p^{22}(1-p)^{30-22} \\]\nBy central limit theorem: \\[ \\sum_{i=1}^{30}{X_{i}} \\sim N(30p, 30(1-p)) \\]\nFrom maximum likelihood estimate, more detailts on MLE can be found here.:\n\\[ \\hat{p} = 0.73 \\]\nEstimate 95% confidence interval: * Assuming a normal distribution: \\[ \\mu \\pm 1.96 \\sigma \\]\n\\[ 30\\hat{p} \\pm 1.96 \\sqrt{ 30 * (1-\\hat{p}) } \\]\n\\[ 22 \\pm 1.96 \\sqrt{( 30 * 0.26 )} = (16.4, 27.58) \\]\n\nrng = np.random.default_rng(42)\n\nDefine a numpy.random.choice function to simulate coin tosses. This can repeated to 30 times.\n\nsampling_30 = rng.choice([0,1], replace=True, size=30) # we can randint(2) here as well. \n\nnp.where is used to find the entries with heads, that way for each 30 coin tosses we can estimate how many heads are there. In this case we are treating heads as 1 and tails as 0\n\nlen(np.where(sampling_30 == 1)[0]) # or just sum the list since all we have is 1 / 0 \n\n15\n\n\n\nsum(sampling_30)\n\n15\n\n\nSetup the problem to perform multiple trails of 30 coin tosses, when done with the trials we will keep an account of how many of those trials had 22 heads.\n\nheads_condition = 22\nnum_heads_list = []\nconstraint_satisy = 0\nnum_trials = 5000\n\n\nfor _ in range(num_trials):\n    sampling_30 = rng.choice([0,1], replace=True, size=30, p=[0.50,0.50]) # A-priori fair coin toss model \n    number_of_heads = len(np.where(sampling_30 == 1)[0])\n    num_heads_list.append(number_of_heads)\n    \n    if number_of_heads == heads_condition:\n        constraint_satisy = constraint_satisy + 1  \n        \nnum_heads_list = np.array(num_heads_list)\n\n\nlen(num_heads_list)\n\n5000\n\n\nDefining a normal distribution function from scipy or we could also use the function defined previously.\n\nfrom scipy.stats import norm\nx = np.linspace(min(num_heads_list), max(num_heads_list))\nstd_norm_coin = norm(np.mean(num_heads_list), np.std(num_heads_list))\n\n\nquantiles_95_confidence = np.quantile(num_heads_list, [0.025, 0.975])\n\n\nfig, ax = plt.subplots(1,1, figsize=(8,5))\n\n# Plot histogram density\nsns.histplot(num_heads_list, stat='density', kde=False, ax=ax)\n\n# Plot normal distribution\nax.plot(x, std_norm_coin.pdf(x), color='black', linestyle='--', label='Normal Distribution')\n\n# Plot sample mean\nax.axvline(np.mean(num_heads_list), color='red', linestyle='--', linewidth=2.0, label='Sample Mean')\nax.axvline(heads_condition, color='blue', linestyle='-', linewidth=2.0, label='Experiment condition')\n\n\n# Plot confidence interval \nax.axvspan(quantiles_95_confidence[0], quantiles_95_confidence[1], alpha=0.15, color='yellow',label='95% confidence interval')\n\nax.set_xlabel('Number of heads in 30 coin tosses')\nplt.title('Visualize distribution of number of heads for 30 coin tosses sampled {} times'.format(num_trials), fontsize=15);\nplt.legend(loc=\"upper left\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\np-value estimate\n\np_value = constraint_satisy / num_trials\nprint(p_value)\n\n0.0042\n\n\nSince p-value is less than 0.05, this means the coin is not fair\nFor most problems, we only care about the order of magnitude: if the p-value is smaller that 1/100, the effect is likely to be real; if it is greater than 1/10, probably not. If you think there is a difference between a 4.8% (significant!) and 5.2% (not significant!), you are taking it too seriously."
  },
  {
    "objectID": "posts/2021-02-03-tsnevsumap.html",
    "href": "posts/2021-02-03-tsnevsumap.html",
    "title": "t-SNE and UMAP - Effect of initialization on the dimensionality reduction",
    "section": "",
    "text": "Recreating the dataset explored in the recent publication looking at the effect of random initializations and sub-methods in well-known dimensionality reduction techniques: Initialization is critical for preserving global data structure in both t-SNE and UMAP"
  },
  {
    "objectID": "posts/2021-02-03-tsnevsumap.html#key-takeaways",
    "href": "posts/2021-02-03-tsnevsumap.html#key-takeaways",
    "title": "t-SNE and UMAP - Effect of initialization on the dimensionality reduction",
    "section": "Key takeaways:",
    "text": "Key takeaways:\n\nUsing either t-SNE or UMAP over another is difficult to justify. There is no evidence per se that UMAP algorithm have any advantage over t-SNE in terms of preserving global structure.\nThese algorithms should be used cautiously and with informative initialization by default\nIn all embeddings, distances between clusters of points can be completely meaningless. It is often impossible to represent complex topologies in 2 dimensions, and embeddings should be approached with the utmost care when attempting to interpret their layout.\nThe only cerrtainty is the closeness of the points and their similarity\nThese methods don’t work that great if the intrinsic dimensionality of the data is higher than 2D\nHigh dimensional data sets typically have lower intrinsic dimensionality $ d &lt;&lt; D $ however \\(d\\) may still be larger than 2 and preserving these distances faithfully might not always be possible.\nWhen using both UMAP or t-SNE, one must take care not to overinterpret the embedding structure or distances.\n\n\nimport numpy as np \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns\n\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nimport openTSNE, umap\nprint('openTSNE', openTSNE.__version__)\nprint('umap', umap.__version__)\n\nopenTSNE 0.6.0\numap 0.5.1\n\n\n\nfrom openTSNE import TSNE\nfrom umap import UMAP"
  },
  {
    "objectID": "posts/2021-02-03-tsnevsumap.html#looking-at-2d-circle",
    "href": "posts/2021-02-03-tsnevsumap.html#looking-at-2d-circle",
    "title": "t-SNE and UMAP - Effect of initialization on the dimensionality reduction",
    "section": "1. Looking at 2D circle",
    "text": "1. Looking at 2D circle\n\n#Generate circle\n\nn = 7000\nnp.random.seed(42)\nX = np.random.randn(n, 3) / 1000\nX[:,0] += np.cos(np.arange(n)*2*np.pi/n)\nX[:,1] += np.sin(np.arange(n)*2*np.pi/n)\n\nplt.plot(X[:,0], X[:,1]);\nplt.axis('equal');\n\n\n\n\n\n\n\n\n\n%%time\n\n# BH is faster for this sample size\nZ1 = TSNE(n_jobs=-1, initialization='random', random_state=42, negative_gradient_method='bh').fit(X)\nZ2 = TSNE(n_jobs=-1, negative_gradient_method='bh').fit(X)\n\nCPU times: user 48.3 s, sys: 760 ms, total: 49.1 s\nWall time: 40.8 s\n\n\n\n%%time\n\nZ3 = UMAP(init='random', random_state=42).fit_transform(X)\nZ4 = UMAP().fit_transform(X)\n\nCPU times: user 58.4 s, sys: 2.59 s, total: 1min\nWall time: 33.4 s\n\n\n\n%%time\nfrom sklearn import decomposition\npca_2D = decomposition.PCA(n_components=2)\npca_2D.fit(X)\nZ5 = pca_2D.transform(X)\n\nCPU times: user 6.17 ms, sys: 5.36 ms, total: 11.5 ms\nWall time: 5.72 ms\n\n\n\nfrom matplotlib.colors import ListedColormap\ncmap = ListedColormap(sns.husl_palette(n))\n\ntitles = ['Data', 't-SNE, random init', 't-SNE, PCA init', \n          'UMAP, random init', 'UMAP, LE init', 'PCA']\n\nplt.figure(figsize=(10,2))\n\nfor i,Z in enumerate([X,Z1,Z2,Z3,Z4,Z5],1):\n    plt.subplot(1,6,i)\n    plt.gca().set_aspect('equal', adjustable='datalim')\n    plt.scatter(Z[:,0], Z[:,1], s=1, c=np.arange(n), cmap=cmap, \n                edgecolor='none', rasterized=True)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(titles[i-1], fontsize=8)\n    \n#sns.despine(left=True, bottom=True)"
  },
  {
    "objectID": "posts/2021-02-03-tsnevsumap.html#looking-at-hand-written-digit-data",
    "href": "posts/2021-02-03-tsnevsumap.html#looking-at-hand-written-digit-data",
    "title": "t-SNE and UMAP - Effect of initialization on the dimensionality reduction",
    "section": "2. Looking at hand-written digit data",
    "text": "2. Looking at hand-written digit data\n\nfrom sklearn.datasets import load_digits\ndigits = load_digits()\n\n\ndigits.keys()\n\ndict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n\n\n\nX = digits.data\nY = digits.target\n\n\n%%time\n\n# BH is faster for this sample size\nZ1 = TSNE(n_jobs=-1, initialization='random', random_state=42, negative_gradient_method='bh').fit(X)\nZ2 = TSNE(n_jobs=-1, negative_gradient_method='bh').fit(X)\n\nCPU times: user 14.8 s, sys: 331 ms, total: 15.2 s\nWall time: 13.3 s\n\n\n\n%%time\n\nZ3 = UMAP(init='random', random_state=42).fit_transform(X)\nZ4 = UMAP().fit_transform(X)\n\nCPU times: user 17.7 s, sys: 311 ms, total: 18 s\nWall time: 12.5 s\n\n\n\n%%time\n\npca_2D = decomposition.PCA(n_components=2)\npca_2D.fit(X)\nZ5 = pca_2D.transform(X)\n\nCPU times: user 17.8 ms, sys: 16.7 ms, total: 34.5 ms\nWall time: 10.2 ms\n\n\n\nfrom matplotlib.colors import ListedColormap\ncmap = ListedColormap(sns.husl_palette(len(np.unique(Y))))\n\ntitles = ['Data', 't-SNE, random init', 't-SNE, PCA init', \n          'UMAP, random init', 'UMAP, LE init', 'PCA']\n\nfig, ax = plt.subplots(3,2, figsize=(15,15))\nax = ax.flatten()\n\nfor i,Z in enumerate([X,Z1,Z2,Z3,Z4,Z5],0):\n    im = ax[i].scatter(Z[:,0], Z[:,1], s=10, c=Y, cmap=cmap, edgecolor='none')\n    ax[i].set_xticks([])\n    ax[i].set_yticks([])\n    ax[i].set_title(titles[i], fontsize=15)\n    \nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.25, 0.01, 0.5], label='digit')\ncbar = fig.colorbar(im, cax=cbar_ax,label='Digit')"
  },
  {
    "objectID": "posts/2020-08-01-sp_500.html",
    "href": "posts/2020-08-01-sp_500.html",
    "title": "S&P 500 analysis using beautifulsoup and pandas",
    "section": "",
    "text": "To extract stock information we will use yfinance module which is a convenient way to download data from Yahoo Finance. The official API for Yahoo Finance was decommissioned some time back. More details about this module can be found here.\n\nfrom requests import get \nimport numpy as np \nimport pandas as pd \nfrom bs4 import BeautifulSoup\nimport time as time \nfrom tqdm import tqdm\nimport yfinance as yf\n\nfrom IPython.core.display import clear_output\n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nsns.color_palette(\"husl\")\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 30,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'lines.linewidth' : 3,\n'lines.markersize' : 10,\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)"
  },
  {
    "objectID": "posts/2020-08-01-sp_500.html#generate-list-of-sp-500-companies",
    "href": "posts/2020-08-01-sp_500.html#generate-list-of-sp-500-companies",
    "title": "S&P 500 analysis using beautifulsoup and pandas",
    "section": "1. Generate list of S&P 500 companies",
    "text": "1. Generate list of S&P 500 companies\n\nParse wikipedia to generate a list\n\nwiki_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\nresponse = get(wiki_url)\nhtml_soup = BeautifulSoup(response.text, 'html.parser')\ntab = html_soup.find(\"table\",{\"class\":\"wikitable sortable\"})\n\n\ncolumn_headings = [entry.text.strip() for entry in tab.findAll('th')]\nprint(column_headings)\n\n['Symbol', 'Security', 'SEC filings', 'GICS Sector', 'GICS Sub-Industry', 'Headquarters Location', 'Date first added', 'CIK', 'Founded']\n\n\n\nSP_500_dict = {keys:[] for keys in column_headings}\n\n\nfor i, name in enumerate(SP_500_dict.keys()):\n    print(i, name)\n\n0 Symbol\n1 Security\n2 SEC filings\n3 GICS Sector\n4 GICS Sub-Industry\n5 Headquarters Location\n6 Date first added\n7 CIK\n8 Founded\n\n\n\n\nPopulate each row entry as per company data\n\nfor row_entry in tab.findAll('tr')[1:]:\n    row_elements = row_entry.findAll('td')\n    for key, _elements in zip(SP_500_dict.keys(), row_elements):\n        SP_500_dict[key].append(_elements.text.strip())\n\n\nSP_500_df = pd.DataFrame(SP_500_dict, columns=SP_500_dict.keys())\n\n\nSP_500_df\n\n\n\n\n\n\n\n\nSymbol\nSecurity\nSEC filings\nGICS Sector\nGICS Sub-Industry\nHeadquarters Location\nDate first added\nCIK\nFounded\n\n\n\n\n0\nMMM\n3M Company\nreports\nIndustrials\nIndustrial Conglomerates\nSt. Paul, Minnesota\n1976-08-09\n0000066740\n1902\n\n\n1\nABT\nAbbott Laboratories\nreports\nHealth Care\nHealth Care Equipment\nNorth Chicago, Illinois\n1964-03-31\n0000001800\n1888\n\n\n2\nABBV\nAbbVie Inc.\nreports\nHealth Care\nPharmaceuticals\nNorth Chicago, Illinois\n2012-12-31\n0001551152\n2013 (1888)\n\n\n3\nABMD\nAbiomed\nreports\nHealth Care\nHealth Care Equipment\nDanvers, Massachusetts\n2018-05-31\n0000815094\n1981\n\n\n4\nACN\nAccenture\nreports\nInformation Technology\nIT Consulting & Other Services\nDublin, Ireland\n2011-07-06\n0001467373\n1989\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n500\nYUM\nYum! Brands Inc\nreports\nConsumer Discretionary\nRestaurants\nLouisville, Kentucky\n1997-10-06\n0001041061\n1997\n\n\n501\nZBRA\nZebra Technologies\nreports\nInformation Technology\nElectronic Equipment & Instruments\nLincolnshire, Illinois\n2019-12-23\n0000877212\n1969\n\n\n502\nZBH\nZimmer Biomet\nreports\nHealth Care\nHealth Care Equipment\nWarsaw, Indiana\n2001-08-07\n0001136869\n1927\n\n\n503\nZION\nZions Bancorp\nreports\nFinancials\nRegional Banks\nSalt Lake City, Utah\n2001-06-22\n0000109380\n1873\n\n\n504\nZTS\nZoetis\nreports\nHealth Care\nPharmaceuticals\nParsippany, New Jersey\n2013-06-21\n0001555280\n1952\n\n\n\n\n505 rows × 9 columns\n\n\n\n\nSP_500_df['GICS Sector'].value_counts()\n\nInformation Technology    75\nIndustrials               74\nFinancials                65\nConsumer Discretionary    63\nHealth Care               62\nConsumer Staples          32\nReal Estate               29\nMaterials                 28\nUtilities                 28\nCommunication Services    26\nEnergy                    23\nName: GICS Sector, dtype: int64\n\n\n\n\nVisualize distribution of the companies as per sectors\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nSP_500_df['GICS Sector'].value_counts().plot.pie(y='GICS Sector', autopct='%1.1f%%', fontsize=20, ax = ax, colormap='tab20')\nplt.axis('off')\n\n\n\n\n\n\n\n\n\nSP_500_df.loc[ SP_500_df['GICS Sector'] == 'Energy']\n\n\n\n\n\n\n\n\nSymbol\nSecurity\nSEC filings\nGICS Sector\nGICS Sub-Industry\nHeadquarters Location\nDate first added\nCIK\nFounded\n\n\n\n\n44\nAPA\nAPA Corporation\nreports\nEnergy\nOil & Gas Exploration & Production\nHouston, Texas\n1997-07-28\n0000006769\n1954\n\n\n59\nBKR\nBaker Hughes Co\nreports\nEnergy\nOil & Gas Equipment & Services\nHouston, Texas\n2017-07-07\n0001701605\n2017\n\n\n80\nCOG\nCabot Oil & Gas\nreports\nEnergy\nOil & Gas Exploration & Production\nHouston, Texas\n2008-06-23\n0000858470\n1989\n\n\n101\nCVX\nChevron Corp.\nreports\nEnergy\nIntegrated Oil & Gas\nSan Ramon, California\n1957-03-04\n0000093410\n1879\n\n\n121\nCOP\nConocoPhillips\nreports\nEnergy\nOil & Gas Exploration & Production\nHouston, Texas\n1957-03-04\n0001163165\n2002\n\n\n140\nDVN\nDevon Energy\nreports\nEnergy\nOil & Gas Exploration & Production\nOklahoma City, Oklahoma\n2000-08-30\n0001090012\n1971\n\n\n142\nFANG\nDiamondback Energy\nreports\nEnergy\nOil & Gas Exploration & Production\nMidland, Texas\n2018-12-03\n0001539838\n2007\n\n\n169\nEOG\nEOG Resources\nreports\nEnergy\nOil & Gas Exploration & Production\nHouston, Texas\n2000-11-02\n0000821189\n1999\n\n\n183\nXOM\nExxon Mobil Corp.\nreports\nEnergy\nIntegrated Oil & Gas\nIrving, Texas\n1957-03-04\n0000034088\n1999\n\n\n219\nHAL\nHalliburton Co.\nreports\nEnergy\nOil & Gas Equipment & Services\nHouston, Texas\n1957-03-04\n0000045012\n1919\n\n\n227\nHES\nHess Corporation\nreports\nEnergy\nIntegrated Oil & Gas\nNew York, New York\n1984-05-31\n0000004447\n1919\n\n\n230\nHFC\nHollyFrontier Corp\nreports\nEnergy\nOil & Gas Refining & Marketing\nDallas, Texas\n2018-06-18\n0000048039\n1947\n\n\n274\nKMI\nKinder Morgan\nreports\nEnergy\nOil & Gas Storage & Transportation\nHouston, Texas\n2012-05-25\n0001506307\n1997\n\n\n298\nMRO\nMarathon Oil Corp.\nreports\nEnergy\nOil & Gas Exploration & Production\nHouston, Texas\n1991-05-01\n0000101778\n1887\n\n\n299\nMPC\nMarathon Petroleum\nreports\nEnergy\nOil & Gas Refining & Marketing\nFindlay, Ohio\n2011-07-01\n0001510295\n2009 (1887)\n\n\n345\nNOV\nNOV Inc.\nreports\nEnergy\nOil & Gas Equipment & Services\nHouston, Texas\n2005-03-14\n0001021860\n1841\n\n\n352\nOXY\nOccidental Petroleum\nreports\nEnergy\nOil & Gas Exploration & Production\nHouston, Texas\n1982-12-31\n0000797468\n1920\n\n\n355\nOKE\nOneok\nreports\nEnergy\nOil & Gas Storage & Transportation\nTulsa, Oklahoma\n2010-03-15\n0001039684\n1906\n\n\n372\nPSX\nPhillips 66\nreports\nEnergy\nOil & Gas Refining & Marketing\nHouston, Texas\n2012-05-01\n0001534701\n2012 (1917)\n\n\n374\nPXD\nPioneer Natural Resources\nreports\nEnergy\nOil & Gas Exploration & Production\nIrving, Texas\n2008-09-24\n0001038357\n1997\n\n\n411\nSLB\nSchlumberger Ltd.\nreports\nEnergy\nOil & Gas Equipment & Services\nCuraçao, Kingdom of the Netherlands\n1965-03-31\n0000087347\n1926\n\n\n466\nVLO\nValero Energy\nreports\nEnergy\nOil & Gas Refining & Marketing\nSan Antonio, Texas\n\n0001035002\n1980\n\n\n494\nWMB\nWilliams Companies\nreports\nEnergy\nOil & Gas Storage & Transportation\nTulsa, Oklahoma\n1975-03-31\n0000107263\n1908\n\n\n\n\n\n\n\nWe can parse these tables and search companies based on the sector\n\nSP_500_df.loc[ SP_500_df['GICS Sector'] == 'Information Technology']\n\n\n\n\n\n\n\n\nSymbol\nSecurity\nSEC filings\nGICS Sector\nGICS Sub-Industry\nHeadquarters Location\nDate first added\nCIK\nFounded\n\n\n\n\n4\nACN\nAccenture\nreports\nInformation Technology\nIT Consulting & Other Services\nDublin, Ireland\n2011-07-06\n0001467373\n1989\n\n\n6\nADBE\nAdobe Inc.\nreports\nInformation Technology\nApplication Software\nSan Jose, California\n1997-05-05\n0000796343\n1982\n\n\n7\nAMD\nAdvanced Micro Devices\nreports\nInformation Technology\nSemiconductors\nSanta Clara, California\n2017-03-20\n0000002488\n1969\n\n\n13\nAKAM\nAkamai Technologies\nreports\nInformation Technology\nInternet Services & Infrastructure\nCambridge, Massachusetts\n2007-07-12\n0001086222\n1998\n\n\n38\nAPH\nAmphenol Corp\nreports\nInformation Technology\nElectronic Components\nWallingford, Connecticut\n2008-09-30\n0000820313\n1932\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n475\nV\nVisa Inc.\nreports\nInformation Technology\nData Processing & Outsourced Services\nSan Francisco, California\n2009-12-21\n0001403161\n1958\n\n\n489\nWDC\nWestern Digital\nreports\nInformation Technology\nTechnology Hardware, Storage & Peripherals\nSan Jose, California\n2009-07-01\n0000106040\n1970\n\n\n490\nWU\nWestern Union Co\nreports\nInformation Technology\nData Processing & Outsourced Services\nEnglewood, Colorado\n2006-09-29\n0001365135\n1851\n\n\n498\nXLNX\nXilinx\nreports\nInformation Technology\nSemiconductors\nSan Jose, California\n1999-11-08\n0000743988\n1984\n\n\n501\nZBRA\nZebra Technologies\nreports\nInformation Technology\nElectronic Equipment & Instruments\nLincolnshire, Illinois\n2019-12-23\n0000877212\n1969\n\n\n\n\n75 rows × 9 columns"
  },
  {
    "objectID": "posts/2020-08-01-sp_500.html#get-total-number-of-shares",
    "href": "posts/2020-08-01-sp_500.html#get-total-number-of-shares",
    "title": "S&P 500 analysis using beautifulsoup and pandas",
    "section": "Get total number of Shares",
    "text": "Get total number of Shares\nWe will use yfinance to extact Tickr information for each SP500 company and use pandas datareader\nyf_tickr = yf.Ticker('ADBE')\nyf_tickr.info['sharesOutstanding'] #info has good summary info for the stock \n\nimport yfinance as yf\n\n\nSTART_DATE = \"2020-01-01\"\nEND_DATE = \"2020-07-26\"\n\n\nyf_tickr = yf.Ticker('TSLA')\n\n\n_shares_outstanding = yf_tickr.info['sharesOutstanding']\n_previous_close = yf_tickr.info['previousClose']\nprint('Outstanding shares: {}'.format(_shares_outstanding))\nprint('Market Cap: {} Million USD'.format((_shares_outstanding * _previous_close)/10**6))\n\nOutstanding shares: 959854016\nMarket Cap: 676447.51923584 Million USD\n\n\n\ndf_tckr = yf_tickr.history(start=START_DATE, end=END_DATE, interval=\"1wk\", actions=False)\ndf_tckr['Market_Cap'] = df_tckr['Open'] * _shares_outstanding\ndf_tckr['YTD'] = (df_tckr['Open'] - df_tckr['Open'][0]) * 100 / df_tckr['Open'][0]\n\n\nfig, ax = plt.subplots(1,1, figsize=(10,8))\ndf_tckr.plot(use_index=True, y=\"YTD\",ax=ax, linewidth=4, grid=False, label='TSLA')\nax.set_xlabel('Date')\nax.set_ylabel('% YTD change (Weekly basis)')\n\nText(0, 0.5, '% YTD change (Weekly basis)')\n\n\n\n\n\n\n\n\n\n\nExtend this to plotting for multiple companies\n\nimport time as time \ndef plot_market_cap(tickr_list, START_DATE, END_DATE):\n    \n    total_data = {}\n    for tickr in tickr_list:\n        total_data[tickr] = {}\n        print('Looking at: {}'.format(tickr))\n        yf_tickr = yf.Ticker(tickr)\n        #try:\n        #    _shares_outstanding = yf_tickr.info['sharesOutstanding']\n        #except(IndexError):\n        #    print('Shares outstanding not found')\n        #    _shares_outstanding = None\n        \n        df_tckr = yf_tickr.history(start=START_DATE, end=END_DATE, actions=False)\n        df_tckr['YTD'] = (df_tckr['Open'] - df_tckr['Open'][0]) * 100 / df_tckr['Open'][0]\n            \n        total_data[tickr]['hist'] = df_tckr\n        #total_data[tickr]['shares'] = _shares_outstanding\n        time.sleep(np.random.randint(10))\n        \n    return total_data\n\n\ntickr_list = ['AAPL', 'TSLA','FB','DAL','XOM']\ndata = plot_market_cap(tickr_list, START_DATE, END_DATE)\n\nLooking at: AAPL\nLooking at: TSLA\nLooking at: FB\nLooking at: DAL\nLooking at: XOM\n\n\n\ncompany_name = [SP_500_df[SP_500_df['Symbol'].str.contains(i)]['Security'].values[0] for i in tickr_list]\n\n\ncompany_name\n\n['Apple Inc.',\n 'Tesla, Inc.',\n 'Facebook, Inc.',\n 'Delta Air Lines Inc.',\n 'Exxon Mobil Corp.']\n\n\n\nprint(len(data['AAPL']['hist']['YTD']))\n\n142\n\n\n\nytd_stat = pd.DataFrame()\nfor tickr in tickr_list: \n    ytd_stat[tickr] = data[tickr]['hist']['YTD'].values\nytd_stat['Date'] = data['AAPL']['hist'].index\n\n\nytd_stat\n\n\n\n\n\n\n\n\nAAPL\nTSLA\nFB\nDAL\nXOM\nDate\n\n\n\n\n0\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n2020-01-02\n\n\n1\n0.307187\n3.769137\n0.222494\n-2.426609\n1.566061\n2020-01-03\n\n\n2\n-0.827016\n3.762073\n-0.024185\n-3.292044\n0.113891\n2020-01-06\n\n\n3\n1.215244\n8.692576\n2.935916\n-1.730873\n0.370157\n2020-01-07\n\n\n4\n0.310568\n11.590101\n3.022975\n-2.002382\n-0.185078\n2020-01-08\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n137\n30.850611\n257.835096\n16.111244\n-53.866312\n-36.389268\n2020-07-20\n\n\n138\n34.589490\n286.320361\n19.090690\n-54.720640\n-36.477584\n2020-07-21\n\n\n139\n31.223803\n276.678424\n16.207978\n-55.181977\n-35.005460\n2020-07-22\n\n\n140\n31.637726\n295.512370\n15.903267\n-55.574967\n-36.109559\n2020-07-23\n\n\n141\n23.481414\n233.571249\n11.337365\n-54.754814\n-35.402933\n2020-07-24\n\n\n\n\n142 rows × 6 columns"
  },
  {
    "objectID": "posts/2020-08-01-sp_500.html#final-plot-for-returns",
    "href": "posts/2020-08-01-sp_500.html#final-plot-for-returns",
    "title": "S&P 500 analysis using beautifulsoup and pandas",
    "section": "Final plot for returns",
    "text": "Final plot for returns\n\nfig, ax = plt.subplots(1,1,figsize=(15,10))\nfor i, tickr in enumerate(tickr_list):\n    ax.plot(ytd_stat['Date'], ytd_stat[tickr], linewidth=5.0, label=company_name[i])\nax.set_ylabel('YTD %Return 2020')\nax.set_xlabel('Date')\nax.legend()"
  },
  {
    "objectID": "posts/2019-08-02-end2endml_housing.html",
    "href": "posts/2019-08-02-end2endml_housing.html",
    "title": "End-to-end Machine Learning Project",
    "section": "",
    "text": "This project is adapted from Aurelien Geron’s ML book (Github link) . The aim to predict median house values in Californian districts, given a number of features from these districts.\nMain steps we will go through: 1. Formulate the problem 2. Get the data 3. Discover and visualize data / Data exploration to gain insight 4. Prep data for ML algorithm testing 5. Select model and train it 6. Fine-tuning the model\n\nStep 1: Formulate the problem\nPrediction of district’s median housing price given all other metrics. A supervised learning task is where we are given ‘labelled’ data for training purpose. Regression model to predict a continuous variable i.e. district median housing price. Given multiple features, this is a multi-class regression type problem. Univariate regression since a single output is estimated.\n\n\nStep 2: Get the data\n\nimport os \nimport pandas as pd\nimport numpy as np \n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nsns.color_palette(\"husl\")\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 30,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'lines.linewidth' : 3,\n'lines.markersize' : 10,\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)\n\n\n#Load the dataset \nhousing = pd.read_csv('./data/housing.csv')\n\n\nhousing.sample(7)\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n\n\n\n\n10769\n-117.89\n33.66\n33.0\n3595.0\n785.0\n1621.0\n732.0\n4.1372\n265200.0\n&lt;1H OCEAN\n\n\n4165\n-118.20\n34.11\n36.0\n1441.0\n534.0\n1809.0\n500.0\n2.1793\n185700.0\n&lt;1H OCEAN\n\n\n3685\n-118.37\n34.21\n36.0\n2080.0\n455.0\n1939.0\n484.0\n4.2875\n176600.0\n&lt;1H OCEAN\n\n\n8040\n-118.15\n33.84\n37.0\n1508.0\n252.0\n635.0\n241.0\n3.7500\n221300.0\n&lt;1H OCEAN\n\n\n11836\n-120.98\n39.08\n20.0\n4570.0\n906.0\n2125.0\n815.0\n3.0403\n148000.0\nINLAND\n\n\n1525\n-122.07\n37.89\n28.0\n3410.0\n746.0\n1428.0\n670.0\n4.3864\n266800.0\nNEAR BAY\n\n\n18180\n-122.03\n37.37\n9.0\n2966.0\n770.0\n1430.0\n740.0\n3.0047\n256000.0\n&lt;1H OCEAN\n\n\n\n\n\n\n\nEach row presents one district. Each of these districts has 10 attributes (features).\n\nhousing.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 20640 entries, 0 to 20639\nData columns (total 10 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   longitude           20640 non-null  float64\n 1   latitude            20640 non-null  float64\n 2   housing_median_age  20640 non-null  float64\n 3   total_rooms         20640 non-null  float64\n 4   total_bedrooms      20433 non-null  float64\n 5   population          20640 non-null  float64\n 6   households          20640 non-null  float64\n 7   median_income       20640 non-null  float64\n 8   median_house_value  20640 non-null  float64\n 9   ocean_proximity     20640 non-null  object \ndtypes: float64(9), object(1)\nmemory usage: 1.6+ MB\n\n\nOne thing to notice in this dataset is the number of total_bedroom entries is different from other entries. This suggests there are some missing entries or null in the dataset.\n\n#To show the null elements (if any in the total_bedroom entries)\nhousing[housing.total_bedrooms.isnull()]\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\n\n\n\n\n290\n-122.16\n37.77\n47.0\n1256.0\nNaN\n570.0\n218.0\n4.3750\n161900.0\nNEAR BAY\n\n\n341\n-122.17\n37.75\n38.0\n992.0\nNaN\n732.0\n259.0\n1.6196\n85100.0\nNEAR BAY\n\n\n538\n-122.28\n37.78\n29.0\n5154.0\nNaN\n3741.0\n1273.0\n2.5762\n173400.0\nNEAR BAY\n\n\n563\n-122.24\n37.75\n45.0\n891.0\nNaN\n384.0\n146.0\n4.9489\n247100.0\nNEAR BAY\n\n\n696\n-122.10\n37.69\n41.0\n746.0\nNaN\n387.0\n161.0\n3.9063\n178400.0\nNEAR BAY\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20267\n-119.19\n34.20\n18.0\n3620.0\nNaN\n3171.0\n779.0\n3.3409\n220500.0\nNEAR OCEAN\n\n\n20268\n-119.18\n34.19\n19.0\n2393.0\nNaN\n1938.0\n762.0\n1.6953\n167400.0\nNEAR OCEAN\n\n\n20372\n-118.88\n34.17\n15.0\n4260.0\nNaN\n1701.0\n669.0\n5.1033\n410700.0\n&lt;1H OCEAN\n\n\n20460\n-118.75\n34.29\n17.0\n5512.0\nNaN\n2734.0\n814.0\n6.6073\n258100.0\n&lt;1H OCEAN\n\n\n20484\n-118.72\n34.28\n17.0\n3051.0\nNaN\n1705.0\n495.0\n5.7376\n218600.0\n&lt;1H OCEAN\n\n\n\n\n207 rows × 10 columns\n\n\n\nFor categorical entries (here, ocean_proximity entries) we can find out the entries and their number using the value_counts(). We can do this for any entry we wish but makes more sense for categorical entries.\n\nhousing[\"ocean_proximity\"].value_counts()\n\n&lt;1H OCEAN     9136\nINLAND        6551\nNEAR OCEAN    2658\nNEAR BAY      2290\nISLAND           5\nName: ocean_proximity, dtype: int64\n\n\n\nhousing.describe().round(2)\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n\n\n\n\ncount\n20640.00\n20640.00\n20640.00\n20640.00\n20433.00\n20640.00\n20640.00\n20640.00\n20640.00\n\n\nmean\n-119.57\n35.63\n28.64\n2635.76\n537.87\n1425.48\n499.54\n3.87\n206855.82\n\n\nstd\n2.00\n2.14\n12.59\n2181.62\n421.39\n1132.46\n382.33\n1.90\n115395.62\n\n\nmin\n-124.35\n32.54\n1.00\n2.00\n1.00\n3.00\n1.00\n0.50\n14999.00\n\n\n25%\n-121.80\n33.93\n18.00\n1447.75\n296.00\n787.00\n280.00\n2.56\n119600.00\n\n\n50%\n-118.49\n34.26\n29.00\n2127.00\n435.00\n1166.00\n409.00\n3.53\n179700.00\n\n\n75%\n-118.01\n37.71\n37.00\n3148.00\n647.00\n1725.00\n605.00\n4.74\n264725.00\n\n\nmax\n-114.31\n41.95\n52.00\n39320.00\n6445.00\n35682.00\n6082.00\n15.00\n500001.00\n\n\n\n\n\n\n\nDescribe is powerful subroutine since that allows us to check the stat summary of numerical attributes\nThe 25%-50%-75% entries for each column show corresponding percentiles. It indicates the value below which a given percentage of observations in a group of observations fall. For example, 25% of observation have median income below 2.56, 50% observations have median income below 3.53, and 75% observations have median income below 4.74. 25% –&gt; 1st Quartile, 50% –&gt; Median, 75% –&gt; 3rd Quartile\n\nhousing.hist(bins=50,figsize=(20,20));\n\n\n\n\n\n\n\n\nFew observations from the Histogram plots, again remember each row is an entry for an ENTIRE district:\n\nNOTICE: From the dataset’s source disclaimer: The housing_median_value, housing_median_age, median_income_value are capped at an arbitrary value.\n\n\nFrom latitute and longitude plots there seems to be lots of district in four particular locations (34,37 – latitude) and (-120,-118 – longitude). We cannot comment on the exact location but only one on these pairs giving most data.\nWe see a tighter distribution for total_rooms, total_bedrooms, and population but spread for house_value and an intresting spike at its end.\nSmall spike at the end of median_income plot suggests presence of small group of affluent families but interestingly that spike does not correlate with the spike in the house_value (More high-end property entries than more “rich” people in a district)\n\nFinally, the dataset is tail-heavy that is they extend further to the right from the median which might make modeling using some ML algorithm a bit chanellenging. Few entries should be scaled such that the distribution is more normal.\n\n\nCreate a test-set\nThis ensures that this is the data on which training, testing occurs and we do not try overfitting to account for all the variance in the data. Typical 20% of data-points are randomly chosen.\n\ndef split_train_test(data,test_ratio):\n    shuffled_indices=np.random.permutation(len(data))\n    test_set_size=int(len(data)*test_ratio)\n    test_indices=shuffled_indices[:test_set_size]\n    train_indices=shuffled_indices[test_set_size:]\n    return(data.iloc[train_indices],data.iloc[test_indices])\n\n\n#To ensure we get similar results at each run -- if not initiated every successive will give more random \n#shuffled indices risking the possibility of the algo seeing the entire dataset! \n\nnp.random.seed(42)\n\n#Random seed set to 42 for no particular reason \n#but just cause its the answer to the Ultimate Question of Life, The Universe, and Everything\n\ntrain_set, test_set = split_train_test(housing, 0.2)\nprint(len(train_set), \"train +\", len(test_set), \"test\")\n\n16512 train + 4128 test\n\n\nBetter way is to have an instance identifier (like id) for each entry to distingusih each entry and see if its sampled or not.\n\nfrom zlib import crc32\n\ndef test_set_check(identifier, test_ratio):\n    return crc32(np.int64(identifier)) & 0xffffffff &lt; test_ratio * 2**32\n\ndef split_train_test_by_id(data, test_ratio, id_column):\n    ids = data[id_column]\n    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n    return data.loc[~in_test_set], data.loc[in_test_set]\n\nThe dataset currently doesnt have inherent id. We could use the row index as id. Or we could use an ad-hoc unique identifier as an interim id.\n\n#HOUSING DATA WITH ID as ROW INDEX\nhousing_with_id = housing.reset_index()   # adds an `index` column\ntrain_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")\n\n#HOUSING DATA WITH ID AS COMBO OF LAT AND LONG. \nhousing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\ntrain_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")\n\n#SCIKIT-LEARN IMPLEMENTATION\n#from sklearn.model_selection import train_test_split\n#train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n\n\ntest_set.head()\n\n\n\n\n\n\n\n\nindex\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\nocean_proximity\nid\n\n\n\n\n59\n59\n-122.29\n37.82\n2.0\n158.0\n43.0\n94.0\n57.0\n2.5625\n60000.0\nNEAR BAY\n-122252.18\n\n\n60\n60\n-122.29\n37.83\n52.0\n1121.0\n211.0\n554.0\n187.0\n3.3929\n75700.0\nNEAR BAY\n-122252.17\n\n\n61\n61\n-122.29\n37.82\n49.0\n135.0\n29.0\n86.0\n23.0\n6.1183\n75000.0\nNEAR BAY\n-122252.18\n\n\n62\n62\n-122.29\n37.81\n50.0\n760.0\n190.0\n377.0\n122.0\n0.9011\n86100.0\nNEAR BAY\n-122252.19\n\n\n67\n67\n-122.29\n37.80\n52.0\n1027.0\n244.0\n492.0\n147.0\n2.6094\n81300.0\nNEAR BAY\n-122252.20\n\n\n\n\n\n\n\nHowever the sampling we have considered here or the one used in Scikit-learn is random sampling by default. This is fine for large dataset however for smaller dataset it is utmost important that the sampled data is representative of the main population data or else we will introduce sampling bias.\nThis is an important bias that could be introduced without prior knowledge and could be overlooked at multiple occassion leading to wrong conclusions. To ensure the sampled dataset is representative of the population set we use stratified sampling (pseudo-random sampling). To make the stratified sampling tractable we first divide the main data into multiple ‘stratas’ based on an variable which we feel is an feature that should be replicated in our test set. The sample is divided into strata and right number of instances are chosen from each strata. We must not have too many stratas and the each strate must have appropriate number of instances.\nFor the case of property pricing in the district, median_income variable is chosen as the variable whose distribution in the main population and the randomly chosen test sample is same. This attribute is an important attribute to predict the final median housing price. So we can think of converting the continuous variable of median_variable into categorical variable – that is stratas.\n\nStratified sampling using median income\n\nhousing[\"median_income\"].hist()\n\n\n\n\n\n\n\n\nFrom the median_income histogram it is seen that most of the entries are clustered in the range of 2-5 (arbitrary units). We can then use this information to make stratas around these instances. Cut routine in the pandas is used for this purpose. This function is also useful for going from a continuous variable to a categorical variable. For example, cut could convert ages to groups of age ranges.\n\nhousing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf], #bins around 2-5 income bracket\n                               labels=[1, 2, 3, 4, 5])\nhousing[\"income_cat\"].value_counts()\n\n3    7236\n2    6581\n4    3639\n5    2362\n1     822\nName: income_cat, dtype: int64\n\n\n\nhousing[\"income_cat\"].hist()\n\n\n\n\n\n\n\n\nNow with the population categorised into various median income groups we can use stratified sampling routine (as implemented in scikit-learn) to make our test-set. As an additional proof let’s compare this to a randomly sampled test_case. We will redo the random sampling we did prviously but with the new population with categorised median_income.\n\n#Stratified sampling from scikit-learn \nfrom sklearn.model_selection import StratifiedShuffleSplit, train_test_split\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]\n\n#Using random sampling\nrand_train_set, rand_test_set = train_test_split(housing, test_size=0.2, random_state=42)\n\nLet’s check the distribution of the income_cat variable in the strat_test, random_test, and the main sample.\n\nhousing[\"income_cat\"].value_counts()/len(housing[\"income_cat\"])\n\n3    0.350581\n2    0.318847\n4    0.176308\n5    0.114438\n1    0.039826\nName: income_cat, dtype: float64\n\n\n\nrand_test_set[\"income_cat\"].value_counts()/len(rand_test_set[\"income_cat\"])\n\n3    0.358527\n2    0.324370\n4    0.167393\n5    0.109496\n1    0.040213\nName: income_cat, dtype: float64\n\n\n\nstrat_test_set[\"income_cat\"].value_counts()/len(strat_test_set[\"income_cat\"])\n\n3    0.350533\n2    0.318798\n4    0.176357\n5    0.114583\n1    0.039729\nName: income_cat, dtype: float64\n\n\n\ndef income_cat_proportions(data):\n    return data[\"income_cat\"].value_counts() / len(data)\n\ncompare_props = pd.DataFrame({\n    \"Overall\": income_cat_proportions(housing),\n    \"Stratified\": income_cat_proportions(strat_test_set),\n    \"Random\": income_cat_proportions(rand_test_set),\n}).sort_index()\ncompare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\ncompare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100\n\n\ncompare_props\n\n\n\n\n\n\n\n\nOverall\nStratified\nRandom\nRand. %error\nStrat. %error\n\n\n\n\n1\n0.039826\n0.039729\n0.040213\n0.973236\n-0.243309\n\n\n2\n0.318847\n0.318798\n0.324370\n1.732260\n-0.015195\n\n\n3\n0.350581\n0.350533\n0.358527\n2.266446\n-0.013820\n\n\n4\n0.176308\n0.176357\n0.167393\n-5.056334\n0.027480\n\n\n5\n0.114438\n0.114583\n0.109496\n-4.318374\n0.127011\n\n\n\n\n\n\n\nNow, we can remove the income_cat column\n\nfor set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"income_cat\", axis=1, inplace=True)\n\n\n\n\nPreliminary visualization of the data\nLet’s now dive a bit deeper into the data visualization and analysis. Before we do so, copy the strat_train_set as that would be the data-set we would be playing around and make sure the main data-set is not touched.\n\nhousing=strat_train_set.copy()\nhousing.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 16512 entries, 17606 to 15775\nData columns (total 10 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   longitude           16512 non-null  float64\n 1   latitude            16512 non-null  float64\n 2   housing_median_age  16512 non-null  float64\n 3   total_rooms         16512 non-null  float64\n 4   total_bedrooms      16354 non-null  float64\n 5   population          16512 non-null  float64\n 6   households          16512 non-null  float64\n 7   median_income       16512 non-null  float64\n 8   median_house_value  16512 non-null  float64\n 9   ocean_proximity     16512 non-null  object \ndtypes: float64(9), object(1)\nmemory usage: 1.4+ MB\n\n\n\nGeographical visualization\nLet’s now plot the data entries in the housing data as per the latitude and longitude.\n\nhousing.plot(kind='scatter',x='longitude',y='latitude');\n\n*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n\n\n\n\n\n\n\n\n\nThis look’s like California however, we cannot infer anything more out of this. Let’s play around a little bit more…\n\nPlaying with the alpha value in the plotting routine allows us to see the frequency of THAT datapoint in the plot\n\n\nhousing.plot(kind='scatter',x='longitude',y='latitude',alpha=0.1);\n\n*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n\n\n\n\n\n\n\n\n\nFrom here, we can see the high density of listings in the Bay area and LA also around Sacramento and Fresco.\n\nhousing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n    s=housing[\"population\"]/100, label=\"population\", figsize=(8,5),\n    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n    sharex=False)\nplt.legend()\n\n\n\n\n\n\n\n\nThis is more interesting! We have now plotted the data with more information. Each data-point has two additional set of info apart of frequency of occurence. First being the color of the point is the median_house_value entry (option c). The radius of the data-point is the population of that district (option s). It can be seen that the housing prices are very much related to the location. The ones closer to the bay area are more expensive but need not be densely populated.\n\n\nLooking for simple correlations\nIn addition to looking at the plot of housing price, we can check for simpler correaltions. Pearson’s correlation matrix is something which is in-built in pandas and can be directly used. It checks for correlation between every pair of feature provided in the data-set. It estimates the covariance of the two features and estimates whether the correlation is inverse, direct, or none.\n\ncorr_matrix=housing.corr()\ncorr_matrix.style.background_gradient(cmap='coolwarm').set_precision(2)\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\n\n\n\n\nlongitude\n1.00\n-0.92\n-0.11\n0.05\n0.08\n0.11\n0.06\n-0.02\n-0.05\n\n\nlatitude\n-0.92\n1.00\n0.01\n-0.04\n-0.07\n-0.12\n-0.08\n-0.08\n-0.14\n\n\nhousing_median_age\n-0.11\n0.01\n1.00\n-0.36\n-0.33\n-0.30\n-0.31\n-0.11\n0.11\n\n\ntotal_rooms\n0.05\n-0.04\n-0.36\n1.00\n0.93\n0.86\n0.92\n0.20\n0.14\n\n\ntotal_bedrooms\n0.08\n-0.07\n-0.33\n0.93\n1.00\n0.88\n0.98\n-0.01\n0.05\n\n\npopulation\n0.11\n-0.12\n-0.30\n0.86\n0.88\n1.00\n0.90\n0.00\n-0.03\n\n\nhouseholds\n0.06\n-0.08\n-0.31\n0.92\n0.98\n0.90\n1.00\n0.01\n0.06\n\n\nmedian_income\n-0.02\n-0.08\n-0.11\n0.20\n-0.01\n0.00\n0.01\n1.00\n0.69\n\n\nmedian_house_value\n-0.05\n-0.14\n0.11\n0.14\n0.05\n-0.03\n0.06\n0.69\n1.00\n\n\n\n\n\n\ncorr_matrix['median_house_value'].sort_values(ascending=True)\n\nlatitude             -0.142724\nlongitude            -0.047432\npopulation           -0.026920\ntotal_bedrooms        0.047689\nhouseholds            0.064506\nhousing_median_age    0.114110\ntotal_rooms           0.135097\nmedian_income         0.687160\nmedian_house_value    1.000000\nName: median_house_value, dtype: float64\n\n\nThe correlation matrix suggests the amount of correlation between a pair of variables. When close to 1 it means a strong +ve correlation whereas, -1 means an inverse correlation. Looking at the correlation between median_house_values and other variables, we can see that there’s some correlation with median_income (0.68 – so +ve), and with the latitude (-0.14 – so an inverse relation).\nAnother to check this relation is to plot scatter plots for each pair of variables in the dataset. Below we plot this for few potential/interesting variables\n\n# from pandas.tools.plotting import scatter_matrix # For older versions of Pandas\nfrom pandas.plotting import scatter_matrix\n\nattributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n              \"housing_median_age\"]\nscatter_axes = scatter_matrix(housing[attributes], figsize=(12, 8));\n#y labels\n[plt.setp(item.yaxis.get_label(), 'size', 10) for item in scatter_axes.ravel()];\n#x labels\n[plt.setp(item.xaxis.get_label(), 'size', 10) for item in scatter_axes.ravel()];\n\n\n\n\n\n\n\n\nThe diagonal entries show the histogram for each variable. We saw this previously for some variables. The most promising variable from this analysis seems to be the median_income.\n\nhousing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n             alpha=0.1);\n\n*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n\n\n\n\n\n\n\n\n\nPlotting it shows the stronger correlation with the target variable i.e. median_house_value however we can see horizontal lines (especially at USD 500k, 450k 350k) these could be due to some stratifying done in the dataset implicitly. It would be better to remove those to ensure our model does not spuriously fit for those since they are some of the quirks in the data.\n\n\n\nExperimenting with attributes\nBefore we began proposing models for the data. We can play around with the variables and try different combinations of them to see if we get better trends. Let’s look at a few. First, the total_room and/or total_bedroom variable could be changed to average_bedroom_per_house to better for bedrooms rather than looking for total bedroom in that district we would be looking at avg_bedroom per district and similarly we would do it for rooms.\n\n#Average bedroom per house-holds in the district \nhousing['avg_bedroom']=housing['total_bedrooms']/housing['households']\n\n#Average room per house-holds in the district \nhousing['avg_room']=housing['total_rooms']/housing['households']\n\n#Average bedrooms per rooms in a given district\nhousing['bedroom_per_room']=housing['total_bedrooms']/housing['total_rooms']\n\n#Average population per household in a given district\nhousing['population_per_household']=housing['population']/housing['households']\n\n#Average room per population in a given district\nhousing['room_per_popoulation']=housing['total_rooms']/housing['population']\n\n#Average room per population in a given district\nhousing['room_per_popoulation']=housing['total_rooms']/housing['population']\n\n\n#Making the correlation matrix again \ncorr_matrix=housing.corr()\ncorr_matrix.style.background_gradient(cmap='coolwarm').set_precision(2)\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nmedian_house_value\navg_bedroom\navg_room\nbedroom_per_room\npopulation_per_household\nroom_per_popoulation\n\n\n\n\nlongitude\n1.00\n-0.92\n-0.11\n0.05\n0.08\n0.11\n0.06\n-0.02\n-0.05\n0.01\n-0.03\n0.10\n-0.00\n-0.07\n\n\nlatitude\n-0.92\n1.00\n0.01\n-0.04\n-0.07\n-0.12\n-0.08\n-0.08\n-0.14\n0.07\n0.11\n-0.12\n0.01\n0.14\n\n\nhousing_median_age\n-0.11\n0.01\n1.00\n-0.36\n-0.33\n-0.30\n-0.31\n-0.11\n0.11\n-0.08\n-0.15\n0.14\n0.02\n-0.10\n\n\ntotal_rooms\n0.05\n-0.04\n-0.36\n1.00\n0.93\n0.86\n0.92\n0.20\n0.14\n0.03\n0.13\n-0.19\n-0.02\n0.12\n\n\ntotal_bedrooms\n0.08\n-0.07\n-0.33\n0.93\n1.00\n0.88\n0.98\n-0.01\n0.05\n0.04\n0.00\n0.09\n-0.03\n0.05\n\n\npopulation\n0.11\n-0.12\n-0.30\n0.86\n0.88\n1.00\n0.90\n0.00\n-0.03\n-0.07\n-0.07\n0.04\n0.08\n-0.14\n\n\nhouseholds\n0.06\n-0.08\n-0.31\n0.92\n0.98\n0.90\n1.00\n0.01\n0.06\n-0.06\n-0.08\n0.07\n-0.03\n-0.04\n\n\nmedian_income\n-0.02\n-0.08\n-0.11\n0.20\n-0.01\n0.00\n0.01\n1.00\n0.69\n-0.06\n0.31\n-0.62\n0.02\n0.23\n\n\nmedian_house_value\n-0.05\n-0.14\n0.11\n0.14\n0.05\n-0.03\n0.06\n0.69\n1.00\n-0.04\n0.15\n-0.26\n-0.02\n0.20\n\n\navg_bedroom\n0.01\n0.07\n-0.08\n0.03\n0.04\n-0.07\n-0.06\n-0.06\n-0.04\n1.00\n0.86\n0.05\n-0.01\n0.84\n\n\navg_room\n-0.03\n0.11\n-0.15\n0.13\n0.00\n-0.07\n-0.08\n0.31\n0.15\n0.86\n1.00\n-0.40\n-0.01\n0.90\n\n\nbedroom_per_room\n0.10\n-0.12\n0.14\n-0.19\n0.09\n0.04\n0.07\n-0.62\n-0.26\n0.05\n-0.40\n1.00\n0.00\n-0.26\n\n\npopulation_per_household\n-0.00\n0.01\n0.02\n-0.02\n-0.03\n0.08\n-0.03\n0.02\n-0.02\n-0.01\n-0.01\n0.00\n1.00\n-0.05\n\n\nroom_per_popoulation\n-0.07\n0.14\n-0.10\n0.12\n0.05\n-0.14\n-0.04\n0.23\n0.20\n0.84\n0.90\n-0.26\n-0.05\n1.00\n\n\n\n\n\n\ncorr_matrix['median_house_value'].sort_values(ascending=True)\n\nbedroom_per_room           -0.259984\nlatitude                   -0.142724\nlongitude                  -0.047432\navg_bedroom                -0.043343\npopulation                 -0.026920\npopulation_per_household   -0.021985\ntotal_bedrooms              0.047689\nhouseholds                  0.064506\nhousing_median_age          0.114110\ntotal_rooms                 0.135097\navg_room                    0.146285\nroom_per_popoulation        0.199429\nmedian_income               0.687160\nmedian_house_value          1.000000\nName: median_house_value, dtype: float64\n\n\nThis is interesting! We see that bedroom_per_room is another potential descriptor with negative corelation moreover we get room_per_population and avg_room to be decent new descriptors for the median_house_value. Not bad for a simple math manipulation to better represent the data. This is a crucial step and where domain knowledge and intuition would come handy.\n\n\nData cleaning and prepping\n\nSeparate the predictors and the target values\nWrite functions to conduct various data transformations ensuring consistency and ease\nMake sure the data is devoid of any NaN values since that would raise warning and errors. We have three strategies we can implement here:\n\nGet rid of those points (districts) entirely\nGet rid of whole attribute\nSet missing values to either zero or one of the averages (mean, median, or mode)\n\n\nIn our case, total bedrooms had some missing values.\n# Option a:\nhousing.dropna(subset=[\"total_bedrooms\"])\n# Option b:\nhousing.drop(\"total_bedrooms\", axis=1)\n# Option c:\nmedian = housing[\"total_bedrooms\"].median()\nhousing[\"total_bedrooms\"].fillna(median, inplace=True) # option 3\nBefore we do any of this let’s first separate the predictor and target_values\n\nhousing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\nhousing_labels = strat_train_set[\"median_house_value\"].copy()\n\n\n#Checking the NULL enties in the dataset\nsample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\nsample_incomplete_rows\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nocean_proximity\n\n\n\n\n4629\n-118.30\n34.07\n18.0\n3759.0\nNaN\n3296.0\n1462.0\n2.2708\n&lt;1H OCEAN\n\n\n6068\n-117.86\n34.01\n16.0\n4632.0\nNaN\n3038.0\n727.0\n5.1762\n&lt;1H OCEAN\n\n\n17923\n-121.97\n37.35\n30.0\n1955.0\nNaN\n999.0\n386.0\n4.6328\n&lt;1H OCEAN\n\n\n13656\n-117.30\n34.05\n6.0\n2155.0\nNaN\n1039.0\n391.0\n1.6675\nINLAND\n\n\n19252\n-122.79\n38.48\n7.0\n6837.0\nNaN\n3468.0\n1405.0\n3.1662\n&lt;1H OCEAN\n\n\n\n\n\n\n\n\nsample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # option 1\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nocean_proximity\n\n\n\n\n\n\n\n\n\n\nsample_incomplete_rows.drop(\"total_bedrooms\", axis=1)   #option 2\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\npopulation\nhouseholds\nmedian_income\nocean_proximity\n\n\n\n\n4629\n-118.30\n34.07\n18.0\n3759.0\n3296.0\n1462.0\n2.2708\n&lt;1H OCEAN\n\n\n6068\n-117.86\n34.01\n16.0\n4632.0\n3038.0\n727.0\n5.1762\n&lt;1H OCEAN\n\n\n17923\n-121.97\n37.35\n30.0\n1955.0\n999.0\n386.0\n4.6328\n&lt;1H OCEAN\n\n\n13656\n-117.30\n34.05\n6.0\n2155.0\n1039.0\n391.0\n1.6675\nINLAND\n\n\n19252\n-122.79\n38.48\n7.0\n6837.0\n3468.0\n1405.0\n3.1662\n&lt;1H OCEAN\n\n\n\n\n\n\n\n\nmedian = housing[\"total_bedrooms\"].median()\nsample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # option 3\nsample_incomplete_rows\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nocean_proximity\n\n\n\n\n4629\n-118.30\n34.07\n18.0\n3759.0\n433.0\n3296.0\n1462.0\n2.2708\n&lt;1H OCEAN\n\n\n6068\n-117.86\n34.01\n16.0\n4632.0\n433.0\n3038.0\n727.0\n5.1762\n&lt;1H OCEAN\n\n\n17923\n-121.97\n37.35\n30.0\n1955.0\n433.0\n999.0\n386.0\n4.6328\n&lt;1H OCEAN\n\n\n13656\n-117.30\n34.05\n6.0\n2155.0\n433.0\n1039.0\n391.0\n1.6675\nINLAND\n\n\n19252\n-122.79\n38.48\n7.0\n6837.0\n433.0\n3468.0\n1405.0\n3.1662\n&lt;1H OCEAN\n\n\n\n\n\n\n\n\nScikit-learn imputer class\nThis is a handy class to take of missing values. First, we create an instance of that class with specifying what is to be replaced and what strategy is used. Before doing so, we need to make srue the entire data-set has ONLY numerical entries and Imputer will evaluate the given average for all the dataset and store it in the statistics_ instance\nWhat the imputer will do is, 1. Evaluate an specified type of average. 2. For a given numerical data-set look for NaN or Null entires in a given attribute and replace it with the computed avearge for that attribute\n\ntry:\n    from sklearn.impute import SimpleImputer # Scikit-Learn 0.20+\nexcept ImportError:\n    from sklearn.preprocessing import Imputer as SimpleImputer\n\nimputer = SimpleImputer(strategy=\"median\") #We define the strategy here \nhousing_num = housing.drop('ocean_proximity', axis=1)\n# alternatively: housing_num = housing.select_dtypes(include=[np.number])\n\n\nimputer.fit(housing_num)\n\nSimpleImputer(strategy='median')\n\n\n\nimputer.statistics_\n\narray([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,\n        408.    ,    3.5409])\n\n\n\nhousing_num.median().values\n\narray([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,\n        408.    ,    3.5409])\n\n\nWe can now use this as a training variables set for our model\n\nX = imputer.transform(housing_num)\n\nWe convert the Pandas dataframe entries to a numpy array which is transformed with appropriately replacing the missing entries with median.\n\nprint(type(X), type(housing_num))\n\n&lt;class 'numpy.ndarray'&gt; &lt;class 'pandas.core.frame.DataFrame'&gt;\n\n\n\nprint(np.shape(X), housing_num.shape)\n'''\nIf we need the data-frame back\nhousing_tr = pd.DataFrame(X, columns=housing_num.columns,\n                          index=housing.index)\n'''\n\n(16512, 8) (16512, 8)\n\n\n'\\nIf we need the data-frame back\\nhousing_tr = pd.DataFrame(X, columns=housing_num.columns,\\n                          index=housing.index)\\n'\n\n\n\n\n\nHandling Text and Categorical Attribute\nNow let’s preprocess the categorical input feature, ocean_proximity:\n\nhousing_cat = housing[['ocean_proximity']]\ntype(housing_cat)\n\npandas.core.frame.DataFrame\n\n\nConverting the categorical entries to integers\n\ntry:\n    from sklearn.preprocessing import OrdinalEncoder\nexcept ImportError:\n    from future_encoders import OrdinalEncoder # Scikit-Learn &lt; 0.20\n    \nordinal_encoder = OrdinalEncoder()\nhousing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\nhousing_cat_encoded[:10]\n\narray([[0.],\n       [0.],\n       [4.],\n       [1.],\n       [0.],\n       [1.],\n       [0.],\n       [1.],\n       [0.],\n       [0.]])\n\n\n\nhousing[\"ocean_proximity\"].value_counts()\n\n&lt;1H OCEAN     7276\nINLAND        5263\nNEAR OCEAN    2124\nNEAR BAY      1847\nISLAND           2\nName: ocean_proximity, dtype: int64\n\n\nNow, housing_cat_encoded has converted the categorical entries to purely numerical values for each category\n\nordinal_encoder.categories_\n\n[array(['&lt;1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n       dtype=object)]\n\n\nNow, this is helpful with the string categories getting converted to numerical categories. However, there is still an small issue. The categorical numbering may introduce some bias in the final model. ML algorithms will assume that two nearby values are more similar than two distant values.\nIn the above case, ‘&lt;1H OCEAN’ and ‘INLAND’have category values as 0 and 1 however’&lt;1H OCEAN’ is more closer to ‘NEAR OCEAN’ with category value 4.\nTo fix this issue, one solution is to create one binary attribute per category. This is called One-hot encoding as ONLY one of the attribute in the vector is 1 (hot) and others are 0 (cold).\nScikit-learn provides a OneHotEncoder encoder to convert integer categorical values to one-hot vectors.\n\ntry:\n    from sklearn.preprocessing import OrdinalEncoder # just to raise an ImportError if Scikit-Learn &lt; 0.20\n    from sklearn.preprocessing import OneHotEncoder\nexcept ImportError:\n    from future_encoders import OneHotEncoder # Scikit-Learn &lt; 0.20\n\ncat_encoder = OneHotEncoder()\n#1-Hot encoded vector for the housing training data-set \nhousing_cat_1hot = cat_encoder.fit_transform(housing_cat)\ntype(housing_cat_1hot)\n\nscipy.sparse.csr.csr_matrix\n\n\nA sparse array is declared in this case which has the position of the non-zero value and not necessarily the entire numpy matrix. This is helpful in the cases where there are too many categories and also many datapoints. For examples, if we have 4 categories and 1000 datapoints the final one-hot matrix would be 1000x4 size. Most of that would be full of 0s, with only one 1 per row for a particular category.\nThe housing_cat_1hot can be converted to numpy array by using the housing_cat_1hot.toarray()\nAlternatively, you can set sparse=False when creating the OneHotEncoder\n\ncat_encoder.categories_\n\n[array(['&lt;1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n       dtype=object)]\n\n\nLet’s create a custom transformer to add extra attributes:\n\nhousing.columns\n\nIndex(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n       'total_bedrooms', 'population', 'households', 'median_income',\n       'ocean_proximity'],\n      dtype='object')\n\n\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n# get the right column indices: safer than hard-coding indices\nrooms_ix, bedrooms_ix, population_ix, household_ix = [\n    list(housing.columns).index(col) for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n\n#Here we convert the housing.columns to list and \n#then find the index for the entry which matches the string in the loop \n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True): # no *args or **kwargs\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    def fit(self, X, y=None):\n        return self  # nothing else to do\n    def transform(self, X, y=None):\n        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n        population_per_household = X[:, population_ix] / X[:, household_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household,\n                         bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]\n\nattr_adder = CombinedAttributesAdder(add_bedrooms_per_room=True)\nhousing_extra_attribs = attr_adder.transform(housing.values)\n\nFrom the above class, there’s only one hyperparameter in the class. add_bedrooms_per_room is the only option and is set True by default. Let’s check the new feature space by converting it to a Pandas Dataframe\n\nhousing_extra_attribs = pd.DataFrame(\n    housing_extra_attribs,\n    columns=list(housing.columns)+[\"bedrooms_per_room\",\"rooms_per_household\", \"population_per_household\"],\n    index=housing.index)\nhousing_extra_attribs.head()\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nhousing_median_age\ntotal_rooms\ntotal_bedrooms\npopulation\nhouseholds\nmedian_income\nocean_proximity\nbedrooms_per_room\nrooms_per_household\npopulation_per_household\n\n\n\n\n17606\n-121.89\n37.29\n38.0\n1568.0\n351.0\n710.0\n339.0\n2.7042\n&lt;1H OCEAN\n4.625369\n2.094395\n0.223852\n\n\n18632\n-121.93\n37.05\n14.0\n679.0\n108.0\n306.0\n113.0\n6.4214\n&lt;1H OCEAN\n6.00885\n2.707965\n0.159057\n\n\n14650\n-117.2\n32.77\n31.0\n1952.0\n471.0\n936.0\n462.0\n2.8621\nNEAR OCEAN\n4.225108\n2.025974\n0.241291\n\n\n3230\n-119.61\n36.31\n25.0\n1847.0\n371.0\n1460.0\n353.0\n1.8839\nINLAND\n5.232295\n4.135977\n0.200866\n\n\n3555\n-118.59\n34.23\n17.0\n6592.0\n1525.0\n4459.0\n1463.0\n3.0347\n&lt;1H OCEAN\n4.50581\n3.047847\n0.231341\n\n\n\n\n\n\n\n\n\nFeature scaling\nFeaature scaling is an important transformation needed to be applied to the data. With some exceptions, ML algorithms dont perform well when the input numerical entries have very different scales. Eg: One variable has range 0-1 but other variable has range 1-1000. This is the case in our data-base where the total number of rooms range from 6 to 39,320 while the objective variable i.e. median income only ranges from 0-15. Two common ways of scaling:\n\nMin-max scaling (also called Normalization) Values are shifted such that they are normalized. They are rescaled in the range of 0-1. We do this by subtracting the min value and dividing by the range in the data \\[\\begin{equation}\nx_{i} = \\frac{X_{i}-min}{max-min}\n\\end{equation}\\]\nStandardization This is when the mean of the dataset is subtracted from each entry so that the data has mean as 0 and then divided by the standard deviation so that the resulting distribution has a unit variance. Unlike min-max scaling, standardization does not bound to a particular range like 0-1. However, standardisation is much less affected by outliers. If a particular values is extremely high or low that could affect the other inputs in the case of min-max scaling. However that effect is reduced in the case of standardization given it does not directly account for the range in the scaling but the mean and variance. \\[\\begin{equation}\nx_{i} = \\frac{X_{i}-\\mu}{\\sigma}\n\\end{equation}\\]\n\n\nNOTE: It is important that these scaling operations are performed on the training data only and not on the full dataset\n\n\n\nTransformation pipelines\nPipeline class in scikit-learn can help with sequences of transformations. Now let’s build a pipeline for preprocessing the numerical attributes (note that we could use CombinedAttributesAdder() instead of FunctionTransformer(...) if we preferred):\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")), #Fill in missing values using the median of each entry \n        ('attribs_adder', CombinedAttributesAdder(add_bedrooms_per_room=True)), #Add additional columns entrys\n        ('std_scaler', StandardScaler()), #Feature scaling -- using standardisation here \n    ])\n\nhousing_num_tr = num_pipeline.fit_transform(housing_num)\n\n\nhousing_num_tr\n\narray([[-1.15604281,  0.77194962,  0.74333089, ..., -0.31205452,\n        -0.08649871,  0.15531753],\n       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.21768338,\n        -0.03353391, -0.83628902],\n       [ 1.18684903, -1.34218285,  0.18664186, ..., -0.46531516,\n        -0.09240499,  0.4222004 ],\n       ...,\n       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.3469342 ,\n        -0.03055414, -0.52177644],\n       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.02499488,\n         0.06150916, -0.30340741],\n       [-1.43579109,  0.99645926,  1.85670895, ..., -0.22852947,\n        -0.09586294,  0.10180567]])\n\n\nThis Pipeline constructor takes a list of name/estimator pairs defining a sequence of steps. All but the last step/estimator must be the trasnformers (like feature scaling).\n\ntry:\n    from sklearn.compose import ColumnTransformer\nexcept ImportError:\n    from future_encoders import ColumnTransformer # Scikit-Learn &lt; 0.20\n\nNow let’s join all these components into a big pipeline that will preprocess both the numerical and the categorical features (again, we could use CombinedAttributesAdder() instead of FunctionTransformer(...) if we preferred):\n\nnum_attribs = list(housing_num)\ncat_attribs = [\"ocean_proximity\"]\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs),\n    ])\n\nhousing_prepared = full_pipeline.fit_transform(housing)\n\n\nhousing_prepared\n\narray([[-1.15604281,  0.77194962,  0.74333089, ...,  0.        ,\n         0.        ,  0.        ],\n       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 1.18684903, -1.34218285,  0.18664186, ...,  0.        ,\n         0.        ,  1.        ],\n       ...,\n       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.        ,\n         0.        ,  0.        ],\n       [-1.43579109,  0.99645926,  1.85670895, ...,  0.        ,\n         1.        ,  0.        ]])\n\n\n\nhousing_prepared.shape\n\n(16512, 16)\n\n\n\n\nStep 3: Select and train a model\nFinally.\n\nTraining and evaluation on the training set\nGiven the prioir transformations, the features are scaled, categories are converted to one-hot vectors, and the missing variables are taken account of. Let’s train a Linear Regression model first\n\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression() \nlin_reg.fit(housing_prepared, housing_labels)\n\nLinearRegression()\n\n\n\n#Test some data out on the model \ntrial_input = housing.iloc[:5] #First 5 entries \ntrial_label = housing_labels.iloc[:5] #First 5 labels corresponding to the entries \nprep_trial_input = full_pipeline.transform(trial_input) #Transforming the entries to suit the trained input \nprint('Predictions:',lin_reg.predict(prep_trial_input))\n\nPredictions: [210644.60459286 317768.80697211 210956.43331178  59218.98886849\n 189747.55849879]\n\n\n\nprint('Labels:',list(trial_label))\n\nLabels: [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n\n\n\nfrom sklearn.metrics import mean_squared_error\n\nhousing_predictions = lin_reg.predict(housing_prepared)\nlin_mse = mean_squared_error(housing_labels, housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse\n\n68628.19819848923\n\n\n\nhousing_labels.describe()\n\ncount     16512.000000\nmean     206990.920724\nstd      115703.014830\nmin       14999.000000\n25%      119800.000000\n50%      179500.000000\n75%      263900.000000\nmax      500001.000000\nName: median_house_value, dtype: float64\n\n\nAs seen the RMSE is 68628 which is better than nothing but still it is quite high when the range of the median_house_values range from 15000 to 500000\n\nfrom sklearn.metrics import mean_absolute_error\n\nlin_mae = mean_absolute_error(housing_labels, housing_predictions)\nlin_mae\n\n49439.89599001897\n\n\nHere the model is underfitting the data since the RMSE is so high. &gt; When this happens either the features do not provide enough information to make good predictions or the model is not powerful enough.\nLet’s try using a more complex model, DecisionTreeRegressor which is capable of finding non-linear relationships in the data\n\n\nDecision Tree Regressor\n\nfrom sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor(random_state=42)\ntree_reg.fit(housing_prepared, housing_labels)\n\nDecisionTreeRegressor(random_state=42)\n\n\n\nhousing_predictions = tree_reg.predict(housing_prepared)\ntree_mse = mean_squared_error(housing_labels, housing_predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse\n\n0.0\n\n\nLOL!\nThis model is badly overfitting the data! Let’s proof this hypothesis using cross-validation schemes. We dont want to touch the test set, JUST WORK WITH THE TRAINING SET. Only touch the test set when the model we are using is good enough. We will use the part of the training set for training and other part for model validation.\n\n\nFine-tune the model\nCross-validation\nCross-validation is a method of getting reliable estimate of model performance using only the training data 10-fold cross-validation — breaking training data in 10 equal parts creating 10 miniature test/train splits. Out of the 10 folds, train data on 9 and test on 10th. Do this 10 times each time holding out different fold.\n\nScikit-learn cross-validation feature expects a utility function (greater the better) rather than a cost function (lower the better), so to score the functions we use opposite of MSE, which is why we again compute -scores before calculating the square root\n\n\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n                         scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)\n\n\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())\n\ndisplay_scores(tree_rmse_scores)\n\nScores: [70194.33680785 66855.16363941 72432.58244769 70758.73896782\n 71115.88230639 75585.14172901 70262.86139133 70273.6325285\n 75366.87952553 71231.65726027]\nMean: 71407.68766037929\nStandard deviation: 2439.4345041191004\n\n\nCross-validation not only allows us to get an estimate of the performance of the model but also the measure of how precise this estimate is (i.e. standard deviation). The Decision tree has high std-dev. This information could not be obtained with just one validation set. However, caveat is that cross-validation comes at the cost of training the model several times, so it is not always possible.\nLet’s compute the same score for LinearRegresson model.\n\nlin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n                             scoring=\"neg_mean_squared_error\", cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)\n\nScores: [66782.73843989 66960.118071   70347.95244419 74739.57052552\n 68031.13388938 71193.84183426 64969.63056405 68281.61137997\n 71552.91566558 67665.10082067]\nMean: 69052.46136345083\nStandard deviation: 2731.674001798342\n\n\nHere it can be seen that DecisionTree model performs much worse than the LinearRegression model.\n\n\nRandom Forrest Regressor\nRandom forrest works by employing many decision trees on random subsets of the features, then averaging out their predictions. Building a model on top of many other models is called Ensemble Learning and it is often great way to push ML algorithms even further.\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\nforest_reg.fit(housing_prepared, housing_labels)\n\nRandomForestRegressor(n_estimators=10, random_state=42)\n\n\n\nNote: we specify n_estimators=10 to avoid a warning about the fact that the default value is going to change to 100 in Scikit-Learn 0.22.\n\n\nhousing_predictions = forest_reg.predict(housing_prepared)\nforest_mse = mean_squared_error(housing_labels, housing_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse\n\n21933.31414779769\n\n\n\nfrom sklearn.model_selection import cross_val_score\n\nforest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n                                scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)\n\nScores: [51646.44545909 48940.60114882 53050.86323649 54408.98730149\n 50922.14870785 56482.50703987 51864.52025526 49760.85037653\n 55434.21627933 53326.10093303]\nMean: 52583.72407377466\nStandard deviation: 2298.353351147122\n\n\nRandom forest regressor looks better than DecisionTree and LinearRegression. The RMSE is still quite high for production quality code and could be due to overfitting. We can try other algorithms before spending time on a particular algorithm tweaking the hyperparameters. The goal is to shortlist 2-3 methods that are promising then fine-tune the model. Before we move ahead we can take a look at one more ML algorithm which is commonly employed for such supervised learning cases: Support Vector Regression\n\nfrom sklearn.svm import SVR\n\nsvm_reg = SVR(kernel=\"linear\")\nsvm_reg.fit(housing_prepared, housing_labels)\nhousing_predictions = svm_reg.predict(housing_prepared)\nsvm_mse = mean_squared_error(housing_labels, housing_predictions)\nsvm_rmse = np.sqrt(svm_mse)\nsvm_rmse\n\n111094.6308539982\n\n\n\n\n\nStep 4: Fine-tune the model\nOnce we settle for an algorithm we can fine-tune them efficiently using some of the in-built scikit-learn routines.\n\nGrid Search\nGridSearchCV is a faster way of tweaking the hyper-parameters for a given algorithm. It needs the hyper-parameters you want to experiment with, what values to try out, and it will evaluate possible combination of hyperparameters values using cross-validation. We can do that step for RandomForrestRegressor which we found to have lowesst RMSE of the three methods we tried\n\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    # try 12 (3×4) combinations of hyperparameters\n    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n    # then try 6 (2×3) combinations with bootstrap set as False\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n  ]\n\nforest_reg = RandomForestRegressor(random_state=42)\n\n# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error', return_train_score=True)\ngrid_search.fit(housing_prepared, housing_labels)\n\nGridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n             param_grid=[{'max_features': [2, 4, 6, 8],\n                          'n_estimators': [3, 10, 30]},\n                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n                          'n_estimators': [3, 10]}],\n             return_train_score=True, scoring='neg_mean_squared_error')\n\n\nThe param_grid tells Scikit-learn to: 1. First evaluate 3x4 combinations of n_estimators and max_features with bootstrap True which is the default. 2. Then with bootstrap set as False we look for 2x3 combinations of n_estimators and max_featurs for the random forest 3. Finally, both these models are trained 5 times for the cross validation purposes in a 5-fold cross-validation fashion.\nTotal of (12+6)x5=90 round of training are conducted. Finally when it is done we get the best model parameters which give lowest RMSE.\n\ngrid_search.best_params_\n\n{'max_features': 8, 'n_estimators': 30}\n\n\n\ngrid_search.best_estimator_\n\nRandomForestRegressor(max_features=8, n_estimators=30, random_state=42)\n\n\n\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)\n\n63669.11631261028 {'max_features': 2, 'n_estimators': 3}\n55627.099719926795 {'max_features': 2, 'n_estimators': 10}\n53384.57275149205 {'max_features': 2, 'n_estimators': 30}\n60965.950449450494 {'max_features': 4, 'n_estimators': 3}\n52741.04704299915 {'max_features': 4, 'n_estimators': 10}\n50377.40461678399 {'max_features': 4, 'n_estimators': 30}\n58663.93866579625 {'max_features': 6, 'n_estimators': 3}\n52006.19873526564 {'max_features': 6, 'n_estimators': 10}\n50146.51167415009 {'max_features': 6, 'n_estimators': 30}\n57869.25276169646 {'max_features': 8, 'n_estimators': 3}\n51711.127883959234 {'max_features': 8, 'n_estimators': 10}\n49682.273345071546 {'max_features': 8, 'n_estimators': 30}\n62895.06951262424 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n54658.176157539405 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n59470.40652318466 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n52724.9822587892 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n57490.5691951261 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n51009.495668875716 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n\n\n\npd.DataFrame(grid_search.cv_results_)\n\n\n\n\n\n\n\n\nmean_fit_time\nstd_fit_time\nmean_score_time\nstd_score_time\nparam_max_features\nparam_n_estimators\nparam_bootstrap\nparams\nsplit0_test_score\nsplit1_test_score\n...\nmean_test_score\nstd_test_score\nrank_test_score\nsplit0_train_score\nsplit1_train_score\nsplit2_train_score\nsplit3_train_score\nsplit4_train_score\nmean_train_score\nstd_train_score\n\n\n\n\n0\n0.053401\n0.002499\n0.003312\n0.000173\n2\n3\nNaN\n{'max_features': 2, 'n_estimators': 3}\n-3.837622e+09\n-4.147108e+09\n...\n-4.053756e+09\n1.519591e+08\n18\n-1.064113e+09\n-1.105142e+09\n-1.116550e+09\n-1.112342e+09\n-1.129650e+09\n-1.105559e+09\n2.220402e+07\n\n\n1\n0.182488\n0.002683\n0.010123\n0.001727\n2\n10\nNaN\n{'max_features': 2, 'n_estimators': 10}\n-3.047771e+09\n-3.254861e+09\n...\n-3.094374e+09\n1.327062e+08\n11\n-5.927175e+08\n-5.870952e+08\n-5.776964e+08\n-5.716332e+08\n-5.802501e+08\n-5.818785e+08\n7.345821e+06\n\n\n2\n0.503301\n0.010947\n0.024532\n0.000476\n2\n30\nNaN\n{'max_features': 2, 'n_estimators': 30}\n-2.689185e+09\n-3.021086e+09\n...\n-2.849913e+09\n1.626875e+08\n9\n-4.381089e+08\n-4.391272e+08\n-4.371702e+08\n-4.376955e+08\n-4.452654e+08\n-4.394734e+08\n2.966320e+06\n\n\n3\n0.081569\n0.001284\n0.003247\n0.000154\n4\n3\nNaN\n{'max_features': 4, 'n_estimators': 3}\n-3.730181e+09\n-3.786886e+09\n...\n-3.716847e+09\n1.631510e+08\n16\n-9.865163e+08\n-1.012565e+09\n-9.169425e+08\n-1.037400e+09\n-9.707739e+08\n-9.848396e+08\n4.084607e+07\n\n\n4\n0.269809\n0.005145\n0.008730\n0.000133\n4\n10\nNaN\n{'max_features': 4, 'n_estimators': 10}\n-2.666283e+09\n-2.784511e+09\n...\n-2.781618e+09\n1.268607e+08\n8\n-5.097115e+08\n-5.162820e+08\n-4.962893e+08\n-5.436192e+08\n-5.160297e+08\n-5.163863e+08\n1.542862e+07\n\n\n5\n0.800619\n0.007793\n0.024065\n0.000543\n4\n30\nNaN\n{'max_features': 4, 'n_estimators': 30}\n-2.387153e+09\n-2.588448e+09\n...\n-2.537883e+09\n1.214614e+08\n3\n-3.838835e+08\n-3.880268e+08\n-3.790867e+08\n-4.040957e+08\n-3.845520e+08\n-3.879289e+08\n8.571233e+06\n\n\n6\n0.113473\n0.004140\n0.003330\n0.000178\n6\n3\nNaN\n{'max_features': 6, 'n_estimators': 3}\n-3.119657e+09\n-3.586319e+09\n...\n-3.441458e+09\n1.893056e+08\n14\n-9.245343e+08\n-8.886939e+08\n-9.353135e+08\n-9.009801e+08\n-8.624664e+08\n-9.023976e+08\n2.591445e+07\n\n\n7\n0.378872\n0.014358\n0.009405\n0.001258\n6\n10\nNaN\n{'max_features': 6, 'n_estimators': 10}\n-2.549663e+09\n-2.782039e+09\n...\n-2.704645e+09\n1.471569e+08\n6\n-4.980344e+08\n-5.045869e+08\n-4.994664e+08\n-4.990325e+08\n-5.055542e+08\n-5.013349e+08\n3.100456e+06\n\n\n8\n1.222785\n0.030201\n0.027815\n0.001110\n6\n30\nNaN\n{'max_features': 6, 'n_estimators': 30}\n-2.370010e+09\n-2.583638e+09\n...\n-2.514673e+09\n1.285080e+08\n2\n-3.838538e+08\n-3.804711e+08\n-3.805218e+08\n-3.856095e+08\n-3.901917e+08\n-3.841296e+08\n3.617057e+06\n\n\n9\n0.146751\n0.002996\n0.003320\n0.000174\n8\n3\nNaN\n{'max_features': 8, 'n_estimators': 3}\n-3.353504e+09\n-3.348552e+09\n...\n-3.348850e+09\n1.241939e+08\n13\n-9.228123e+08\n-8.553031e+08\n-8.603321e+08\n-8.881964e+08\n-9.151287e+08\n-8.883545e+08\n2.750227e+07\n\n\n10\n0.510138\n0.016372\n0.009396\n0.000904\n8\n10\nNaN\n{'max_features': 8, 'n_estimators': 10}\n-2.571970e+09\n-2.718994e+09\n...\n-2.674041e+09\n1.392777e+08\n5\n-4.932416e+08\n-4.815238e+08\n-4.730979e+08\n-5.155367e+08\n-4.985555e+08\n-4.923911e+08\n1.459294e+07\n\n\n11\n1.518905\n0.056501\n0.025125\n0.001086\n8\n30\nNaN\n{'max_features': 8, 'n_estimators': 30}\n-2.357390e+09\n-2.546640e+09\n...\n-2.468328e+09\n1.091662e+08\n1\n-3.841658e+08\n-3.744500e+08\n-3.773239e+08\n-3.882250e+08\n-3.810005e+08\n-3.810330e+08\n4.871017e+06\n\n\n12\n0.077979\n0.001837\n0.003983\n0.000390\n2\n3\nFalse\n{'bootstrap': False, 'max_features': 2, 'n_est...\n-3.785816e+09\n-4.166012e+09\n...\n-3.955790e+09\n1.900964e+08\n17\n-0.000000e+00\n-0.000000e+00\n-0.000000e+00\n-0.000000e+00\n-0.000000e+00\n0.000000e+00\n0.000000e+00\n\n\n13\n0.259085\n0.003267\n0.010411\n0.000311\n2\n10\nFalse\n{'bootstrap': False, 'max_features': 2, 'n_est...\n-2.810721e+09\n-3.107789e+09\n...\n-2.987516e+09\n1.539234e+08\n10\n-6.056477e-02\n-0.000000e+00\n-0.000000e+00\n-0.000000e+00\n-2.967449e+00\n-6.056027e-01\n1.181156e+00\n\n\n14\n0.104454\n0.004167\n0.003841\n0.000315\n3\n3\nFalse\n{'bootstrap': False, 'max_features': 3, 'n_est...\n-3.618324e+09\n-3.441527e+09\n...\n-3.536729e+09\n7.795057e+07\n15\n-0.000000e+00\n-0.000000e+00\n-0.000000e+00\n-0.000000e+00\n-6.072840e+01\n-1.214568e+01\n2.429136e+01\n\n\n15\n0.345978\n0.004147\n0.010372\n0.000444\n3\n10\nFalse\n{'bootstrap': False, 'max_features': 3, 'n_est...\n-2.757999e+09\n-2.851737e+09\n...\n-2.779924e+09\n6.286720e+07\n7\n-2.089484e+01\n-0.000000e+00\n-0.000000e+00\n-0.000000e+00\n-5.465556e+00\n-5.272080e+00\n8.093117e+00\n\n\n16\n0.135484\n0.015839\n0.004140\n0.000585\n4\n3\nFalse\n{'bootstrap': False, 'max_features': 4, 'n_est...\n-3.134040e+09\n-3.559375e+09\n...\n-3.305166e+09\n1.879165e+08\n12\n-0.000000e+00\n-0.000000e+00\n-0.000000e+00\n-0.000000e+00\n-0.000000e+00\n0.000000e+00\n0.000000e+00\n\n\n17\n0.453605\n0.013427\n0.010725\n0.000358\n4\n10\nFalse\n{'bootstrap': False, 'max_features': 4, 'n_est...\n-2.525578e+09\n-2.710011e+09\n...\n-2.601969e+09\n1.088048e+08\n4\n-0.000000e+00\n-1.514119e-02\n-0.000000e+00\n-0.000000e+00\n-0.000000e+00\n-3.028238e-03\n6.056477e-03\n\n\n\n\n18 rows × 23 columns\n\n\n\n\n\nRandomised search\nGrid search approach is fine when we are exploring relatively few combinations. But when hyperparameter space is large it is often preferrable to use RandomizedSearchCV instead. Here instead of doing all the possible combinationes of hyperparameters, it evaluates a given number of random combinations by selecting a random value for each hyper parameter at every iteration.\n\n\nEnsemble search\nCombine models that perform best. The group or ‘ensemble’ will often perform better than the best individual model just like RandomForest peforms better than Decision Trees especially if we have individual models make different types of errors.\n\n\n\nStep 5: Analyze the Best Models and their Errors\nRandomForestRegressor can indicate the relative importance of each attribute for making the accurate predictions.\n\nfeature_importances = grid_search.best_estimator_.feature_importances_\nfeature_importances\n\narray([7.33442355e-02, 6.29090705e-02, 4.11437985e-02, 1.46726854e-02,\n       1.41064835e-02, 1.48742809e-02, 1.42575993e-02, 3.66158981e-01,\n       5.64191792e-02, 1.08792957e-01, 5.33510773e-02, 1.03114883e-02,\n       1.64780994e-01, 6.02803867e-05, 1.96041560e-03, 2.85647464e-03])\n\n\n\nextra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\ncat_encoder = full_pipeline.named_transformers_[\"cat\"]\ncat_one_hot_attribs = list(cat_encoder.categories_[0])\nattributes = num_attribs + extra_attribs + cat_one_hot_attribs\nsorted(zip(feature_importances, attributes), reverse=True)\n\n[(0.36615898061813423, 'median_income'),\n (0.16478099356159054, 'INLAND'),\n (0.10879295677551575, 'pop_per_hhold'),\n (0.07334423551601243, 'longitude'),\n (0.06290907048262032, 'latitude'),\n (0.056419179181954014, 'rooms_per_hhold'),\n (0.053351077347675815, 'bedrooms_per_room'),\n (0.04114379847872964, 'housing_median_age'),\n (0.014874280890402769, 'population'),\n (0.014672685420543239, 'total_rooms'),\n (0.014257599323407808, 'households'),\n (0.014106483453584104, 'total_bedrooms'),\n (0.010311488326303788, '&lt;1H OCEAN'),\n (0.0028564746373201584, 'NEAR OCEAN'),\n (0.0019604155994780706, 'NEAR BAY'),\n (6.0280386727366e-05, 'ISLAND')]\n\n\n\n\nStep 6: Evaluate the model on the Test Set\n\nfinal_model = grid_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1)\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)\nfinal_predictions = final_model.predict(X_test_prepared)\n\n\nfig, ax = plt.subplots(1,1, figsize=(8,8))\nax.scatter(y_test, final_predictions, s=100)\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n       ]\n\nax.plot(lims, lims, 'k--', linewidth=2.0, alpha=0.75, zorder=0)\nax.set_aspect('equal')\nax.set_xlim(lims)\nax.set_ylim(lims)\n\nax.set_xlabel('ML Prediction')\nax.set_ylabel('Actual Value')\n\nText(0, 0.5, 'Actual Value')\n\n\n\n\n\n\n\n\n\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)\nprint(final_rmse)\n\n47730.22690385927\n\n\nWe can compute a 95% confidence interval for the test RMSE:\n\nfrom scipy import stats\nconfidence = 0.95\nsquared_errors = (final_predictions - y_test) ** 2\nmean = squared_errors.mean()\nm = len(squared_errors)\n\nnp.sqrt(stats.t.interval(confidence, m - 1,\n                         loc=np.mean(squared_errors),\n                         scale=stats.sem(squared_errors)))\n\narray([45685.10470776, 49691.25001878])\n\n\nAlternatively, we could use a z-scores rather than t-scores:\n\nzscore = stats.norm.ppf((1 + confidence) / 2)\nzmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(m)\nnp.sqrt(mean - zmargin), np.sqrt(mean + zmargin)\n\n(45685.717918136594, 49690.68623889426)"
  },
  {
    "objectID": "posts/2021-09-10-ML_checklit.html",
    "href": "posts/2021-09-10-ML_checklit.html",
    "title": "Model building checklist",
    "section": "",
    "text": "Learn about your data\n\n\nType of the data being analyzed\n\nIs the data set, sensor measure-reading what you think it is measuring\nDsitribution of the data / target\nOutliers in the data\n\n\nSingle variables\n\n\nType – continuous, discreet, categorical\nDistribution in the data\nScale of each variable\nWhat is the resolution I am interested in?\nOutliers in the variables\n\n\nFeature correlations\n\n\nStart simple – linear correlation\nUse domain knowledge and see if they make sense\nLook at subset of the data to make it tractable / subsampling\n\n\nSelection and feature engineering\n\n\nMake new (better?) features combining the orginal features\nRecast, resample, forward difference, simple arthimatic operations\n\n\n\n\n\nSplit in train and test – look at target prop statistics\nSplit train into CV or train / validation\nTrain models on the training data: - Linear model - Non linear models - Ensemble models - Decision models\nModel hyperparameters\n\n\n\n\n\nTrain on full training dataset\nAvenues of data bleed\nSplit quality - is the train/validation data representative of test data / real-life data?\n\n\n\n\n\nWhat is the source of the data (database, publication, direct experiment)?\nHow many data points are in the training, validation and test sets?\nHow were the sets split? Is any bias being introduced based on the type of split?\nAre the data, including the data splits used, released in a public forum?\nHow were the data encoded and preprocessed for the ML algorithm?\nHow many parameters (p) are used in the model?\nHow many features (f) are used as input?\nIs p much larger than the number of training points and/or is f large?\nWhich overfitting prevention techniques used?\nAre the hyperparameter configurations, optimization schedule, model files and optimization parameters reported?\nIs the model black box or interpretable?\nIs the model classification or regression?\nHow much time does a single representative prediction require on a standard machine?\nIs the source code released?\nHow was the method evaluated?\nWhich performance metrics are reported?\nWas a comparison to publicly available methods performed on benchmark datasets?\nDo the performance metrics have confidence intervals?\nAre the raw evaluation files available?"
  },
  {
    "objectID": "posts/2021-09-10-ML_checklit.html#things-to-consider-when-building-a-ml-model",
    "href": "posts/2021-09-10-ML_checklit.html#things-to-consider-when-building-a-ml-model",
    "title": "Model building checklist",
    "section": "",
    "text": "Learn about your data\n\n\nType of the data being analyzed\n\nIs the data set, sensor measure-reading what you think it is measuring\nDsitribution of the data / target\nOutliers in the data\n\n\nSingle variables\n\n\nType – continuous, discreet, categorical\nDistribution in the data\nScale of each variable\nWhat is the resolution I am interested in?\nOutliers in the variables\n\n\nFeature correlations\n\n\nStart simple – linear correlation\nUse domain knowledge and see if they make sense\nLook at subset of the data to make it tractable / subsampling\n\n\nSelection and feature engineering\n\n\nMake new (better?) features combining the orginal features\nRecast, resample, forward difference, simple arthimatic operations\n\n\n\n\n\nSplit in train and test – look at target prop statistics\nSplit train into CV or train / validation\nTrain models on the training data: - Linear model - Non linear models - Ensemble models - Decision models\nModel hyperparameters\n\n\n\n\n\nTrain on full training dataset\nAvenues of data bleed\nSplit quality - is the train/validation data representative of test data / real-life data?\n\n\n\n\n\nWhat is the source of the data (database, publication, direct experiment)?\nHow many data points are in the training, validation and test sets?\nHow were the sets split? Is any bias being introduced based on the type of split?\nAre the data, including the data splits used, released in a public forum?\nHow were the data encoded and preprocessed for the ML algorithm?\nHow many parameters (p) are used in the model?\nHow many features (f) are used as input?\nIs p much larger than the number of training points and/or is f large?\nWhich overfitting prevention techniques used?\nAre the hyperparameter configurations, optimization schedule, model files and optimization parameters reported?\nIs the model black box or interpretable?\nIs the model classification or regression?\nHow much time does a single representative prediction require on a standard machine?\nIs the source code released?\nHow was the method evaluated?\nWhich performance metrics are reported?\nWas a comparison to publicly available methods performed on benchmark datasets?\nDo the performance metrics have confidence intervals?\nAre the raw evaluation files available?"
  },
  {
    "objectID": "posts/2020-11-08-network_analysis_basics.html",
    "href": "posts/2020-11-08-network_analysis_basics.html",
    "title": "Network analysis hands-on",
    "section": "",
    "text": "Good resource to learn basics of Network science: - http://networksciencebook.com/chapter/0\nRecent summary of Graph Network and their use in ML: - Relational inductive biases, deep learning, and graph networks\nExamples of Network graphs: 1. NetworkX Example dataset 2. Stanford Large Network Dataset Collection\nNetwork building and manipulation will be done using NetworkX - a python package made for this exact function\n# import modules \nimport os \nimport numpy as np\nimport networkx as nx\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}"
  },
  {
    "objectID": "posts/2020-11-08-network_analysis_basics.html#basics",
    "href": "posts/2020-11-08-network_analysis_basics.html#basics",
    "title": "Network analysis hands-on",
    "section": "1. Basics",
    "text": "1. Basics\nNodes: Points which are connected to each other. Can represent people, words, or atoms – objects which have attributes of their own\nEdges: Connection between the nodes - show how nodes (entities) are connected, bond distance, social network (friendships) – property which connect the entities\n\n# Start an empty graph \nG = nx.Graph() \n\n# Add a node \nG.add_node(42)\n\n# Add node from list of entities \ntemp_list = ['A','B','C']\nG.add_nodes_from(temp_list)\n\n\nG.nodes\n\nNodeView((42, 'A', 'B', 'C'))\n\n\n\n# Remove nodes \nG.remove_node(42) #This is definite node name and should exist in the network \n\n# Multiple nodes \nG.remove_nodes_from(['A','Z','Blah']) #Here it is compared to the element to that in the list \n\n\nG.nodes\n\nNodeView(('B', 'C'))\n\n\n\n# add single edge - tuple of nodes (source, target)\n# this also adds nodes if they don't already exist\nG.add_edge('C','Z')\n\n\nprint(G.edges, G.nodes)\n\n[('C', 'Z')] ['B', 'C', 'Z']\n\n\n\n# add multiple edges (list of tuples) [(source, target), (source, target)]\nG.add_edges_from([('B', 'C') , ('B', 'Z')])\n\n\nG.edges\n\nEdgeView([('B', 'C'), ('B', 'Z'), ('C', 'Z')])\n\n\n\n# Like nodes, we can remove multiple edges \n# remove multiple edges (list of tuples)\nG.remove_edges_from([('A', 'B') , ('C', 'B')]) #Here list are commutative \n\n\nG.edges\n\nEdgeView([('B', 'Z'), ('C', 'Z')])\n\n\n\n# get number of nodes in network G\nG.number_of_nodes()\n\n3\n\n\n\n# get number of edges in network G\nG.number_of_edges()\n\n2\n\n\n\n# get number of neighbors (connections)\nG.degree('B')\n\n1\n\n\n\nG.clear()"
  },
  {
    "objectID": "posts/2020-11-08-network_analysis_basics.html#reading-from-a-file",
    "href": "posts/2020-11-08-network_analysis_basics.html#reading-from-a-file",
    "title": "Network analysis hands-on",
    "section": "2. Reading from a file",
    "text": "2. Reading from a file\nFor example we will look at Facebook dataset installed from SNAP dataset\n\n# input edgelist from file\nG = nx.read_edgelist('./data/facebook_combined.txt')\n\n\nG.number_of_nodes()\n\n4039\n\n\n\nG.number_of_edges()\n\n88234\n\n\n\n# get the 2nd node's neighbors (retrieves a dictionary)\ndict_neighbors = G.neighbors('2')\n\n\nG.degree('2')\n\n10\n\n\n\nlist(dict_neighbors)\n\n['0', '20', '115', '116', '149', '226', '312', '326', '333', '343']\n\n\n\nG.clear()"
  },
  {
    "objectID": "posts/2020-11-08-network_analysis_basics.html#type-of-different-networks",
    "href": "posts/2020-11-08-network_analysis_basics.html#type-of-different-networks",
    "title": "Network analysis hands-on",
    "section": "3. Type of different networks",
    "text": "3. Type of different networks\n\na. Weighted Graphs\nEdge weight Consider that the edge that you are adding should contain additional information, such as the strength of the connection. This would be important, for example, when analyzing communication networks to check friendship/connectivity strength. You want to capture how many times they exchanged e-mails, calls, text messages, to indicate the strength of the connection. For this you will assign weights to the edge, values that can be the number of communications, or the fraction of communications, normalized.\nI had used this type of graph in my analysis for Indian spices. In that case, the edge was assigned a weight corresponding to the number of times a pair of spice occured together in a recipe.\n\n# assign weight to edge\nG.add_edge('Water','Soda', weight=10)\n\nWays to access edge property:\n\nG.edges.data()\n\nEdgeDataView([('Water', 'Soda', {'weight': 10})])\n\n\n\nG['Soda']['Water']\n\n{'weight': 10}\n\n\n\nG['Water']['Soda']\n\n{'weight': 10}\n\n\n\n# change edge weight\nG['Water']['Soda']['weight'] = -1\n\n\nG.edges.data()\n\nEdgeDataView([('Water', 'Soda', {'weight': -1})])\n\n\n\n\nb. Directed Graphs\nIncorporate directionality in the edge. Instead of having just the edge showing the connection: A — B encode a type of connection. If A is giving (food, resources, atoms, electrons) to B. In that case: A —-&gt; B\n\n#undirected\nG.nodes\n\nNodeView(('Water', 'Soda'))\n\n\n\n# you can create a directed representation of network G\ndg = nx.to_directed(G)\n\n\ndg.edges\n\nOutEdgeView([('Water', 'Soda'), ('Soda', 'Water')])\n\n\n\ndg.get_edge_data('Water','Soda')\n\n{'weight': -1}\n\n\n\n\nc. Multigraphs\nNetworkX provides classes for graphs which allow multiple edges between any pair of nodes. The MultiGraph and MultiDiGraph classes allow you to add the same edge twice, possibly with different edge data. This can be powerful for some applications, but many algorithms are not well defined on such graphs.\n\n# multigraphs can store multiple edges information between same two nodes that can have different properties\nMG = nx.MultiGraph()\nMG.add_weighted_edges_from([(1, 2, 3.0), (1, 2, 75), (2, 3, 5), (1, 2, 4.2)])\n\n\n# lists the edges (node1, node2, edge_index), including the multiedges, adding the multiedge index as 3rd element in edge tuple\nMG.edges\n\nMultiEdgeView([(1, 2, 0), (1, 2, 1), (1, 2, 2), (2, 3, 0)])\n\n\n\n# lists the edges (node1, node2, weight/edge_attribute), the 3rd element is the weights of the edges\nMG.edges.data('weight')\n\nMultiEdgeDataView([(1, 2, 3.0), (1, 2, 75), (1, 2, 4.2), (2, 3, 5)])\n\n\n\nMG.edges.data()\n\nMultiEdgeDataView([(1, 2, {'weight': 3.0}), (1, 2, {'weight': 75}), (1, 2, {'weight': 4.2}), (2, 3, {'weight': 5})])\n\n\n\n# check the weight of an edge\nMG[1][2]\n\nAtlasView({0: {'weight': 3.0}, 1: {'weight': 75}, 2: {'weight': 4.2}})\n\n\n\n\nd. Bipartite\nBipartite graphs B = (U, V, E) have two node sets U,V and edges in E that only connect nodes from opposite sets. It is common in the literature to use an spatial analogy referring to the two node sets as top and bottom nodes.\n\nfrom networkx.algorithms import bipartite\n\n\nbip = nx.Graph()\n\n\n# add nodes with the node attribute \"bipartite\", a network of who likes what fruits\nbip.add_nodes_from(['apple', 'peach', 'watermelon', 'pear'], bipartite=0)\nbip.add_nodes_from(['Alice', 'Steve', 'Mary'], bipartite=1)\n\n\nbip.add_edges_from([('Alice', 'apple'), ('Alice', 'peach'), ('Steve', 'watermelon'), \n                    ('Mary', 'pear'), ('Mary', 'apple'), ('Mary', 'watermelon')])\n\n\nnx.draw(bip, with_labels=True)\n\n\n\n\n\n\n\n\nCurrently, NetworkX does not provide a bipartite graph visualization method to visually delimit the two sets of nodes. However, we can draw the left and right set of nodes and see how they connect to each other. Further, you can play around with coloring the nodes based on the ‘bipartite’ attribute to further refine visually to which node set each node belongs to.\n\nimport scipy.sparse as sparse\n\nX, Y = bipartite.sets(bip)\npos = dict()\npos.update((n, (1, i*10)) for i, n in enumerate(X))\npos.update((n, (1.5, i*10)) for i, n in enumerate(Y))\n\nnx.draw(bip, with_labels=True, pos=pos)\n\n\n\n\n\n\n\n\nBipartite graphs can be projected as two separate graphs G1 = (U, E1) and G2 = (V, E2). The edges will be different though.\nWe can create a network of fruits, where nodes will be fruits and the edges will between two fruits will be created if someone likes both fruits. Such, peach and apple will have one edge, as Alice likes both. Same for apple and pear, which are both liked by Mary. Likewise, we can create the second network as the network of individuals, where connections between them will be their preference for the same fruit. Here, we can create a connection/edge between Steve and Mary since both of them like watermelon."
  },
  {
    "objectID": "posts/2020-11-08-network_analysis_basics.html#network-models",
    "href": "posts/2020-11-08-network_analysis_basics.html#network-models",
    "title": "Network analysis hands-on",
    "section": "3. Network Models",
    "text": "3. Network Models\nNetwork models can be very useful for comparing their topology to the structural properties of our network built from real data. Different network models have very distinct structural characteristics, which defines their behavior in case of information flow on the network, attacks/failures on the nodes/edges, etc, and these properties have been extensively studied and are well documented. Knowing to which network model your graph corresponds to can provide valuable insights about its potential behavior under various circumstances.\nThere are a miriad of network models with different topological properties. Here we will try out some of the most useful ones (that frequently occur in real complex systems).\n\n# Barabasi-Albert (scale-free) network \nba = nx.barabasi_albert_graph(10, 5)\nnx.draw_spectral(ba, node_size=200)\n\n\n\n\n\n\n\n\nBarabasi-Alber Graph. A graph of N nodes is grown by attaching new nodes each with M edges that are preferentially attached to existing nodes with high degree.\n\n# Erdos-Renyi (random) network \ner = nx.erdos_renyi_graph(50, 0.1)\nnx.draw_circular(er)\n\n\n\n\n\n\n\n\n\n# complete graph (every pair of nodes is connected by a unique edge)\ncomplete = nx.complete_graph(5)\nnx.draw(complete)"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html",
    "href": "posts/2025-01-06-small_molecule_resources.html",
    "title": "Medicine drug discovery resources",
    "section": "",
    "text": "Last update: March 2025"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#noteworthy-blogs-to-follow",
    "href": "posts/2025-01-06-small_molecule_resources.html#noteworthy-blogs-to-follow",
    "title": "Medicine drug discovery resources",
    "section": "Noteworthy blogs to follow:",
    "text": "Noteworthy blogs to follow:\nCheminformatics\n\nPatrick Walters Blog on Cheminformatics\n\nCheminformatics Tutorials\n\nIs Life Worth Living\nAndrew White’s Deep Learning for Molecule and Material\nCheminformia\nDepth-First\nNoel O’Blog\n\nFragment-based drug dicovery\n\nPractical Fragments\n\nMedicinal chemistry\n\nDarryl B McConnell’s Medchem blogpost\nChris Swaim’s MedChem blogpost\n\nSynthesis chemistry\n\nChemistryByDesign\n\nComputational chemistry 1. Gilles Ouvry\nGeneral field\n\nDrugDiscovery.NET - Andreas Bender\nDrugHunter\nDerek Lowe’s In the Pipeline"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#online-resources",
    "href": "posts/2025-01-06-small_molecule_resources.html#online-resources",
    "title": "Medicine drug discovery resources",
    "section": "Online resources",
    "text": "Online resources\n\nAndrea Volkmer, TeachOpenCADD: a teaching platform for computer-aided drug design (CADD)\nPatrick Walter’s Cheminformatics Tutorials\nPat Walters’ RSC CICAG Open Source Tools for Chemistry.Video. Github\nPen’s Python cookbook for Cheminformatics\nChem LibreText collection from ACS Division of Chemical Education\nRDkit blogpost from Greg Landrum\nJeremy Monat’s blogpost"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#books",
    "href": "posts/2025-01-06-small_molecule_resources.html#books",
    "title": "Medicine drug discovery resources",
    "section": "Books",
    "text": "Books\n\nBajorath, 2011. Chemoinformatics and Computational Chemical Biology. Methods in Molecular Biology.\nHeifetz, Alexander. (Ed.) (2022). “Artificial Intelligence in Drug Design.”"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#best-practices",
    "href": "posts/2025-01-06-small_molecule_resources.html#best-practices",
    "title": "Medicine drug discovery resources",
    "section": "Best practices",
    "text": "Best practices\n\nBender, Andreas, et al. “Evaluation guidelines for machine learning tools in the chemical sciences.” Nature Reviews Chemistry (2022): 1-15.. Temporary SharedIt Link\n\nNice account outlining guidelines for evaluating different AI/ML methodologies in molecular science. They propose a checklist of tests and best practices to assess the practicality and importance of different methodologies thereby providing a framework on how to evaluate plethora of ML workflows being proposed in different areas of chemical science. The basis for not overlooking the older non-ML method when evaluating the ‘new’ learning-based method, emphasis on model interpretation to translate the corrleation to chemical causality and finally\n\nArtrith, Nongnuch, et al. “Best practices in machine learning for chemistry.” Nature chemistry 13.6 (2021): 505-508.\n\nSet of rules, considerations, and caveats to keep in mind when designing ML model for chemical science. The authors propose a checklist when evaluating ML models, while intuitive at first, when lot of the new ML papers are scanned through that lens, you can identify the shortcommings of the proposed model. This checklist is especially helpful for those entering just entering the field."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#pharma-rd-business",
    "href": "posts/2025-01-06-small_molecule_resources.html#pharma-rd-business",
    "title": "Medicine drug discovery resources",
    "section": "Pharma R&D Business",
    "text": "Pharma R&D Business\n\nSchuhmacher, Alexander, et al. “Analysis of pharma R&D productivity–a new perspective needed.” Drug Discovery Today (2023): 103726.\nPaul, Steven M., et al. “How to improve R&D productivity: the pharmaceutical industry’s grand challenge.” Nature reviews Drug discovery 9.3 (2010): 203-214."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#overviews-and-reviews",
    "href": "posts/2025-01-06-small_molecule_resources.html#overviews-and-reviews",
    "title": "Medicine drug discovery resources",
    "section": "Overviews and Reviews",
    "text": "Overviews and Reviews\n\nF. Strieth-Kalthoff, F. Sandfort, M. H. S. Segler, and F. Glorius, Machine learning the ropes: principles, applications and directions in synthetic chemistry, Chem. Soc. Rev\n\nPedagogical account of various machine learning techniques, models, representation schemes from perspective of synthetic chemistry. Covers different applications of machine learning in synthesis planning, property prediction, molecular design, and reactivity prediction\n\nRodríguez-Pérez, Raquel, Filip Miljković, and Jürgen Bajorath. “Machine Learning in Chemoinformatics and Medicinal Chemistry.” Annual review of biomedical data science 5 (2022)\nMariia Matveieva & Pavel Polishchuk. Benchmarks for interpretation of QSAR models. Github. Patrick Walter’s blog on the paper.\n\nPaper outlining good practices for interpretating QSAR (Quantative Structure-Property Prediction) models. Good set of heuristics and comparison in the paper in terms of model interpretability. Create 6 synthetic datasets with varying complexity for QSAR tasks. The authors compare interpretability of graph-based methods to conventional QSAR methods. In regards to performance graph-based models show low interpretation compared to conventional QSAR method.\n\nW. Patrick Walters & Regina Barzilay. Applications of Deep Learning in Molecule Generation and Molecular Property Prediction\n\nRecent review summarising the state of the molecular property prediction and structure generation research. In spite of exciting recent advances in the modeling efforts, there is a need to generate better (realistic) training data, assess model prediction confidence, and metrics to quantify molecular generation performance.\n\nNavigating through the Maze of Homogeneous Catalyst Design with Machine Learning\nColey, C. W. Defining and Exploring Chemical Spaces. Trends in Chemistry 2020\nMachine learning directed drug formulation development\n\nReview from Aspuru-Guzik and Allen’s group discussing how ML can be leveraged for various tasks in drug formulation tasks."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#commentary",
    "href": "posts/2025-01-06-small_molecule_resources.html#commentary",
    "title": "Medicine drug discovery resources",
    "section": "Commentary",
    "text": "Commentary\n\nWeaver, Donald F. “Chemists Invent Drugs and Drugs Save Lives.” ChemMedChem (2024): e202400074.\nWill AI turbocharge the hunt for new drugs?\nComment about generative design from Patrick Walters\nWalters, W. Patrick, and Mark Murcko. “Assessing the impact of generative AI on medicinal chemistry.” Nature biotechnology 38.2 (2020): 143-145.\n\nCorrespondence on assessing the impact of AI on medicinal chemistry. It is a well written account on practical implication of generative design on pharmaceutical research.They outline two recent cases of ‘success’ of AI generative design in drug discovery and give more context and propose best practices for furthering the development of algorithms and drug discovery pipelines.\n\nWe need better benchmarking for machine learning in drug discovery\n\nVery good post outlining the focus on the good practices and lack thereof for consistent datasets for comparing different ML algorithms."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#industry-focused-drug-discovery-reviews",
    "href": "posts/2025-01-06-small_molecule_resources.html#industry-focused-drug-discovery-reviews",
    "title": "Medicine drug discovery resources",
    "section": "Industry-focused drug discovery reviews",
    "text": "Industry-focused drug discovery reviews\n\nGoldman, B., Kearnes, S., Kramer, T., Riley, P., & Walters, W. P. (2022). Defining levels of automated chemical design. Journal of medicinal chemistry, 65(10), 7073-7087.\n\nGroup at Relay Therapeutics propose a framework to categorize automated chemical design paradigm - splitting it into generator and decision axes. They give good example of model systems where the machine generates and human chemist select and more recently machine generated and machine chosen designs. In of these discussion, it is evident we havent achieved the full automated execution of a design cycle.\n\nHasselgren, Catrin, and Tudor I. Oprea. “Artificial Intelligence for Drug Discovery: Are We There Yet?.” Annual Review of Pharmacology and Toxicology 64 (2024). ArXiv\n\nLatest review of the field and application of AI technologies to various functions of drug discovery. In addition to providing a quick review of the main technology the author list different case studies where AI has proposed clinical candidates across different therapeutic areas. Yet, the need for better data, novelty estimation, and validation in wet lab limit the full scale deployment and accuracy of AI pipelines in drug discovery. In closing they also hint at the limitation of ML model training a single property with single structure, QSAR, while in reality the molecule can exist in different conformers something multi-instance learning (MIL) can address. ‘It is reasonable to assume that user expertise, bias, and time constraints play a significant role in early drug discovery, often more so than AI.’\n\nJayatunga, Madura KP, et al. “AI in small-molecule drug discovery: A coming wave.” Nat. Rev. Drug Discov 21 (2022): 175-176.\nAbramov, Yuriy A., Guangxu Sun, and Qun Zeng. “Emerging Landscape of Computational Modeling in Pharmaceutical Development.” Journal of Chemical Information and Modeling (2022).\n\nOverview of methods and scope of computational methods used in the drug development process.\n\nDragovich, Peter S., et al. “Small-Molecule Lead-Finding Trends across the Roche and Genentech Research Organizations.” Journal of Medicinal Chemistry (2022).\nA. Bender and I. Cortés-Ciriano, “Artificial intelligence in drug discovery: what is realistic, what are illusions? Part 1: Ways to make an impact, and why we are not there yet,” Drug Discov. Today, vol. 26, no. 2, pp. 511–524, 2021"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#special-journal-issues",
    "href": "posts/2025-01-06-small_molecule_resources.html#special-journal-issues",
    "title": "Medicine drug discovery resources",
    "section": "Special Journal Issues",
    "text": "Special Journal Issues\n\nData Science Meets Chemistry\n\nThis issue includes contributions that demonstrate the profound impact data science techniques have had in chemistry including chemical and materials synthesis, catalyst and materials design, and overhauling the models used in traditional theoretical or computational chemistry.\n\nJournal of Medicinal Chemistry compendium of AI in Drug discovery issue\nAccount of Chemical Research Special Issue on advances in data-driven chemistry research\nSpecial Issue on Reaction Informatics and Chemical Space, Journal of Chemical Information and Modeling (2022)"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#meeting-notes",
    "href": "posts/2025-01-06-small_molecule_resources.html#meeting-notes",
    "title": "Medicine drug discovery resources",
    "section": "Meeting notes",
    "text": "Meeting notes\n\nWarr, W. (2021). National Institutes of Health (NIH) Workshop on Reaction Informatics\nWarr, W. (2021). Report on an NIH Workshop on Ultralarge Chemistry Databases."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#chemical-modalities",
    "href": "posts/2025-01-06-small_molecule_resources.html#chemical-modalities",
    "title": "Medicine drug discovery resources",
    "section": "Chemical modalities",
    "text": "Chemical modalities\n\nBlanco, Maria-Jesus, and Kevin M. Gardinier. “New chemical modalities and strategic thinking in early drug discovery.” ACS medicinal chemistry letters 11.3 (2020): 228-231.\n\nOverview of different chemical modalities currently at work to address different disease targets. The article addresses the small molecule medicinal chemists and how they can expand their outlook of small molecules to include other molecular entities when considering the angle of attack for different target engagement strategies. The authors offer a nice set of tools and thought process when selecting possible drug modalities for different target classes and what questions should be asked when zeroing in a possible mode of action.\n\nTargeted Protein Degradation: Advances, Challenges, and Prospects for Computational Methods"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#meta-themes-on-optimizing-small-molecules",
    "href": "posts/2025-01-06-small_molecule_resources.html#meta-themes-on-optimizing-small-molecules",
    "title": "Medicine drug discovery resources",
    "section": "Meta themes on optimizing small molecules",
    "text": "Meta themes on optimizing small molecules\n\nRing Systems in Medicinal Chemistry: A Cheminformatics Analysis of Ring Popularity in Drug Discovery Over Time\nDon’t Fall in Love with Your Molecule\n\nNice primer on target-product profiles for a drug molecule and how clinical relevance and success is predicated by good decision on TPP in addition to technical success on the biology and chemistry front.\n\nBlackwell, J. Henry, Iacovos N. Michaelides, and Floriane Gibault. “A Perspective on the Strategic Application of Deconstruction–Reconstruction in Drug Discovery.” Journal of Medicinal Chemistry (2025).\nFree Drug Concepts: A Lingering Problem in Drug Discovery\nTertiary Alcohol: Reaping the Benefits but Minimizing the Drawbacks of Hydroxy Groups in Drug Discovery\nWalters, W. Patrick, and Mark A. Murcko. “Prediction of ‘drug-likeness’.” Advanced drug delivery reviews 54.3 (2002): 255-271.\nVeber, Daniel F., et al. “Molecular properties that influence the oral bioavailability of drug candidates.” Journal of medicinal chemistry 45.12 (2002): 2615-2623.\n\nRetrospective analysis on factors influencing the bioavailability of drug candidates. Authors find rotatable bonds and polar surface area or hydrogen bond count (sum of donor and accpetors) found to be important predictors of good oral bioavailability. Compounds having &lt;10 rotatable bonds and &lt;140 A (or &lt; 12 hydrogen bonds) have good chances of being orally bioavailable.\n\nDeGoey, David A., et al. “Beyond the rule of 5: lessons learned from AbbVie’s drugs and compound collection: miniperspective.” Journal of Medicinal Chemistry 61.7 (2017): 2636-2651.\n\nAB-MPS calculated using cLogD, the number of aromatic rings (nAr), and the number of rotatable bonds (nRotB) according to the formula AB-MPS = Abs(cLogD −3) + nAr + nRotB. The lower the AB-MPS score, the more likely the compound is to be absorbed, and a value of ≤14 is reported to predict a higher probability of oral absorption.\n\nPoongavanam, Vasanthanathan, Bradley C. Doak, and Jan Kihlberg. “Opportunities and guidelines for discovery of orally absorbed drugs in beyond rule of 5 space.” Current Opinion in Chemical Biology 44 (2018): 23-29.\n\nHueristics for oral bioavailability of molecules that are violating the rule of 5. MW may reach up to approximately 1000 Da provided that TPSA increases proportionally up to 250 Å2. In contrast, cLogP and HBDs must be carefully controlled at high MW. Our lack of ability to predict compound conformations and flexibility is currently a hurdle that is critical to overcome to enable further prospective design in oral bRo5 space.\n\nTaylor, R. D.; MacCoss, M.; Lawson, A. D. G. Rings in Drugs. J. Med. Chem. 2014, 57 (14), 5845–5859.\nSubbaiah, Murugaiah AM, and Nicholas A. Meanwell. “Bioisosteres of the phenyl ring: Recent strategic applications in lead optimization and drug design.” Journal of Medicinal Chemistry 64.19 (2021): 14046-14128.\n\nLooks at biosteric replacements for the phenyl rings in the lead optimization phase. Phenyl rings results in improve potency but have poor solubility and lipophilicitty. Find biosteres can be used to improve them.\n\nErtl, Peter. “Magic Rings: Navigation in the Ring Chemical Space Guided by the Bioactive Rings.” Journal of Chemical Information and Modeling (2021).\n\nAnalyze the nature of rings which appear in bioactive compounds. Ring systems are systematically extracted from one billion molecules and are analyzed to discover a structure or correlation in the bioactivity and type of rings. No simple set of structural descriptors separating active and inactive rings could be identified, the separation is best described by a neural network model taking into account a complex combination of many substructure features.\n\nHartung, Ingo V., Bayard R. Huck, and Alejandro Crespo. “Rules were made to be broken.” Nature Reviews Chemistry 7.1 (2023): 3-4.\n\nLongitudinal analysis of physico-chemical properties for approved drugs in the clinic. They show that most of the drugs flout most of the Lipinski’s rule of 5 except the HBD which is always consistently less 4. In addition, they show that in recent times, by categorizing the drugs in different time-bound classes, the mean MW and HBA has increased but mean HBD has constantly stayed less than 2.\n\nYoung, Robert J., et al. “The time and place for nature in drug discovery.” Jacs Au 2.11 (2022): 2400-2416.\n\nCritique on the paper, interesting take\n\nProperty-Based Drug Design Merits a Nobel Prize\n\nProbably contentious topic but a good short review of the property-based optimization thought process for medicine discovery.\n\nPennington, Lewis D., and Demetri T. Moustakas. “The necessary nitrogen atom: a versatile high-impact design element for multiparameter optimization.” Journal of Medicinal Chemistry 60.9 (2017): 3552-3579.\n\nGood perspective highlighting the impact of replacing CH group with N in aromatic and heteraromatic ring systems on molecular and physiochemical properties that translate to improved pharmacological properties."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#synthesis-chemistry",
    "href": "posts/2025-01-06-small_molecule_resources.html#synthesis-chemistry",
    "title": "Medicine drug discovery resources",
    "section": "Synthesis Chemistry",
    "text": "Synthesis Chemistry\nCatalog of recent research articles that look at synthesis chemistry from a point of view of computational workflows, how traditional synthetic chemistry methods can be combined with informatics to augment drug discovery and synthesis processes.\n\nRuck, Rebecca T., Neil A. Strotman, and Shane W. Krska. “The Catalysis Laboratory at Merck: 20 Years of Catalyzing Innovation.” ACS Catalysis 13 (2022): 475-503.\nDreher, Spencer D., and Shane W. Krska. “Chemistry informer libraries: Conception, early experience, and role in the future of cheminformatics.” Accounts of Chemical Research 54.7 (2021): 1586-1596.\n\nCurated set of substrates to quickly assess the practicality of synthetic methods with the complete capture of success and failure, that can optimize reaction conditions with a broader scope with respect to relevant applications.\n\nCampos, Kevin R., et al. “The importance of synthetic chemistry in the pharmaceutical industry.” Science 363.6424 (2019): eaat0805.\nLate-stage diversification of indole skeletons through nitrogen atom insertion"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#structure-elucidation-analytical-techniques-modeling",
    "href": "posts/2025-01-06-small_molecule_resources.html#structure-elucidation-analytical-techniques-modeling",
    "title": "Medicine drug discovery resources",
    "section": "Structure elucidation / analytical techniques modeling",
    "text": "Structure elucidation / analytical techniques modeling\n\nBohde, Montgomery, et al. “DiffMS: Diffusion Generation of Molecules Conditioned on Mass Spectra.” arXiv preprint arXiv:2502.09571 (2025).\n\nDiffMS is a novel machine learning framework for generating molecular structures from mass spectra. It uses a formula-restricted encoder-decoder network, achieving state-of-the-art performance. The novelty lies in its discrete graph diffusion model and extensive pretraining. However, gaps remain in fully elucidating exact molecular structures due to inherent ambiguities in mass spectra.\n\nLi, Haote, et al. “Rapid Quantification of Protein Secondary Structure Composition from a Single Unassigned 1D 13C Nuclear Magnetic Resonance Spectrum.” Journal of the American Chemical Society 146.40 (2024): 27542-27554.\n\nSecondary protein structure determination from 1D NMR without chemical shift assignments. Each residue is modeled as ensemble of secondary structure viz. alpha-helix, beta-sheet, random coil. While the approach can hint at residue-level differences, its primary output is the overall ensemble distribution of secondary structural elements."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#large-chemical-libraries",
    "href": "posts/2025-01-06-small_molecule_resources.html#large-chemical-libraries",
    "title": "Medicine drug discovery resources",
    "section": "Large chemical libraries",
    "text": "Large chemical libraries\nOver the past few years several entites offering ultra-large ensembles of chemical libraries which can be made on-demand or purchased immediately have emerged. The existence of such services has reinvigorated the field of virtual screening and combinatorial library design. In addition, research groups have devised novel ways to navigate these libraries, more efficiently and also understand the differences in the chemical space these library cover. Following are some of the key papers in the field.\n\nWarr, W. (2021). Report on an NIH Workshop on Ultralarge Chemistry Databases.\nWarr, Wendy A., et al. “Exploration of ultralarge compound collections for drug discovery.” Journal of Chemical Information and Modeling 62.9 (2022): 2021-2034.\nThe next level in chemical space navigation: going far beyond enumerable compound libraries\nBellmann, Louis, et al. “Comparison of combinatorial fragment spaces and its application to ultralarge make-on-demand compound catalogs.” Journal of Chemical Information and Modeling 62.3 (2022): 553-566.\n\nSpaceCompare: calculation of the overlap of large, nonenumerable combinatorial fragment spaces, utilizes topological fingerprints and the combinatorial character of these chemical spaces. Enamine’s REAL Space, WuXi’s GalaXi Space, and Otava’s CHEMriya. The overlap of the commercial make-on-demand catalogs is only in the low single-digit percent range, despite their large overall size.\n\nKonze, Kyle D., et al. “Reaction-based enumeration, active learning, and free energy calculations to rapidly explore synthetically tractable chemical space and optimize potency of cyclin-dependent kinase 2 inhibitors.” Journal of chemical information and modeling 59.9 (2019): 3782-3793.\n\nPathFinder uses retrosynthetic analysis followed by combinatorial synthesis to generate novel compounds in synthetically accessible chemical space.\n\nIrwin, John J., et al. “ZINC20—a free ultralarge-scale chemical database for ligand discovery.” Journal of chemical information and modeling 60.12 (2020): 6065-6073.\n\nNew version of ZINC with two major new features: billions of new molecules and new methods to search them. As a fully enumerated database, ZINC can be searched precisely using explicit atomic-level graph-based methods. Over 97% of the core Bemis–Murcko scaffolds in make-on-demand libraries are unavailable from “in-stock” collections. Correspondingly, the number of new Bemis–Murcko scaffolds is rising almost as a linear fraction of the elaborated molecules. Thus, an 88-fold increase in the number of molecules in the make-on-demand versus the in-stock sets is built upon a 16-fold increase in the number of Bemis–Murcko scaffolds. The make-on-demand library is also more structurally diverse than physical libraries\n\nNeumann, Alexander, Lester Marrison, and Raphael Klein. “Relevance of the Trillion-Sized Chemical Space “eXplore” as a Source for Drug Discovery.” ACS Medicinal Chemistry Letters (2023).\n\nThe authors examine the composition of the recently published and, so far, biggest chemical space, “eXplore”, which comprises approximately 2.8 trillion virtual product molecules. The utility of eXplore to retrieve interesting chemistry around approved drugs and common Bemis Murcko scaffolds has been assessed with several methods (FTrees, SpaceLight, SpaceMACS). Further, the overlap between several vendor chemical spaces and a physicochemical property distribution analysis has been performed. Despite the straightforward chemical reactions underlying its setup, eXplore is demonstrated to provide relevant and, most importantly, easily accessible molecules for drug discovery campaigns."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#virtual-screeening",
    "href": "posts/2025-01-06-small_molecule_resources.html#virtual-screeening",
    "title": "Medicine drug discovery resources",
    "section": "Virtual screeening",
    "text": "Virtual screeening\n\nSynthon-Based Strategies Exploiting Molecular Similarity and Protein–Ligand Interactions for Efficient Screening of Ultra-Large Chemical Libraries\nDodds, Michael, et al. “Sample efficient reinforcement learning with active learning for molecular design.” Chemical Science 15.11 (2024): 4146.\n\nAn active learning system linked with an RL model (RL–AL) for molecular design, which aims to improve the sample-efficiency of the optimization process. AZ group looking at generative design + RL + Virtual screening campaign\n\nVakili, Mohammad Ghazi, et al. “Quantum Computing-Enhanced Algorithm Unveils Novel Inhibitors for KRAS.” arXiv preprint arXiv:2402.08210 (2024).\n\nFirst paper to showcase deployment of quantum-based generative models with virtual screening workflow on a target-based compound discovery. Chemistry42 is used for reward function implementation. The authors show that molecule generated from this combined effort are ‘better’ quality-wise than traditional workflow (LSTM and Genetic algorithm) and the modeling success downstream is roughly correlated with number of qubits employed. This is exciting more from technical standpoint of combining quantum + traditional workflows.\n\nSadybekov, Anastasiia V., and Vsevolod Katritch. “Computational approaches streamlining drug discovery.” Nature 616.7958 (2023): 673-685.\n\nNice review on virtual screening workflow for streamlining drug discovery\n\nGorgulla, Christoph, et al. “An open-source drug discovery platform enables ultra-large virtual screens.” Nature 580.7805 (2020): 663-668.\n\nVirtualFlow as a tool for conducting virtual screening. The authors use VirtualFlow, to prepare one of the largest and freely available ready-to-dock ligand libraries, with more than 1.4 billion commercially available molecules. They screening ~1 billion compounds and identified a set of structurally diverse molecules that bind to KEAP1 with submicromolar affinity.\n\nDeep Learning Strategies for Enhanced Molecular Docking and Virtual Screening\nA practical guide to machine-learning scoring for structure-based virtual screening\nKeeping pace with the explosive growth of chemical libraries with structure-based virtual screening\nLyu, Jiankun, et al. “Ultra-large library docking for discovering new chemotypes.” Nature 566.7743 (2019): 224-229.\n\nResearchers at UCSF looking at large scale docking for making ultra-large libraries accessible. They dock 170 million make-on-demand compounds from 130 well characterized reactions. Found new chemotypes that have interaction with 2 targets."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#fragment-based-drug-discovery",
    "href": "posts/2025-01-06-small_molecule_resources.html#fragment-based-drug-discovery",
    "title": "Medicine drug discovery resources",
    "section": "Fragment-based drug discovery",
    "text": "Fragment-based drug discovery\nWhat is a fragment?\nIn fragment-based drug discovery (FBDD), a fragment is a small, low-molecular-weight chemical entity typically ranging from 120-250 Daltons, with properties such as cLogP &lt; 2.5, hydrogen atom count (HAC) of 9-18, hydrogen bond acceptors (HBA) &lt; 7, and hydrogen bond donors (HBD) &lt; 4, as specified by Asinex. These fragments serve as starting points for drug development. They bind to target proteins with low affinity but high efficiency, enabling the identification of key interactions. By optimizing and linking fragments, researchers can develop potent lead compounds, enhancing the efficiency of the drug discovery process and improving hit finding.\nKnown collection\n\nCambridge Chem Consulting\nEvotec\nDiamond light source\n\nBlogs\n\nPractical Fragment blog\n\nBook Chapters\n\nRees, D. C.; Congreve, M.; Murray, C. W.; Carr, R. Fragment-Based Lead Discovery. Nat Rev Drug Discov 2004, 3 (8), 660–672\n\nThe paper by Rees, D. C.; Congreve, M.; Murray, C. W.; Carr, R. discusses the concept of fragment-based lead discovery in drug development. The authors highlight the challenges in the drug discovery pipeline, particularly the ‘target-rich, lead-poor’ issue and the high attrition rate of chemical compounds in preclinical development. They discuss the use of fragment-based approaches as a solution, which involves the selection, screening, and optimization of fragments (also referred to as needles, shapes, binding elements, or seed templates) for lead identification. This approach requires significantly fewer compounds to be screened and synthesized, and has a high success rate in generating chemical series with lead-like properties. The authors also discuss different strategies for developing fragments into high-affinity leads, such as fragment evolution and fragment linking. The paper includes examples from 25 different protein targets to illustrate these strategies.\nReviews\n\nTwenty years on: the impact of fragments on drug discovery\n\nArticles\n\nErlanson, Daniel A., et al. “Where and how to house big data on small fragments.” Nature Communications 16.1 (2025): 1-6.\nFragmenstein: predicting protein-ligand structures of compounds derived from known crystallographic fragment hits using a strict conserved-binding–based methodology\n\nFragmenstein, stitches ligand atoms from known fragment hits to predict protein-ligand complex conformations more accurately. Fragmenstein uses a Python package to merge or place compounds by stitching together atoms from fragment hits and then energy minimizing them under strong constraints.\n\nZhang, Yueqing, et al. “FragGrow: A Web Server for Structure-Based Drug Design by Fragment Growing within Constraints.” Journal of Chemical Information and Modeling (2024).\nCree, Ben, et al. “Active learning driven prioritisation of compounds from on-demand libraries targeting the SARS-CoV-2 main protease.” (2024).FEGrow Github\nIgashov, Ilia, et al. “Equivariant 3D-conditional diffusion model for molecular linker design.” Nature Machine Intelligence (2024): 1-11. Pen’s blog\nPenner, Patrick, et al. “FastGrow: on-the-fly growing and its application to DYRK1A.” Journal of Computer-Aided Molecular Design 36.9 (2022): 639-651. Pen’s blog\nCarbery, Anna, et al. “Fragment libraries designed to be functionally diverse recover protein binding information more efficiently than standard structurally diverse libraries.” Journal of Medicinal Chemistry 65.16 (2022): 11404-11413.. Practical Fragment Blog\nBoby, M. L. Open Science Discovery of Potent Noncovalent SARS-CoV-2 Main Protease Inhibitors. Science 2023, 382 (6671)\nMüller, Janis, et al. “Magnet for the needle in haystack:“crystal structure first” fragment hits unlock active chemical matter using targeted exploration of vast chemical spaces.” Journal of Medicinal Chemistry 65.23 (2022): 15663-15678.. Blog\n\nThe authors use a fragment screening approach to look at hits for protein kinase target and instead of using biophysical assay in fragment screening use crystallographic data directly to learn the conformation of the fragments. They find 4 ‘seed’ substructures which fit nicely in the protein(not affinity) and use those to inform the latter expansion which is done through the Enamine REAL dataset and known reaction classes. What I liked the most and found interesting is the high throughput binding pose and docking workflow of 200k compounds, the large scale crystallographic fragment hit analysis, and the focused curated library generation using Enamine REAL dataset. I was curious to know what seasoned experts had to say about this.\n\nBROOD\n\nCommercial software solution from OpenEye for fragment exchange\nCodebase\n\nSyndirella\nHIPPO"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#protein-engineering",
    "href": "posts/2025-01-06-small_molecule_resources.html#protein-engineering",
    "title": "Medicine drug discovery resources",
    "section": "Protein engineering",
    "text": "Protein engineering\n\nPeSTo: parameter-free geometric deep learning for accurate prediction of protein binding interfaces"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#protein-ligand-interactions",
    "href": "posts/2025-01-06-small_molecule_resources.html#protein-ligand-interactions",
    "title": "Medicine drug discovery resources",
    "section": "Protein-ligand interactions",
    "text": "Protein-ligand interactions\n\nYim, Jason, et al. “Diffusion models in protein structure and docking.” Wiley Interdisciplinary Reviews: Computational Molecular Science 14.2 (2024): e1711.\n\nNice review of the field that looks at computational model to predict protein-ligand interaction and molecular docking. In recent times, diffusion-based model have shown promising performance. This review documents the current state of the field and next steps. This survey covers DMs primarily from the point of view of backbone generation, both unconditional and conditional generation. It is interesting to see how modeling the backbone, sequence, and side chains would bring further benefit beyond the current strategy of modeling them one after the other.\n\nDiffDock\nQiao, Zhuoran, Weili Nie, Arash Vahdat, Thomas F. Miller III, and Animashree Anandkumar. “State-specific protein–ligand complex structure prediction with a multiscale deep generative model.” Nature Machine Intelligence 6, no. 2 (2024): 195-208.\n\nIambic Therapeutics’ AI model that predicts the combined shape of proteins and small molecules outperforms Google DeepMind’s AlphaFold. Lambic’s newest model, called NeuralPLexer2, had a 75% success rate in predicting these protein-ligand structures. AlphaFold’s latest version, as described last October in a blog post, was 74% successful. But Iambic’s model jumps to a 93% success rate when the model receives additional info on amino acids near the small molecule.\n\nRFdiffusion All-Atom Github\n\nRoseTTAFold All-Atom (RFAA) was trained to represent amino acids and DNA bases at the residue level and all other chemical groups at the atomic level, allowing it to accurately model proteins and the other chemicals they so often interact with.\nRFdiffusion All-Atom: build bespoke protein structures around small molecules. The team designed and experimentally validated, through crystallography and binding measurements, proteins that bind the cardiac disease therapeutic digoxigenin, the enzymatic cofactor heme, and the light-harvesting molecule bilin. Although there is still room for improvement in prediction accuracy, we anticipate that RFAA should be broadly useful for modeling full biological assemblies and RFdiffusionAA for designing small molecule–binding proteins and sensors.\n\nDynamicBind\n\nDynamicBind, a deep learning method that employs equivariant geometric diffusion networks to construct a smooth energy landscape, promoting efficient transitions between different equilibrium states. DynamicBind accurately recovers ligand-specific conformations from unbound protein structures without the need for holo-structures or extensive sampling.\n\nYu, Jie, et al. “Computing the relative binding affinity of ligands based on a pairwise binding comparison network.” Nature Computational Science 3.10 (2023): 860-872.\n\n\nConformer generators\n\nThe impact of conformer quality on learned representations of molecular conformer ensembles\nRaush, Eugene, Ruben Abagyan, and Maxim Totrov. “Efficient generation of conformer ensembles using internal coordinates and a generative directional graph convolution neural network.” Journal of Chemical Theory and Computation 20.9 (2024): 4054-4063.\n\nFrom team at MolSoft, this paper introduces GINGER, a GNN trained to predct low-energy conformers using internal coordinate representation.\n\nMcNutt, Andrew T., et al. “Conformer Generation for Structure-Based Drug Design: How Many and How Good?.” Journal of Chemical Information and Modeling (2023).\nWang, Zhe, et al. “Small-Molecule Conformer Generators: Evaluation of Traditional Methods and AI Models on High-Quality Data Sets.” Journal of Chemical Information and Modeling (2023).\nZhu, Yanqiao, et al. “Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks.” arXiv preprint arXiv:2310.00115 (2023).\nFriedrich, Nils-Ole, et al. “Benchmarking commercial conformer ensemble generators.” Journal of chemical information and modeling 57.11 (2017): 2719-2728.\n\nThe paper benchmarks eight commercial conformer ensemble generators: OMEGA, ConfGenX, iCon, MOE LowModeMD, MacroModel, LigPrep, OpenEye, and Schrödinger, along with RDKit. It finds that commercial algorithms are highly robust and accurate, with OMEGA being the top performer in terms of accuracy and speed. RDKit shows competitive performance compared to mid-ranked commercial algorithms. The study highlights the impact of rotatable bonds on success rates and recommends enabling built-in clustering for better accuracy.\nStructure Quality Assessment\n\nButtenschoen, Martin, Garrett M. Morris, and Charlotte M. Deane. “PoseBusters: AI-based docking methods fail to generate physically valid poses or generalise to novel sequences.” arXiv preprint arXiv:2308.05777 (2023).\n\nPython package for evaluating the quality of docked poses. PoseBusters performs a series of geometry checks on docked poses and also evaluates intra and inter-molecular interactions. The authors used the Astex Diverse Set and a newly developed PoseBusters benchmark set to evaluate five popular deep learning docking programs and two conventional docking approaches. The conventional docking programs dramatically outperformed the deep learning methods on both datasets. In most cases, more than half of the solutions generated by the DL docking programs failed the PoseBusters validity tests. In contrast, with the conventional docking programs, only 2-3% of the docked poses failed to validate.\n\nMorehead, Alex, et al. “Deep Learning for Protein-Ligand Docking: Are We There Yet?.” arXiv preprint arXiv:2405.14108 (2024)Github\n\nSuite of tools and workflow to benchmark Deep learning method’s ability to predict protein-ligand interaction modeling - from apo to halo configuration for P/L pairs. The authors find that all but one DL method fail to generalize to multi-ligand protein targets.\nBenchmarking Generated Poses: How Rational is Structure-based Drug Design with Generative Models\nPoseCheck evaluates steric clashes, ligand strain energy, and intramolecular interactions to identify problematic structures. In addition, structures are redocked with AutoDock Vina to confirm the validity of the proposed binding mode. In evaluating several recently published generative models, the authors identify failure modes that will hopefully influence future work on structure-based generative design.\n\n\nBinding energetic prediction\n\nValsson, Ísak, et al. “Narrowing the gap between machine learning scoring functions and free energy perturbation using augmented data.” Communications Chemistry 8.1 (2025): 41.\nWarren, M., Deane, C., Magarkar, A., Morris, G., & Biggin, P. (2024). How to make machine learning scoring functions competitive with FEP.\n\nCurrent SOTA model fail in out of distribution datasets implying overfitting or memorization of ligand-specific features. This paper introduces AEV-PLIG, atomic environment vector with protein-ligand interaction graphs. They propose new benchmark metrics and data augmentation strategies.A multi-head attention graph NN is trained with the node features of the P-L interaction. They report comparable performance to FEP+ on standard benchmarks.\n\nKoh, Huan Yee, et al. “Physicochemical graph neural network for learning protein–ligand interaction fingerprints from sequence data.” Nature Machine Intelligence (2024): 1-15.. Github\n\nPSICHIC (PhySIcoCHemICal graph neural network), a framework incorporating physicochemical constraints to decode interaction fingerprints directly from sequence data alone.\n\nJanela, Tiago, and Jürgen Bajorath. “Rationalizing general limitations in assessing and comparing methods for compound potency prediction.” Scientific Reports 13.1 (2023): 17816.\nEfficient prediction of relative ligand binding affinity in drug discovery. Nat Comput Sci 3, 829–830 (2023). https://doi.org/10.1038/s43588-023-00531-1\nXu, Huafeng. “The slow but steady rise of binding free energy calculations in drug discovery.” Journal of Computer-Aided Molecular Design (2022): 1-8.\nThompson, James, et al. “Optimizing active learning for free energy calculations.” Artificial Intelligence in the Life Sciences 2 (2022): 100050."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#molecular-dynamics",
    "href": "posts/2025-01-06-small_molecule_resources.html#molecular-dynamics",
    "title": "Medicine drug discovery resources",
    "section": "Molecular-dynamics",
    "text": "Molecular-dynamics\n\nMDANCE\n\nMolecular Dynamics Analysis with N-ary Clustering Ensembles (MDANCE) is a flexible n-ary clustering package that provides a set of tools for clustering Molecular Dynamics trajectories."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#cheminformatics-focus",
    "href": "posts/2025-01-06-small_molecule_resources.html#cheminformatics-focus",
    "title": "Medicine drug discovery resources",
    "section": "Cheminformatics-focus",
    "text": "Cheminformatics-focus\nCatalog of recent reviews and manuscripts I have found useful when learning more about the state-of-the-art in Cheminformatics. I’ve tried to categorize them roughly based on their area of application:\n\nRepresentation\nSmall molecules to be understood by computers and used for model training have to represented in a form amenable for optimization. In addition, this form of abstraction much capture appropriate level of chemical properties so as to imbue the data-driven models with necessary chemistry and physics for modeling. A lot of times different properties of the molecules are ‘lost in translation’ or obfuscated when converting them into machine-ready forms. Formerly the process of converting molecules from one form to another is called featurization. There are different forms, methods, theories to encode the molecules. Broadly there are as follows: * Fingerprints * Descriptors * Pharmacophores * Graph-based * Natural language-based * Shape-based\nReviews\n\nFrom intuition to AI: evolution of small molecule representations in drug discovery\nRepresentation of Molecules in NN: Molecular representation in AI-driven drug discovery: review and guide\n\nArticles\n\nBoulougouri, Maria, Pierre Vandergheynst, and Daniel Probst. “Molecular set representation learning.” (2023).\n\nThe authors propose a new way to represent molecules, not as chemical bonds, but rather set representations. They show the set representation scheme can be alternative to SOTA graph-models and performs at par to the predictive tasks such as reaction yields and protein-ligand affinities.\n\nM. Krenn, F. Hase, A. Nigam, P. Friederich, and A. Aspuru-Guzik, “Self-Referencing Embedded Strings (SELFIES): A 100% robust molecular string representation,” Mach. Learn. Sci. Technol., pp. 1–9, 2020\nCould graph neural networks learn better molecular representation for drug discovery? A comparison study of descriptor-based and graph-based models\n\nComparative study of descriptor-based and graph-based models using public data set. Used descriptor-based models (XGBoost, RF, SVM, using ECFP) and compared them to graph-based models (GCN, GAT, AttentiveFP, MPNN). They show descriptor-based models outperform the graph-based models in terms of prediction accuracy and computational efficiency with SVM having best predictions. Graph-based methods are good for multi-task learning.\n\nHe, Jiazhen, et al. “Molecular optimization by capturing chemist’s intuition using deep neural networks.” Journal of cheminformatics 13.1 (2021): 1-17.\n\nDescriptor generation\n\nMorfeus Machine learning focused descriptors for small molecules with emphasis on 3D information.\nMordred\nMolFeat\nDeepChem\nPMapper\n\nPmapper is a Python module to generate 3D pharmacophore signatures and fingerprints. Signatures uniquely encode 3D pharmacophores with hashes suitable for fast identification of identical pharmacophores.\n\nSteriMol\n\nGenerate conformationally sampled descriptors for a molecule. This workflow provides Boltzmann-averaged Sterimol parameters. These descriptors might be useful for problems where spatial orientation inform the selectivity or properties being trained for. Github\n\n\nPredictive modeling\nArticles\n\nChen, Jacky, et al. “Data Scaling and Generalization Insights for Medicinal Chemistry Deep Learning Models.” Journal of Chemical Information and Modeling (2025).\n\nBenchmarks comparing traditional ML to deep learning methods that also include nice ablation studies on different splitting strategies. The authors look at ADME(T) endpoints and general drug discovery assays. They once again show that for larger datasets GNNs perform well but what they do different from other work is they show the scaling behavior of ADMET models.\n\nChemical complexity challenge: Is multi-instance machine learning a solution\n\nTraditional ML uses the relationship between a single instance (a chemical structure) and a single label (a property). It doesn’t provide a facility for mapping multiple instances (an ensemble of conformers) to a label. There has recently been renewed interest in multiple instance learning (MIL), a technique developed over 30 years ago. MIL provides a framework that enables the mapping of conformational ensembles to properties. A recent review by Zankov from Hokkaido University and coworkers at other institutions provides an excellent overview of the challenges and opportunities associated with MIL in QSAR, genomics, and several other areas. The paper also provides links to several software packages for building MIL models.\n\nCurrent Methods for Drug Property Prediction in the Real World\n\nOverview of the field and some factors that complicate current benchmarking efforts. The authors compared several molecular representations and ML algorithms in evaluating model accuracy and uncertainty. These evaluations highlighted the strengths of different QSAR modeling and ADME prediction methods. Consistent with other papers published in 2023, 2D descriptors performed best for ADME prediction, while Gaussian Process Regression with fingerprints was the method of choice when predicting biological activity.\n\nRationalizing general limitations in assessing and comparing methods for compound potency prediction\n\nA paper by Janela and Bajorath outlines several limitations in current benchmarking strategies. The authors used sound statistical methodologies to examine the impact of compound potency value distributions on performance metrics associated with regression models. They found that across several different ML algorithms, there was a consistent relationship between model performance and the activity range of the dataset. These findings enabled the authors to define bounds for prediction accuracy. The method used in this paper should be informative to those designing future benchmarks.\n\nYang, K., Swanson, K., Jin, W., Coley, C., Eiden, P., Gao, H., Guzman-Perez, A., Hopper, T., Kelley, B., Mathea, M. and Palmer, A., 2019. Analyzing learned molecular representations for property prediction. Journal of chemical information and modeling, 59(8), pp.3370-3388\n\nBenchmark property prediction models on 19 public and 16 proprietary industrial data sets spanning a wide variety of chemical end points. Introduce a modeling framework (Chemprop) that consistently matches or outperforms models using fixed molecular descriptors as well as previous graph neural architectures on both public and proprietary data sets.\n\nStuyver, T. and Coley, C.W., 2021. Quantum chemistry-augmented neural networks for reactivity prediction: Performance, generalizability and interpretability. arXiv preprint arXiv:2107.10402\n\nCombine structure (Graph-networks) and descriptor based features (QM-derived) to predict activation energies (E2/SN2 barrier height prediction) and regioselectivity. Incorporating QM and structure leads to better overall accuracy and generalizability even in low data regions. Atom and bond level features derived using QM and used in the model generation with a smaller dataset.\nTransformer-based\n\nInfoAlign\nChemBERTa\n\npKa prediction\n\nAbarbanel, Omri, and Geoffrey Hutchison. “QupKake: Integrating Machine Learning and Quantum Chemistry for micro-pKa Predictions.” (2023).. Github\n\nQupKake combines GFN2-xTB calculations with graph-neural-networks to accurately predict micro-pKa values of organic molecules.\nHydrogen bond energy\n\nJazzy: Fast calculation of hydrogen-bond strengths and free energy of hydration of small molecules\n\nSolvent prediction\n\nMachine Learning Models for Solvent Prediction in Organic Reactions: Bridging the Gap between Theory and Practical Efficacy"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#pharmacophore-shape-searching",
    "href": "posts/2025-01-06-small_molecule_resources.html#pharmacophore-shape-searching",
    "title": "Medicine drug discovery resources",
    "section": "Pharmacophore / shape searching",
    "text": "Pharmacophore / shape searching\n\nRianjongdee, Francesco, et al. “bbSelect–An Open-Source Tool for Performing a 3D Pharmacophore-Driven Diverse Selection of R-Groups.” Journal of Chemical Information and Modeling (2024).. Pen’s blog\nPheSA: An Open-Source Tool for Pharmacophore-Enhanced Shape Alignment\n\nPheSA is a CPU bound algorithmic improvement over ROCS shape/color alignment that gives you an option to incorporate binding site knowledge.\n\nShaEP\nRoshambo\n\nROSHAMBO is a GPU accelerated implementation of ROCS\n\nQSAR benchmarks\n\nLlompart, P., et al. “Will we ever be able to accurately predict solubility?” Scientific Data 11.1 (2024): 303.\n\nThe paper discusses challenges in predicting thermodynamic solubility with machine learning. It reviews historical data, analyzes solubility datasets, and assesses model reliability. The authors propose a workflow for data curation and present new models and quality-assessed datasets for public use.\n\nMulti-task ADME/PK Prediction at Industrial Scale: Leveraging Large and Diverse Experimental Datasets\nDeng, Jianyuan, et al. “A systematic study of key elements underlying molecular property prediction.” Nature Communications 14.1 (2023): 6395.\n\nDeng and coworkers from Stony Brook University compared many popular ML algorithms and representations, curated new datasets, and performed statistical analysis on the results. This paper provides one of the best comparisons of ML methods published to date. The authors compare fixed representations, such as molecular fingerprints, with representations learned from SMILES strings and molecular graphs and conclude that, in most cases, the fixed representations provide the best performance. Another interesting aspect of this paper was an attempt to establish a relationship between dataset size and the performance of different molecular representations. While fixed representations performed well on smaller datasets, learned representations didn’t become competitive until between 6K and 100K datapoints were available.\n\nFang, Cheng, et al. “Prospective Validation of Machine Learning Algorithms for Absorption, Distribution, Metabolism, and Excretion Prediction: An Industrial Perspective.” Journal of Chemical Information and Modeling (2023).\n\nA paper from Fang and coworkers at Biogen introduced several new ADME datasets. Unlike most literature benchmarks, which contain data collected from dozens of papers, these experiments were consistently performed by the same people in the same lab. The authors provided prospective comparisons of several widely used ML methods, including random forest, SVM, XGBoost, LightGBM, and message-passing neural networks (MPNNs) on several relevant endpoints, including aqueous solubility, metabolic stability, membrane permeability, and plasma protein binding.\n\nBeckers, Maximilian, et al. “Prediction of Small-Molecule Developability Using Large-Scale In Silico ADMET Models.” Journal of Medicinal Chemistry (2023).\n\nThe paper presents a novel deep learning approach to predict the developability of small molecules based on their predicted ADMET properties. The authors use a large-scale data set of compounds from the Novartis pipeline and train a neural network to rank compounds according to their potential to progress beyond in vivo PK studies. The resulting score, called bPK, outperforms other compound scoring methods and shows strong generalization ability on public data. The authors demonstrate the usefulness of bPK for series prioritization and optimization in drug discovery projects.\n\nD van Tilborg, Derek, Alisa Alenicheva, and Francesca Grisoni. “Exposing the limitations of molecular machine learning with activity cliffs.” Journal of Chemical Information and Modeling 62.23 (2022): 5938-5951.\n\nAccount on how to treat and analyze activity cliffs in context of developing a predictive model. The authors outline best practices to probe activity cliffs. They show, using 24 DL and ML models and 30 targets, ML approaches based on molecular descriptors outperformed more complex deep learning methods. Activity cliff pairs were defined on similarity of the molecule SMILES and the bioactivity difference. Compared to most traditional machine learning approaches, deep neural networks seem to fall short at picking up subtle structural differences (and the corresponding property change) that give rise to activity cliffs.\n\nLarge-scale comparison of machine learning methods for drug target prediction on ChEMBL - Chemical Science (RSC Publishing)\nBeyond the hype: deep neural networks outperform established methods using a ChEMBL bioactivity benchmark set, Journal of Cheminformatics\nSystematic Evaluation of Local and Global Machine Learning Models for the Prediction of ADME Properties\n\nAuthors provide an evaluation of global and local models for ADME endpoint prediction. They compare the performance of global models and domain-specific local models. 10 different asays and 112 drug discovery projects were analyzed. The results showed consistent superior performance of global ADME models for property prediction. Performance improvement of global models over project-wise local models ranged from 3% to 25% in MAE. Local model improvements higher than 20% were achieved for only 7% of the assay-project pairs.\n\nSwanson, Kyle, et al. “ADMET-AI: A machine learning ADMET platform for evaluation of large-scale chemical libraries.” BioRxiv (2023): 2023-12. Web interface Code\n\nOnline web interface to quickly predict ADMET properties using specific AI models trained on Therapeutic Data Commmons dataset.\nDatasets\n\nQMugs\n\nQMugs (Quantum mechanical properties of drug-like molecules) collection comprises quantum mechanical properties of more than 665 k biologically and pharmacologically relevant molecules extracted from the ChEMBL database, totaling 2M conformers.\n\nMoleculeNet: a benchmark for molecular machine learning (rsc.org)\nTDC: Therapeutic Data Commons\n\n\n\nMatched molecular-pair\n\nMatched Molecular Pair Analysis in Short: Algorithms, Applications and Limitations\nRaymond, John W., and Peter Willett. “Maximum common subgraph isomorphism algorithms for the matching of chemical structures.” Journal of computer-aided molecular design 16.7 (2002): 521-533.\nDalke, Andrew, Jerome Hert, and Christian Kramer. “mmpdb: An open-source matched molecular pair platform for large multiproperty data sets.” Journal of chemical information and modeling 58.5 (2018): 902-910.\nWizePairZ: A Novel Algorithm to Identify, Encode, and Exploit Matched Molecular Pairs with Unspecified Cores in Medicinal Chemistry\n\n\n\nR-group replacement dataset\n\n\nEnumeration of chemical space\n\nBellmann, Louis, et al. “Comparison of Combinatorial Fragment Spaces and Its Application to Ultralarge Make-on-Demand Compound Catalogs.” Journal of Chemical Information and Modeling (2022).\n\nAuthors propose an algorithmic approach called as SpaceCompare to calculate overlap and diversity of the ultra-large combinatorial chemical libraries. The tool uses topological fragment spaces to capture the subtlties of the reaction having same product but different reactant substructures.\n\nNicolaou, Christos A., et al. “The proximal lilly collection: Mapping, exploring and exploiting feasible chemical space.” Journal of chemical information and modeling 56.7 (2016): 1253-1266.\nZabolotna, Y., et al. (2021). “SynthI: A New Open-Source Tool for Synthon-Based Library Design.” Journal of Chemical Information and Modeling.\n\nInteresting work on de-novo design of molecules wherein, the molecules being created are made up from the fragments that is known to exist and are available to the user. New molecules are generated based on the fragmented (synthons) made available in the dataset.\n\nFully Automated Creation of Virtual Chemical Fragment Spaces Using the Open-Source Library OpenChemLib\n\nOpen-source tool to generate synthetically accessible chemical spaces using reaction definitions and building blocks. Virtual fragments are generated using one-step reaction and real-world building blocks - the workflow also support 2-3 steps creation.\n\nZabolotna, Yuliana, et al. “NP navigator: a new look at the natural product chemical space.” Molecular informatics 40.9 (2021): 2100068..\n\nOrganizing the chemical space of ChEMBL, and ZINC to compare its overlap with natural products through COCONUT. Generative Topological Mapping is used for the clustering and analysis. Helpful overview of the method with its application to drug discovery can be found here"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#explainableinterpretable-machine-learning",
    "href": "posts/2025-01-06-small_molecule_resources.html#explainableinterpretable-machine-learning",
    "title": "Medicine drug discovery resources",
    "section": "Explainable/Interpretable Machine Learning",
    "text": "Explainable/Interpretable Machine Learning\nReviews/Perspectives\n\nWellawatte, Geemi P., et al. “A Perspective on Explanations of Molecular Prediction Models.” (2022).\nRodríguez-Pérez, Raquel, and Jürgen Bajorath. “Explainable Machine Learning for Property Predictions in Compound Optimization.” Journal of medicinal chemistry 64.24 (2021): 17744-17752\n\nArticles\n\nWellawatte, Geemi P., Aditi Seshadri, and Andrew D. White. “Model agnostic generation of counterfactual explanations for molecules.” (2021).\nMatveieva, Mariia, and Pavel Polishchuk. “Benchmarks for interpretation of QSAR models.” Journal of cheminformatics 13.1 (2021): 1-20. Patrick Walter’s blog"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#uncertainty-quantification",
    "href": "posts/2025-01-06-small_molecule_resources.html#uncertainty-quantification",
    "title": "Medicine drug discovery resources",
    "section": "Uncertainty quantification",
    "text": "Uncertainty quantification\n\nGAUCHE: A Library for Gaussian Processes in Chemistry\nMervin, L. H., Johansson, S., Semenova, E., Giblin, K. A., & Engkvist, O. (2021). Uncertainty quantification in drug design. Drug discovery today, 26(2), 474-489.\nAlan Aspuru-Guzik perspective on uncertainty and confidence\nUncertainty Quantification Using Neural Networks for Molecular Property Prediction. J. Chem. Inf. Model. (2020) Hirschfeld, L., Swanson, K., Yang, K., Barzilay, R. & Coley, C. W.\n\nBenchmark different models and uncertainty metrics for molecular property prediction.\n\nEvidential Deep learning for guided molecular property prediction and disocovery Ava Soleimany, Conor Coley, et. al.. Slides\n\nTrain network to output the parameters of an evidential distribution. One forward-pass to find the uncertainty as opposed to dropout or ensemble - principled incorporation of uncertainties\n\nDifferentiable sampling of molecular geometries with uncertainty-based adversarial attacks\nJ. P. Janet, S. Ramesh, C. Duan, H. J. Kulik, ACS Cent. Sci. 2020\n\nConduct a global multi-objective optimization with expected improvement criterion. Find transition metal complex redox couples for Redox flow batteries that address stability, solubility, and redox potential metric. Use distance of a point from a training data in latent space as a metric to quantify uncertainty."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#active-learning",
    "href": "posts/2025-01-06-small_molecule_resources.html#active-learning",
    "title": "Medicine drug discovery resources",
    "section": "Active Learning",
    "text": "Active Learning\nActive learning provides strategies for efficient screening of subsets of the library. In many cases, we can identify a large portion of the most promising molecules with a fraction of the compute cost.\nBlogs\n\nHow to drug a novel target in 500 molecules\n\nComparisons\nTraversing Chemical Space with Active Deep Learning\nThe authors compared six active learning approaches on three benchmark datasets and concluded that the acquisition function is critical to AL performance. When comparing molecular representations, they found that fingerprints generalized better than graph neural networks. Consistent with previous studies, they found that the choice of an initial training set had little impact on the outcome of an AL model.\nArticles\n\nDodds, M., Guo, J., Löhr, T., Tibo, A., Engkvist, O., & Janet, J. P. (2024). Sample efficient reinforcement learning with active learning for molecular design. Chemical Science, 15(11), 4146-4160.\n\nActive learning system linked with Reinforcement learning model for molecule design through REINVENT-Active Learning. They aim to improve the sampling efficiency of the generation required to improving the MPO. Compounds discovered through RL-AL approach show significant enrichment in the MPO score.\n\nCorrey, Galen J., Moira M. Rachman, Takaya Togo, Stefan Gahbauer, Yagmur U. Doruk, Maisie GV Stevens, Priyadarshini Jaishankar et al. “Extensive exploration of structure activity relationships for the SARS-CoV-2 macrodomain from shape-based fragment merging and active learning.” bioRxiv (2024): 2024-08.\n\nVery nice work from Shoichet (Zinc, UCSF) + Relay folks (Pat Walter et al) expanding on their active learning method to SAR CoV2. Use FrankenROCS and Thompson sampling to screen millions of compounds, identifying hits with IC50 values as low as 130 μM + ~100 X-ray crystal structures with binding data. Have been a big fan of active learning esp. multi-armed bandits.\n\nGusev, Filipp, et al. “Active learning guided drug design lead optimization based on relative binding free energy modeling.” Journal of Chemical Information and Modeling 63.2 (2023): 583-594.\n\nActive learning on BDE.\n\nKlarich, Kathryn, et al. “Thompson Sampling─ An Efficient Method for Searching Ultralarge Synthesis on Demand Databases.” Journal of Chemical Information and Modeling (2024).. Update on it from AZ folks Link\nFromer, Jenna C., David E. Graff, and Connor W. Coley. “Pareto optimization to accelerate multi-objective virtual screening.” Digital Discovery (2024).\nGraff, David E., Eugene I. Shakhnovich, and Connor W. Coley. “Accelerating high-throughput virtual screening through molecular pool-based active learning.” Chemical science 12.22 (2021): 7866-7881.. GitHub\n\nArticle talks about MolPAL as an active learning methodology. The team explores the application of these techniques to computational docking datasets and assess the impact of surrogate model architecture, acquisition function, and acquisition batch size on optimization performance. We observe significant reductions in computational costs; for example, using a directedmessage passing neural network we can identify 94.8% or 89.3% of the top-50 000 ligands in a 100M member library after testing only 2.4% of candidate ligands using an upper confidence bound or greedy acquisition strategy, respectively.\n\nThompson, James, et al. “Optimizing active learning for free energy calculations.” Artificial Intelligence in the Life Sciences 2 (2022): 100050.\n\nArticle exploring different active learning strategies for looking at sampling the congeneric RBFE calculations. The paper explores the impact of several AL design choices. They show that in their case, the overall AL performance is largely insensitive to the specific ML method and acquisition functions used. The significant factor affecting the performance was the number of molecules sampled at each iteration.\n\nReker, D. Practical Considerations for Active Machine Learning in Drug Discovery. Drug Discov. Today Technol. 2020\nA. P. Soleimany, A. Amini, S. Goldman, D. Rus, S. N. Bhatia, and C. W. Coley, “Evidential Deep Learning for Guided Molecular Property Prediction and Discovery,” ACS Cent. Sci., Jul. 2021.. Slideshare\n\nTrain property prediction model to output a distribution statistics in single pass that describes the uncertainty. This is in contrast to using ensemble models like MC dropout. Interesting way to estimate the epistemic (due to / from model) uncertainty in the prediction. Use this approach on antibiotic search problem of Stokes et. al. Compare Chemprop and SchNet models on different tasks.\nSelf-contained software\n\nPyepal\nBayBE. Paper. Examples\nGryffin\nAtlas\nEDBO+\nBaird, Sterling G., Andrew R. Falkowski, and Taylor D. Sparks. “Honegumi: An Interface for Accelerating the Adoption of Bayesian Optimization in the Experimental Sciences.” arXiv, February 4, 2025. https://doi.org/10.48550/arXiv.2502.06815.\n\nSaaS companies\n\nYoneda Labs\nReactWise\nAllchemy\nAtinary\nChemify\n\n\nMulti-parameter optimization\n\nComputer-aided multi-objective optimization in small molecule discovery\nPareto Optimization to Accelerate Multi-Objective Virtual Screening"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#transfer-learning",
    "href": "posts/2025-01-06-small_molecule_resources.html#transfer-learning",
    "title": "Medicine drug discovery resources",
    "section": "Transfer Learning",
    "text": "Transfer Learning\nReviews\n\nCai, Chenjing, et al. “Transfer learning for drug discovery.” Journal of Medicinal Chemistry 63.16 (2020): 8683-8694.\n\nArticles\n\nApproaching coupled cluster accuracy with a general-purpose neural network potential through transfer learning\n\nTransfer learning by training a network to DFT data and then retrain on a dataset of gold standard QM calculations (CCSD(T)/CBS) that optimally spans chemical space. The resulting potential is broadly applicable to materials science, biology, and chemistry, and billions of times faster than CCSD(T)/CBS calculations.\n\nImproving the generative performance of chemical autoencoders through transfer learning"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#meta-learning",
    "href": "posts/2025-01-06-small_molecule_resources.html#meta-learning",
    "title": "Medicine drug discovery resources",
    "section": "Meta Learning",
    "text": "Meta Learning\n\nAltae-Tran, H., Ramsundar, B., Pappu, A. S., & Pande, V. (2017). Low data drug discovery with one-shot learning. ACS central science, 3(4), 283-293.\n\nAuthors demonstrate how one-shot learning can be used to signifinicantly lower the amount of data required to make predictions in drug discovery tasks. LSTM combined with GCNNs is shown to improve learning capabilities of the model. In the simplest one-shot learning formalism these continuous vectors are then fed into a simple nearest-neighbor classifier that labels new examples by distance-weighted combination of support set labels\n\nNguyen, C. Q., Kreatsoulas, C., & Branson, K. M. (2020). Meta-learning GNN initializations for low-resource molecular property prediction. arXiv preprint arXiv:2003.05996.\n\nUse CheMBL dataset to train a gated graph neural network (GGNN) for prediction and classification tasks using meta learning protocols. Show appreciable model performance even with just approx. 256 datapoints."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#federated-learning",
    "href": "posts/2025-01-06-small_molecule_resources.html#federated-learning",
    "title": "Medicine drug discovery resources",
    "section": "Federated Learning",
    "text": "Federated Learning\n\nSimm, Jaak, et al. “Splitting chemical structure data sets for federated privacy-preserving machine learning.” Journal of Cheminformatics 13.1 (2021): 1-14.\nMelloddy consortium\n\nConsortia comprising of leading resarch labs and companies working on decentralized datasets and predictive modeling of biochemical and cellular activity."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#generative-design",
    "href": "posts/2025-01-06-small_molecule_resources.html#generative-design",
    "title": "Medicine drug discovery resources",
    "section": "Generative design",
    "text": "Generative design\nReviews\n\nDu, Y., Jamasb, A. R., Guo, J., Fu, T., Harris, C., Wang, Y., … & Blundell, T. L. (2024). Machine learning-aided generative molecular design. Nature Machine Intelligence, 1-16.\nTang, Yidan, Rocco Moretti, and Jens Meiler. “Recent Advances in Automated Structure-Based De Novo Drug Design.” Journal of Chemical Information and Modeling (2024).\nAnstine, Dylan M., and Olexandr Isayev. “Generative Models as an Emerging Paradigm in the Chemical Sciences.” Journal of the American Chemical Society 145.16 (2023): 8736-8750.\nMouchlis VD, Afantitis A, Serra A, et al. Advances in de Novo Drug Design: From Conventional to Machine Learning Methods. Int J Mol Sci. 2021;22(4):1676. Published 2021 Feb 7. doi:10.3390/ijms22041676\nB. Sanchez-Lengeling and A. Aspuru-Guzik, “Inverse molecular design using machine learning: Generative models for matter engineering,” Science (80)., vol. 361, no. 6400, pp. 360–365, Jul. 2018\n\nBenchmarks\n\nThomas, Morgan, et al. “MolScore: a scoring, evaluation and benchmarking framework for generative models in de novo drug design.” Journal of Cheminformatics 16.1 (2024): 1-20.. Github\n\nMolScore contains code to score and benchmark de novo compounds in the context of generative de novo design by generative models via the subpackage molscore, as well as, facilitate downstream evaluation via the subpackage moleval. An objective is defined via a JSON file which can be shared to propose new benchmark objectives, or to conduct multi-parameter objectives for drug design.\n\nFlam-Shepherd, Daniel, Kevin Zhu, and Alán Aspuru-Guzik. “Keeping it Simple: Language Models can learn Complex Molecular Distributions.” arXiv preprint arXiv:2112.03041 (2021).. Nature Comms Link\n\nTest SOTA language models and representation performance against graph-based methods (CGVAE, JTVAE) for ‘challenging’ generative modeling tasks - generate a molecule - property distribution as a function of synthetic feasiblity. Graph models faced chanllenge in generating large molcules (&gt; 100 HAs). Selfies provided advantage here. All of the models seem to generate novel molecules - how practical each of these novel molecules are is yet an open question.\n\nMOSES - Benchmarking platform for generative models.\n\nPropose a platform to deploy and compare state-of-the-art generative models for exploring molecular space on same dataset. In addition the authors also propose list of metrics to evaluate the quality and diversity of the generated structures.\n\nGuacaMol: Benchmarking models for De Novo Molecular Design. Blogpost\n\nEvaluation framework from BenevolentAI to compare different de-novo design models.\n\nJ. Zhang, R. Mercado, O. Engkvist, and H. Chen, “Comparative Study of Deep Generative Models on Chemical Space Coverage,” J. Chem. Inf. Model., vol. 61, no. 6, pp. 2572–2581, Jun. 2021.\n\nInteresting analysis from team at AstraZeneca R&D. They look at the chemical space coverage accounted by the SOTA generative models. Proposes a metric for evaluating space coverage, and thereby comparing different SOTA models, using a reference data (GDB-13 in this case). The new metric computes how much of the GDB-13 dataset can be recovered by a model that is trained on small GDB subset. Generative models were trained on same 1M data points and 1B molecules were then sampled from each model. It was seen that at most 39% of the molecules in the parent dataset were sampled / generated by the model. Most models sampled the same compounds atleast twice. It was observed that graph-based model sampled much diverse molecules than string-based methods. Besides, the coverage of GAN-based models was worse compared to Language and Graph models.\n\nGao, W.; Coley, C. W. The Synthesizability of Molecules Proposed by Generative Models. J. Chem. Inf. Model. 2020\n\nThis paper looks at different ways of integrating synthesizability criteria into generative models.\n\nREINVENT4: Modern AI–Driven Generative Molecule Design [Supported with PyTorch 2.0]\n\nREINVENT is a molecular design tool for de novo design, scaffold hopping, R-group replacement, linker design, molecule optimization, and other small molecule design tasks. At its heart, REINVENT uses a Reinforcement Learning (RL) algorithm to generate optimized molecules compliant with a user defined property profile defined as a multi-component score. Transfer Learning (TL) can be used to create or pre-train a model that generates molecules closer to a set of input molecules.\nGenetic algorithms\n\nTripp, Austin, and José Miguel Hernández-Lobato. “Genetic algorithms are strong baselines for molecule generation.” arXiv preprint arXiv:2310.09267 (2023).\nJensen, Jan H. “A graph-based genetic algorithm and generative model/Monte Carlo tree search for the exploration of chemical space.” Chemical science 10.12 (2019): 3567-3572.. Code\n\nLanguage models:\n\nPromptSMILES: Prompting for scaffold decoration and fragment linking in chemical language models\nWu, K., Xia, Y., Deng, P., Liu, R., Zhang, Y., Guo, H., … & Liu, T. Y. (2024). TamGen: drug design with target-aware molecule generation through a chemical language model. Nature Communications, 15(1), 9360.\n\nCollaboration with Microsoft AI and Global Health Drug Discovery Institute. TamGen, a method that employs a GPT-like chemical language model and enables target-aware molecule generation and compound refinement.The authors identified 7 compounds showing compelling inhibitory activity against the Tuberculosis ClpP protease. The model considers 1-D information of the protein and molecule.\n\nMaziarz, Krzysztof, et al. “Learning to extend molecular scaffolds with structural motifs.” arXiv preprint arXiv:2103.03864 (2021).. Github\n\nTeam at Novartis and Microsoft propose MoLeR, graph based model to generate molecule using scaffold as a seed. Scaffold based SAR speed up shown.\n\nRoss, Jerret, et al. “Large-scale chemical language representations capture molecular structure and properties.” Nature Machine Intelligence 4.12 (2022): 1256-1264.. [Github]https://github.com/IBM/molformer?tab=readme-ov-file)\nSELFIES and generative models using STONED\n\nReproducibility study of the STONED work from Jablonka et. al.\nRepresentation using SELFIES proposed to make it much more powerful\n\nIovanac, Nicolae C., Robert MacKnight, and Brett Savoie. “Actively Searching: Inverse Design of Novel Molecules with Simultaneously Optimized Properties.” ChemRxiv (2021)\n\nUsing quantum chemistry attributes calculated on-the-fly as scoring functions for sampling the generative model chemical space. Active learning strategy is deployed to explore the area of space where the properties of the molecules are unknown.\n\nR. Gómez-Bombarelli et al., “Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules,” ACS Cent. Sci., vol. 4, no. 2, pp. 268–276, 2018\n\nOne of the first implementation of a variational auto-encoder for molecule generation.\nGraph-based\n\nFlam-Shepherd, Daniel, Alexander Zhigalin, and Alán Aspuru-Guzik. “Scalable Fragment-Based 3D Molecular Design with Reinforcement Learning.” arXiv preprint arXiv:2202.00658 (2022)\n\nReinforcement learning-based generative model whici is an update on point cloud approach by the same group to now incorporate ‘grammar’ for building molecules in form of functional groups in 3D space.\n\nW. Jin, R. Barzilay, and T. Jaakkola, “Junction tree variational autoencoder for molecular graph generation,” 35th Int. Conf. Mach. Learn. ICML 2018, vol. 5, pp. 3632–3648, 2018\n\nJunction tree based decoding. Define a grammar for the small molecule and find sub-units based on that grammar to construct a molecule. The molecule is generated in two-steps: first being generating the scaffold or backbone of the molelcule, then the nodes are added with molecular substructure as identified from the ‘molecular grammar’.\nGANs\n\nMolGAN: An implicit generative model for small molecular graphs, N. De Cao and T. Kipf, 2018\n\nGenerative adversarial network for finding small molecules using graph networks, quite interesting. Avoids issues arising from node ordering that are associated with likelihood based methods by using an adversarial loss instead (GAN)\nScaffold-retained\n\nKaitoh, Kazuma, and Yoshihiro Yamanishi. “Scaffold-Retained Structure Generator to Exhaustively Create Molecules in an Arbitrary Chemical Space.” Journal of Chemical Information and Modeling (2022).\nMaziarz, Krzysztof, et al. “Learning to extend molecular scaffolds with structural motifs.” arXiv preprint arXiv:2103.03864 (2021).. Github\n\nTeam at Novartis and Microsoft propose MoLeR, graph based model to generate molecule using scaffold as a seed. Scaffold based SAR speed up shown.\nSynthesizable-space aware\n\nSynFlowNet: Design of Diverse and Novel Molecules with Synthesis Constraints\n\nFrom Recursion team - SynFlowNet, a GFlowNet model whose action space uses chemical reactions and purchasable reactants to sequentially build new molecules. Synflownet-boltz is their expansion that combine binding affinity predictions with boltz-2.\n\nGrowing and Linking Optimizers: Synthesis-driven Molecule Design\n\nThe team at Iktos suggest a reaction-based generative design. They break down the method into growing and linking steps to emulate real-life process. They compare their approach to REIVENT and show their model is able to design molecule which are not only synthesizable but also closer to the pre-defined desired properties.\n\nGao, Wenhao, Shitong Luo, and Connor W. Coley. “Generative artificial intelligence for navigating synthesizable chemical space.” arXiv preprint arXiv:2410.03494 (2024).\n\nSynFormer from Coley group to look at synthesizable space. The idea is to constraint the molecules generated by the transformations amenable to a particular platform, like automated synthesis workflow. Building blocks are selected through a diffusion module. They propose two models - a decoder to get feedback from black-box optimizer and a encoder-decoder system to incorporate synthetic pathways in the design proposal.\n\nLuo, S., Gao, W., Wu, Z., Peng, J., Coley, C. W., & Ma, J. (2024). Projecting Molecules into Synthesizable Chemical Spaces. arXiv preprint arXiv:2406.04628.\nGenerative Flows on Synthetic Pathway for Drug Design. Code\n\nRxnFlow, building on the GFlowNets (GFNs) framework for molecule generation, the authors use reaction templates and pre-defined molecular building blocks to constrains the synthetic chemical pathway. They employ this method for pocket-specific optimization across various target pockets.\n\nExpanding the chemical space using a chemical reaction knowledge graph\nSwanson, K., Liu, G., Catacutan, D.B. et al. Generative AI for designing and validating easily synthesizable and structurally novel antibiotics. Nat Mach Intell 6, 338–353 (2024).. RL-version extension RL-version code\n\nSyntheMol to generate reaction-based molecules by choosing reaction and the building blocks to connect them by. They use this approach for finding novel molecules for antibacterial discovery.\n\nSeo, Seonghwan, Jaechang Lim, and Woo Youn Kim. “Molecular Generative Model via Retrosynthetically Prepared Chemical Building Block Assembly.” Advanced Science (2023): 2206674.\nBradshaw, John, et al. “Barking up the right tree: an approach to search over molecule synthesis dags.” Advances in neural information processing systems 33 (2020): 6852-6866.\nFialková, Vendy, et al. “LibINVENT: reaction-based generative scaffold decoration for in silico library design.” Journal of Chemical Information and Modeling 62.9 (2021): 2046-2063.\nNguyen, Dai Hai, and Koji Tsuda. “A generative model for molecule generation based on chemical reaction trees.” arXiv preprint arXiv:2106.03394 (2021).\n\nAuthors propose a generative model to generate molecules via multi-step chemical reaction trees, each campaign first generates a reaction-tree with template transformations as breaking points.\n\nBradshaw, John, et al. “A model to search for synthesizable molecules.” Advances in Neural Information Processing Systems 32 (2019).\n\nDiffusion models\n\nCremer, J., Irwin, R., Tibot, A., Janet, J. P., Olsson, S., & Clevert, D. A. (2025). FLOWR: Flow Matching for Structure-Aware De Novo, Interaction-and Fragment-Based Ligand Generation. arXiv preprint arXiv:2504.10564.\n\nTeam at Pfizer includes FLOWR, a diffusion-based generator to generate pocket-conditioned molecule moieties, and SPINDR a curated dataset of ligand-pocket co-crystal complexes.\n\nAdams, K., Abeywardane, K., Fromer, J., & Coley, C. W. (2024). ShEPhERD: Diffusing shape, electrostatics, and pharmacophores for bioisosteric drug design. arXiv preprint arXiv:2411.04130.\n\nA SE(3)-equivariant diffusion model for 3D molecule structures and their interaction profile with the target of choice. The authors show their model application for typical drug design tasks including hit diversification, bioisosteric replacement and fragment merging, and ligand hopping. Shepherd is a joint denoising diffusion probabilistic model (DDPM) that learns the joint distribution over 3D molecules (atom types, bond types, coordinates) and their 3D shapes, ESP surfaces, and pharmacophores.\n\nSako, Masami, Nobuaki Yasuo, and Masakazu Sekijima. “DiffInt: A Pharmacophore-Aware Diffusion Model for Structure-Based Drug Design with Explicit Hydrogen Bond Interaction Guidance.” (2024).. Github\n\nDiffInt as a novel structure-based approach that explicitly addresses interactions. The model naturally incorporates hydrogen bonds between the protein and ligand by treating them as pseudoparticles.\n\nMixed Continuous and Categorical Flow Matching for 3D De Novo Molecule Generation\n\nThis model extends beyond traditional diffusion models by learning to map samples directly from arbitrary distributions, allowing for greater flexibility and application-specific model design. It is achieving remarkable efficiency (&gt;10-fold reduction in inference time) and accuracy in molecule generation.\n\nIgashov, Ilia, et al. “Equivariant 3D-conditional diffusion model for molecular linker design.” Nature Machine Intelligence (2024): 1-11.. Blog from Pen\nSchneuing, Arne, et al. “Structure-based drug design with equivariant diffusion models.” arXiv preprint arXiv:2210.13695 (2022). Blog from Pen. Link\n\n3D conformations-aware\n\nIntegrating structure-based approaches in generative molecular design\nBolcato, Giovanni, Esther Heid, and Jonas Boström. “On the Value of Using 3D Shape and Electrostatic Similarities in Deep Generative Methods.” Journal of chemical information and modeling 62.6 (2022): 1388-1398.\n\nExtension to the fragment-based generative design model (DeepFMPO) using reinforcement learning now incorporating 3D electrostatic similarity in the analysis. Ability to replace fragment with similar 3D shape and electrostatics. ESP_sim tutorial for comparison of electrostatic potential and molecule shape is used for this purpose. The authors find scaffold-hopping bioisoteres for CDK2.\nProtein-ligand interactions aware\n\nZhang, Jie, and Hongming Chen. “De novo molecule design using molecular generative models constrained by ligand–protein interactions.” Journal of Chemical Information and Modeling 62.14 (2022): 3291-3306.\n\nLinker design\n\nIgashov, Ilia, et al. “Equivariant 3d-conditional diffusion models for molecular linker design.” arXiv preprint arXiv:2210.05274 (2022).\nGuo, Jeff, et al. “Link-INVENT: Generative Linker Design with Reinforcement Learning.” (2022).. BlogPost\nImrie, Fergus, et al. “Deep generative models for 3D linker design.” Journal of chemical information and modeling 60.4 (2020): 1983-1995.. Blogpost\n\nInteresting work on designing linkers using conformation aware generative design algorithm. Think of it like fragment-growing.\n\nNori, Divya, Connor W. Coley, and Rocío Mercado. “De novo PROTAC design using graph-based deep generative models.” arXiv preprint arXiv:2211.02660 (2022).\n\nSynthetic-cost aware\n\nFromer, Jenna C., and Connor W. Coley. “An algorithmic framework for synthetic cost-aware decision making in molecular design. Sparrow” Nature Computational Science (2024): 1-11.. Preprint. Medium blogpost\n\nSPARROW prioritizes molecules that both have high rewards and can be synthesized in a few steps from cheap starting materials. It is also shown to combine the library-focused and generative design based compounds in one setting depending on the harmony of the proposed synthetic routes and costs."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#computer-aided-synthesis-planning-casp",
    "href": "posts/2025-01-06-small_molecule_resources.html#computer-aided-synthesis-planning-casp",
    "title": "Medicine drug discovery resources",
    "section": "Computer Aided Synthesis Planning (CASP)",
    "text": "Computer Aided Synthesis Planning (CASP)\nReviews:\n\nXuan-Vu, Nguyen, Daniel Armstrong, Zlatko Joncev, and Philippe Schwaller. “TempRe: Template generation for single and direct multi-step retrosynthesis.” arXiv preprint arXiv:2507.21762 (2025).\n\nNew methodology for template generation where extraction of the template is seen as a language generation tasks instead of selecting from a pre-defined template.\n\nTorren-Peraire, Paula, et al. “Models Matter: the impact of single-step retrosynthesis on synthesis planning.” Digital Discovery 3.3 (2024): 558-572.\n\nHow the choice of single-step retrosynthesis models affects multi-step synthesis planning in chemistry. The authors show that high performance on single-step benchmarks doesn’t always mean better synthesis planning, and that single-step models should be evaluated within real multi-step tasks, as the choice of model can significantly impact successful synthesis routes and their diversity\n\nThakkar, Amol, et al. “Artificial intelligence and automation in computer aided synthesis planning.” Reaction chemistry & engineering 6.1 (2021): 27-51.\n\nPerspective on the current SOTA of synthesis planning, automation, and reaction optimization in drug discovery and development phases using AI and ML.\n\nMadzhidov, T. I., et al. (2021). “Machine learning modelling of chemical reaction characteristics: yesterday, today, tomorrow.” Mendeleev Communications 31(6): 769-780.\nJorner, K., et al. (2021). “Organic reactivity from mechanism to machine learning.” Nature Reviews Chemistry 5(4): 240-255.\nStruble, T. J., et al. (2020). “Current and Future Roles of Artificial Intelligence in Medicinal Chemistry Synthesis.” J Med Chem 63(16): 8667-8682\nThe Exploration of Chemical Reaction Networks\n\nPerspective article summarising their position on the current state of research and future considerations on developing better reaction network models. Break down the analysis of reaction networks as into 3 classes (1) Front Open End: exploration of products from reactants (2) Backward Open Start: Know the product and explore potential reactants (3) Start to End: Product and reactant known, explore the likely intermediates.\nNice summary of potential challenges in the field:\n\nValidating exploration algorithms on a consistent set of reaction system.\nNeed to generate a comparative metric to benchmark different algorithms.\n\nConsidering effect of solvents and/or protein embeddings in the analysis\n\nBest practices\n\nGimadiev, T. R., Lin, A., Afonina, V. A., Batyrshin, D., Nugmanov, R. I., Akhmetshin, T., … & Varnek, A. (2021). Reaction Data Curation I: Chemical Structures and Transformations Standardization. Molecular Informatics, 2100119.\n\nArticle from Varnek group on best practices on processing data for reaction informatics.\nBenchmarking\n\nHastedt, Friedrich, et al. “Investigating the reliability and interpretability of machine learning frameworks for chemical retrosynthesis.” Digital Discovery 3.6 (2024): 1194-1212.\nGenheden S, Bjerrum E. PaRoutes: a framework for benchmarking retrosynthesis route predictions. ChemRxiv. Cambridge: Cambridge Open Engage; 2022. Github\n\nBenchmarking framework for comparing different multi-step retrosynthesis methods from researchers at AstraZeneca R&D. Provides 10k synthetic routes which can be used as a validation set for different methodologies, providing a platform for systematic comparison of different methods being proposed in the community.\nClassifying chemical reactions:\n\nSchwaller, Philippe, et al. “Mapping the space of chemical reactions using attention-based neural networks.” Nature Machine Intelligence 3.2 (2021): 144-152.. rxnfp - Github. Preprint. News Article.\n\nTransformer-based model for reaction classification. Compared it with BERT. Besides classification, the work also formalizes the reaction fingerprint generation using the learned representations. The reaction fingerprints are visualized using TMAPS.\n\nHeid, E; Green, W; Machine learning of reaction properties via learned representations of the condensed graph of reaction. ChemRxiv (2021)\n\nReaction classifiction prediction using atom-mapped reaction that are used to generate condensed reaction graphs and passed through a GCN-variant as implemented in chemprop.\nReaction-specific features\n\nHeid, E., & Green, W. H. (2021). Machine learning of reaction properties via learned representations of the condensed graph of reaction. Journal of Chemical Information and Modeling, 62(9), 2101-2110.\nProbst, Daniel, Philippe Schwaller, and Jean-Louis Reymond. “Reaction Classification and Yield Prediction Using the Differential Reaction Fingerprint DRFP.” ChemRxiv (2021)\nSchneider, N., et al. (2015). “Development of a Novel Fingerprint for Chemical Reactions and Its Application to Large-Scale Reaction Classification and Similarity.” Journal of Chemical Information and Modeling 55(1): 39-53.\n\nUsing scrapped US Patent data to classify chemical reactions and deploy various fingerprints and ML models for classification.\nAtom mapping:\n\nChen, Shuan, et al. “Precise atom-to-atom mapping for organic reactions via human-in-the-loop machine learning.” Nature Communications 15.1 (2024): 2250.\nLin, A., et al. (2021). “Atom-to-atom Mapping: A Benchmarking Study of Popular Mapping Algorithms and Consensus Strategies.”\n\nComparative analysis of different atom-mapping schemes for generating atom-mapped reaction features. Comments on the state of the art methods and their performance on a curated reaction database.\n\nExtraction of organic chemistry grammar from unsupervised learning of chemical reactions. RXMapper\n\nData-driven atom mapping schemes which uses transformers for learning the context of the chemical reaction. Researchers at IBM trained a flavor of language model based on Transformer architecture and used it to find reaction centers and maps atoms. Shown to be robust compared to other SOTA methods.\n\nAutomatic mapping of atoms across both simple and complex chemical reactions\n\nPredicting reaction outcomes:\n\nData-Efficient, Chemistry-Aware Machine Learning Predictions of Diels–Alder Reaction Outcomes\n\nResearchers use NERF that model electron flow in the reaction alongside bond-enviorment to propose diels-alder chemistry products.\n\nC. W. Coley et al., “A graph-convolutional neural network model for the prediction of chemical reactivity,” Chem. Sci., vol. 10, no. 2, pp. 370–377, 2019.\n\nTemplate-free prediction of organic reaction outcomes using graph convolutional neural networks\n\nPrediction of Organic Reaction Outcomes Using Machine Learning, ACS Cent. Sci. 2017\nGuan, Y., et al. (2021). “Regio-selectivity prediction with a machine-learned reaction representation and on-the-fly quantum mechanical descriptors.” Chemical Science 12(6): 2198-2208\nMulti-Instance Learning Approach to the Modeling of Enantioselectivity of Conformationally Flexible Organic Catalysts\n\nConformational sampling and designing of chiral organic catalysts.\nYield prediction\n\nKrzyzanowski, Adrian, Stephen D. Pickett, and Peter Pogány. “Exploring BERT for Reaction Yield Prediction: Evaluating the Impact of Tokenization, Molecular Representation, and Pretraining Data Augmentation.” Journal of Chemical Information and Modeling (2025).. Synthcoder\n\nSynthcoder is a GSK’s mini-platform for creating encoder models. The main focus of SynthCoder is a model creation and validation for organic chemistry, however, the platform can be used also with the regular human language or other text-based problems, e.g., protein sequences. The group evaluates the impact of tokenization, featurization, and pre-training data on the yield prediction of Hartwig and Suzuki reactions. They also show pretraining with &lt;100k samples acehieve comparable performance to larger datasets.\n\nRaghavan, Priyanka, et al. “Incorporating Synthetic Accessibility in Drug Design: Predicting Reaction Yields of Suzuki Cross-Couplings by Leveraging AbbVie’s 15-Year Parallel Library Data Set.” Journal of the American Chemical Society (2024).\n\nEvaluation of AbbVie’s medicinal chemistry library data set to build machine learning models for the prediction of Suzuki coupling reaction yields.\n\nMa, Yihong, et al. “Are we making much progress? Revisiting chemical reaction yield prediction from an imbalanced regression perspective.” Companion Proceedings of the ACM on Web Conference 2024. 2024.\n\nThrough experiments on real-world datasets, they demonstrate that treating reaction yield prediction as an imbalanced regression problem and incorporating cost-sensitive reweighting methods can significantly improve predictions for underrepresented high-yield reactions.\n\nVoinarovska, Varvara, et al. “When yield prediction does not yield prediction: an overview of the current challenges.” (2023\nSaebi, Mandana, et al. “On the use of real-world datasets for reaction yield prediction.” Chemical science 14.19 (2023): 4997-5005.\nPredicting reaction performance in C–N cross-coupling using machine learning\nMultilabel Classification Models for the Prediction of Cross-Coupling Reaction Conditions\nSchwaller, P., et al. (2021). “Prediction of chemical reaction yields using deep learning.” Machine Learning: Science and Technology 2(1). Tutorial and blogpost\nSchwaller, P., et al. (2019). “Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction.” ACS Central Science 5(9): 1572-1583.\nAhneman, D. T., Estrada, J. G., Lin, S., Dreher, S. D., & Doyle, A. G. (2018). Predicting reaction performance in C–N cross-coupling using machine learning. Science, 360(6385), 186-190.\n\nClassic paper, one of the firsts to show modeling reaction yields using ML. A random forest algorithm, was used to predict synthetic reaction performance in multidimensional chemical space with high-throughput experimentation data. Descriptors for components in a palladium-catalyzed Buchwald-Hartwig cross-coupling were computed and used as inputs. The random forest model outperformed linear regression in predictive accuracy, even with sparse training sets and out-of-sample predictions, highlighting its potential for synthetic methodology adoption.\nRetrosynthetic routes:\n\nTempRe\nDo Chemformers Dream of Organic Matter? Evaluating a Transformer Model for Multistep Retrosynthesis\n\nTransformer model evaluation for retrosynthesis from AZ folks. Template-free method.\n\nWesterlund, Annie, et al. “Data-driven approaches for identifying hyperparameters in multi-step retrosynthesis.” (2023).\n\nMeta analysis on the best set of hyperparameters for retrosynthesis routines. Here the authors explore different parameters of the retrosynthesis workflow and their impact on the performance of the route scoping. They propose new set of parameters, other than the default, to assist in improving the odds of the software finding a route for diverse of set of molecules. First of its kind look into an approach to identify such a set.\n\nSchwaller, P., et al. (2020). “Predicting retrosynthetic pathways using transformer-based models and a hyper-graph exploration strategy.” Chemical Science 11(12): 3316-3325.\nComputational planning of the synthesis of complex natural products\nWatson, I. A., et al. (2019). “A retrosynthetic analysis algorithm implementation.” J Cheminform 11(1)\nSegler, Marwin HS, and Mark P. Waller. “Neural‐symbolic machine learning for retrosynthesis and reaction prediction.” Chemistry–A European Journal 23.25 (2017): 5966-5971.\n\nHybrid neural-symbolic approach for both retrosynthesis and reaction prediction that can be trained with large reaction sets from databases. Template extraction from known reaction datasets to classify new reaction to known reaction classes.\n\nSeidl, Philipp, et al. “Improving Few-and Zero-Shot Reaction Template Prediction Using Modern Hopfield Networks.” Journal of chemical information and modeling 62.9 (2022): 2111-2120.\n\nIntroduce a template-based single-step retrosynthesis model based on Modern Hopfield Networks, which learn an encoding of both molecules and reaction templates in order to predict the relevance of templates for a given molecule. The model does not consider templates as distinct categories, but can leverage structural information about the template. The retrieval approach enables generalization across templates, which makes zero-shot learning possible and improves few-shot learning. On the single-step retrosynthesis benchmark USPTO-50k, the MHN model reaction reaches the state-of-the-art at top-k accuracy for k ≥ 3.\n\nTu, Zhengkai, and Connor W. Coley. “Permutation invariant graph-to-sequence model for template-free retrosynthesis and reaction prediction.” Journal of Chemical Information and Modeling (2021).\n\nGraph2SMILES, a template-free retrosynthesis model to predict reaction outcomes and retrosynthesis routes. This model eliminates the need for any input-side SMILES augmentation, while achieving noticeable improvements over Transformer baselines (especially for top-1 accuracy).\nGenerate reaction networks:\n\nFooshee, David, et al. “Deep learning for chemical reaction prediction.” Molecular Systems Design & Engineering 3.3 (2018): 442-452.\nM. Liu et al., “Reaction Mechanism Generator v3.0: Advances in Automatic Mechanism Generation,” J. Chem. Inf. Model., May 2021\n\nNewest version of RMG (v3) is updated to Python v3. It has ability to generate heterogeneous catalyst models, uncertainty analysis to conduct first order sensitivity analysis. RMG dataset for the thermochemical and kinetic parameters have been expanded.\n\nMore and Faster: Simultaneously Improving Reaction Coverage and Computational Cost in Automated Reaction Prediction Tasks\n\nPresents an algorithmic improvement to the reaction network prediction task through their YARP (Yet Another Reaction Program) methodology. Shown to reduce computational cost of optimization while improving the diversity of identified products and reaction pathways.\n\nMolecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction\n\nFollow-up: Quantitative interpretation explains machine learning models for chemical reaction prediction and uncovers bias\n\nAutomatic discovery of chemical reactions using imposed activation\nMachine learning in chemical reaction space\n\nLook at exploration of reaction space rather than compound space. SOAP kernel for representing the moelcules. Estimate atomization energy for the molecules using ML. Calculate the d(AE) for different ML-estimated AEs. Reaction energies (RE) are estimated and uncertainty propogation is used to estimate the errors. Uncorrelated constant error propogation. 30,000 bond breaking reaction steps Rad-6-RE network used. RE prediction is not as good as AE.\nEstimate molecular complexity and synthesizability\nThe idea of estimating whether a molecule is ‘synthesizable’ can be thought of from two areas: 1. Structure-based (complexity) - compare the fragments in the molecule to the known fragments in the chemical space\n2. Full retrosynthesis based (synthesizability) - entire route is considered for molecule generation. Reactant complexity drives route complexity.\n\nLi, Junren, Lei Fang, and Jian-Guang Lou. “Retro-BLEU: quantifying chemical plausibility of retrosynthesis routes through reaction template sequence analysis.” Digital Discovery (2024).\n\nRetro-BLEU, a statistical metric adapted from the well-established BLEU score in machine translation, to evaluate the plausibility of retrosynthesis routes based on reaction template sequences analysis. The authors use PaRoute to validate this approach.\n\nErtl, Peter, and Ansgar Schuffenhauer. “Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions.” Journal of cheminformatics 1.1 (2009): 1-11.. RDkit implementation\n\nSynthetic Accessbility score (SA_Score) is a popular heuristic score for quantifying synthesizability. It computes a score using a fragment-contribution approach, where rarer fragments (as judged by their abundance in the PubChem database of 1mil representative cmpds) are taken as an indication of lower synthesizability.\n\nColey, Connor W., et al. “SCScore: synthetic complexity learned from a reaction corpus.” Journal of chemical information and modeling 58.2 (2018): 252-261.. DeepChem implementation\n\nSCScore is a learned synthetic complexity score computed as a neural network model trained on reaction data from the Reaxys database. It was designed with synthesis planning in mind to operate on molecules resembling not just drug-like products but intermediates and simpler building blocks as well.\n\nLiu, Cheng-Hao, et al. “RetroGNN: Fast Estimation of Synthesizability for Virtual Screening and De Novo Design by Learning from Slow Retrosynthesis Software.” Journal of Chemical Information and Modeling 62.10 (2022): 2293-2300.\n\nRetroGNN is a graph neural network based model to predict outcome of a synthesis planner given the target molecule. Shown to better perform than SAScore. Code is yet to be released.\n\nChen, Shuan, and Yousung Jung. “Estimating the synthetic accessibility of molecules with building block and reaction-aware SAScore.” Journal of Cheminformatics 16 (2024).\n\nAuthors introduce BR-SAScore, an enhanced version of SAScore that integrates the available building block information (B) and reaction knowledge (R) from synthesis planning programs into the scoring process. The score can also identify fragment contributing to the synthetic infeasibility.\n\nParrot, Maud, et al. “Integrating synthetic accessibility with AI-based generative drug design.” Journal of Cheminformatics 15.1 (2023): 83.\n\nFrom team at Iktos for triaging molecule designs. The group introduces (retro-score) RScore and RSPred (derived score from RScore using NN). RScore is computed through a full retrosynthesis analysis. The R2 value for RSPred is 0.75.\n\nA View on Molecular Complexity from the GDB Chemical Space\n\nShort perspective from Reymond group on complexity where they compare structural complexity of the molecules in the GDBs for synthesis using the node splits in the molecule. The idea is that as the number or the fraction of non-divalent nodes in the molecule graph increase the more complex the molecules becomes.\n\nData-driven chemistry modeling and reaction optimization\nReview / Perspectives\n\nRaghavan, Priyanka, et al. “Dataset design for building models of chemical reactivity.” ACS Central Science 9.12 (2023): 2196-2204.\n\nAuthors discuss the design of reaction datasets in ways that are conducive to data-driven modeling, emphasizing the idea that training set diversity and model generalizability rely on the choice of molecular or reaction representation. They lay down the experimental constraints associated with generating common types of chemistry datasets and how these considerations should influence dataset design and model building.\n\nMaloney, Michael P., et al. “Negative Data in Data Sets for Machine Learning Training.” Organic Letters (2023).\n\nThoughts from industry practioners on how to label low/no yield reactions in electronic lab notebooks (eLNs). This is important when building ML model for reaction outcomes.\n\nWilliams, Wendy L., et al. “The evolution of data-driven modeling in organic chemistry.” ACS central science 7.10 (2021): 1622-1637.\nMachine Learning Strategies for Reaction Development: Toward the Low-Data Limit\n\nIndustrial reactions commentary\n\nExpanding the medicinal chemistry synthetic toolbox\nThe Medicinal Chemist’s Toolbox: An Analysis of Reactions Used in the Pursuit of Drug Candidates\nLate-Stage Saturation of Drug Molecules\n\nSubstrate Scoping\nArea to understand the coverage of chemical space by a specific reaction transformation. Knowing which substrates can be used for a specific type of reactions can accelerate the generation of HTE datasets, and also reduce wastage and failures in searching for right substrates. Every new reaction protocol which is proposed would have a corresponding set of amenable ‘action-space’ for the ligands.\n\nRevealing the Relationship between Publication Bias and Chemical Reactivity with Contrastive Learning\n\nColey group explore publication bias in generating substrate scope for known synthetic methods. They devise a substrate scope contrastive learning method that treat reported substrates as +ve samples and unreported as -ve samples. Using an embedding space trained on substrate publication history the model groups them in two classes. They show the learned embeddings correlate with phys-org reactivity descriptiors.\n\nRana, D., Pflüger, P. M., Hölter, N. P., Tan, G., & Glorius, F. (2024). Standardizing Substrate Selection: A Strategy toward Unbiased Evaluation of Reaction Generality. ACS Central Science, 10(4), 899-906.\n\nThe authors report a standardized substrate selection strategy which mitigates biases found in traditional substrate scoping tables. This way the chemists can showcase unbiased applicability of novel methodologies facilitating their practical applications.\n\nGao, W., Raghavan, P., Shprints, R., & Coley, C. W. (2024). Substrate Scope Contrastive Learning: Repurposing Human Bias to Learn Atomic Representations. arXiv preprint arXiv:2402.16882.\nKariofillis, Stavros K., et al. “Using data science to guide aryl bromide substrate scope analysis in a Ni/photoredox-catalyzed cross-coupling with acetals as alcohol-derived radical sources.” Journal of the American Chemical Society 144.2 (2022): 1045-1055.\n\nIntegration of data science techniques, including DFT featurization, dimensionality reduction, and hierarchical clustering, to delineate a diverse and succinct collection of aryl bromides that is representative of the chemical space of the substrate class\n\nOn the Topic of Substrate Scope\n\nHTE-based Condition Optimization\n\nSouza, Lucas W., et al. “Applying Active Learning toward Building a Generalizable Model for Ni-Photoredox Cross-Electrophile Coupling of Aryl and Alkyl Bromides.” Journal of the American Chemical Society 147.22 (2025): 18747-18759.. Github\n\nDoyle group collaborates with Novartis to generate an active learning strategy to inform reaction condition optimization routines for Ni-Photoredox cross electrophile reaction. They build a model using less than 400 data points, they show the AL-based method is significantly better at predicting which reactions will be successful.\n\nSin, Joshua W., et al. “Highly parallel optimisation of chemical reactions through automation and machine intelligence.” Nature Communications 16.1 (2025): 6464.. Codebase\n\nPhillipe Schwaller’s group propose Minerva - an multi-objective reaction optimization routine that uses HTE data to optimze conditions for Ni-catalyzed Suzuki reaction. They use ML model to fill in gaps for the domain that model is trained on to complete the data set and train a better model.\n\nPomberger, Alexander, et al. “The effect of chemical representation on active machine learning towards closed-loop optimization.” Reaction Chemistry & Engineering 7.6 (2022): 1368-1379.\n\nLapkin and co look at the effect of chemical representation on reaction performance and condition prediction tasks. They look at the high throughput experientation generated datasets and the impact of calculated chemical descriptors on the prediction of reaction yields. They show tailored descriptions did not outperform the traditional ones but larger initial data accelerated reaction performance.\n\nHaas, Brittany, et al. “Rapid Prediction of Conformationally-Dependent DFT-Level Descriptors using Graph Neural Networks for Carboxylic Acids and Alkyl Amines.” (2024).\n\n2D and 3D-aware GNNs to predict DFT descriptors for conformationally flexible molecules, focusing on carboxylic acid and amines in particular.\n\nWang, J.Y., Stevens, J.M., Kariofillis, S.K. et al. Identifying general reaction conditions by bandit optimization. Nature 626, 1025–1033 (2024).\n\nLatest from Abigail Doyle’s group where they use bandit optimization routine, related to Thompson sampling, to find reaction condition.\n\nGötz, Julian, et al. “High-throughput synthesis provides data for predicting molecular properties and reaction success.” Science advances 9.43 (2023). Github\n\nThe authors propose a platform that is built for looking at photocatalytic N-heterocycle synthesis connected with HTE, automated purification, and physicochemical assays. Implement train-test split in 3 different strategies to minimize ligand overlap.\n\nMachine learning from quantum chemistry to predict experimental solvent effects on reaction rates\nCasetti, Nicholas, et al. “Combining Molecular Quantum Mechanical Modeling and Machine Learning for Accelerated Reaction Screening and Discovery.” Chemistry–A European Journal 29.60 (2023): e202301957.\nB. J. Shields et al., “Bayesian reaction optimization as a tool for chemical synthesis,” Nature, vol. 590, no. June 2020, p. 89, 2021. Github\n\nExperimental design using Bayesian Optimization. Look at 3 rxn class with multiple reaction parameters - temp solvent ligand. Algorithm identifies the optimal conditions. Variables looked into: ligands, bases, solvents, temperatures, concentrations. Algorithm arrived at 99% yields consistently - which was possible by using unusual ligand not known to work well (cognitive bias).\n\nTorres, Jose Garrido, et al. “A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.” (2022).. Follow-up Version 2.0\nHickman, Riley J., et al. “Bayesian optimization with known experimental and design constraints for chemistry applications.” arXiv preprint arXiv:2203.17241 (2022).\nGensch, Tobias, et al. “A comprehensive discovery platform for organophosphorus ligands for catalysis.” Journal of the American Chemical Society 144.3 (2022): 1205-1217.\n\nAlso called Kraken - a discovery platform covering monodentate organophosphorus(III) ligands providing comprehensive physicochemical descriptors based on representative conformer ensembles. Using quantum-mechanical methods, the authors calculated descriptors for 1558 ligands, including commercially available examples, and trained machine learning models to predict properties of over 300000 new ligands.\n\nHäse, Florian, et al. “Gryffin: An algorithm for Bayesian optimization of categorical variables informed by expert knowledge.” Applied Physics Reviews 8.3 (2021): 031406.\nDotson, Jordan, et al. “Data-driven multi-objective optimization tactics for catalytic asymmetric reactions.” (2022).\n\nMulti-objective optimization of catalytic reactions that employ chiral bisphosphine ligands. Optimization of 2 sequential reactions in asymmetric synthesis of API. Classification method identify active catalysts – 5% yield (user provided) cutoff for binary classification. Linear regression to model reaction selectivity. DFT-derived descriptor dataset of &gt;550 bisphosphine ligands. Develop an interpretable chemical space mapping tool using PCA. Look at the domain of applicability with the euclidean distance in chemical space.\nGenerate catalysts\n\nSchilter, Oliver, et al. “Designing catalysts with deep generative models and computational data. A case study for Suzuki cross coupling reactions.” Digital Discovery (2023).\n\nUse VAE and RNN to propose new catalyst for Suzuki cross-coupling reaction. The trained models are used to find catalyst’s binding energy and find high percentage of novel and valid designs.\nDatabases\n\nAvila, Claudio, et al. “Chemistry in a graph: modern insights into commercial organic synthesis planning.” Digital Discovery (2024).\n\nTeam from Pfizer use Graph Datasets and Network visualization to show how process chemistry data (GLP1 inhibitor Lotiglipron in this case) can be stored, queried, and used for illustration purposes. They demonstrate the utility of knowledge graph for optimizing the route selection process. Neo4J is used for querying the dataset.\n\nKearnes, S. M., et al. (2021). “The Open Reaction Database.” Journal of the American Chemical Society.\nData Sharing in Chemistry: Lessons Learned and a Case for Mandating Structured Reaction Data\nRohrbach, Simon, et al. “Digitization and validation of a chemical synthesis literature database in the ChemPU.” Science 377.6602 (2022): 172-180.\nCGRdb2.0: A Python Database Management System for Molecules, Reactions, and Chemical Data\n\nReaction sanitization\n\nORDerly: Datasets and benchmarks for chemical reaction data\nReaction Data Curation I: Chemical Structures and Transformations Standardization\n\nReaction data extraction\n\nDong, Qingyang, and Jacqueline M. Cole. “Snowball 2.0: Generic Material Data Parser for ChemDataExtractor.” Journal of Chemical Information and Modeling (2023).\nReactionDataExtractor 2.0: A Deep Learning Approach for Data Extraction from Chemical Reaction Schemes\n\n\n\nAutomated chemistry workflows\nReviews\n\nSelf-Driving Laboratories for Chemistry and Materials Science\n\nThis review article provides an in-depth analysis of the state-of-the-art in SDL technology, its applications across various scientific disciplines, and the potential implications for research, and industry. This review additionally provides an overview of the enabling technologies for SDLs, including their hardware, software, and integration with laboratory infrastructure. Most importantly, this review explores the diverse range of scientific domains where SDLs have made significant contributions, from drug discovery and materials science to genomics and chemistry.\n\nSeifrid, Martin, et al. “Autonomous Chemical Experiments: Challenges and Perspectives on Establishing a Self-Driving Lab.” Accounts of Chemical Research (2022): e0229862-131.\nGodfrey, Alexander G., Thierry Masquelin, and Horst Hemmerle. “A remote-controlled adaptive medchem lab: an innovative approach to enable drug discovery in the 21st Century.” Drug Discovery Today 18.17-18 (2013): 795-802.\n\nAccount of Eli Lilly and Company’s ASL (Automated Synthesis Lab)\nArticles\n\nAutonomous, multiproperty-driven molecular discovery: From predictions to measurements and back\nNambiar, Anirudh MK, et al. “Bayesian Optimization of Computer-Proposed Multistep Synthetic Routes on an Automated Robotic Flow Platform.” ACS Central Science (2022).\nWilbraham, Liam, S. Hessam M. Mehr, and Leroy Cronin. “Digitizing chemistry using the chemical processing unit: from synthesis to discovery.” Accounts of Chemical Research 54.2 (2020): 253-262.\n\n\n\nDNA-encoded Libraries\n\nMatthew Clark, et. al. DNA-encoded small-molecule libraries (DEL). C&EN article on the topic\n\nNew form of storing huge amounts of molecule related data using DNA. Made partially possible by low cost of DNA sequencing. Each molecule in the storage is attached with a DNA strand which encode information about its recipe.\n\nFollow up to the work with Machine Learning for hit finding.\n\nDNA encodings for discovery of novel small-molecule protein inhibitors. Outline a process for building a ML model using DEL. Compare graph convolutions to random forest for classification tasks with application to protein target binding. Graph models seemed to achieve high hit rate comapred to random forest. Apply diversity, logistical, structural filtering to search for novel candidates. First work to use GCN for hit searching.\n\nMartín, A., et al. (2020). “Navigating the DNA encoded libraries chemical space.” Communications Chemistry 3(1).\nZabolotna, Y., Pikalyova, R., Volochnyuk, D., Horvath, D., Marcou, G., & Varnek, A. (2021). Exploration of the chemical space of DNA-encoded libraries.\nShmilovich, Kirill, et al. “DEL-Dock: Molecular Docking-Enabled Modeling of DNA-Encoded Libraries.” arXiv preprint arXiv:2212.00136 (2022).\n\nPropose a way to incoporate 3D-spatial information in the DEL read outs to denoise the data.\n\nZhang, Chris, et al. “Building Block-Based Binding Predictions for DNA-Encoded Libraries.” (2023). Github\n\nSet of informatic tools to look at BBs producitivity in DEL screens and guide designs for new DELs. Authors calculate joint probabilities of the BBs for its activity and find increasing binding metric for individual BBs also increases the overall binding energy. The authors then cluster these BBs using 2D and 3D tanimoto FPs (3D Tanimoto Combo) and HDBSCAN clustering. Good workflow for implementing 3D-based ROCs filtering."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#large-language-models-llms",
    "href": "posts/2025-01-06-small_molecule_resources.html#large-language-models-llms",
    "title": "Medicine drug discovery resources",
    "section": "Large Language Models (LLMs)",
    "text": "Large Language Models (LLMs)\nIt’s a stretch to say that GPT-5 or any other LLM understands Chemistry. They are atleast getting better at it slowly.\nAt this point, LLMs seem to have two general use cases. First, summarization and information retrieval. LLMs can parse vast collections of text, which can be queried using natural language. These information retrieval capabilities have many applications, from writing computer code and collating clinical trial results to summarizing papers on a specific topic.\nWhile there are still issues with LLMs hallucinating and providing incorrect information, tools and strategies are being developed to ensure the validity of LLM responses.\nThe other area where LLMs appear to be making inroads is workflow management or tools orchestration. Many activities in drug discovery, whether computational or experimental, require long sequences of steps, which can be tedious to orchestrate. These include asking questions about data, analyze results, do routine post processing for comparing with known state of the project.\nWhile it is often possible to script the execution of these steps, scripting requires a detailed knowledge of each step. LLMs have the potential to simplify this process and carry out multi-step procedures given only a set of initial conditions and a final objective. While the amount of progress the field has made in a short time is impressive, I don’t see LLMs replacing scientists any time soon.\nPreviously the field has propose assistants for this job here which comprised of pre-scripted set of rules and processes. While tedious, they seem to add lot of value to project teams for quickly analyzing the SAR. The hope is LLMs might make the dream of all encompasing assistant a reality.\n\nTotal survey of the LLM landscape\nGeneral LLM-based multi-agent survey\n\nReviews\n\nRamos, Mayk Caldas, Christopher J. Collison, and Andrew D. White. “A Review of Large Language Models and Autonomous Agents in Chemistry.” arXiv preprint arXiv:2407.01603 (2024).. Github\nScientific Large Language Models: A Survey on Biological & Chemical Domains\nBran, Andres M., and Philippe Schwaller. “Transformers and Large Language Models for Chemistry and Drug Discovery.” arXiv preprint arXiv:2310.06083 (2023).\nGao, S., Fang, A., Huang, Y., Giunchiglia, V., Noori, A., Schwarz, J. R., Ektefaie, Y., Kondic, J., & Zitnik, M. (2024). Empowering biomedical discovery with AI agents. Cell, 187(22), 6125–6151. https://doi.org/10.1016/j.cell.2024.09.022\nPyzer-Knapp, Edward O., et al. “Foundation models for materials discovery–current state and future directions.” npj Computational Materials 11.1 (2025): 61.\n\nMeta-Analysis\n\nRuncie, Nicholas T., Charlotte M. Deane, and Fergus Imrie. “Assessing the Chemical Intelligence of Large Language Models.” arXiv preprint arXiv:2505.07735 (2025).\n\nNice analysis by folks at OPIG asking if LLMs esp. the reasoning-based models understand chemistry. While the results aren’t outstanding, they do show improvements in LLMs knowledge of SMILES, chemical stuctures, and NMR spectras. More importantly, this paper proposes a new benchmark, ChemIQ, to assess this features much more robustly moving beyond the usual MCQ based contemporary datasets.\nAgents\n\nBioDiscoveryAgent\nTxAgent\n\nAI Agent for therapeutic reasoning across a universe of tools. I like the Tool-RAG and the plethora of tools that are documented and exposed.\n\nGhafarollahi, Alireza, and Markus J. Buehler. “ProtAgents: Protein discovery via large language model multi-agent collaborations combining physics and machine learning.” arXiv preprint arXiv:2402.04268 (2024).\nPaperQA: Retrieval-Augmented Generative Agent for Scientific Research\n\nPaperQA, a Retrieval-Augmented Generation (RAG) agent for the scientific literature. PaperQA begins by constructing LLM search queries from a set of keywords. The results of these searches are aggregated into a vector database and combined with a pre-trained LLM to create a summary of the search results. In benchmark comparisons, the differences between answers provided by PaperQA and human evaluators were similar to differences between individual human evaluators. Encouragingly, unlike many other LLMs, PaperQA didn’t hallucinate citations.\n\nBran, Andres M., et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\n\nChemCrow provides software tools for performing domain-specific tasks, including web searches, file format conversions, and similarity searches. Compared with GPT-4, ChemCrow provided superior performance on tasks like synthetic route planning. The authors also point to potential misuse of LLMs and suggest mitigation strategies.\n\nBoiko, Daniil A., Robert MacKnight, and Gabe Gomes. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).. Peer-review\n\nCoscientist, a set of LLMs for designing and executing organic syntheses. Coscientist consists of four components designed to search the web, write Python code, extract information from documentation, and program laboratory robotics. The authors test Coscientist using several open and closed-source LLMs and present examples of the system’s ability to plan and execute simple organic syntheses.\n\nWu, Shirley, et al. “AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning.” The Thirty-eighth Annual Conference on Neural Information Processing Systems.\n\nFramework that optimizes an LLM agent to use the provided tools. This framework is integrated in DSPy\n\nZhang, Chonghuan, et al. “SynAsk: unleashing the power of large language models in organic synthesis.” Chemical Science 16.1 (2025): 43-56.\n\nNew ReAct agent from AIChemEco team. No code or data available. LLM with tool use (langchain + qwen 1.2b). Main value prop. are their bespoke tools (section 2.5.5) yield prediction, condition pred. and retrosynthesis model.\nGenerative Design\n\nWang, Haorui, et al. “Efficient Evolutionary Search Over Chemical Space with Large Language Models.” arXiv preprint arXiv:2406.16976 (2024).\n\nIntroduce LLMs for conducting evolutionary algorithm searches.\nFoundation models\n\nNach0\nTx-LLM\n\nThe team is looking at creating an LLM-based predictive model (regression and classification). They show that one large model can be used to predict multiple end points (think of one model used for all ADME endpoints), and it indicates that training on a variety of tasks can improve overall performance (positive transfer learning).\nI am glad to see this work as it shows how much information and feature-richness can be encoded within the transformer model, especially in the low-data regime; that said, one caution with this approach is that the models are purely text-based and extremely black box and correlation doesn’t mean causation, more so here since we don’t have good control over features being used to train the model.\n\nNatureLM\n\nTeam at microsoft research introduces introduces Nature Language Model (NatureLM), a sequence-based science foundation model designed for scientific discovery across multiple domains like small molecules, proteins, and materials. NatureLM excels in generating and optimizing scientific entities and offers top performance, matching or surpassing state-of-the-art specialist models.\n\nSirumalla, S. K., Farina Jr, D. S., Qiao, Z., Di Cesare, D. A., Farias, F. C., O’Connor, M. B., … & Miller, T. Multi-Modal and Multi-Task Transformer for Small Molecule Drug Discovery. In ICML’24 Workshop ML for Life and Material Science: From Theory to Industry Applications.\n\nFrom Iambic team: 1B-parameter transformer model pre-trained on 2.25 trillion tokens from diverse datasets focused on drug discovery. It details a comprehensive data pipeline for standardizing and processing data from various sources. The model architecture is based on LLaMA-2 and includes advanced features like SwishGLU and Rotary Positional Encoding. The fine-tuned model outperforms strong baselines in assay prediction tasks.\nPredictive modeling\n\nThe Goldilocks paradigm: comparing classical machine learning, large language models, and few-shot learning for drug discovery applications\nJablonka, Kevin Maik, et al. “Leveraging Large Language Models for Predictive Chemistry.” (2023).. Peer-review\n\nAuthors show GPT3 based predictive models perform on-par with SOTA with lower data points. Caution is the models are purely text-based and extreme black box and sometimes, while trite, correlation doesnt mean causation might become important here. Finally the fine tuning doesnt do regression on the data in same sense as a linear regression or random forest would do.\n\nBindGPT\n\nSmall molecule related tasks\n\nMDCrow: Automating Molecular Dynamics Workflows with Large Language Models\nether0\nLiu, Shengchao, et al. “Conversational drug editing using retrieval and domain feedback.” The Twelfth International Conference on Learning Representations. 2024.\nLe, Khiem, et al. “MolX: Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension.” arXiv preprint arXiv:2406.06777 (2024).\nLiu, Shengchao, et al. “Multi-modal molecule structure–text model for text-based retrieval and editing.” Nature Machine Intelligence 5.12 (2023): 1447-1457.\nYu, Botao, et al. “LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset.” arXiv preprint arXiv:2402.09391 (2024).\nPei, Qizhi, et al. “BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning.” arXiv preprint arXiv:2402.17810 (2024).\n\nBioT5+ incorporates several novel features: integration of IUPAC names for molecular understanding, inclusion of extensive bio-text and molecule data from sources like bioRxiv and PubChem, the multi-task in struction tuning for generality across tasks, and a novel numerical tokenization technique for improved processing of numerical data.\n\nIrwin, R., Dimitriadis, S., He, J., Bjerrum, E.J., 2021. Chemformer: A Pre-Trained Transformer for Computational Chemistry. Mach. Learn. Sci. Technol.. Previously called MolBART\nLLM-based generation and benchmarking\nLanguage + Molecule Benchmarks\n\nProtein design and mechanics\n\nPinal\nEvo2\nBioEmu-1\nEvoDiff\n\nEvoDiff, a diffusion-based generative model that designs novel proteins directly in sequence space, bypassing limitations of structure-based models. By leveraging large-scale evolutionary data, EvoDiff generates diverse, high-fidelity, and functionally plausible proteins, including those with disordered regions.\n\nQueen, Owen, Yepeng Huang, Robert Calef, Valentina Giunchiglia, Tianlong Chen, George Dasoulas, LeAnn Tai et al. “ProCyon: A multimodal foundation model for protein phenotypes.” bioRxiv (2024): 2024-12.\n\nProCyon integrates phenotypic and protein data. Authors show its use for identifying protein domains that bind small molecule drugs, predicting peptide binding with enzymes, and assessing the functional impact of Alzheimer’s disease mutations. ProCyon enables conditional retrieval of proteins linked to small molecules through complementary mechanisms of action\n\nRuffolo, Jeffrey A., and Ali Madani. “Designing proteins with language models.” Nature Biotechnology 42.2 (2024): 200-202.\nBuehler, Eric L., and Markus J. Buehler. “X-LoRA: Mixture of Low-Rank Adapter Experts, a Flexible Framework for Large Language Models with Applications in Protein Mechanics and Design.” arXiv preprint arXiv:2402.07148 (2024).\n\nMixture of LoRA Experts: Leverage the power of fine-tuned LoRA experts by employing a mixture of experts, or MoE technique.\nClinical text\n\nLopez, Ivan, et al. “Clinical entity augmented retrieval for clinical information extraction.” npj Digital Medicine 8.1 (2025): 45.\nVan Veen, D., Van Uden, C., Blankemeier, L. et al. Adapted large language models can outperform medical experts in clinical text summarization. Nat Med (2024).. Github\n\nAuthors look at clinical summarization and implement quantitative assesments with synctactic, semantic, and conceptual NLP metrics. A clinical reader study with 10 physicians evaluated summary completeness, correctness and conciseness; in most cases, summaries from our best-adapted LLMs were deemed either equivalent (45%) or superior (36%) compared with summaries from medical experts. The research provides evidence of LLMs outperforming medical experts in clinical text summarization across multiple tasks. This suggests that integrating LLMs into clinical workflows could alleviate documentation burden, allowing clinicians to focus more on patient care.\n\nSaab, K.; et. al. Capabilities of Gemini Models in Medicine. arXiv May 1, 2024.\n\nGoogle’s team shows Med-Gemini’s real-world utility by surpassing human experts on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education.\nMedical tasks\n\nMedHELM\n\nMedHELM, an extensible evaluation framework for assessing LLM performance for medical tasks. Building on the HELM framework, MedHELM comprises a structured taxonomy with 5 categories, 22 subcategories, and 121 distinct clinical tasks as well as 35 distinct benchmarks (14 private, 7 gated-access, and 14 public). The benchmarks represent a spectrum of healthcare scenarios, from diagnostic decision-making to patient communication, providing a more nuanced and medically relevant assessment of AI capabilities in healthcare settings\nData curation\n\nLeong, S. X., Pablo-García, S., Wong, B., & Aspuru-Guzik, A. (2025). MERMaid: Universal multimodal mining of chemical reactions from PDFs using vision-language models.\n\nAspuru-Guzik group releases a full suite of tools to ingest, process, and generate knowledge graphs from scientific publications. They show MERMaid, using the vision language models, demonstrate chemical context awareness and reasoning capabilities from the extracted text.\n\nFrom text to insight: large language models for chemical data extraction\n\nJablonka group in Jena shared their early findings in using LLMs for chemical and material data extraction tasks. This is structured as a tutotrial review providing specific workflow examples.\n\nExtracting Structured Data from Free-form Organic Synthesis Text\n\nHackathon to quickly fine-tune GPT to parse synthesis data and extract relevant chemistry-related information.\nMaterial science\n\nGruver, Nate, et al. “Fine-Tuned Language Models Generate Stable Inorganic Materials as Text.” arXiv preprint arXiv:2402.04379 (2024).\n\nReaction development\n\nLLM-Augmented Chemical Synthesis and Design Decision Programs\n\nExplore how LLMs can be used as decision making engines.\n\nBran, Andres M., Theo A. Neukomm, Daniel P. Armstrong, Zlatko Jončev, and Philippe Schwaller. “Chemical reasoning in LLMs unlocks steerable synthesis planning and reaction mechanism elucidation.” arXiv preprint arXiv:2503.08537 (2025).\nLi, H., Sarkar, S., Lu, W., Loftus, P., Qiu, T., Shee, Y., … & Batista, V. (2025). Collective Intelligence of Specialized Language Models Guides Realization of de novo Chemical Synthesis.Code\n\nMOSAIC is a fine-tuned LLama 3.1-8b-instruct model for reaction recipe generation.\n\nLiu, G., Sun, M., Matusik, W., Jiang, M., & Chen, J. (2024). Multimodal Large Language Models for Inverse Molecular Design with Retrosynthetic Planning. arXiv preprint arXiv:2410.04223.\n\nThe team introduces Llamole, multimodal LLM capable of generating text and graphs.\nAgent Engineering\n\n[HiAgent]https://arxiv.org/abs/2408.09559)\nPOPPER\nLADDER\nNarayanan, Siddharth, James D. Braza, Ryan-Rhys Griffiths, Manu Ponnapati, Albert Bou, Jon Laurent, Ori Kabeli et al. “Aviary: training language agents on challenging scientific tasks.” arXiv preprint arXiv:2412.21154 (2024).. Github\n\nCasting the AI Agentic process as a markov decision process and train language-based AI Agent on biology tasks. They show exceeding human-level performance on SeqQA (dataset consists of MCQs questions, such as counting the fragments after digestion, predicting translated sequences, and identifying polymerase chain reaction primers). The trained Language Agent are compute efficient.\n\nHu, S., Lu, C., & Clune, J. (2024). Automated design of agentic systems. arXiv preprint arXiv:2408.08435.Website\n\nFramework to automatically creating new agent given appropriate building blocks and combine them in new ways. They proposed Meta-Agent search and show agents can invent novel and power agent designs.\n\nSwanson, Kyle, Wesley Wu, Nash L. Bulaong, John E. Pak, and James Zou. “The Virtual Lab: AI Agents Design New SARS-CoV-2 Nanobodies with Experimental Validation.” bioRxiv (2024): 2024-11.\n\nA joint paper from James Zou (Stanford) and Chan-Zuckerberg foundation showcases a virtual lab comprising of AI Agentic personas of typical research group collaborating together to design nanobodies. Interesting idea.\n\nAI Scientist from SakanaAI\n\nAutomation to encompass end-to-end scientific discovery, including coding, experiment execution, and automated peer review for manuscript generation.\nModel Improvements\n\nZelikman, E., Harik, G., Shao, Y., Jayasiri, V., Haber, N., & Goodman, N. D. (2024). Quiet-star: Language models can teach themselves to think before speaking. arXiv preprint arXiv:2403.09629."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#data-extraction",
    "href": "posts/2025-01-06-small_molecule_resources.html#data-extraction",
    "title": "Medicine drug discovery resources",
    "section": "Data extraction",
    "text": "Data extraction\nRule-based tool\n\nLeadMine - NextMove\n\nAI-based tool\nDespite so much progress around computer vision and optical character recognition (OCR) the state of the art for molecule image conversion to structure still remains to be manual curation. There have been some interesting tools proposed for automating this using different flavor of computer-vision algorithms.\n\nMarcus\n\nMARCUS (molecule annotation and recoginition for curating unravelled structure) is a tool designed to automate the extraction, recognition, and processing of molecular structures from scientific literature. Integrates multiple Optical Chemical Structure Recognition engines (DECIMER, MolNexTR, MolScribe) to convert chemical images into machine-readable formats (SMILES, molfile).\n\nMolGrapher\nImg2Mol\n\nOne of the core reasons this area has been under explored seems to be molecule patents are MADE to be tough to decipher. The format is non standard and markush enumerations, alongside, their actual chemical space coverage is ill-defined.\n\nDECIMER\n\nDECIMER Image Transformer: Deep Learning for Chemical Image Recognition using Efficient-Net V2 + Transformer. V1. Extraction of chemical structure through OSCR (Optical chemical structure recognition) from Steinbeck’s group.\n\nFan, Vincent, et al. “OpenChemIE: An information extraction toolkit for chemistry literature.” Journal of Chemical Information and Modeling (2024).\n\nFocused on the extraction of reaction data from journals. OpenChemIE is most suited for information extraction on organic chemistry literature, where molecules are generally depicted as planar graphs or written in text and can be consolidated into a SMILES format.\n\nAi, Q., Meng, F., Shi, J., Pelkie, B. G., & Coley, C. W. (2024). Extracting structured data from organic synthesis procedures using a fine-tuned large language model. Digital Discovery.\n\nUsing Llama-2 7b to extract entities from synthesis recipes from reactions."
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#code-packages",
    "href": "posts/2025-01-06-small_molecule_resources.html#code-packages",
    "title": "Medicine drug discovery resources",
    "section": "Code / Packages:",
    "text": "Code / Packages:\nBioinformatics\n\nGaia\n\nProtein sequence annotator and finder based on genomic context that outperforms traditional sequence and structure-based methods\n\nCHEAP\n\nJoint embedding model for protein structure and function.\nPeptide Informatics\nI visit first-ever RDKit UGM early April 2025 and was impressed by the tools available for manipulating and analyzing peptide chemical space. Below are few:\n\nPepFun - From Novo Nordisk informatics team, they provide functionalities to study peptides at different levels, sequence, structures, and large dataset. It is built on BioPython and RDKit.\nSynthCoder\nMolcomplex General purpose package to calculate molecule complexity and synthesizability\nHonegumi\nRxn-INSIGHT\nMolecular AI department at AstraZeneca R&D\nJazzy: Fast calculation of hydrogen-bond strengths and free energy of hydration of small molecules\nGHOST: Generalized threshold shifting procedure. Paper. Blogpost\n\nAutomates the selection of decision threshold for imbalanced classification task. The assumption for this method to work is the similar characteristics (like imbalance ratio) of training and test data.\n\nMOSES - Benchmarking platform for generative models (PyTorch Implementation). Github\n\nBenchmarking platform to implement molecular generative models. It also provides a set of metrics to evaluate the quality and diversity of the generated molecules. A benchmark dataset (subset of ZINC) is provided for training the models.\n\nReinvent 4.0 - an AI tool forr de novo drug design. Github\n\nProduction-ready tool for de novo design from Astra Zeneca. It can be effectively applied on drug discovery projects that are striving to resolve either exploration or exploitation problems while navigating the chemical space. Language model with SMILE output and trained by “randomizing” the SMILES representation of the input data. Implement reinforcement-leraning for directing the model towards relevant area of interest. Now uses PyTorch 2.0!\n\nOpenChem. Github\nDeepChem (Tensorflow). Website\n\nDeepChem aims to provide a high quality open-source toolchain that democratizes the use of deep-learning in drug discovery, materials science, quantum chemistry, and biology - from Github\n\nChemProp (Pytorch)\n\nGithub repository for implmenting message passing neural networks for molecular property prediction as described in the paper Analyzing Learned Molecular Representations for Property Prediction by Yang et. al. \n\nFastJTNN - python 3 version of the JT-NN\nDimeNet++ - extension of Directional message pasing working (DimeNet). Github\nBondNet - Graph neural network model for predicting bond dissociation energies, considers both homolytic and heterolytic bond breaking. Github\nAutodE\nDScribe\nRMG - Reaction Mechanism Generator\n\nTool to generate chemical reaction networks. Includes Arkane, package for calculating thermodynamics from quantum mechanical calculations.\n\nPyePAL\n\nActive learning approach to efficiently and confidently identify the Pareto front with any regression model that can output a mean and a standard deviation.\n\nrxnfp\n\nGithub repository to generate chemical reaction fingerprints from reaction SMILES.\n\nmols2grid\n\nInteractive chemical viewer for small molecules (RDKit wrapper)\n\nmolplotly\n\nSpotfire like capabilities to jupyter notebook. Medium article on explaining the MolPlotly. Link\n\nESPsim\n\nCalculate similarities of shapes and electrostatic potentials between molecules. Pen has a nice blogpost on using to estimate electronic similarities of common bioisosteres. blog\n\nHotSpots: Curran, Peter R., et al. “Hotspots api: a python package for the detection of small molecule binding hotspots and application to structure-based drug design.” Journal of chemical information and modeling 60.4 (2020): 1911-1916.\n\nSurvey protein surfaces for binding hotspots can help to evaluate target tractability and guide exploration of potential ligand binding regions.\n\nMolPal\n\nActive learning methodology for sampling the chemical space\n\nGenerative Toolkit 4 Scientific Discovery\nJazzy + Chemprop\n\nChemprop version that combines Jazzy (AZ’s workflow for predicting H-bond strength)"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#datasets-chemical-libraries",
    "href": "posts/2025-01-06-small_molecule_resources.html#datasets-chemical-libraries",
    "title": "Medicine drug discovery resources",
    "section": "Datasets & Chemical libraries",
    "text": "Datasets & Chemical libraries\nMolecule datasets\n\nPubChem: public sourced molecules\nChEMBL: bioactive molecules (most synthetic)\nSUREChEMBL: small molecules appearing in Patents\nZINC: collection of synthetic molecules (not all are bioactive)\nQM 7/8/9: small molecules having not more than 7/8/9 heavy atoms\nGDB-17\nPapyrus\nCOCONUT: NP 400k there are some which are not NP\nMcule: Used in DEL enumerations\nDrugBank\n\nReaction Datasets\n\nUSPTO\nPistachio\nReaxys\nOpen Reaction Database\n\nCommercial (building block) vendors\n\neMolecules\nEnamine\n\nWuXi\nChembridge\nAsinex\nMolport\nPharmablock\nOtava’s CHEMriya"
  },
  {
    "objectID": "posts/2025-01-06-small_molecule_resources.html#helpful-utilities",
    "href": "posts/2025-01-06-small_molecule_resources.html#helpful-utilities",
    "title": "Medicine drug discovery resources",
    "section": "Helpful utilities:",
    "text": "Helpful utilities:\n\nRD-Kit\n\nGet Atom Indices in the SMILE:\nDatamol for manipulating RDKit molecules\n\nDataMol-SAFE\nMOSES: Molecular generation models benchmark\nTherapeutics Data Commons\n\nTherapeutics Data Commons is an open-science platform with AI/ML-ready datasets and learning tasks for therapeutics, spanning the discovery and development of safe and effective medicines. TDC also provides an ecosystem of tools, libraries, leaderboards, and community resources, including data functions, strategies for systematic model evaluation, meaning"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html",
    "href": "posts/2021-01-27-bayesian_optimization.html",
    "title": "Bayesian optimisation implementation",
    "section": "",
    "text": "If \\(f\\) (objective function) is cheap to evaluate we can sample various points and built a potential surface however, if the \\(f\\) is expensive – like in case of first-principles electronic structure calculations, it is important to minimize the number of \\(f\\) calls and number of samples drawn from this evaluation. In that case, if an exact functional form for f is not available (that is, f behaves as a “black box”), what can we do?\nBayesian optimization proceeds by maintaining a probabilistic belief about \\(f\\) and designing a so called acquisition function to determine where to evaluate the next function call. Bayesian optimization is particularly well-suited to global optimization problems where: 1. \\(f\\) is an expensive black-box function 2. Analytical solution for the gradient of the function is difficult to evaluate\nThe idea is the find “global” minimum with least number of steps. Incorporating prior beliefs about the underlying process and update the prior with samples draw from the model to better estimate the posterior.\nModel used for approximating the objective function is called the surrogate model.\nFollowing are few links I have found useful in understanding the inner workings of the Bayesian opitmization and certain typical surrogate functions used in it:"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html#import-the-acquisition-functions-implemented",
    "href": "posts/2021-01-27-bayesian_optimization.html#import-the-acquisition-functions-implemented",
    "title": "Bayesian optimisation implementation",
    "section": "## Import the acquisition functions implemented",
    "text": "## Import the acquisition functions implemented\n\nEI = acquisition.ExpectedImprovement(delta = 0.01)\nLCB = acquisition.LowerConfidenceBound(sigma = 1.96)"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html#fit-a-gpr-model-surrogate-function-to-the-sampled-points",
    "href": "posts/2021-01-27-bayesian_optimization.html#fit-a-gpr-model-surrogate-function-to-the-sampled-points",
    "title": "Bayesian optimisation implementation",
    "section": "Fit a GPR model (surrogate function) to the sampled points",
    "text": "Fit a GPR model (surrogate function) to the sampled points\n\nconstant = kernels.ConstantKernel()\nmatern = kernels.Matern(nu = 2.5)\nrbf = kernels.RBF()\n\ngpr_model = GPR(kernel = constant*rbf, alpha = 1e-3, n_restarts_optimizer = 20, normalize_y = False, random_state = 42)\n\ngpr_model.fit(x_sample, y_sample)\n\nGaussianProcessRegressor(alpha=0.001, kernel=1**2 * RBF(length_scale=1),\n                         n_restarts_optimizer=20, random_state=42)\n\n\n\n(mean_pred, stddev_pred) = gpr_model.predict(x_pts, return_std = True)\ngpr_model.kernel_\n\n2.78**2 * RBF(length_scale=0.782)"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html#plot-the-initial-sample",
    "href": "posts/2021-01-27-bayesian_optimization.html#plot-the-initial-sample",
    "title": "Bayesian optimisation implementation",
    "section": "Plot the Initial Sample",
    "text": "Plot the Initial Sample\n\n(fig_ec, ax_ec) = plotting_utils.illustrate_1d_gpr(objective, gpr_model, x_pts, EI, LCB)"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html#run-a-few-iterations-and-assess",
    "href": "posts/2021-01-27-bayesian_optimization.html#run-a-few-iterations-and-assess",
    "title": "Bayesian optimisation implementation",
    "section": "Run a Few Iterations and Assess",
    "text": "Run a Few Iterations and Assess\n\npkwargs = {\"num_sample\": 10,\n           \"num_improve\": 5,\n           \"generator\": generator}\n\nres_ec, _ = opti.bayesian_optimization(objective, gpr_model, LCB, domain, max_iter=10, noise=noise_, prop_kwargs = pkwargs)\ngpr_model.fit(res_ec[\"X\"], res_ec[\"y\"]) # Incorporate final point into plots.\n\n10\n\n\nGaussianProcessRegressor(alpha=0.001, kernel=1**2 * RBF(length_scale=1),\n                         n_restarts_optimizer=20, random_state=42)\n\n\n\n(fig_ec, ax_ec) = plotting_utils.illustrate_1d_gpr(objective, gpr_model, x_pts, EI, LCB, num_sample_points)"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html#run-a-few-more-iterations",
    "href": "posts/2021-01-27-bayesian_optimization.html#run-a-few-more-iterations",
    "title": "Bayesian optimisation implementation",
    "section": "Run a Few More Iterations",
    "text": "Run a Few More Iterations\n\nres_ec, _ = opti.bayesian_optimization(objective, gpr_model, LCB, domain, noise=noise_, prop_kwargs = pkwargs)\ngpr_model.fit(res_ec[\"X\"], res_ec[\"y\"]) # Incorporate final point into plots.\n\n20\n\n\nGaussianProcessRegressor(alpha=0.001, kernel=1**2 * RBF(length_scale=1),\n                         n_restarts_optimizer=20, random_state=42)\n\n\n\n(fig_ec, ax_ec) = plotting_utils.illustrate_1d_gpr(objective, gpr_model, x_pts, EI, LCB, num_sample_points)\n\n\n\n\n\n\n\n\nIn total the noisy estimation of the ground-truth is conducted on 30 additional points. It is evident from the plot that most of those points are near the x = (4,6) since that is the minimum value region for the function."
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html",
    "title": "Classification-based algorithms walkthrough",
    "section": "",
    "text": "Some times the data in a supervised learning task is more qualitative than quantitative such as high, medium, low; or the task has categorical outputs such as colors - red, blue, green, or type of fruits: orange or apple. In such cases we look at classification models for training a model predictor. Various types of classification tasks exists:\n\n\n\n\nDistinguish between two classes - high, low, or cat and a dog. A simplest algorithm to train for such a task is logistic regression. Most of the off-the-shelf algorithms work directly on the such tasks – SVM, Random Forests, Naive Bayes.\n\n\n\nDistinguish between more than two classes - digits classifier is an example of multi-class classification since for a given digit image the answer could any number from 0-9. It is still one class but multiple options exists. Certain algorithms like Random Forest, Naive Bayes are capable of handling multi-class classifier. Others like SVM and linear classifiers are strictly binary classifier.\nThere are ways you can convert a binary classifier: * One-versus-all:\nTrain n classifier for n classes such that each classifier ONLY predicts whether that class is present or not. Eg: Train a classifier to predict if a digit is 2 or not.\n\nOne-versus-one:\n\nPair-wise classifier, in this case models are trained in a binary fashion for as many pair there can be between n classes. This can become computationally expensive since for n classes: \\(n(n-1)/2\\) classifiers are needed.\nMain advantage in this approach is that size of training data is small as only pair-wise data is required. Such an approach is useful when models dont scale well with large data – such as SVM or gaussian based\n\n\n\nDistinguish between more than class but also the answer is not just one value but a list of possiblities. When the output amongst the list is only Binary it is usually refered to as Multi-label classification. For example:\nIf we train a model to classify a digit image as:\n1. Is it smaller than 4? (1:yes; 0:no)\n\n2. Is it odd number? (1:yes; 0:no)\n\n3. Is it is greater than 7? (1:yes; 0:no)\nThen the output would be a list - for 5: [0, 1, 0] ; 4: [0, 0, 0]; 3: [1, 1, 0]\nK-Nearest neighbor is a type of classifier which supports such a classification.\nScikit-learn has a wonderful documentation on metrics to be used for different types of classification tasks (Link here)\nFrom the Scikit-learn documentation:\nSome metrics are essentially defined for binary classification tasks (e.g. f1_score, roc_auc_score). In these cases, by default only the positive label is evaluated, assuming by default that the positive class is labelled 1 (though this may be configurable through the pos_label parameter).\n\nIn extending a binary metric to multiclass or multilabel problems, the data is treated as a collection of binary problems, one for each class. There are then a number of ways to average binary metric calculations across the set of classes, each of which may be useful in some scenario. Where available, you should select among these using the average parameter.\nThe code in this notebook is adapted from Aurélien Geron’s hands-on machine learning tutorial on Classifications Github Link\n\nimport os \nimport copy\nimport numpy as np\n\nnp.random.seed(42)\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\nplot_params = {\n'font.size' : 22,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n\nplt.rcParams.update(plot_params)"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#what-is-classification",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#what-is-classification",
    "title": "Classification-based algorithms walkthrough",
    "section": "",
    "text": "Some times the data in a supervised learning task is more qualitative than quantitative such as high, medium, low; or the task has categorical outputs such as colors - red, blue, green, or type of fruits: orange or apple. In such cases we look at classification models for training a model predictor. Various types of classification tasks exists:\n\n\n\n\nDistinguish between two classes - high, low, or cat and a dog. A simplest algorithm to train for such a task is logistic regression. Most of the off-the-shelf algorithms work directly on the such tasks – SVM, Random Forests, Naive Bayes.\n\n\n\nDistinguish between more than two classes - digits classifier is an example of multi-class classification since for a given digit image the answer could any number from 0-9. It is still one class but multiple options exists. Certain algorithms like Random Forest, Naive Bayes are capable of handling multi-class classifier. Others like SVM and linear classifiers are strictly binary classifier.\nThere are ways you can convert a binary classifier: * One-versus-all:\nTrain n classifier for n classes such that each classifier ONLY predicts whether that class is present or not. Eg: Train a classifier to predict if a digit is 2 or not.\n\nOne-versus-one:\n\nPair-wise classifier, in this case models are trained in a binary fashion for as many pair there can be between n classes. This can become computationally expensive since for n classes: \\(n(n-1)/2\\) classifiers are needed.\nMain advantage in this approach is that size of training data is small as only pair-wise data is required. Such an approach is useful when models dont scale well with large data – such as SVM or gaussian based\n\n\n\nDistinguish between more than class but also the answer is not just one value but a list of possiblities. When the output amongst the list is only Binary it is usually refered to as Multi-label classification. For example:\nIf we train a model to classify a digit image as:\n1. Is it smaller than 4? (1:yes; 0:no)\n\n2. Is it odd number? (1:yes; 0:no)\n\n3. Is it is greater than 7? (1:yes; 0:no)\nThen the output would be a list - for 5: [0, 1, 0] ; 4: [0, 0, 0]; 3: [1, 1, 0]\nK-Nearest neighbor is a type of classifier which supports such a classification.\nScikit-learn has a wonderful documentation on metrics to be used for different types of classification tasks (Link here)\nFrom the Scikit-learn documentation:\nSome metrics are essentially defined for binary classification tasks (e.g. f1_score, roc_auc_score). In these cases, by default only the positive label is evaluated, assuming by default that the positive class is labelled 1 (though this may be configurable through the pos_label parameter).\n\nIn extending a binary metric to multiclass or multilabel problems, the data is treated as a collection of binary problems, one for each class. There are then a number of ways to average binary metric calculations across the set of classes, each of which may be useful in some scenario. Where available, you should select among these using the average parameter.\nThe code in this notebook is adapted from Aurélien Geron’s hands-on machine learning tutorial on Classifications Github Link\n\nimport os \nimport copy\nimport numpy as np\n\nnp.random.seed(42)\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\nplot_params = {\n'font.size' : 22,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n\nplt.rcParams.update(plot_params)"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#mnist-dataset",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#mnist-dataset",
    "title": "Classification-based algorithms walkthrough",
    "section": "MNIST dataset",
    "text": "MNIST dataset\n70,000 small images of hand-written numbers. Each image has 784 features. Those features are split in 28x28 pixels and each feature is simply that pixel gray-scale intensity. Value for each pixel ranges from 0 to 255.\n\nfrom sklearn.datasets import load_digits\nmnist = load_digits()\nprint(mnist.data.shape)\n\n(1797, 64)\n\n\n\n# Using MNIST data from openML website \nfrom sklearn.datasets import fetch_openml\nmnist = fetch_openml('mnist_784', version=1, cache=True)\nmnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings\n\n\ndef sort_by_target(mnist):\n    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]\n    \n    #minist.data is a pandas DataFrame\n    mnist_data_numpy = np.array(mnist.data.values)\n    mnist_target_numpy = np.array(mnist.target.values)\n    \n    mnist_data_numpy[:60000] = mnist_data_numpy[reorder_train]\n    mnist_target_numpy[:60000] = mnist_target_numpy[reorder_train]\n    mnist_data_numpy[60000:] = mnist_data_numpy[reorder_test + 60000]\n    mnist_target_numpy[60000:] = mnist_target_numpy[reorder_test + 60000]\n    \n    return mnist_data_numpy, mnist_target_numpy\n\n\nX, y = sort_by_target(mnist)\n\n\nrandom_idx = 62123\n\ndigit_image, digit_label = X[random_idx], y[random_idx]\nprint('The {0} entry is a photo of {1}'.format(random_idx, digit_label))\n\nrandom_digit_image=digit_image.reshape(28,28)\nplt.imshow(random_digit_image, cmap=cm.binary,\n          interpolation=\"nearest\")\nplt.axis(\"off\");\n\nThe 62123 entry is a photo of 2\n\n\n\n\n\n\n\n\n\n\n#Plot digit convenience function\ndef plot_digit(data):\n    image = data.reshape(28, 28)\n    plt.imshow(image, cmap = mpl.cm.binary,\n               interpolation=\"nearest\")\n    plt.axis(\"off\")\n\n\nX_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n\nBefore training we shuffle the data to ensure all cross-validation folds to be similar. Moreover some classficiation algorithms are sensitive to the order of training instances, and they perform poorly if they get many similar instances in a row.\n\n#Index shuffling \nimport numpy as np \nindex_shuffle = np.random.permutation(60000)\nX_train, y_train = X_train[index_shuffle], y_train[index_shuffle]"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#binary-classification",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#binary-classification",
    "title": "Classification-based algorithms walkthrough",
    "section": "Binary classification",
    "text": "Binary classification\nHere we will build a single digit classifier – for example looking at just 2. Hence in total there will be only 2 classes – Those which are 2 and those which are not.\n\ny_train_2 = (y_train == 2) #True for all 2s, False for all other digits \ny_test_2 = (y_test == 2)\n\nUsing Stochastic Gradient Descent classifier. Known to handle large datasets very well.\n\nfrom sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42)\nsgd_clf.fit(X_train, y_train_2)\n\nSGDClassifier(max_iter=5, random_state=42, tol=-inf)\n\n\n\nsgd_clf.predict([digit_image])\n\narray([ True])"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#performance-metrics",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#performance-metrics",
    "title": "Classification-based algorithms walkthrough",
    "section": "Performance metrics",
    "text": "Performance metrics\nEvaluating classifiers is often significantly challenging than the case for a regressor wherein we can use RMSE or MAE. Let’s look at some usual metrics used to gauge the classifier performance.\n\n1. Accuracy using Cross-validation\nIt involves splitting your training data in K-folds. Training the model on K-1 folds and testing it on the left out fold. Scikit learn has in-built method to do so: cross_val_score(). We can implement our own version as well.\n\\[ \\% Accuracy = \\frac{Correct}{Total} * 100 \\]\n\n#Inside the scikit-learn's crossvalidation accuracy method\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.base import clone \n\nskfolds = StratifiedKFold(n_splits=3, shuffle=False)\n\nfor train_index, test_index in skfolds.split(X_train,y_train_2):\n    clone_clf = clone(sgd_clf)\n    X_train_folds = X_train[train_index]\n    y_train_folds = y_train_2[train_index]\n    \n    X_test_folds = X_train[test_index]\n    y_test_folds = y_train_2[test_index]\n    \n    clone_clf.fit(X_train_folds, y_train_folds)\n    y_pred=clone_clf.predict(X_test_folds)\n    \n    n_correct = sum(y_pred == y_test_folds)\n    print(n_correct/len(y_pred))\n\n0.97365\n0.96255\n0.96165\n\n\n\n#Using scikit-learn's in-built method \nfrom sklearn.model_selection import cross_val_score\ncross_val_score(sgd_clf, X_train, y_train_2, cv=3, scoring='accuracy')\n\narray([0.97365, 0.96255, 0.96165])\n\n\nDoes this high accuracy tell us anything?\nIs the sample space we are looking at uniform enough for this accuracy?\nMaybe we have way less one-digit samples for training in the first place.\n\n_count=0.\nfor i in range(len(y_train)):\n    if y_train[i] == 2: \n        _count=_count+1.\nprint(_count/len(y_train)*100)     \n\n9.93\n\n\nSo ~9% of the sample are actually 2. So even if we guess ALWAYS that image is not 2 we will be right 90% of the time!\n\n\nThe dumb classifier\nTo check whether classifier accuracy of ~95% is good enough so just a over-exagerration\n\nfrom sklearn.base import BaseEstimator\nclass Never2(BaseEstimator):\n    def fit(self, X, y=None):\n        pass\n    def predict(self, X):\n        return(np.zeros((len(X),1),dtype=bool))\n\n\nnever2 = Never2()\ncross_val_score(never2,X_train,y_train_2,cv=3,scoring='accuracy')\n\narray([0.9017, 0.9001, 0.9003])\n\n\nThis shows our data is skewed!\n\n\n2. Confusion Matrix\nGeneral idea is to count the number of times instances of Class A are classified as Class B.\nTable that describes the performance of a classification model by grouping predictions into 4 categories. - True Positives: we correctly predicted they do have diabetes - True Negatives: we correctly predicted they don’t have diabetes - False Positives: we incorrectly predicted they do have diabetes (Type I error) - False Negatives: we incorrectly predicted they don’t have diabetes (Type II error)\nThe ROWS in the matrix are the real class-labels i.e. the TRUTH values while COLUMNS are the predicted values.\n&lt;td colspan=\"2\"&gt;&lt;p&gt;&lt;b&gt;Actual class (observation)&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicted class (expectation)\n\n\n\n\ntp (true positive) Correct result\n\n\n\n\nfp (false positive) Unexpected result\n\n\n\n\n\n\nfn (false negative) Missing result\n\n\n\n\ntn (true negative) Correct absence of result\n\n\n\n\n\n\nfrom sklearn.model_selection import cross_val_predict\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train_2, cv=3)\n\n\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_train_2, y_train_pred)\n\narray([[53159,   883],\n       [ 1160,  4798]])\n\n\nEach row in the confusion matrix represent actual class, while each column represents a predicted class. Following are the terms of the confusion matrix: 1. First row of this matrix is the non-2 images – - (0,0) instances were correctly classified as non 2 (True Negative) - (0,1) instances were wrongly classified as 2s (False Positive) 2. Second row considers the images of 5 – - (1,0) instances were wrongly classified as non 2s (False negatives) - (1,1) instances were correctly classified as 2s (True positives)\nAn ideal classifier would be a diagonal matrix with no false positives or false negatives\n\nPrecision\nThink of this as precision of the model in estimating the binary class. FROM POV of the MODEL\nIt is the ratio of the total classification whether as True or Wrongly classified as True to True. That is, \\[Precision = \\frac{TP}{TP+FP}\\]\nThis is looking at +ve classification and how many are really +ve and how many are wrongly shown as +ve. So Precision looks at the prediction of +ve results.\n\n\nRecall\nThink of this as comparing to the actual data in the model training. FROM POV of the REAL DATA\nIt is the ratio of total classification on the +ve samples from where they are classified correctly (TP) to wrongly classified as negative (FN).\n\\[Recall = \\frac{TP}{FN+TP}\\]\nSo Recall looks at the prediction of the +ve samples.\n\nThis is by just comparing the +ve samples in the binary classification. To check how many of them are correctly recalled as +ve.\n\n\n\nF1 score\nHarmonic mean of recall and precision. Higher the Precision and Recall, lower are the instances of FP and FN. So we want to have higher Recall and Precision both.\nF1 favors classifiers with similar recall and precision.\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nprint('Precision score: {}'.format(precision_score(y_train_2, y_train_pred)))\nprint('Recall score: {}'.format(recall_score(y_train_2, y_train_pred)))\nprint('F1 score: {}'.format(f1_score(y_train_2, y_train_pred)))\n\nPrecision score: 0.8445696180249956\nRecall score: 0.8053037932192011\nF1 score: 0.8244694561388435\n\n\n\n\n\nRecall/Precision tradeoff\nUnfortunately increasing precision reduces recall and vise-versa. However sometimes one of the qualities could be desirable in a model.\nRecall looks at lowering the False Negatives so culling +ve cases. That could be detrimental in catching robberies. So we need classifiers with high recall and we are okay with low Precision wherein we would get False alarms.\nMeanwhile, if we are censoring videos we need high Precision to ensure unsafe videos categorised as Safe ones. While we could be removing good videos by wrongly classifying them to be Unsafe (low recall).\nMore discussion here: Link\nDecision functions evaluate a decision_score we can manually set the threshold for the score to whether that will accpted or rejected for the binary case.\nIncreasing threshold reduces recall, but increases precision.\nWhy? The more Precise you want to be i.e. more True Positive than False Positives – the higher the threshold for passing the case of accepting the data as a given class. However doing so we are strict in what we define as a ideal class and can neglect samples which are positive but are not closest to ideal. Hence we do incorrectly mark them as Negative thus increasing the case of False Negaitives and hence lowering Recall.\n\n#Decision scores for all instnces in the training set -- \ny_scores = cross_val_predict(sgd_clf, X_train, y_train_2, cv=3,\n                             method=\"decision_function\")\n\n\nfrom sklearn.metrics import precision_recall_curve\nprecisions, recalls, thresholds = precision_recall_curve(y_train_2, y_scores)\n\n\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n    plt.xlabel(\"Threshold\", fontsize=10)\n    plt.legend(loc=\"best\", fontsize=12)\n    \n    plt.ylim([0, 1])\n\nplt.figure(figsize=(8, 4))\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.xlim([-700000, 700000])\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(8, 4))    \nplt.plot(recalls[:-1],precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\nplt.ylabel(\"Precision\", fontsize=16)\nplt.xlabel(\"Recall\", fontsize=16)\n\nText(0.5, 0, 'Recall')\n\n\n\n\n\n\n\n\n\n\nIf someone says let’s reach 99% PRECISION, we must ALWAYS ask at what RECALL?\n\n\nManually set the Recall/Precision using threshold\n\ny_scores = sgd_clf.decision_function([digit_image])\nprint(y_scores)\n\ny_pred_thresh = sgd_clf.predict([digit_image])\nprint(y_pred_thresh)\n#Setting threshold higher than the y_score\nthreshold = y_scores + 1.0 \ny_pred_thresh = (y_scores &gt; threshold)\nprint(y_pred_thresh)\n\n[247991.40436599]\n[ True]\n[False]\n\n\n\n#Changing the threshold for everyother training example -- more than 90% precision\ny_scores = cross_val_predict(sgd_clf, X_train, y_train_2, cv=3,\n                             method=\"decision_function\")\ny_train_pred_90 = (y_scores &gt; 200000)\nprint('Precision score: {}'.format(precision_score(y_train_2, y_train_pred_90)))\nprint('Recall score: {}'.format(recall_score(y_train_2, y_train_pred_90)))\nprint('F1 score: {}'.format(f1_score(y_train_2, y_train_pred_90)))\n\nPrecision score: 0.9637028700056275\nRecall score: 0.5748573346760658\nF1 score: 0.720142977291842\n\n\nWe have made classifier with an arbitrary Precision score: 97% However doing so we reduced the Recall.\n\n\n\nThe ROC curve\nAnother common tool used for binary classifiers apart from Precision/Recall. Instead of plotting precision vs recall we plot True Positive Rate (TPR) i.e. Recall against False Positive Rate (FPR). FPR is the ratio of negative instances that are incorrectly classified as positive.\nROC plots sensitivity vs 1-specificty\n\nfrom sklearn.metrics import roc_curve\n\n#Decision scores for all instnces in the training set -- \ny_scores = cross_val_predict(sgd_clf, X_train, y_train_2, cv=3,\n                             method=\"decision_function\")\n\nfpr, tpr, thresholds = roc_curve(y_train_2, y_scores)\n\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n\nplt.figure(figsize=(8, 6))\nplot_roc_curve(fpr, tpr)\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(y_train_2, y_scores)\n\n0.9651158581307573\n\n\nPR curve when we care of precision – getting False +ve and not so much of getting False -ve. We are okay with losing some +ve cases but for sure do not want to neglect any -ve ones."
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#random-forest-classifier",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#random-forest-classifier",
    "title": "Classification-based algorithms walkthrough",
    "section": "Random forest classifier",
    "text": "Random forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\nforest_clf = RandomForestClassifier(n_estimators=10, random_state=42)\ny_probas_forest = cross_val_predict(forest_clf, X_train, y_train_2, cv=3,\n                                    method=\"predict_proba\")\n\n\ny_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\nfpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_2, y_scores_forest)\n\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, \"b:\", linewidth=2, label=\"SGD\")\nplot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\nplt.legend(loc=\"lower right\", fontsize=16)\nplt.show()"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#multiclass-classification",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#multiclass-classification",
    "title": "Classification-based algorithms walkthrough",
    "section": "Multiclass classification",
    "text": "Multiclass classification\nMulticlass classifiers are able to label and distinguish between more than two classes. Some algorithms such as Random Forest and Näive Bayes are capable of handling this directly. Having said that, Naive Baye’s has shortcomming of considering class conditional independence and having discrete entries in the input.\n\nOvA (One-versus-all classifiers): Herein, we would train n binary classifiers for n type of labels and see which n-th classifier has highest decision score.\nOvO (One-versus-one strategy): Binary classifier for every pair. So for n labels we will have n(n-1)/2 classifiers."
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#error-analysis",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#error-analysis",
    "title": "Classification-based algorithms walkthrough",
    "section": "Error analysis",
    "text": "Error analysis\n\nX_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\nindex_shuffle = np.random.permutation(60000)\nX_train, y_train = X_train[index_shuffle], y_train[index_shuffle]\n\nsgd_clf = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42)\nsgd_clf.fit(X_train, y_train)\n\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)\ny_scores = cross_val_predict(sgd_clf, X_train, y_train, cv=3,\n                             method=\"decision_function\")\nconf_mx = confusion_matrix(y_train, y_train_pred)\n\n\nplt.matshow(conf_mx, cmap=plt.cm.gray)\nplt.show()"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#plotting-heat-map-for-the-errors-in-the-classification",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#plotting-heat-map-for-the-errors-in-the-classification",
    "title": "Classification-based algorithms walkthrough",
    "section": "Plotting heat-map for the errors in the classification",
    "text": "Plotting heat-map for the errors in the classification\n\nrow_sums = conf_mx.sum(axis=1, keepdims=True)\nnorm_conf_mx = conf_mx / row_sums\n#Diagonals are filled to be zero to concentrate only at the errors\nnp.fill_diagonal(norm_conf_mx, 0)\nplt.matshow(norm_conf_mx, cmap=plt.cm.gray)\nplt.show()\n\n\n\n\n\n\n\n\nROWS in the confusion matrix are the REAL labels. COLUMNS in the confusion matrix are the PREDICTED values. It can seen that in the case of row 3 and column 5: - 5 is most of the times confused with 3 and 8 - 9 is confused with 4 and 7\n\ndef plot_digits(instances, images_per_row=10, **options):\n    size = 28\n    images_per_row = min(len(instances), images_per_row)\n    images = [instance.reshape(size,size) for instance in instances]\n    n_rows = (len(instances) - 1) // images_per_row + 1\n    row_images = []\n    n_empty = n_rows * images_per_row - len(instances)\n    images.append(np.zeros((size, size * n_empty)))\n    for row in range(n_rows):\n        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n        row_images.append(np.concatenate(rimages, axis=1))\n    image = np.concatenate(row_images, axis=0)\n    plt.imshow(image, cmap = cm.binary, **options)\n    plt.axis(\"off\")\n\n\ncl_a, cl_b = 3, 5\nX_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\nX_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\nX_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\nX_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n\n\nplt.figure(figsize=(8,8))\nplt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\nplt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\nplt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\nplt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\nplt.show()\n\n\n\n\n\n\n\n\nGiven above are two sets of ‘3’ and ‘5’ – the boxes to the left are 3 and 5 classified as 3. Top left are the images of 3 classified as 3 while Bottom left are the images of 5 classified as 3. It can seen that some imags of 5 quite poor and the algorithm (which is linear in this case) will have difficulty predicting it."
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#multi-label-classifier",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#multi-label-classifier",
    "title": "Classification-based algorithms walkthrough",
    "section": "Multi-label classifier",
    "text": "Multi-label classifier\nDetermine a label such that it is a list for a every digit answering two questions: 1. Is this number odd? 1: Yes, 0: No 2. Is this number greater than 7? 1: Yes, 0: No\nCreating new y_label for model\n\n# Setting two conditions \nis_odd = (y % 2 == 0).astype(int)\nis_greater_7 = (y &gt; 7).astype(int)\n\ny_multilabel = np.c_[is_odd, is_greater_7]\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_clf = KNeighborsClassifier()\n\n\nX_train, X_test, y_ml_train, y_ml_test = X[:60000], X[60000:], y_multilabel[:60000], y_multilabel[60000:]\nindex_shuffle = np.random.permutation(60000)\nX_train, y_ml_train = X_train[index_shuffle], y_ml_train[index_shuffle]\n\n\nknn_clf.fit(X_train, y_ml_train)\n\nKNeighborsClassifier()\n\n\n\n# Predict\nknn_clf.predict([X_train[12]])\n\narray([[0, 0]])\n\n\n\ny_ml_train[12]\n\narray([0, 0])\n\n\n\n# Metric \ny_knn_ml_pred= cross_val_predict(knn_clf, X_train, y_ml_train, cv=3)\n\n\n# macro assumes all labels are equally important \n# another option is the 'weighted' \nf1_score(y_ml_train, y_knn_ml_pred, average='macro')\n\n0.9719059410724892"
  },
  {
    "objectID": "posts/2020-12-09-food_relations.html",
    "href": "posts/2020-12-09-food_relations.html",
    "title": "Relational analysis of spices used in Indian cuisine",
    "section": "",
    "text": "Spices are central to Indian cuisine. What is referred to colloquially as ‘Indian’ food is made of many different sub-cuisines. As a result, there are a plethora of spices usually brought up when considering ‘Indian’ food. Knowing which spices are most frequently used can help cooks novice or seasoned to make an informed decision about spices that promise the most bang for the buck.\nI use a Kaggle dataset containing 6000+ recipes from https://www.archanaskitchen.com/. Using this data as base collection of recipes representing most of the indian food, I analyze which spices occur most freqeuntly and which spices are most connected to each other.\n\nDataset for Indian recipe: This dataset 6000+ recipe scrapped from | Link to the dataset\n\n\nimport pandas as pd \nimport numpy as np \n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 22,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)\n\n\n\n\nfood_df = pd.read_csv('./data/IndianFoodDatasetCSV.csv')\n\n\nfood_df.columns\n\nIndex(['Srno', 'RecipeName', 'TranslatedRecipeName', 'Ingredients',\n       'TranslatedIngredients', 'PrepTimeInMins', 'CookTimeInMins',\n       'TotalTimeInMins', 'Servings', 'Cuisine', 'Course', 'Diet',\n       'Instructions', 'TranslatedInstructions', 'URL'],\n      dtype='object')\n\n\n\nfood_df.shape\n\n(6871, 15)\n\n\n\n# dropping miscellaneous columns and NaN entries\ncolumns_to_drop = ['CookTimeInMins', 'Servings', 'Course', 'Diet', 'Instructions', 'TranslatedInstructions', 'URL']\nfood_df = food_df.drop(columns = columns_to_drop).dropna()\n\n\n# data has indian-inspired international cuisines which are not what we are interested in\ncuisines_to_drop = ['Mexican', 'Italian Recipes', 'Thai', 'Chinese', 'Asian', 'Middle Eastern', 'European',\n                   'Arab', 'Japanese', 'Vietnamese', 'British', 'Greek', 'French', 'Mediterranean', 'Sri Lankan',\n                   'Indonesian', 'African', 'Korean', 'American', 'Carribbean', 'World Breakfast', 'Malaysian', 'Dessert',\n                   'Afghan', 'Snack', 'Jewish', 'Brunch', 'Lunch', 'Continental', 'Fusion']\n\nfood_df = food_df.loc[ ~ food_df['Cuisine'].isin(cuisines_to_drop) ] #Dropping entries in `food_df` which have non-indian cuisines \n\n\nfood_df.shape\n\n(4881, 8)\n\n\n\nfood_df.head(5)\n\n\n\n\n\n\n\n\nSrno\nRecipeName\nTranslatedRecipeName\nIngredients\nTranslatedIngredients\nPrepTimeInMins\nTotalTimeInMins\nCuisine\n\n\n\n\n0\n1\nMasala Karela Recipe\nMasala Karela Recipe\n6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n15\n45\nIndian\n\n\n1\n2\nटमाटर पुलियोगरे रेसिपी - Spicy Tomato Rice (Re...\nSpicy Tomato Rice (Recipe)\n2-1/2 कप चावल - पका ले,3 टमाटर,3 छोटा चमच्च बी...\n2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...\n5\n15\nSouth Indian Recipes\n\n\n2\n3\nRagi Semiya Upma Recipe - Ragi Millet Vermicel...\nRagi Semiya Upma Recipe - Ragi Millet Vermicel...\n1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n20\n50\nSouth Indian Recipes\n\n\n3\n4\nGongura Chicken Curry Recipe - Andhra Style Go...\nGongura Chicken Curry Recipe - Andhra Style Go...\n500 grams Chicken,2 Onion - chopped,1 Tomato -...\n500 grams Chicken,2 Onion - chopped,1 Tomato -...\n15\n45\nAndhra\n\n\n4\n5\nआंध्रा स्टाइल आलम पचड़ी रेसिपी - Adrak Chutney ...\nAndhra Style Alam Pachadi Recipe - Adrak Chutn...\n1 बड़ा चमच्च चना दाल,1 बड़ा चमच्च सफ़ेद उरद दाल,2...\n1 tablespoon chana dal, 1 tablespoon white ura...\n10\n30\nAndhra\n\n\n\n\n\n\n\n\n\n\n\n# Some entries in the `TranslatedIngredients` have non-english entries \ndef filter_english(string):\n    try:\n        string.encode('utf-8').decode('ascii')\n        out = True\n    except UnicodeDecodeError: \n        out = False\n    return out\n\n\n# Droping columns in the dataset having ingredients in language other than english \ndf = food_df.loc[ food_df['TranslatedIngredients'].apply(filter_english) ]\n\n\ndf.shape\n\n(4273, 8)\n\n\n\ndf = df.reset_index()\n\n\n\n\nNext for consistent tabulation I needed a list of spices to look for. Wikipedia has a page on Indian spices which lists various spices used in Indian cuisine. I use this list to search names of spices in the recipe entries.\n\n#read file of all indian spices on wikipedia\nwiki_file_pd = pd.read_html('https://en.wikipedia.org/wiki/List_of_Indian_spices')\nspices_list = wiki_file_pd[0]['Standard English'].copy().str.lower()\n\n#some important spices to add\nspices_to_add = pd.Series(['black salt', 'green chillies', 'chilli powder'])\n\n#some spices are too common (such as pepper) or not a spice, but a vegetable, or are otherwise corrupted (for example,\n#cardamom is often listed as \"cardamom\" nto specifying whether it is black or green)\n\nspices_to_drop = ['black pepper', 'capers', 'chili pepper powder', 'cinnamon buds', 'citric acid', 'garlic', 'capsicum', 'charoli', 'garcinia gummi-gutta', 'inknut', 'garcinia indica',\n                  'black mustard seeds/raee', 'cumin seed ground into balls', 'dried ginger', 'green chili pepper', 'long pepper', 'four seeds', 'cubeb', 'gum tragacanth', 'jakhya', 'licorice powder',\n                  'indian bedellium tree', 'mango extract', 'coriander powder', 'saffron pulp', 'black cardamom', 'brown mustard seed', 'black cumin', 'panch phoron']\n\nspices_list = spices_list.loc[ ~spices_list.isin(spices_to_drop) ].append(spices_to_add).reset_index(drop=True)\n\n\nspices_list\n\n0                      alkanet root\n1                           amchoor\n2                        asafoetida\n3             celery / radhuni seed\n4         bay leaf, indian bay leaf\n5                          cinnamon\n6                            cloves\n7                    coriander seed\n8                        cumin seed\n9     curry tree or sweet neem leaf\n10                      fennel seed\n11                   fenugreek leaf\n12                   fenugreek seed\n13                     garam masala\n14                           ginger\n15                   green cardamom\n16                indian gooseberry\n17                          kalpasi\n18                     mustard seed\n19                     nigella seed\n20                           nutmeg\n21                             mace\n22                 pomegranate seed\n23                       poppy seed\n24                          saffron\n25                      sesame seed\n26                      star aniseh\n27                         tamarind\n28                thymol/carom seed\n29                         turmeric\n30                     white pepper\n31                       black salt\n32                   green chillies\n33                    chilli powder\ndtype: object\n\n\nOne more step is editing the spices so that my string counter can find different versions of the same spice.\n\n#editing the spices so that my string counter can find different versions of the same spice\nspices_list = spices_list.str.replace('amchoor', 'amchur/amchoor/mango extract') \\\n                    .replace('asafoetida', 'asafetida/asafoetida/hing') \\\n                    .replace('thymol/carom seed', 'ajwain/thymol/carom seed') \\\n                    .replace('alkanet root', 'alkanet/alkanet root') \\\n                    .replace('chilli powder', 'red chilli powder/chilli powder/kashmiri red chilli powder') \\\n                    .replace('celery / radhuni seed', 'celery/radhuni seed') \\\n                    .replace('bay leaf, indian bay leaf', 'bay leaf/bay leaves/tej patta') \\\n                    .replace('curry tree or sweet neem leaf', 'curry leaf/curry leaves') \\\n                    .replace('fenugreek leaf', 'fenugreek/kasoori methi') \\\n                    .replace('nigella seed', 'nigella/black cumin') \\\n                    .replace('ginger', 'dried ginger/ginger powder') \\\n                    .replace('cloves', 'cloves/laung') \\\n                    .replace('green cardamom', 'cardamom/green cardamom/black cardamom')\\\n                    .replace('indian gooseberry', 'indian gooseberry/amla')\\\n                    .replace('coriander seed', 'coriander seed/coriander powder')\\\n                    .replace('star aniseh', 'star anise')\\\n                    .replace('cumin seed', 'cumin powder/cumin seeds/cumin/jeera')\n\n\nspices_list\n\n0                                  alkanet/alkanet root\n1                          amchur/amchoor/mango extract\n2                             asafetida/asafoetida/hing\n3                                   celery/radhuni seed\n4                         bay leaf/bay leaves/tej patta\n5                                              cinnamon\n6                                          cloves/laung\n7                       coriander seed/coriander powder\n8                  cumin powder/cumin seeds/cumin/jeera\n9                               curry leaf/curry leaves\n10                                          fennel seed\n11                              fenugreek/kasoori methi\n12                                       fenugreek seed\n13                                         garam masala\n14                           dried ginger/ginger powder\n15               cardamom/green cardamom/black cardamom\n16                               indian gooseberry/amla\n17                                              kalpasi\n18                                         mustard seed\n19                                  nigella/black cumin\n20                                               nutmeg\n21                                                 mace\n22                                     pomegranate seed\n23                                           poppy seed\n24                                              saffron\n25                                          sesame seed\n26                                           star anise\n27                                             tamarind\n28                             ajwain/thymol/carom seed\n29                                             turmeric\n30                                         white pepper\n31                                           black salt\n32                                       green chillies\n33    red chilli powder/chilli powder/kashmiri red c...\ndtype: object\n\n\n\n\n\n\ningredients_series = df[['TranslatedRecipeName','TranslatedIngredients']]\n\n\ningredients_series\n\n\n\n\n\n\n\n\nTranslatedRecipeName\nTranslatedIngredients\n\n\n\n\n0\nMasala Karela Recipe\n6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n\n\n1\nSpicy Tomato Rice (Recipe)\n2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...\n\n\n2\nRagi Semiya Upma Recipe - Ragi Millet Vermicel...\n1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n\n\n3\nGongura Chicken Curry Recipe - Andhra Style Go...\n500 grams Chicken,2 Onion - chopped,1 Tomato -...\n\n\n4\nAndhra Style Alam Pachadi Recipe - Adrak Chutn...\n1 tablespoon chana dal, 1 tablespoon white ura...\n\n\n...\n...\n...\n\n\n4268\nOne Pot Punjabi Rajma Masala Recipe In Preethi...\n1 cup Rajma (Large Kidney Beans),1 inch Ginger...\n\n\n4269\nSaffron Paneer Peda Recipe\n2 cups Paneer (Homemade Cottage Cheese) - crum...\n\n\n4270\nQuinoa Phirnee Recipe (Quinoa Milk Pudding)\n1 cup Quinoa,3/4 cup Sugar,1 teaspoon Cardamom...\n\n\n4271\nUllikadala Pulusu Recipe | Spring Onion Curry\n150 grams Spring Onion (Bulb & Greens) - chopp...\n\n\n4272\nKashmiri Style Kokur Yakhni Recipe-Chicken Coo...\n1 kg Chicken - medium pieces,1/2 cup Mustard o...\n\n\n\n\n4273 rows × 2 columns\n\n\n\n\nspices_list_column_to_add = {i: np.zeros(len(ingredients_series)) for i in spices_list.to_list()}\n\n\ningredients_series = ingredients_series.join(pd.DataFrame(spices_list_column_to_add))\n\n\ningredients_series\n\n\n\n\n\n\n\n\nTranslatedRecipeName\nTranslatedIngredients\nalkanet/alkanet root\namchur/amchoor/mango extract\nasafetida/asafoetida/hing\ncelery/radhuni seed\nbay leaf/bay leaves/tej patta\ncinnamon\ncloves/laung\ncoriander seed/coriander powder\n...\nsaffron\nsesame seed\nstar anise\ntamarind\najwain/thymol/carom seed\nturmeric\nwhite pepper\nblack salt\ngreen chillies\nred chilli powder/chilli powder/kashmiri red chilli powder\n\n\n\n\n0\nMasala Karela Recipe\n6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\nSpicy Tomato Rice (Recipe)\n2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\nRagi Semiya Upma Recipe - Ragi Millet Vermicel...\n1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\nGongura Chicken Curry Recipe - Andhra Style Go...\n500 grams Chicken,2 Onion - chopped,1 Tomato -...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\nAndhra Style Alam Pachadi Recipe - Adrak Chutn...\n1 tablespoon chana dal, 1 tablespoon white ura...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n4268\nOne Pot Punjabi Rajma Masala Recipe In Preethi...\n1 cup Rajma (Large Kidney Beans),1 inch Ginger...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4269\nSaffron Paneer Peda Recipe\n2 cups Paneer (Homemade Cottage Cheese) - crum...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4270\nQuinoa Phirnee Recipe (Quinoa Milk Pudding)\n1 cup Quinoa,3/4 cup Sugar,1 teaspoon Cardamom...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4271\nUllikadala Pulusu Recipe | Spring Onion Curry\n150 grams Spring Onion (Bulb & Greens) - chopp...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4272\nKashmiri Style Kokur Yakhni Recipe-Chicken Coo...\n1 kg Chicken - medium pieces,1/2 cup Mustard o...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n4273 rows × 36 columns\n\n\n\n\n\n\nI used regular expression to search for spice names in the entries\n\n# Convenience function to search a given ingredient list for spice names\nimport re \ndef search_spice(ingredient_string, spice_string):\n    '''\n    Check if a spice exists in the list of ingredients for a recipe \n    '''\n    spice_list = spice_string.split('/')\n    for _spice in spice_list:\n        if re.search(_spice.lower(), ingredient_string.lower()):\n            return True\n            break\n\n\nfor row, values in ingredients_series.iterrows():\n    for spice_entry in spices_list:\n        if search_spice(values['TranslatedIngredients'], spice_entry):\n            ingredients_series.loc[row, spice_entry] = 1\n        else:\n            ingredients_series.loc[row, spice_entry] = 0\n\n\nfood_spice_mix = ingredients_series.drop(['TranslatedIngredients'], axis=1).reset_index(drop=True)\n\n\n#editing the spices so that my string counter can find different versions of the same spice\nfood_spice_mix.rename(columns={'amchur/amchoor/mango extract':'amchoor', \\\n                    'asafetida/asafoetida/hing': 'asafoetida', \\\n                    'ajwain/thymol/carom seed': 'ajwain', \\\n                    'alkanet/alkanet root': 'alkanet root', \\\n                    'red chilli powder/chilli powder/kashmiri red chilli powder': 'chilli powder', \\\n                    'celery/radhuni seed': 'celery seeds',\\\n                    'bay leaf/bay leaves/tej patta': 'bay leaf', \\\n                    'curry leaf/curry leaves': 'curry leaves',\\\n                    'fenugreek/kasoori methi': 'fenugreek leaf', \\\n                    'nigella/black cumin': 'nigella seed', \\\n                    'ginger': 'dried ginger',\\\n                    'cloves/laung': 'cloves', \\\n                    'cardamom/green cardamom/black cardamom': 'cardamom',\\\n                    'indian gooseberry/amla': 'indian gooseberry',\\\n                    'coriander seed/coriander powder': 'coriander seeds/powder',\\\n                    'cumin powder/cumin seeds/cumin/jeera': 'cumin seeds/powder',\\\n                    'dried ginger/ginger powder': 'ginger powder'}, inplace=True)\n\n\nfood_spice_mix.columns\n\nIndex(['TranslatedRecipeName', 'alkanet root', 'amchoor', 'asafoetida',\n       'celery seeds', 'bay leaf', 'cinnamon', 'cloves',\n       'coriander seeds/powder', 'cumin seeds/powder', 'curry leaves',\n       'fennel seed', 'fenugreek leaf', 'fenugreek seed', 'garam masala',\n       'ginger powder', 'cardamom', 'indian gooseberry', 'kalpasi',\n       'mustard seed', 'nigella seed', 'nutmeg', 'mace', 'pomegranate seed',\n       'poppy seed', 'saffron', 'sesame seed', 'star anise', 'tamarind',\n       'ajwain', 'turmeric', 'white pepper', 'black salt', 'green chillies',\n       'chilli powder'],\n      dtype='object')\n\n\n\nfood_spice_mix = food_spice_mix.sort_index(axis=1)\n\n\n\n\n\nnum_spice = len(spices_list)\nspice_col_name = [i for i in food_spice_mix.columns[1:].to_list()]\nspice_adj = pd.DataFrame(np.zeros(shape=(len(spices_list),len(spices_list))), columns= spice_col_name, index=spice_col_name)\nspice_adj_freq = pd.DataFrame(np.zeros(shape=(len(spices_list),len(spices_list))), columns= spice_col_name, index=spice_col_name)\n\n\nfor row, value in food_spice_mix.iterrows():\n    for i in spice_col_name:\n        for j in spice_col_name:\n            if (value[i] == 1) & (value[j] == 1):\n                spice_adj_freq.loc[i,j] += 1\n                spice_adj.loc[i,j] = 1\n\nNormalize the spice occurance frequency with the total entries in the main dataset\n\nspice_adj_freq = spice_adj_freq / len(food_spice_mix) * 100\n\n\nspice_adj_freq.round(2)\n\n\n\n\n\n\n\n\najwain\nalkanet root\namchoor\nasafoetida\nbay leaf\nblack salt\ncardamom\ncelery seeds\nchilli powder\ncinnamon\n...\nnigella seed\nnutmeg\npomegranate seed\npoppy seed\nsaffron\nsesame seed\nstar anise\ntamarind\nturmeric\nwhite pepper\n\n\n\n\najwain\n5.22\n0.00\n0.70\n1.45\n0.98\n0.07\n1.05\n0.00\n3.49\n1.33\n...\n0.16\n0.16\n0.09\n0.23\n0.21\n0.40\n0.23\n0.37\n2.97\n0.00\n\n\nalkanet root\n0.00\n0.07\n0.00\n0.07\n0.05\n0.00\n0.07\n0.00\n0.07\n0.07\n...\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\namchoor\n0.70\n0.00\n4.98\n1.54\n0.37\n0.21\n0.35\n0.02\n3.86\n0.47\n...\n0.35\n0.00\n0.14\n0.02\n0.05\n0.26\n0.05\n0.33\n3.51\n0.02\n\n\nasafoetida\n1.45\n0.07\n1.54\n24.60\n1.33\n0.30\n1.61\n0.21\n9.69\n1.87\n...\n0.30\n0.14\n0.09\n0.54\n0.28\n1.57\n0.26\n5.17\n15.05\n0.02\n\n\nbay leaf\n0.98\n0.05\n0.37\n1.33\n10.70\n0.09\n6.04\n0.07\n6.72\n6.65\n...\n0.26\n0.61\n0.12\n0.75\n0.66\n0.16\n1.10\n0.26\n7.54\n0.07\n\n\nblack salt\n0.07\n0.00\n0.21\n0.30\n0.09\n1.64\n0.09\n0.02\n0.61\n0.09\n...\n0.02\n0.00\n0.09\n0.00\n0.09\n0.02\n0.02\n0.28\n0.33\n0.00\n\n\ncardamom\n1.05\n0.07\n0.35\n1.61\n6.04\n0.09\n17.79\n0.14\n6.13\n7.98\n...\n0.07\n1.08\n0.23\n1.47\n3.14\n0.35\n1.29\n0.42\n6.60\n0.07\n\n\ncelery seeds\n0.00\n0.00\n0.02\n0.21\n0.07\n0.02\n0.14\n0.80\n0.37\n0.19\n...\n0.00\n0.09\n0.00\n0.00\n0.02\n0.00\n0.02\n0.00\n0.51\n0.00\n\n\nchilli powder\n3.49\n0.07\n3.86\n9.69\n6.72\n0.61\n6.13\n0.37\n37.96\n7.04\n...\n0.84\n0.44\n0.47\n1.38\n0.68\n1.59\n0.82\n3.58\n28.39\n0.05\n\n\ncinnamon\n1.33\n0.07\n0.47\n1.87\n6.65\n0.09\n7.98\n0.19\n7.04\n13.13\n...\n0.14\n0.96\n0.19\n1.40\n0.84\n0.23\n1.38\n0.89\n8.10\n0.07\n\n\ncloves\n2.01\n0.07\n1.43\n5.05\n6.58\n0.16\n7.65\n0.19\n14.14\n9.29\n...\n0.35\n0.70\n0.23\n1.59\n0.80\n0.96\n1.43\n3.93\n17.29\n0.02\n\n\ncoriander seeds/powder\n1.76\n0.00\n2.41\n5.13\n4.91\n0.26\n4.31\n0.47\n16.26\n4.35\n...\n0.35\n0.30\n0.28\n0.70\n0.33\n0.56\n0.59\n1.85\n16.78\n0.00\n\n\ncumin seeds/powder\n2.15\n0.00\n3.28\n13.27\n5.87\n1.19\n5.20\n0.35\n21.55\n6.67\n...\n0.89\n0.54\n0.51\n1.24\n0.54\n1.92\n0.91\n5.87\n27.45\n0.07\n\n\ncurry leaves\n0.61\n0.00\n0.44\n12.54\n1.01\n0.12\n1.17\n0.05\n8.64\n2.04\n...\n0.16\n0.07\n0.07\n0.66\n0.02\n1.73\n0.28\n7.33\n16.52\n0.05\n\n\nfennel seed\n0.75\n0.05\n0.82\n1.68\n1.45\n0.16\n1.99\n0.07\n3.77\n2.46\n...\n0.70\n0.26\n0.09\n0.91\n0.42\n0.37\n0.75\n0.82\n4.21\n0.00\n\n\nfenugreek leaf\n0.87\n0.00\n0.80\n4.54\n1.64\n0.12\n1.52\n0.12\n6.39\n1.73\n...\n0.70\n0.02\n0.16\n0.37\n0.07\n0.89\n0.26\n3.23\n8.71\n0.00\n\n\nfenugreek seed\n0.14\n0.00\n0.47\n3.16\n0.35\n0.07\n0.37\n0.07\n2.36\n0.61\n...\n0.61\n0.00\n0.05\n0.30\n0.02\n0.59\n0.07\n2.93\n4.52\n0.00\n\n\ngaram masala\n1.43\n0.00\n2.29\n3.18\n4.40\n0.26\n3.98\n0.28\n14.07\n4.00\n...\n0.33\n0.14\n0.30\n0.63\n0.49\n0.42\n0.44\n0.49\n13.25\n0.00\n\n\nginger powder\n0.21\n0.02\n0.05\n0.44\n0.35\n0.05\n0.84\n0.02\n0.59\n0.49\n...\n0.00\n0.19\n0.02\n0.02\n0.12\n0.07\n0.00\n0.07\n0.47\n0.00\n\n\ngreen chillies\n1.80\n0.00\n1.59\n7.61\n4.61\n0.28\n3.96\n0.21\n12.22\n4.84\n...\n0.77\n0.19\n0.33\n1.19\n0.33\n1.08\n0.66\n2.36\n17.11\n0.07\n\n\nindian gooseberry\n0.05\n0.00\n0.00\n0.30\n0.00\n0.02\n0.00\n0.02\n0.16\n0.00\n...\n0.00\n0.00\n0.00\n0.00\n0.00\n0.02\n0.00\n0.05\n0.21\n0.00\n\n\nkalpasi\n0.02\n0.00\n0.00\n0.02\n0.02\n0.00\n0.07\n0.00\n0.02\n0.07\n...\n0.00\n0.02\n0.00\n0.07\n0.00\n0.00\n0.05\n0.00\n0.00\n0.00\n\n\nmace\n0.37\n0.00\n0.02\n0.09\n0.82\n0.00\n1.08\n0.05\n0.80\n1.05\n...\n0.00\n0.49\n0.02\n0.26\n0.14\n0.00\n0.30\n0.00\n0.89\n0.00\n\n\nmustard seed\n0.75\n0.00\n0.87\n12.71\n1.15\n0.07\n0.73\n0.02\n8.03\n1.59\n...\n0.70\n0.09\n0.07\n0.80\n0.05\n1.64\n0.28\n6.74\n15.35\n0.00\n\n\nnigella seed\n0.16\n0.00\n0.35\n0.30\n0.26\n0.02\n0.07\n0.00\n0.84\n0.14\n...\n1.66\n0.00\n0.02\n0.16\n0.02\n0.07\n0.02\n0.07\n1.26\n0.02\n\n\nnutmeg\n0.16\n0.00\n0.00\n0.14\n0.61\n0.00\n1.08\n0.09\n0.44\n0.96\n...\n0.00\n1.52\n0.00\n0.30\n0.23\n0.07\n0.28\n0.05\n0.56\n0.00\n\n\npomegranate seed\n0.09\n0.00\n0.14\n0.09\n0.12\n0.09\n0.23\n0.00\n0.47\n0.19\n...\n0.02\n0.00\n0.77\n0.05\n0.07\n0.02\n0.02\n0.07\n0.33\n0.00\n\n\npoppy seed\n0.23\n0.00\n0.02\n0.54\n0.75\n0.00\n1.47\n0.00\n1.38\n1.40\n...\n0.16\n0.30\n0.05\n3.25\n0.19\n0.26\n0.37\n0.42\n1.80\n0.02\n\n\nsaffron\n0.21\n0.00\n0.05\n0.28\n0.66\n0.09\n3.14\n0.02\n0.68\n0.84\n...\n0.02\n0.23\n0.07\n0.19\n4.03\n0.07\n0.14\n0.00\n0.59\n0.00\n\n\nsesame seed\n0.40\n0.00\n0.26\n1.57\n0.16\n0.02\n0.35\n0.00\n1.59\n0.23\n...\n0.07\n0.07\n0.02\n0.26\n0.07\n4.19\n0.07\n0.82\n1.61\n0.00\n\n\nstar anise\n0.23\n0.00\n0.05\n0.26\n1.10\n0.02\n1.29\n0.02\n0.82\n1.38\n...\n0.02\n0.28\n0.02\n0.37\n0.14\n0.07\n1.73\n0.14\n0.89\n0.00\n\n\ntamarind\n0.37\n0.00\n0.33\n5.17\n0.26\n0.28\n0.42\n0.00\n3.58\n0.89\n...\n0.07\n0.05\n0.07\n0.42\n0.00\n0.82\n0.14\n11.96\n7.21\n0.00\n\n\nturmeric\n2.97\n0.00\n3.51\n15.05\n7.54\n0.33\n6.60\n0.51\n28.39\n8.10\n...\n1.26\n0.56\n0.33\n1.80\n0.59\n1.61\n0.89\n7.21\n48.47\n0.05\n\n\nwhite pepper\n0.00\n0.00\n0.02\n0.02\n0.07\n0.00\n0.07\n0.00\n0.05\n0.07\n...\n0.02\n0.00\n0.00\n0.02\n0.00\n0.00\n0.00\n0.00\n0.05\n0.16\n\n\n\n\n34 rows × 34 columns\n\n\n\n\ntemp_name = [i.title() for i in spice_adj_freq.index.to_list()]\nspice_adj_freq['Plot_name'] = temp_name\n\n\nspice_adj_freq = spice_adj_freq.set_index('Plot_name')\n\n\nspice_adj_freq.columns = temp_name\n\n\nspice_adj_freq\n\n\n\n\n\n\n\n\nAjwain\nAlkanet Root\nAmchoor\nAsafoetida\nBay Leaf\nBlack Salt\nCardamom\nCelery Seeds\nChilli Powder\nCinnamon\n...\nNigella Seed\nNutmeg\nPomegranate Seed\nPoppy Seed\nSaffron\nSesame Seed\nStar Anise\nTamarind\nTurmeric\nWhite Pepper\n\n\nPlot_name\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAjwain\n5.218816\n0.000000\n0.702083\n1.450971\n0.982916\n0.070208\n1.053124\n0.000000\n3.487011\n1.333957\n...\n0.163819\n0.163819\n0.093611\n0.234028\n0.210625\n0.397847\n0.234028\n0.374444\n2.972151\n0.000000\n\n\nAlkanet Root\n0.000000\n0.070208\n0.000000\n0.070208\n0.046806\n0.000000\n0.070208\n0.000000\n0.070208\n0.070208\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\nAmchoor\n0.702083\n0.000000\n4.984788\n1.544582\n0.374444\n0.210625\n0.351041\n0.023403\n3.861456\n0.468055\n...\n0.351041\n0.000000\n0.140417\n0.023403\n0.046806\n0.257430\n0.046806\n0.327639\n3.510414\n0.023403\n\n\nAsafoetida\n1.450971\n0.070208\n1.544582\n24.596302\n1.333957\n0.304236\n1.614791\n0.210625\n9.688743\n1.872221\n...\n0.304236\n0.140417\n0.093611\n0.538264\n0.280833\n1.567985\n0.257430\n5.172010\n15.047976\n0.023403\n\n\nBay Leaf\n0.982916\n0.046806\n0.374444\n1.333957\n10.695062\n0.093611\n6.037912\n0.070208\n6.716593\n6.646384\n...\n0.257430\n0.608472\n0.117014\n0.748888\n0.655277\n0.163819\n1.099930\n0.257430\n7.535689\n0.070208\n\n\nBlack Salt\n0.070208\n0.000000\n0.210625\n0.304236\n0.093611\n1.638193\n0.093611\n0.023403\n0.608472\n0.093611\n...\n0.023403\n0.000000\n0.093611\n0.000000\n0.093611\n0.023403\n0.023403\n0.280833\n0.327639\n0.000000\n\n\nCardamom\n1.053124\n0.070208\n0.351041\n1.614791\n6.037912\n0.093611\n17.786099\n0.140417\n6.131524\n7.980342\n...\n0.070208\n1.076527\n0.234028\n1.474374\n3.135970\n0.351041\n1.287152\n0.421250\n6.599579\n0.070208\n\n\nCelery Seeds\n0.000000\n0.000000\n0.023403\n0.210625\n0.070208\n0.023403\n0.140417\n0.795694\n0.374444\n0.187222\n...\n0.000000\n0.093611\n0.000000\n0.000000\n0.023403\n0.000000\n0.023403\n0.000000\n0.514861\n0.000000\n\n\nChilli Powder\n3.487011\n0.070208\n3.861456\n9.688743\n6.716593\n0.608472\n6.131524\n0.374444\n37.959279\n7.044231\n...\n0.842499\n0.444652\n0.468055\n1.380763\n0.678680\n1.591388\n0.819097\n3.580623\n28.387550\n0.046806\n\n\nCinnamon\n1.333957\n0.070208\n0.468055\n1.872221\n6.646384\n0.093611\n7.980342\n0.187222\n7.044231\n13.128949\n...\n0.140417\n0.959513\n0.187222\n1.404166\n0.842499\n0.234028\n1.380763\n0.889305\n8.097355\n0.070208\n\n\nCloves\n2.012637\n0.070208\n1.427568\n5.054996\n6.576176\n0.163819\n7.652703\n0.187222\n14.135268\n9.290896\n...\n0.351041\n0.702083\n0.234028\n1.591388\n0.795694\n0.959513\n1.427568\n3.931664\n17.294641\n0.023403\n\n\nCoriander Seeds/Powder\n1.755207\n0.000000\n2.410484\n5.125205\n4.914580\n0.257430\n4.306108\n0.468055\n16.264919\n4.352914\n...\n0.351041\n0.304236\n0.280833\n0.702083\n0.327639\n0.561666\n0.585069\n1.848818\n16.779780\n0.000000\n\n\nCumin Seeds/Powder\n2.153054\n0.000000\n3.276387\n13.269366\n5.874093\n1.193541\n5.195413\n0.351041\n21.553943\n6.669787\n...\n0.889305\n0.538264\n0.514861\n1.240346\n0.538264\n1.919026\n0.912708\n5.874093\n27.451439\n0.070208\n\n\nCurry Leaves\n0.608472\n0.000000\n0.444652\n12.543880\n1.006319\n0.117014\n1.170138\n0.046806\n8.635619\n2.036040\n...\n0.163819\n0.070208\n0.070208\n0.655277\n0.023403\n1.731804\n0.280833\n7.325064\n16.522350\n0.046806\n\n\nFennel Seed\n0.748888\n0.046806\n0.819097\n1.684999\n1.450971\n0.163819\n1.989235\n0.070208\n3.767845\n2.457290\n...\n0.702083\n0.257430\n0.093611\n0.912708\n0.421250\n0.374444\n0.748888\n0.819097\n4.212497\n0.000000\n\n\nFenugreek Leaf\n0.865902\n0.000000\n0.795694\n4.540136\n1.638193\n0.117014\n1.521179\n0.117014\n6.388954\n1.731804\n...\n0.702083\n0.023403\n0.163819\n0.374444\n0.070208\n0.889305\n0.257430\n3.229581\n8.705827\n0.000000\n\n\nFenugreek Seed\n0.140417\n0.000000\n0.468055\n3.159373\n0.351041\n0.070208\n0.374444\n0.070208\n2.363679\n0.608472\n...\n0.608472\n0.000000\n0.046806\n0.304236\n0.023403\n0.585069\n0.070208\n2.925345\n4.516733\n0.000000\n\n\nGaram Masala\n1.427568\n0.000000\n2.293471\n3.182776\n4.399719\n0.257430\n3.978469\n0.280833\n14.065060\n4.001872\n...\n0.327639\n0.140417\n0.304236\n0.631875\n0.491458\n0.421250\n0.444652\n0.491458\n13.245963\n0.000000\n\n\nGinger Powder\n0.210625\n0.023403\n0.046806\n0.444652\n0.351041\n0.046806\n0.842499\n0.023403\n0.585069\n0.491458\n...\n0.000000\n0.187222\n0.023403\n0.023403\n0.117014\n0.070208\n0.000000\n0.070208\n0.468055\n0.000000\n\n\nGreen Chillies\n1.802013\n0.000000\n1.591388\n7.605897\n4.610344\n0.280833\n3.955067\n0.210625\n12.216242\n4.844372\n...\n0.772291\n0.187222\n0.327639\n1.193541\n0.327639\n1.076527\n0.655277\n2.363679\n17.107419\n0.070208\n\n\nIndian Gooseberry\n0.046806\n0.000000\n0.000000\n0.304236\n0.000000\n0.023403\n0.000000\n0.023403\n0.163819\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.023403\n0.000000\n0.046806\n0.210625\n0.000000\n\n\nKalpasi\n0.023403\n0.000000\n0.000000\n0.023403\n0.023403\n0.000000\n0.070208\n0.000000\n0.023403\n0.070208\n...\n0.000000\n0.023403\n0.000000\n0.070208\n0.000000\n0.000000\n0.046806\n0.000000\n0.000000\n0.000000\n\n\nMace\n0.374444\n0.000000\n0.023403\n0.093611\n0.819097\n0.000000\n1.076527\n0.046806\n0.795694\n1.053124\n...\n0.000000\n0.491458\n0.023403\n0.257430\n0.140417\n0.000000\n0.304236\n0.000000\n0.889305\n0.000000\n\n\nMustard Seed\n0.748888\n0.000000\n0.865902\n12.707700\n1.146735\n0.070208\n0.725486\n0.023403\n8.027147\n1.591388\n...\n0.702083\n0.093611\n0.070208\n0.795694\n0.046806\n1.638193\n0.280833\n6.739995\n15.352212\n0.000000\n\n\nNigella Seed\n0.163819\n0.000000\n0.351041\n0.304236\n0.257430\n0.023403\n0.070208\n0.000000\n0.842499\n0.140417\n...\n1.661596\n0.000000\n0.023403\n0.163819\n0.023403\n0.070208\n0.023403\n0.070208\n1.263749\n0.023403\n\n\nNutmeg\n0.163819\n0.000000\n0.000000\n0.140417\n0.608472\n0.000000\n1.076527\n0.093611\n0.444652\n0.959513\n...\n0.000000\n1.521179\n0.000000\n0.304236\n0.234028\n0.070208\n0.280833\n0.046806\n0.561666\n0.000000\n\n\nPomegranate Seed\n0.093611\n0.000000\n0.140417\n0.093611\n0.117014\n0.093611\n0.234028\n0.000000\n0.468055\n0.187222\n...\n0.023403\n0.000000\n0.772291\n0.046806\n0.070208\n0.023403\n0.023403\n0.070208\n0.327639\n0.000000\n\n\nPoppy Seed\n0.234028\n0.000000\n0.023403\n0.538264\n0.748888\n0.000000\n1.474374\n0.000000\n1.380763\n1.404166\n...\n0.163819\n0.304236\n0.046806\n3.252984\n0.187222\n0.257430\n0.374444\n0.421250\n1.802013\n0.023403\n\n\nSaffron\n0.210625\n0.000000\n0.046806\n0.280833\n0.655277\n0.093611\n3.135970\n0.023403\n0.678680\n0.842499\n...\n0.023403\n0.234028\n0.070208\n0.187222\n4.025275\n0.070208\n0.140417\n0.000000\n0.585069\n0.000000\n\n\nSesame Seed\n0.397847\n0.000000\n0.257430\n1.567985\n0.163819\n0.023403\n0.351041\n0.000000\n1.591388\n0.234028\n...\n0.070208\n0.070208\n0.023403\n0.257430\n0.070208\n4.189094\n0.070208\n0.819097\n1.614791\n0.000000\n\n\nStar Anise\n0.234028\n0.000000\n0.046806\n0.257430\n1.099930\n0.023403\n1.287152\n0.023403\n0.819097\n1.380763\n...\n0.023403\n0.280833\n0.023403\n0.374444\n0.140417\n0.070208\n1.731804\n0.140417\n0.889305\n0.000000\n\n\nTamarind\n0.374444\n0.000000\n0.327639\n5.172010\n0.257430\n0.280833\n0.421250\n0.000000\n3.580623\n0.889305\n...\n0.070208\n0.046806\n0.070208\n0.421250\n0.000000\n0.819097\n0.140417\n11.958811\n7.208051\n0.000000\n\n\nTurmeric\n2.972151\n0.000000\n3.510414\n15.047976\n7.535689\n0.327639\n6.599579\n0.514861\n28.387550\n8.097355\n...\n1.263749\n0.561666\n0.327639\n1.802013\n0.585069\n1.614791\n0.889305\n7.208051\n48.467119\n0.046806\n\n\nWhite Pepper\n0.000000\n0.000000\n0.023403\n0.023403\n0.070208\n0.000000\n0.070208\n0.000000\n0.046806\n0.070208\n...\n0.023403\n0.000000\n0.000000\n0.023403\n0.000000\n0.000000\n0.000000\n0.000000\n0.046806\n0.163819\n\n\n\n\n34 rows × 34 columns\n\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nsns.heatmap(spice_adj_freq.round(2).corr(), ax=ax)\n#plt.savefig(\"heatmap.png\", format=\"PNG\", dpi=300)\n\n\n\n\n\n\n\n\nUsing frequency adjacency matrix we can plot a heatmap showing the pair-wise occurence for a given pair of spices. The idea with such an analysis is that if we can check the variation of Spice 1 with all the other spices in the list and compare that to Spice 2’s variation with all the other spices in the list, if spice 1 and spice 2 should have similar variation.\nThis map itself is quite interesting. The color intensity of each title shows the frequency that pair of spice occurred together in a recipe. Brighter the color higher their occurence together.\nSome prominent spice pairs which show similarity are:\n\nCurry leaves and Mustard seeds\nTumeric and Chilli Powder\n\nSome pair of spices never occur together:\n\nSaffron and Fenugreek seeds\nNutmeg and Mustard Seeds\n\nThose who cook or know indian recipes would see that these pairs make sense and thereby validate the correlation seen from corpus of Indian recipes.\nWith that analysis, we can go a step further and analyze this information in form of a circular network graph. Using this method of plotting, we can see the interactions between different spices.\n#hide spice_dict = {i : spice_adj_freq.loc[i, i] for i in spice_col_name } top_10_spices = list({k: v for k, v in sorted(spice_dict.items(), reverse=True, key=lambda item: item[1])}.keys())[:10] spice_adj_10 = spice_adj_freq.loc[top_10_spices, top_10_spices]\n#hide top_10_spices\n\n\n\nimport networkx as nx \n\n\nnodes_data = [(i, {'count':spice_adj_freq.loc[i, i]}) for i in temp_name]\n\n\n# most binary interactions \nbinary_int = []\nfor i in temp_name:\n    binary_int.append((i, spice_adj_freq.loc[i].sort_values(ascending=False).index[1]))\n\n\nspice_dict = {i : spice_adj_freq.loc[i, i] for i in temp_name }\n\n\nspice_dict\n\n{'Ajwain': 5.218815820266792,\n 'Alkanet Root': 0.07020828457758016,\n 'Amchoor': 4.984788205008191,\n 'Asafoetida': 24.596302363678916,\n 'Bay Leaf': 10.695062017318044,\n 'Black Salt': 1.6381933068102035,\n 'Cardamom': 17.78609875965364,\n 'Celery Seeds': 0.7956938918792418,\n 'Chilli Powder': 37.959279194945005,\n 'Cinnamon': 13.128949216007488,\n 'Cloves': 28.34074420781652,\n 'Coriander Seeds/Powder': 20.336999765972386,\n 'Cumin Seeds/Powder': 43.59934472267727,\n 'Curry Leaves': 27.615258600514856,\n 'Fennel Seed': 7.208050549964897,\n 'Fenugreek Leaf': 12.965129885326467,\n 'Fenugreek Seed': 7.208050549964897,\n 'Garam Masala': 18.34776503627428,\n 'Ginger Powder': 1.357360168499883,\n 'Green Chillies': 29.815118183945703,\n 'Indian Gooseberry': 0.3978469459396209,\n 'Kalpasi': 0.07020828457758016,\n 'Mace': 1.2403463608705827,\n 'Mustard Seed': 24.315469225368595,\n 'Nigella Seed': 1.6615960683360638,\n 'Nutmeg': 1.5211794991809033,\n 'Pomegranate Seed': 0.7722911303533817,\n 'Poppy Seed': 3.2529838520945473,\n 'Saffron': 4.025274982447929,\n 'Sesame Seed': 4.189094313128949,\n 'Star Anise': 1.7318043529136438,\n 'Tamarind': 11.958811139714488,\n 'Turmeric': 48.46711912005617,\n 'White Pepper': 0.16381933068102036}\n\n\n\nedges_data = [] \nfor i in temp_name:\n    for j in temp_name:\n        if i != j:\n            if spice_adj_freq.loc[i,j] != 0.0:\n                edges_data.append((i, j, {'weight':spice_adj_freq.loc[i,j], 'distance':1}))\n\n\n#G = nx.from_pandas_adjacency(spice_adj_freq)\n#BUILD THE INITIAL FULL GRAPH\nG=nx.Graph()\nG.add_nodes_from(nodes_data)\nG.add_edges_from(edges_data)\n\n\nprint(nx.info(G))\n\nName: \nType: Graph\nNumber of nodes: 34\nNumber of edges: 471\nAverage degree:  27.7059\n\n\n\ndeg_l = {i:G.degree(i) for i in temp_name} \n\n\nhighest_centrality_node = max(deg_l.items(), key=lambda x: x[1])[0]\n\n\nhighest_centrality_node\n\n'Asafoetida'\n\n\n\n#Adopted from: https://stackoverflow.com/questions/43894987/networkx-node-labels-relative-position\nn = len(nodes_data)\nedges = G.edges()\n\nweights = [G[u][v]['weight'] for u,v in edges]\nw_arr = np.array(weights)\nnorm_weight =  (w_arr - w_arr.min())/(w_arr.max() - w_arr.min())\n\n\nangle = []\nangle_dict = {}\nnode_list = sorted(G.nodes())\nfor i, node in zip(np.arange(n),node_list):\n    theta = 2.0*np.pi*i/n\n    angle.append((np.cos(theta),np.sin(theta)))\n    angle_dict[node] = theta\npos = {}\nfor node_i, node in enumerate(node_list):\n    pos[node] = angle[node_i]\n    \nfig, ax = plt.subplots(figsize=(20,20))\nmargin=0.33\nfig.subplots_adjust(margin, margin, 1.-margin, 1.-margin)\nax.axis('equal')\n\nnx.draw(G,pos=pos,with_labels=False, node_size=[spice_dict[k]*20 for k in spice_dict], width=norm_weight*2.0, node_color=np.arange(n), cmap=plt.cm.viridis, ax=ax)\ndescription = nx.draw_networkx_labels(G,pos)\n\nr = fig.canvas.get_renderer()\ntrans = plt.gca().transData.inverted()\nfor node, t in description.items():\n    bb = t.get_window_extent(renderer=r)\n    bbdata = bb.transformed(trans)\n    radius = 1.1+bbdata.width/2\n    position = (radius*np.cos(angle_dict[node]),radius* np.sin(angle_dict[node]))\n    t.set_position(position)\n    t.set_rotation(angle_dict[node]*360.0/(2.0*np.pi))\n    t.set_clip_on(False)\n    \n#plt.savefig(\"Graph.png\", format=\"PNG\", dpi=300)\n\n\n\n\n\n\n\n\nFinally a networkx circular graph is made where each node is a spice entry. Each edge between a pair of spice is a connection provided those two spices are found together in a recipe. The size of the node is the frequency of that spice to occur in all of 6000 food recipes. The thickness of the edge connecting a give spice-pair is the normalized frequency that pair occured among 6000 recipes.\nRepresenting the analysis this way we find few key takeaways: * Tumeric, Mustard Seeds, Chilli Powder, Corriander Seeds, Cumin Seeds, Curry Leaves, Green Chillies, Asafoetida are the key spices in the Indian cuisine.\n\nMost recipes use Tumeric + Chilli Powder + Cumin Powder (Seeds) in them."
  },
  {
    "objectID": "posts/2020-12-09-food_relations.html#drop-non-english-entries-for-consistency",
    "href": "posts/2020-12-09-food_relations.html#drop-non-english-entries-for-consistency",
    "title": "Relational analysis of spices used in Indian cuisine",
    "section": "",
    "text": "# Some entries in the `TranslatedIngredients` have non-english entries \ndef filter_english(string):\n    try:\n        string.encode('utf-8').decode('ascii')\n        out = True\n    except UnicodeDecodeError: \n        out = False\n    return out\n\n\n# Droping columns in the dataset having ingredients in language other than english \ndf = food_df.loc[ food_df['TranslatedIngredients'].apply(filter_english) ]\n\n\ndf.shape\n\n(4273, 8)\n\n\n\ndf = df.reset_index()"
  },
  {
    "objectID": "posts/2020-12-09-food_relations.html#generate-a-consistent-list-of-indian-spices-for-better-tabulation",
    "href": "posts/2020-12-09-food_relations.html#generate-a-consistent-list-of-indian-spices-for-better-tabulation",
    "title": "Relational analysis of spices used in Indian cuisine",
    "section": "",
    "text": "Next for consistent tabulation I needed a list of spices to look for. Wikipedia has a page on Indian spices which lists various spices used in Indian cuisine. I use this list to search names of spices in the recipe entries.\n\n#read file of all indian spices on wikipedia\nwiki_file_pd = pd.read_html('https://en.wikipedia.org/wiki/List_of_Indian_spices')\nspices_list = wiki_file_pd[0]['Standard English'].copy().str.lower()\n\n#some important spices to add\nspices_to_add = pd.Series(['black salt', 'green chillies', 'chilli powder'])\n\n#some spices are too common (such as pepper) or not a spice, but a vegetable, or are otherwise corrupted (for example,\n#cardamom is often listed as \"cardamom\" nto specifying whether it is black or green)\n\nspices_to_drop = ['black pepper', 'capers', 'chili pepper powder', 'cinnamon buds', 'citric acid', 'garlic', 'capsicum', 'charoli', 'garcinia gummi-gutta', 'inknut', 'garcinia indica',\n                  'black mustard seeds/raee', 'cumin seed ground into balls', 'dried ginger', 'green chili pepper', 'long pepper', 'four seeds', 'cubeb', 'gum tragacanth', 'jakhya', 'licorice powder',\n                  'indian bedellium tree', 'mango extract', 'coriander powder', 'saffron pulp', 'black cardamom', 'brown mustard seed', 'black cumin', 'panch phoron']\n\nspices_list = spices_list.loc[ ~spices_list.isin(spices_to_drop) ].append(spices_to_add).reset_index(drop=True)\n\n\nspices_list\n\n0                      alkanet root\n1                           amchoor\n2                        asafoetida\n3             celery / radhuni seed\n4         bay leaf, indian bay leaf\n5                          cinnamon\n6                            cloves\n7                    coriander seed\n8                        cumin seed\n9     curry tree or sweet neem leaf\n10                      fennel seed\n11                   fenugreek leaf\n12                   fenugreek seed\n13                     garam masala\n14                           ginger\n15                   green cardamom\n16                indian gooseberry\n17                          kalpasi\n18                     mustard seed\n19                     nigella seed\n20                           nutmeg\n21                             mace\n22                 pomegranate seed\n23                       poppy seed\n24                          saffron\n25                      sesame seed\n26                      star aniseh\n27                         tamarind\n28                thymol/carom seed\n29                         turmeric\n30                     white pepper\n31                       black salt\n32                   green chillies\n33                    chilli powder\ndtype: object\n\n\nOne more step is editing the spices so that my string counter can find different versions of the same spice.\n\n#editing the spices so that my string counter can find different versions of the same spice\nspices_list = spices_list.str.replace('amchoor', 'amchur/amchoor/mango extract') \\\n                    .replace('asafoetida', 'asafetida/asafoetida/hing') \\\n                    .replace('thymol/carom seed', 'ajwain/thymol/carom seed') \\\n                    .replace('alkanet root', 'alkanet/alkanet root') \\\n                    .replace('chilli powder', 'red chilli powder/chilli powder/kashmiri red chilli powder') \\\n                    .replace('celery / radhuni seed', 'celery/radhuni seed') \\\n                    .replace('bay leaf, indian bay leaf', 'bay leaf/bay leaves/tej patta') \\\n                    .replace('curry tree or sweet neem leaf', 'curry leaf/curry leaves') \\\n                    .replace('fenugreek leaf', 'fenugreek/kasoori methi') \\\n                    .replace('nigella seed', 'nigella/black cumin') \\\n                    .replace('ginger', 'dried ginger/ginger powder') \\\n                    .replace('cloves', 'cloves/laung') \\\n                    .replace('green cardamom', 'cardamom/green cardamom/black cardamom')\\\n                    .replace('indian gooseberry', 'indian gooseberry/amla')\\\n                    .replace('coriander seed', 'coriander seed/coriander powder')\\\n                    .replace('star aniseh', 'star anise')\\\n                    .replace('cumin seed', 'cumin powder/cumin seeds/cumin/jeera')\n\n\nspices_list\n\n0                                  alkanet/alkanet root\n1                          amchur/amchoor/mango extract\n2                             asafetida/asafoetida/hing\n3                                   celery/radhuni seed\n4                         bay leaf/bay leaves/tej patta\n5                                              cinnamon\n6                                          cloves/laung\n7                       coriander seed/coriander powder\n8                  cumin powder/cumin seeds/cumin/jeera\n9                               curry leaf/curry leaves\n10                                          fennel seed\n11                              fenugreek/kasoori methi\n12                                       fenugreek seed\n13                                         garam masala\n14                           dried ginger/ginger powder\n15               cardamom/green cardamom/black cardamom\n16                               indian gooseberry/amla\n17                                              kalpasi\n18                                         mustard seed\n19                                  nigella/black cumin\n20                                               nutmeg\n21                                                 mace\n22                                     pomegranate seed\n23                                           poppy seed\n24                                              saffron\n25                                          sesame seed\n26                                           star anise\n27                                             tamarind\n28                             ajwain/thymol/carom seed\n29                                             turmeric\n30                                         white pepper\n31                                           black salt\n32                                       green chillies\n33    red chilli powder/chilli powder/kashmiri red c...\ndtype: object"
  },
  {
    "objectID": "posts/2020-12-09-food_relations.html#ingredients-in-the-recipes",
    "href": "posts/2020-12-09-food_relations.html#ingredients-in-the-recipes",
    "title": "Relational analysis of spices used in Indian cuisine",
    "section": "",
    "text": "ingredients_series = df[['TranslatedRecipeName','TranslatedIngredients']]\n\n\ningredients_series\n\n\n\n\n\n\n\n\nTranslatedRecipeName\nTranslatedIngredients\n\n\n\n\n0\nMasala Karela Recipe\n6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n\n\n1\nSpicy Tomato Rice (Recipe)\n2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...\n\n\n2\nRagi Semiya Upma Recipe - Ragi Millet Vermicel...\n1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n\n\n3\nGongura Chicken Curry Recipe - Andhra Style Go...\n500 grams Chicken,2 Onion - chopped,1 Tomato -...\n\n\n4\nAndhra Style Alam Pachadi Recipe - Adrak Chutn...\n1 tablespoon chana dal, 1 tablespoon white ura...\n\n\n...\n...\n...\n\n\n4268\nOne Pot Punjabi Rajma Masala Recipe In Preethi...\n1 cup Rajma (Large Kidney Beans),1 inch Ginger...\n\n\n4269\nSaffron Paneer Peda Recipe\n2 cups Paneer (Homemade Cottage Cheese) - crum...\n\n\n4270\nQuinoa Phirnee Recipe (Quinoa Milk Pudding)\n1 cup Quinoa,3/4 cup Sugar,1 teaspoon Cardamom...\n\n\n4271\nUllikadala Pulusu Recipe | Spring Onion Curry\n150 grams Spring Onion (Bulb & Greens) - chopp...\n\n\n4272\nKashmiri Style Kokur Yakhni Recipe-Chicken Coo...\n1 kg Chicken - medium pieces,1/2 cup Mustard o...\n\n\n\n\n4273 rows × 2 columns\n\n\n\n\nspices_list_column_to_add = {i: np.zeros(len(ingredients_series)) for i in spices_list.to_list()}\n\n\ningredients_series = ingredients_series.join(pd.DataFrame(spices_list_column_to_add))\n\n\ningredients_series\n\n\n\n\n\n\n\n\nTranslatedRecipeName\nTranslatedIngredients\nalkanet/alkanet root\namchur/amchoor/mango extract\nasafetida/asafoetida/hing\ncelery/radhuni seed\nbay leaf/bay leaves/tej patta\ncinnamon\ncloves/laung\ncoriander seed/coriander powder\n...\nsaffron\nsesame seed\nstar anise\ntamarind\najwain/thymol/carom seed\nturmeric\nwhite pepper\nblack salt\ngreen chillies\nred chilli powder/chilli powder/kashmiri red chilli powder\n\n\n\n\n0\nMasala Karela Recipe\n6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\nSpicy Tomato Rice (Recipe)\n2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n2\nRagi Semiya Upma Recipe - Ragi Millet Vermicel...\n1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\nGongura Chicken Curry Recipe - Andhra Style Go...\n500 grams Chicken,2 Onion - chopped,1 Tomato -...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\nAndhra Style Alam Pachadi Recipe - Adrak Chutn...\n1 tablespoon chana dal, 1 tablespoon white ura...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n4268\nOne Pot Punjabi Rajma Masala Recipe In Preethi...\n1 cup Rajma (Large Kidney Beans),1 inch Ginger...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4269\nSaffron Paneer Peda Recipe\n2 cups Paneer (Homemade Cottage Cheese) - crum...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4270\nQuinoa Phirnee Recipe (Quinoa Milk Pudding)\n1 cup Quinoa,3/4 cup Sugar,1 teaspoon Cardamom...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4271\nUllikadala Pulusu Recipe | Spring Onion Curry\n150 grams Spring Onion (Bulb & Greens) - chopp...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4272\nKashmiri Style Kokur Yakhni Recipe-Chicken Coo...\n1 kg Chicken - medium pieces,1/2 cup Mustard o...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n4273 rows × 36 columns"
  },
  {
    "objectID": "posts/2020-12-09-food_relations.html#using-the-spice_list-to-find-spice-name-in-the-recipe",
    "href": "posts/2020-12-09-food_relations.html#using-the-spice_list-to-find-spice-name-in-the-recipe",
    "title": "Relational analysis of spices used in Indian cuisine",
    "section": "",
    "text": "I used regular expression to search for spice names in the entries\n\n# Convenience function to search a given ingredient list for spice names\nimport re \ndef search_spice(ingredient_string, spice_string):\n    '''\n    Check if a spice exists in the list of ingredients for a recipe \n    '''\n    spice_list = spice_string.split('/')\n    for _spice in spice_list:\n        if re.search(_spice.lower(), ingredient_string.lower()):\n            return True\n            break\n\n\nfor row, values in ingredients_series.iterrows():\n    for spice_entry in spices_list:\n        if search_spice(values['TranslatedIngredients'], spice_entry):\n            ingredients_series.loc[row, spice_entry] = 1\n        else:\n            ingredients_series.loc[row, spice_entry] = 0\n\n\nfood_spice_mix = ingredients_series.drop(['TranslatedIngredients'], axis=1).reset_index(drop=True)\n\n\n#editing the spices so that my string counter can find different versions of the same spice\nfood_spice_mix.rename(columns={'amchur/amchoor/mango extract':'amchoor', \\\n                    'asafetida/asafoetida/hing': 'asafoetida', \\\n                    'ajwain/thymol/carom seed': 'ajwain', \\\n                    'alkanet/alkanet root': 'alkanet root', \\\n                    'red chilli powder/chilli powder/kashmiri red chilli powder': 'chilli powder', \\\n                    'celery/radhuni seed': 'celery seeds',\\\n                    'bay leaf/bay leaves/tej patta': 'bay leaf', \\\n                    'curry leaf/curry leaves': 'curry leaves',\\\n                    'fenugreek/kasoori methi': 'fenugreek leaf', \\\n                    'nigella/black cumin': 'nigella seed', \\\n                    'ginger': 'dried ginger',\\\n                    'cloves/laung': 'cloves', \\\n                    'cardamom/green cardamom/black cardamom': 'cardamom',\\\n                    'indian gooseberry/amla': 'indian gooseberry',\\\n                    'coriander seed/coriander powder': 'coriander seeds/powder',\\\n                    'cumin powder/cumin seeds/cumin/jeera': 'cumin seeds/powder',\\\n                    'dried ginger/ginger powder': 'ginger powder'}, inplace=True)\n\n\nfood_spice_mix.columns\n\nIndex(['TranslatedRecipeName', 'alkanet root', 'amchoor', 'asafoetida',\n       'celery seeds', 'bay leaf', 'cinnamon', 'cloves',\n       'coriander seeds/powder', 'cumin seeds/powder', 'curry leaves',\n       'fennel seed', 'fenugreek leaf', 'fenugreek seed', 'garam masala',\n       'ginger powder', 'cardamom', 'indian gooseberry', 'kalpasi',\n       'mustard seed', 'nigella seed', 'nutmeg', 'mace', 'pomegranate seed',\n       'poppy seed', 'saffron', 'sesame seed', 'star anise', 'tamarind',\n       'ajwain', 'turmeric', 'white pepper', 'black salt', 'green chillies',\n       'chilli powder'],\n      dtype='object')\n\n\n\nfood_spice_mix = food_spice_mix.sort_index(axis=1)"
  },
  {
    "objectID": "posts/2020-12-09-food_relations.html#generating-a-spice-adjacency-matrix",
    "href": "posts/2020-12-09-food_relations.html#generating-a-spice-adjacency-matrix",
    "title": "Relational analysis of spices used in Indian cuisine",
    "section": "",
    "text": "num_spice = len(spices_list)\nspice_col_name = [i for i in food_spice_mix.columns[1:].to_list()]\nspice_adj = pd.DataFrame(np.zeros(shape=(len(spices_list),len(spices_list))), columns= spice_col_name, index=spice_col_name)\nspice_adj_freq = pd.DataFrame(np.zeros(shape=(len(spices_list),len(spices_list))), columns= spice_col_name, index=spice_col_name)\n\n\nfor row, value in food_spice_mix.iterrows():\n    for i in spice_col_name:\n        for j in spice_col_name:\n            if (value[i] == 1) & (value[j] == 1):\n                spice_adj_freq.loc[i,j] += 1\n                spice_adj.loc[i,j] = 1\n\nNormalize the spice occurance frequency with the total entries in the main dataset\n\nspice_adj_freq = spice_adj_freq / len(food_spice_mix) * 100\n\n\nspice_adj_freq.round(2)\n\n\n\n\n\n\n\n\najwain\nalkanet root\namchoor\nasafoetida\nbay leaf\nblack salt\ncardamom\ncelery seeds\nchilli powder\ncinnamon\n...\nnigella seed\nnutmeg\npomegranate seed\npoppy seed\nsaffron\nsesame seed\nstar anise\ntamarind\nturmeric\nwhite pepper\n\n\n\n\najwain\n5.22\n0.00\n0.70\n1.45\n0.98\n0.07\n1.05\n0.00\n3.49\n1.33\n...\n0.16\n0.16\n0.09\n0.23\n0.21\n0.40\n0.23\n0.37\n2.97\n0.00\n\n\nalkanet root\n0.00\n0.07\n0.00\n0.07\n0.05\n0.00\n0.07\n0.00\n0.07\n0.07\n...\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\namchoor\n0.70\n0.00\n4.98\n1.54\n0.37\n0.21\n0.35\n0.02\n3.86\n0.47\n...\n0.35\n0.00\n0.14\n0.02\n0.05\n0.26\n0.05\n0.33\n3.51\n0.02\n\n\nasafoetida\n1.45\n0.07\n1.54\n24.60\n1.33\n0.30\n1.61\n0.21\n9.69\n1.87\n...\n0.30\n0.14\n0.09\n0.54\n0.28\n1.57\n0.26\n5.17\n15.05\n0.02\n\n\nbay leaf\n0.98\n0.05\n0.37\n1.33\n10.70\n0.09\n6.04\n0.07\n6.72\n6.65\n...\n0.26\n0.61\n0.12\n0.75\n0.66\n0.16\n1.10\n0.26\n7.54\n0.07\n\n\nblack salt\n0.07\n0.00\n0.21\n0.30\n0.09\n1.64\n0.09\n0.02\n0.61\n0.09\n...\n0.02\n0.00\n0.09\n0.00\n0.09\n0.02\n0.02\n0.28\n0.33\n0.00\n\n\ncardamom\n1.05\n0.07\n0.35\n1.61\n6.04\n0.09\n17.79\n0.14\n6.13\n7.98\n...\n0.07\n1.08\n0.23\n1.47\n3.14\n0.35\n1.29\n0.42\n6.60\n0.07\n\n\ncelery seeds\n0.00\n0.00\n0.02\n0.21\n0.07\n0.02\n0.14\n0.80\n0.37\n0.19\n...\n0.00\n0.09\n0.00\n0.00\n0.02\n0.00\n0.02\n0.00\n0.51\n0.00\n\n\nchilli powder\n3.49\n0.07\n3.86\n9.69\n6.72\n0.61\n6.13\n0.37\n37.96\n7.04\n...\n0.84\n0.44\n0.47\n1.38\n0.68\n1.59\n0.82\n3.58\n28.39\n0.05\n\n\ncinnamon\n1.33\n0.07\n0.47\n1.87\n6.65\n0.09\n7.98\n0.19\n7.04\n13.13\n...\n0.14\n0.96\n0.19\n1.40\n0.84\n0.23\n1.38\n0.89\n8.10\n0.07\n\n\ncloves\n2.01\n0.07\n1.43\n5.05\n6.58\n0.16\n7.65\n0.19\n14.14\n9.29\n...\n0.35\n0.70\n0.23\n1.59\n0.80\n0.96\n1.43\n3.93\n17.29\n0.02\n\n\ncoriander seeds/powder\n1.76\n0.00\n2.41\n5.13\n4.91\n0.26\n4.31\n0.47\n16.26\n4.35\n...\n0.35\n0.30\n0.28\n0.70\n0.33\n0.56\n0.59\n1.85\n16.78\n0.00\n\n\ncumin seeds/powder\n2.15\n0.00\n3.28\n13.27\n5.87\n1.19\n5.20\n0.35\n21.55\n6.67\n...\n0.89\n0.54\n0.51\n1.24\n0.54\n1.92\n0.91\n5.87\n27.45\n0.07\n\n\ncurry leaves\n0.61\n0.00\n0.44\n12.54\n1.01\n0.12\n1.17\n0.05\n8.64\n2.04\n...\n0.16\n0.07\n0.07\n0.66\n0.02\n1.73\n0.28\n7.33\n16.52\n0.05\n\n\nfennel seed\n0.75\n0.05\n0.82\n1.68\n1.45\n0.16\n1.99\n0.07\n3.77\n2.46\n...\n0.70\n0.26\n0.09\n0.91\n0.42\n0.37\n0.75\n0.82\n4.21\n0.00\n\n\nfenugreek leaf\n0.87\n0.00\n0.80\n4.54\n1.64\n0.12\n1.52\n0.12\n6.39\n1.73\n...\n0.70\n0.02\n0.16\n0.37\n0.07\n0.89\n0.26\n3.23\n8.71\n0.00\n\n\nfenugreek seed\n0.14\n0.00\n0.47\n3.16\n0.35\n0.07\n0.37\n0.07\n2.36\n0.61\n...\n0.61\n0.00\n0.05\n0.30\n0.02\n0.59\n0.07\n2.93\n4.52\n0.00\n\n\ngaram masala\n1.43\n0.00\n2.29\n3.18\n4.40\n0.26\n3.98\n0.28\n14.07\n4.00\n...\n0.33\n0.14\n0.30\n0.63\n0.49\n0.42\n0.44\n0.49\n13.25\n0.00\n\n\nginger powder\n0.21\n0.02\n0.05\n0.44\n0.35\n0.05\n0.84\n0.02\n0.59\n0.49\n...\n0.00\n0.19\n0.02\n0.02\n0.12\n0.07\n0.00\n0.07\n0.47\n0.00\n\n\ngreen chillies\n1.80\n0.00\n1.59\n7.61\n4.61\n0.28\n3.96\n0.21\n12.22\n4.84\n...\n0.77\n0.19\n0.33\n1.19\n0.33\n1.08\n0.66\n2.36\n17.11\n0.07\n\n\nindian gooseberry\n0.05\n0.00\n0.00\n0.30\n0.00\n0.02\n0.00\n0.02\n0.16\n0.00\n...\n0.00\n0.00\n0.00\n0.00\n0.00\n0.02\n0.00\n0.05\n0.21\n0.00\n\n\nkalpasi\n0.02\n0.00\n0.00\n0.02\n0.02\n0.00\n0.07\n0.00\n0.02\n0.07\n...\n0.00\n0.02\n0.00\n0.07\n0.00\n0.00\n0.05\n0.00\n0.00\n0.00\n\n\nmace\n0.37\n0.00\n0.02\n0.09\n0.82\n0.00\n1.08\n0.05\n0.80\n1.05\n...\n0.00\n0.49\n0.02\n0.26\n0.14\n0.00\n0.30\n0.00\n0.89\n0.00\n\n\nmustard seed\n0.75\n0.00\n0.87\n12.71\n1.15\n0.07\n0.73\n0.02\n8.03\n1.59\n...\n0.70\n0.09\n0.07\n0.80\n0.05\n1.64\n0.28\n6.74\n15.35\n0.00\n\n\nnigella seed\n0.16\n0.00\n0.35\n0.30\n0.26\n0.02\n0.07\n0.00\n0.84\n0.14\n...\n1.66\n0.00\n0.02\n0.16\n0.02\n0.07\n0.02\n0.07\n1.26\n0.02\n\n\nnutmeg\n0.16\n0.00\n0.00\n0.14\n0.61\n0.00\n1.08\n0.09\n0.44\n0.96\n...\n0.00\n1.52\n0.00\n0.30\n0.23\n0.07\n0.28\n0.05\n0.56\n0.00\n\n\npomegranate seed\n0.09\n0.00\n0.14\n0.09\n0.12\n0.09\n0.23\n0.00\n0.47\n0.19\n...\n0.02\n0.00\n0.77\n0.05\n0.07\n0.02\n0.02\n0.07\n0.33\n0.00\n\n\npoppy seed\n0.23\n0.00\n0.02\n0.54\n0.75\n0.00\n1.47\n0.00\n1.38\n1.40\n...\n0.16\n0.30\n0.05\n3.25\n0.19\n0.26\n0.37\n0.42\n1.80\n0.02\n\n\nsaffron\n0.21\n0.00\n0.05\n0.28\n0.66\n0.09\n3.14\n0.02\n0.68\n0.84\n...\n0.02\n0.23\n0.07\n0.19\n4.03\n0.07\n0.14\n0.00\n0.59\n0.00\n\n\nsesame seed\n0.40\n0.00\n0.26\n1.57\n0.16\n0.02\n0.35\n0.00\n1.59\n0.23\n...\n0.07\n0.07\n0.02\n0.26\n0.07\n4.19\n0.07\n0.82\n1.61\n0.00\n\n\nstar anise\n0.23\n0.00\n0.05\n0.26\n1.10\n0.02\n1.29\n0.02\n0.82\n1.38\n...\n0.02\n0.28\n0.02\n0.37\n0.14\n0.07\n1.73\n0.14\n0.89\n0.00\n\n\ntamarind\n0.37\n0.00\n0.33\n5.17\n0.26\n0.28\n0.42\n0.00\n3.58\n0.89\n...\n0.07\n0.05\n0.07\n0.42\n0.00\n0.82\n0.14\n11.96\n7.21\n0.00\n\n\nturmeric\n2.97\n0.00\n3.51\n15.05\n7.54\n0.33\n6.60\n0.51\n28.39\n8.10\n...\n1.26\n0.56\n0.33\n1.80\n0.59\n1.61\n0.89\n7.21\n48.47\n0.05\n\n\nwhite pepper\n0.00\n0.00\n0.02\n0.02\n0.07\n0.00\n0.07\n0.00\n0.05\n0.07\n...\n0.02\n0.00\n0.00\n0.02\n0.00\n0.00\n0.00\n0.00\n0.05\n0.16\n\n\n\n\n34 rows × 34 columns\n\n\n\n\ntemp_name = [i.title() for i in spice_adj_freq.index.to_list()]\nspice_adj_freq['Plot_name'] = temp_name\n\n\nspice_adj_freq = spice_adj_freq.set_index('Plot_name')\n\n\nspice_adj_freq.columns = temp_name\n\n\nspice_adj_freq\n\n\n\n\n\n\n\n\nAjwain\nAlkanet Root\nAmchoor\nAsafoetida\nBay Leaf\nBlack Salt\nCardamom\nCelery Seeds\nChilli Powder\nCinnamon\n...\nNigella Seed\nNutmeg\nPomegranate Seed\nPoppy Seed\nSaffron\nSesame Seed\nStar Anise\nTamarind\nTurmeric\nWhite Pepper\n\n\nPlot_name\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAjwain\n5.218816\n0.000000\n0.702083\n1.450971\n0.982916\n0.070208\n1.053124\n0.000000\n3.487011\n1.333957\n...\n0.163819\n0.163819\n0.093611\n0.234028\n0.210625\n0.397847\n0.234028\n0.374444\n2.972151\n0.000000\n\n\nAlkanet Root\n0.000000\n0.070208\n0.000000\n0.070208\n0.046806\n0.000000\n0.070208\n0.000000\n0.070208\n0.070208\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\nAmchoor\n0.702083\n0.000000\n4.984788\n1.544582\n0.374444\n0.210625\n0.351041\n0.023403\n3.861456\n0.468055\n...\n0.351041\n0.000000\n0.140417\n0.023403\n0.046806\n0.257430\n0.046806\n0.327639\n3.510414\n0.023403\n\n\nAsafoetida\n1.450971\n0.070208\n1.544582\n24.596302\n1.333957\n0.304236\n1.614791\n0.210625\n9.688743\n1.872221\n...\n0.304236\n0.140417\n0.093611\n0.538264\n0.280833\n1.567985\n0.257430\n5.172010\n15.047976\n0.023403\n\n\nBay Leaf\n0.982916\n0.046806\n0.374444\n1.333957\n10.695062\n0.093611\n6.037912\n0.070208\n6.716593\n6.646384\n...\n0.257430\n0.608472\n0.117014\n0.748888\n0.655277\n0.163819\n1.099930\n0.257430\n7.535689\n0.070208\n\n\nBlack Salt\n0.070208\n0.000000\n0.210625\n0.304236\n0.093611\n1.638193\n0.093611\n0.023403\n0.608472\n0.093611\n...\n0.023403\n0.000000\n0.093611\n0.000000\n0.093611\n0.023403\n0.023403\n0.280833\n0.327639\n0.000000\n\n\nCardamom\n1.053124\n0.070208\n0.351041\n1.614791\n6.037912\n0.093611\n17.786099\n0.140417\n6.131524\n7.980342\n...\n0.070208\n1.076527\n0.234028\n1.474374\n3.135970\n0.351041\n1.287152\n0.421250\n6.599579\n0.070208\n\n\nCelery Seeds\n0.000000\n0.000000\n0.023403\n0.210625\n0.070208\n0.023403\n0.140417\n0.795694\n0.374444\n0.187222\n...\n0.000000\n0.093611\n0.000000\n0.000000\n0.023403\n0.000000\n0.023403\n0.000000\n0.514861\n0.000000\n\n\nChilli Powder\n3.487011\n0.070208\n3.861456\n9.688743\n6.716593\n0.608472\n6.131524\n0.374444\n37.959279\n7.044231\n...\n0.842499\n0.444652\n0.468055\n1.380763\n0.678680\n1.591388\n0.819097\n3.580623\n28.387550\n0.046806\n\n\nCinnamon\n1.333957\n0.070208\n0.468055\n1.872221\n6.646384\n0.093611\n7.980342\n0.187222\n7.044231\n13.128949\n...\n0.140417\n0.959513\n0.187222\n1.404166\n0.842499\n0.234028\n1.380763\n0.889305\n8.097355\n0.070208\n\n\nCloves\n2.012637\n0.070208\n1.427568\n5.054996\n6.576176\n0.163819\n7.652703\n0.187222\n14.135268\n9.290896\n...\n0.351041\n0.702083\n0.234028\n1.591388\n0.795694\n0.959513\n1.427568\n3.931664\n17.294641\n0.023403\n\n\nCoriander Seeds/Powder\n1.755207\n0.000000\n2.410484\n5.125205\n4.914580\n0.257430\n4.306108\n0.468055\n16.264919\n4.352914\n...\n0.351041\n0.304236\n0.280833\n0.702083\n0.327639\n0.561666\n0.585069\n1.848818\n16.779780\n0.000000\n\n\nCumin Seeds/Powder\n2.153054\n0.000000\n3.276387\n13.269366\n5.874093\n1.193541\n5.195413\n0.351041\n21.553943\n6.669787\n...\n0.889305\n0.538264\n0.514861\n1.240346\n0.538264\n1.919026\n0.912708\n5.874093\n27.451439\n0.070208\n\n\nCurry Leaves\n0.608472\n0.000000\n0.444652\n12.543880\n1.006319\n0.117014\n1.170138\n0.046806\n8.635619\n2.036040\n...\n0.163819\n0.070208\n0.070208\n0.655277\n0.023403\n1.731804\n0.280833\n7.325064\n16.522350\n0.046806\n\n\nFennel Seed\n0.748888\n0.046806\n0.819097\n1.684999\n1.450971\n0.163819\n1.989235\n0.070208\n3.767845\n2.457290\n...\n0.702083\n0.257430\n0.093611\n0.912708\n0.421250\n0.374444\n0.748888\n0.819097\n4.212497\n0.000000\n\n\nFenugreek Leaf\n0.865902\n0.000000\n0.795694\n4.540136\n1.638193\n0.117014\n1.521179\n0.117014\n6.388954\n1.731804\n...\n0.702083\n0.023403\n0.163819\n0.374444\n0.070208\n0.889305\n0.257430\n3.229581\n8.705827\n0.000000\n\n\nFenugreek Seed\n0.140417\n0.000000\n0.468055\n3.159373\n0.351041\n0.070208\n0.374444\n0.070208\n2.363679\n0.608472\n...\n0.608472\n0.000000\n0.046806\n0.304236\n0.023403\n0.585069\n0.070208\n2.925345\n4.516733\n0.000000\n\n\nGaram Masala\n1.427568\n0.000000\n2.293471\n3.182776\n4.399719\n0.257430\n3.978469\n0.280833\n14.065060\n4.001872\n...\n0.327639\n0.140417\n0.304236\n0.631875\n0.491458\n0.421250\n0.444652\n0.491458\n13.245963\n0.000000\n\n\nGinger Powder\n0.210625\n0.023403\n0.046806\n0.444652\n0.351041\n0.046806\n0.842499\n0.023403\n0.585069\n0.491458\n...\n0.000000\n0.187222\n0.023403\n0.023403\n0.117014\n0.070208\n0.000000\n0.070208\n0.468055\n0.000000\n\n\nGreen Chillies\n1.802013\n0.000000\n1.591388\n7.605897\n4.610344\n0.280833\n3.955067\n0.210625\n12.216242\n4.844372\n...\n0.772291\n0.187222\n0.327639\n1.193541\n0.327639\n1.076527\n0.655277\n2.363679\n17.107419\n0.070208\n\n\nIndian Gooseberry\n0.046806\n0.000000\n0.000000\n0.304236\n0.000000\n0.023403\n0.000000\n0.023403\n0.163819\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.023403\n0.000000\n0.046806\n0.210625\n0.000000\n\n\nKalpasi\n0.023403\n0.000000\n0.000000\n0.023403\n0.023403\n0.000000\n0.070208\n0.000000\n0.023403\n0.070208\n...\n0.000000\n0.023403\n0.000000\n0.070208\n0.000000\n0.000000\n0.046806\n0.000000\n0.000000\n0.000000\n\n\nMace\n0.374444\n0.000000\n0.023403\n0.093611\n0.819097\n0.000000\n1.076527\n0.046806\n0.795694\n1.053124\n...\n0.000000\n0.491458\n0.023403\n0.257430\n0.140417\n0.000000\n0.304236\n0.000000\n0.889305\n0.000000\n\n\nMustard Seed\n0.748888\n0.000000\n0.865902\n12.707700\n1.146735\n0.070208\n0.725486\n0.023403\n8.027147\n1.591388\n...\n0.702083\n0.093611\n0.070208\n0.795694\n0.046806\n1.638193\n0.280833\n6.739995\n15.352212\n0.000000\n\n\nNigella Seed\n0.163819\n0.000000\n0.351041\n0.304236\n0.257430\n0.023403\n0.070208\n0.000000\n0.842499\n0.140417\n...\n1.661596\n0.000000\n0.023403\n0.163819\n0.023403\n0.070208\n0.023403\n0.070208\n1.263749\n0.023403\n\n\nNutmeg\n0.163819\n0.000000\n0.000000\n0.140417\n0.608472\n0.000000\n1.076527\n0.093611\n0.444652\n0.959513\n...\n0.000000\n1.521179\n0.000000\n0.304236\n0.234028\n0.070208\n0.280833\n0.046806\n0.561666\n0.000000\n\n\nPomegranate Seed\n0.093611\n0.000000\n0.140417\n0.093611\n0.117014\n0.093611\n0.234028\n0.000000\n0.468055\n0.187222\n...\n0.023403\n0.000000\n0.772291\n0.046806\n0.070208\n0.023403\n0.023403\n0.070208\n0.327639\n0.000000\n\n\nPoppy Seed\n0.234028\n0.000000\n0.023403\n0.538264\n0.748888\n0.000000\n1.474374\n0.000000\n1.380763\n1.404166\n...\n0.163819\n0.304236\n0.046806\n3.252984\n0.187222\n0.257430\n0.374444\n0.421250\n1.802013\n0.023403\n\n\nSaffron\n0.210625\n0.000000\n0.046806\n0.280833\n0.655277\n0.093611\n3.135970\n0.023403\n0.678680\n0.842499\n...\n0.023403\n0.234028\n0.070208\n0.187222\n4.025275\n0.070208\n0.140417\n0.000000\n0.585069\n0.000000\n\n\nSesame Seed\n0.397847\n0.000000\n0.257430\n1.567985\n0.163819\n0.023403\n0.351041\n0.000000\n1.591388\n0.234028\n...\n0.070208\n0.070208\n0.023403\n0.257430\n0.070208\n4.189094\n0.070208\n0.819097\n1.614791\n0.000000\n\n\nStar Anise\n0.234028\n0.000000\n0.046806\n0.257430\n1.099930\n0.023403\n1.287152\n0.023403\n0.819097\n1.380763\n...\n0.023403\n0.280833\n0.023403\n0.374444\n0.140417\n0.070208\n1.731804\n0.140417\n0.889305\n0.000000\n\n\nTamarind\n0.374444\n0.000000\n0.327639\n5.172010\n0.257430\n0.280833\n0.421250\n0.000000\n3.580623\n0.889305\n...\n0.070208\n0.046806\n0.070208\n0.421250\n0.000000\n0.819097\n0.140417\n11.958811\n7.208051\n0.000000\n\n\nTurmeric\n2.972151\n0.000000\n3.510414\n15.047976\n7.535689\n0.327639\n6.599579\n0.514861\n28.387550\n8.097355\n...\n1.263749\n0.561666\n0.327639\n1.802013\n0.585069\n1.614791\n0.889305\n7.208051\n48.467119\n0.046806\n\n\nWhite Pepper\n0.000000\n0.000000\n0.023403\n0.023403\n0.070208\n0.000000\n0.070208\n0.000000\n0.046806\n0.070208\n...\n0.023403\n0.000000\n0.000000\n0.023403\n0.000000\n0.000000\n0.000000\n0.000000\n0.046806\n0.163819\n\n\n\n\n34 rows × 34 columns\n\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nsns.heatmap(spice_adj_freq.round(2).corr(), ax=ax)\n#plt.savefig(\"heatmap.png\", format=\"PNG\", dpi=300)\n\n\n\n\n\n\n\n\nUsing frequency adjacency matrix we can plot a heatmap showing the pair-wise occurence for a given pair of spices. The idea with such an analysis is that if we can check the variation of Spice 1 with all the other spices in the list and compare that to Spice 2’s variation with all the other spices in the list, if spice 1 and spice 2 should have similar variation.\nThis map itself is quite interesting. The color intensity of each title shows the frequency that pair of spice occurred together in a recipe. Brighter the color higher their occurence together.\nSome prominent spice pairs which show similarity are:\n\nCurry leaves and Mustard seeds\nTumeric and Chilli Powder\n\nSome pair of spices never occur together:\n\nSaffron and Fenugreek seeds\nNutmeg and Mustard Seeds\n\nThose who cook or know indian recipes would see that these pairs make sense and thereby validate the correlation seen from corpus of Indian recipes.\nWith that analysis, we can go a step further and analyze this information in form of a circular network graph. Using this method of plotting, we can see the interactions between different spices.\n#hide spice_dict = {i : spice_adj_freq.loc[i, i] for i in spice_col_name } top_10_spices = list({k: v for k, v in sorted(spice_dict.items(), reverse=True, key=lambda item: item[1])}.keys())[:10] spice_adj_10 = spice_adj_freq.loc[top_10_spices, top_10_spices]\n#hide top_10_spices\n\n\n\nimport networkx as nx \n\n\nnodes_data = [(i, {'count':spice_adj_freq.loc[i, i]}) for i in temp_name]\n\n\n# most binary interactions \nbinary_int = []\nfor i in temp_name:\n    binary_int.append((i, spice_adj_freq.loc[i].sort_values(ascending=False).index[1]))\n\n\nspice_dict = {i : spice_adj_freq.loc[i, i] for i in temp_name }\n\n\nspice_dict\n\n{'Ajwain': 5.218815820266792,\n 'Alkanet Root': 0.07020828457758016,\n 'Amchoor': 4.984788205008191,\n 'Asafoetida': 24.596302363678916,\n 'Bay Leaf': 10.695062017318044,\n 'Black Salt': 1.6381933068102035,\n 'Cardamom': 17.78609875965364,\n 'Celery Seeds': 0.7956938918792418,\n 'Chilli Powder': 37.959279194945005,\n 'Cinnamon': 13.128949216007488,\n 'Cloves': 28.34074420781652,\n 'Coriander Seeds/Powder': 20.336999765972386,\n 'Cumin Seeds/Powder': 43.59934472267727,\n 'Curry Leaves': 27.615258600514856,\n 'Fennel Seed': 7.208050549964897,\n 'Fenugreek Leaf': 12.965129885326467,\n 'Fenugreek Seed': 7.208050549964897,\n 'Garam Masala': 18.34776503627428,\n 'Ginger Powder': 1.357360168499883,\n 'Green Chillies': 29.815118183945703,\n 'Indian Gooseberry': 0.3978469459396209,\n 'Kalpasi': 0.07020828457758016,\n 'Mace': 1.2403463608705827,\n 'Mustard Seed': 24.315469225368595,\n 'Nigella Seed': 1.6615960683360638,\n 'Nutmeg': 1.5211794991809033,\n 'Pomegranate Seed': 0.7722911303533817,\n 'Poppy Seed': 3.2529838520945473,\n 'Saffron': 4.025274982447929,\n 'Sesame Seed': 4.189094313128949,\n 'Star Anise': 1.7318043529136438,\n 'Tamarind': 11.958811139714488,\n 'Turmeric': 48.46711912005617,\n 'White Pepper': 0.16381933068102036}\n\n\n\nedges_data = [] \nfor i in temp_name:\n    for j in temp_name:\n        if i != j:\n            if spice_adj_freq.loc[i,j] != 0.0:\n                edges_data.append((i, j, {'weight':spice_adj_freq.loc[i,j], 'distance':1}))\n\n\n#G = nx.from_pandas_adjacency(spice_adj_freq)\n#BUILD THE INITIAL FULL GRAPH\nG=nx.Graph()\nG.add_nodes_from(nodes_data)\nG.add_edges_from(edges_data)\n\n\nprint(nx.info(G))\n\nName: \nType: Graph\nNumber of nodes: 34\nNumber of edges: 471\nAverage degree:  27.7059\n\n\n\ndeg_l = {i:G.degree(i) for i in temp_name} \n\n\nhighest_centrality_node = max(deg_l.items(), key=lambda x: x[1])[0]\n\n\nhighest_centrality_node\n\n'Asafoetida'\n\n\n\n#Adopted from: https://stackoverflow.com/questions/43894987/networkx-node-labels-relative-position\nn = len(nodes_data)\nedges = G.edges()\n\nweights = [G[u][v]['weight'] for u,v in edges]\nw_arr = np.array(weights)\nnorm_weight =  (w_arr - w_arr.min())/(w_arr.max() - w_arr.min())\n\n\nangle = []\nangle_dict = {}\nnode_list = sorted(G.nodes())\nfor i, node in zip(np.arange(n),node_list):\n    theta = 2.0*np.pi*i/n\n    angle.append((np.cos(theta),np.sin(theta)))\n    angle_dict[node] = theta\npos = {}\nfor node_i, node in enumerate(node_list):\n    pos[node] = angle[node_i]\n    \nfig, ax = plt.subplots(figsize=(20,20))\nmargin=0.33\nfig.subplots_adjust(margin, margin, 1.-margin, 1.-margin)\nax.axis('equal')\n\nnx.draw(G,pos=pos,with_labels=False, node_size=[spice_dict[k]*20 for k in spice_dict], width=norm_weight*2.0, node_color=np.arange(n), cmap=plt.cm.viridis, ax=ax)\ndescription = nx.draw_networkx_labels(G,pos)\n\nr = fig.canvas.get_renderer()\ntrans = plt.gca().transData.inverted()\nfor node, t in description.items():\n    bb = t.get_window_extent(renderer=r)\n    bbdata = bb.transformed(trans)\n    radius = 1.1+bbdata.width/2\n    position = (radius*np.cos(angle_dict[node]),radius* np.sin(angle_dict[node]))\n    t.set_position(position)\n    t.set_rotation(angle_dict[node]*360.0/(2.0*np.pi))\n    t.set_clip_on(False)\n    \n#plt.savefig(\"Graph.png\", format=\"PNG\", dpi=300)\n\n\n\n\n\n\n\n\nFinally a networkx circular graph is made where each node is a spice entry. Each edge between a pair of spice is a connection provided those two spices are found together in a recipe. The size of the node is the frequency of that spice to occur in all of 6000 food recipes. The thickness of the edge connecting a give spice-pair is the normalized frequency that pair occured among 6000 recipes.\nRepresenting the analysis this way we find few key takeaways: * Tumeric, Mustard Seeds, Chilli Powder, Corriander Seeds, Cumin Seeds, Curry Leaves, Green Chillies, Asafoetida are the key spices in the Indian cuisine.\n\nMost recipes use Tumeric + Chilli Powder + Cumin Powder (Seeds) in them."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Personal blogposts and explorations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nCategories\n\n\nReading Time\n\n\n\n\n\n\nFingerprints on fingertips\n\n\npython, chemical-science, data-analysis\n\n\n4 min\n\n\n\n\nWeb-scraping Hindi (Bollywood) movies from IMDb\n\n\n \n\n\n1 min\n\n\n\n\nClassifying reactions using machine-learning\n\n\npython, chemical-science, data-analysis\n\n\n3 min\n\n\n\n\nFingerprints\n\n\n \n\n\n2 min\n\n\n\n\nResources I Keep Coming Back To\n\n\nchemical-science, machine-learning, resources, AI\n\n\n5 min\n\n\n\n\nMedicine drug discovery resources\n\n\nchemical-science, machine-learning, resources\n\n\n92 min\n\n\n\n\nLarge Language Models\n\n\nchemical-science, machine-learning, resources, AI\n\n\n5 min\n\n\n\n\nAuto3D to make optimize tautomers and 3D conformers\n\n\n \n\n\n1 min\n\n\n\n\nCheminformatics basics - Clustering molecules\n\n\n \n\n\n1 min\n\n\n\n\nCheminformatics basics - Why the SMIRKS?\n\n\n \n\n\n4 min\n\n\n\n\nCheminformatics basics - A SMARTS way to filter molecules\n\n\n \n\n\n8 min\n\n\n\n\nOn machine learning model interpretability\n\n\nexploratory-data-analysis, machine-learning, resources, chemical-science\n\n\n2 min\n\n\n\n\nRdkit quick tips\n\n\nchemical-science, exploratory-data-analysis, machine-learning, resources\n\n\n6 min\n\n\n\n\nModel building checklist\n\n\nexploratory-data-analysis, machine-learning, resources, chemical-science\n\n\n3 min\n\n\n\n\nResources list\n\n\nexploratory-data-analysis, machine-learning, resources\n\n\n6 min\n\n\n\n\nPandas cookbook\n\n\nexploratory-data-analysis, machine-learning, resources\n\n\n7 min\n\n\n\n\nExploratory Data Analysis on Behavioral Risk Factor Surveillance System (BRFSS) dataset\n\n\n \n\n\n4 min\n\n\n\n\nMaterial-informatics Literature and Resources\n\n\nchemical-science, machine-learning, resources\n\n\n17 min\n\n\n\n\nCheminformatics basics - RDkit, regression models, similarity\n\n\n \n\n\n5 min\n\n\n\n\nMateiral informatics sample project\n\n\nchemical-science, python, machine-learning\n\n\n2 min\n\n\n\n\nMaking equal spaces parity plots using Matplotlib\n\n\n \n\n\n1 min\n\n\n\n\nAnamoly detection using autoencoders\n\n\n \n\n\n3 min\n\n\n\n\nImplement neural network from scratch for binary classification\n\n\npython, pytorch, machine-learning\n\n\n5 min\n\n\n\n\nt-SNE and UMAP - Effect of initialization on the dimensionality reduction\n\n\npython, data-visualization\n\n\n2 min\n\n\n\n\nBayesian optimisation implementation\n\n\n \n\n\n4 min\n\n\n\n\nEstimating prediction confidence through dropout\n\n\n \n\n\n3 min\n\n\n\n\nSolving the birthday problem using simple counting\n\n\n \n\n\n2 min\n\n\n\n\nCentral limit theorem\n\n\n \n\n\n4 min\n\n\n\n\nRelational analysis of spices used in Indian cuisine\n\n\n \n\n\n3 min\n\n\n\n\nNetwork analysis hands-on\n\n\n \n\n\n4 min\n\n\n\n\nTransfer learning walkthrough using Pytorch\n\n\n \n\n\n3 min\n\n\n\n\nGet SMILES from PubChem using DASK\n\n\n \n\n\n1 min\n\n\n\n\nAnalyze Bollywood movie ratings (1950-2020)\n\n\n \n\n\n2 min\n\n\n\n\nClassification-based algorithms walkthrough\n\n\n \n\n\n10 min\n\n\n\n\nS&P 500 analysis using beautifulsoup and pandas\n\n\n \n\n\n1 min\n\n\n\n\nPlotting surface in matplotlib\n\n\n \n\n\n2 min\n\n\n\n\nActivation functions\n\n\n \n\n\n2 min\n\n\n\n\nConvolutional neural network example\n\n\n \n\n\n3 min\n\n\n\n\nImplement Support Vector Machines in scikit-learn\n\n\n \n\n\n6 min\n\n\n\n\nAn Example Markdown Post\n\n\nmarkdown\n\n\n2 min\n\n\n\n\nVectorisation in python using numpy\n\n\n \n\n\n1 min\n\n\n\n\nLambda, Filter, and Map functions in Python\n\n\n \n\n\n1 min\n\n\n\n\nPrincipal component analysis\n\n\n \n\n\n7 min\n\n\n\n\nNeural network implementation in PyTorch\n\n\n \n\n\n1 min\n\n\n\n\nEnd-to-end Machine Learning Project\n\n\npython, exploratory-data-analysis, machine-learning\n\n\n17 min\n\n\n\n\n\nNo matching items"
  }
]