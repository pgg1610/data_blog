<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-05-01">
<meta name="description" content="Resources around LLM development and research">

<title>Omnis tempus datum - Large Language Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Omnis tempus datum</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pgg1610"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/mepgg"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Large Language Models</h1>
                  <div>
        <div class="description">
          Resources around LLM development and research
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">chemical-science</div>
                <div class="quarto-category">machine-learning</div>
                <div class="quarto-category">resources</div>
                <div class="quarto-category">AI</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 1, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#prompt-engineering" id="toc-prompt-engineering" class="nav-link active" data-scroll-target="#prompt-engineering">Prompt engineering</a></li>
  <li><a href="#chains" id="toc-chains" class="nav-link" data-scroll-target="#chains">Chains</a></li>
  <li><a href="#agents" id="toc-agents" class="nav-link" data-scroll-target="#agents">[[Agents]]</a>
  <ul class="collapse">
  <li><a href="#autogen-vs-semantic-kernel" id="toc-autogen-vs-semantic-kernel" class="nav-link" data-scroll-target="#autogen-vs-semantic-kernel">AutoGen vs Semantic Kernel :</a></li>
  </ul></li>
  <li><a href="#evaluations" id="toc-evaluations" class="nav-link" data-scroll-target="#evaluations">Evaluations</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">Training</a></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications">Applications</a>
  <ul class="collapse">
  <li><a href="#machine-translation" id="toc-machine-translation" class="nav-link" data-scroll-target="#machine-translation">Machine translation</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>How LLMs benefit modeling processes: 1. Low data modeling 2. Fewer (one model) to predict multiple end points across different modalities (sentiment, regression, classification, text completion) 3. Rich embeddings generated for unstructured data sets - useful for recommenders | similarity search 4. Quick prototyping - LLMs based workflow can increase the pace at which we code, search, train models</p>
<p>General areas:<br>
1) Predictive modeling 2) Automation and novel human-machine interaction 3) Knowledge extraction and translation 4) Education (lowering entry barrier) ## Applications ### Chemistry - [[Autonomous chemical research with large language models]] - <a href="https://arxiv.org/abs/2304.05376">Chemcrow</a> - [Is GPT-3 all you need?](https://chemrxiv.org/engage/chemrxiv/article-details/63eb5a669da0bc6b33e97a35](https://chemrxiv.org/engage/chemrxiv/article-details/63eb5a669da0bc6b33e97a35)<a href="https://www.nature.com/articles/s42256-023-00788-1">Nature Paper</a> - <a href="https://pubs.acs.org/doi/10.1021/acscatal.3c04956">Catalyst Property Prediction with CatBERTa: Unveiling Feature Exploration Strategies through Large Language Models</a> * <a href="https://github.com/qai222/LLM_organic_synthesis#extracting-structured-data-from-free-form-organic-synthesis-text">Chemistry reaction entity extraction</a> * [[Multi-modal molecule structure–text model for text-based retrieval and editing]] * <a href="https://arxiv.org/pdf/2404.01475.pdf">Are large language models superhuman chemists?</a></p>
<section id="prompt-engineering" class="level2">
<h2 class="anchored" data-anchor-id="prompt-engineering">Prompt engineering</h2>
<p>Prompt blog: <a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#external-apis">https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/#external-apis</a></p>
<p>Prompts are tiny programs <a href="https://twitter.com/balajis/status/1750086314928873865">Inspiration</a> &gt; Prompt engineering is a subset of software engineering</p>
<p>PromptBase : https://github.com/microsoft/promptbase &gt;&gt; Medicine related prompts</p>
<p>OpenAI Prompt Engineering : https://platform.openai.com/docs/guides/prompt-engineering/prompt-engineering</p>
</section>
<section id="chains" class="level2">
<h2 class="anchored" data-anchor-id="chains">Chains</h2>
<p>Pre-determined set of steps to undertake a task This is first step in creating a platform ### RAGs</p>
<p>RAG for LLMs - A Survey : https://arxiv.org/abs/2312.10997</p>
<p>Deconstructing RAG <a href="https://twitter.com/RLanceMartin/status/1727019896394207624">https://twitter.com/RLanceMartin/status/1727019896394207624</a></p>
<p>It can be hard to follow all of the RAG strategies that have come out over the past months.</p>
<p>I created a few guides to organize them into major themes and show how to build multi-modal / semi-structured RAG on complex docs (w/ images, tables).</p>
<p>Here’s a few of the major themes:</p>
<ol type="1">
<li><p>Query Transformations - User questions may not be well-posed / -worded for retrieval. There’s a host of methods that re-write and / or expand (fan-out into multiple sub-questions) questions that maximize the chance of retrieving relevant documents. See blog: <a href="https://blog.langchain.dev/query-transformations/">https://blog.langchain.dev/query-transformations/</a></p></li>
<li><p>Routing - Queries may need to be routed to different data sources depending on what is being asked. Recent blog reviewing OpenAI’s RAG strategies provides some guidance on question routing: <a href="https://blog.langchain.dev/applying-openai-rag/">https://blog.langchain.dev/applying-openai-rag/</a></p></li>
<li><p>Query Construction - To access structured data, natural language needs to be converted into specific a query syntax. Various approaches can access data in SQL, SQL w/ semantic columns (pgvector), graph DBs, vectorDB w/ metadata filters, etc. See blog: <a href="https://blog.langchain.dev/query-construction/">https://blog.langchain.dev/query-construction/</a></p></li>
<li><p>Index Building - One of the most useful tricks I’ve been using is multi-representation indexing: decouple what you index for retrieval (e.g., table or image summary) from what you pass to the llm for answer synthesis (e.g., the raw image, a table). See blog:</p></li>
</ol>
<p><a href="https://blog.langchain.dev/semi-structured-multi-modal-rag/">https://blog.langchain.dev/semi-structured-multi-modal-rag/</a></p>
<p>4a. Multi-Modal -</p>
<p>This cookbook show how I used this approach for RAG on a substack (</p>
<p><span class="citation" data-cites="jaminball">@jaminball</span></p>
<p>’s Clouded Judgement) that has many images of densely packed tables, graphs:</p>
<p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Multi_modal_RAG.ipynb">https://github.com/langchain-ai/langchain/blob/master/cookbook/Multi_modal_RAG.ipynb</a></p>
<p>4b. Semi-Structured -</p>
<p>This cookbook show how I used this for RAG on a docs (papers) with tables, which can be split using naive RAG text-splitting (that does not explicitly preserve them):</p>
<p><a href="https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb">https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb</a></p>
<ol start="5" type="1">
<li>Post-processing - Given retrieved documents, there are various way to rank / filter them. Recent blog reviewing OpenAI’s RAG strategies provides a few ideas on applying post-processing: <a href="https://blog.langchain.dev/applying-openai-rag/">https://blog.langchain.dev/applying-openai-rag/</a></li>
</ol>
<p>Self-querying to work with meta data in the document chunks :<a href="https://python.langchain.com/docs/modules/data_connection/retrievers/self_query">https://python.langchain.com/docs/modules/data_connection/retrievers/self_query</a></p>
<p>Knowledge graph data : <a href="https://www.youtube.com/watch?v=nPG_jKrSpi0&amp;t=11s">https://www.youtube.com/watch?v=nPG_jKrSpi0&amp;t=11s</a></p>
<p>OpenAI recipe for graphDB implementation : https://github.com/openai/openai-cookbook/blob/main/examples/RAG_with_graph_db.ipynb</p>
</section>
<section id="agents" class="level2">
<h2 class="anchored" data-anchor-id="agents">[[Agents]]</h2>
<p>Hitchhiker’s Guide from Chain-of-Thought reasoning to Language Agents: https://arxiv.org/pdf/2311.11797.pdf</p>
<p>Non-structured ways to do task by giving central model access to tools - Different orchestration platforms : 1) https://github.com/guidance-ai/guidance 2) Semantic kernel 3) Langchain 4) Autogen</p>
<p>Medium open solution from. companies : crew.ai</p>
<p>Agent on MineCraft : Voyager / MineDojo</p>
<p>Agents with API : Gorilla</p>
<p>AutoGen with Semantic Kernel : https://github.com/microsoft/semantic-kernel/blob/sk-autogen/python/notebooks/12-sk-autogen-agents.ipynb</p>
<section id="autogen-vs-semantic-kernel" class="level3">
<h3 class="anchored" data-anchor-id="autogen-vs-semantic-kernel">AutoGen vs Semantic Kernel :</h3>
<p>Autogen is a framework for letting multiple agents collaborate with each other to complete a request. Semantic Kernel, on the other hand, is an SDK that helps you give a single agent a set of tools (via plugins). Because of this, we believe both projects complement each other. To make a team of agents in Autogen productive, you’ll ultimately want to give them plugins so they can complete real work. This is when you’d want to use the two projects together.</p>
<p>Put more simply…<br>
– Need agents to collaborate with each other? Use agents.<br>
– Need agents to do work with tools (i.e., plugins)? Use Semantic Kernel.<br>
– Need agents to collaborate with each other with tools? Use both!</p>
<p><strong>How does LLM use the function/tool ?</strong></p>
<p>We pass the parameters in term of json or protobuf with function name, description, params</p>
<p>The LLM doesnt call the function for us - it JUST tells us with the known information what would be the function we NEED to call Not every time we would get a json output so we need safeguards for it.</p>
<p><code>functions</code> and <code>function_calls</code> are accounted in the tokens</p>
<p>Gorilla : <a href="https://gorilla.cs.berkeley.edu/" title="https://gorilla.cs.berkeley.edu/">https://gorilla.cs.berkeley.edu/</a></p>
<p>Solutions from external companies : https://www.lindy.ai/ crew.ai</p>
<p>LLM powered autonomous agents :</p>
<p><a href="https://lilianweng.github.io/posts/2023-06-23-agent/?utm_source=pocket_saves">https://lilianweng.github.io/posts/2023-06-23-agent/?utm_source=pocket_saves</a></p>
<p><a href="https://peterroelants.github.io/posts/react-repl-agent/">https://peterroelants.github.io/posts/react-repl-agent/</a></p>
<p>Python REPL agent:<a href="https://python.langchain.com/docs/integrations/toolkits/python">https://python.langchain.com/docs/integrations/toolkits/python</a></p>
<p>Robust MRKL:<br>
<a href="https://github.com/whitead/robust-mrkl/tree/main">https://github.com/whitead/robust-mrkl/tree/main</a></p>
<p>Microsoft Autogen : https://github.com/microsoft/semantic-kernel/blob/sk-autogen/python/notebooks/12-sk-autogen-agents.ipynb https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat/#diverse-applications-implemented-with-autogen</p>
<p>OpenAI’s Assistant API vs Langchain Agent : https://blog.langchain.dev/openais-bet-on-a-cognitive-architecture/</p>
</section>
</section>
<section id="evaluations" class="level2">
<h2 class="anchored" data-anchor-id="evaluations">Evaluations</h2>
<ol type="1">
<li>Regas</li>
<li>PromptFlow</li>
</ol>
<p>Andrej Karpathy : https://nicholas.carlini.com/writing/2024/my-benchmark-for-large-language-models.html</p>
</section>
<section id="training" class="level2">
<h2 class="anchored" data-anchor-id="training">Training</h2>
<ol type="1">
<li>[[DPO]]</li>
</ol>
</section>
<section id="applications" class="level1">
<h1>Applications</h1>
<p>LLM Chatbot to converse and answer domain specific questions (think of NPA-space) by providing library and digest the literature</p>
<p>LLM prediction benchmarking with other model we have in-house How can we more 10x more or 10x better?</p>
<blockquote class="blockquote">
<blockquote class="blockquote">
<p>Knowledge base for conversing in domain-specific fashion for latest information</p>
</blockquote>
</blockquote>
<section id="machine-translation" class="level3">
<h3 class="anchored" data-anchor-id="machine-translation">Machine translation</h3>
<blockquote class="blockquote">
<blockquote class="blockquote">
<p>NLP substructure queries —&gt; Protobuf substructure script —&gt; Search in the dataset</p>
</blockquote>
</blockquote>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>